{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8fe09351-cceb-4aa6-8db9-48802f3ce056",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "35914ec1-29d8-4332-9cb3-80933392ac21",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "import sparknlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ce5ce712-f79e-420a-9bcb-93d591feb08f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning::Spark Session already created, some configs may not take.\n"
     ]
    }
   ],
   "source": [
    "spark = sparknlp.start()\n",
    "csv_path = 'data/all_data.csv'\n",
    "indeed_ads_pd = pd.read_csv(csv_path)\n",
    "indeed_ads = spark.createDataFrame(indeed_ads_pd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "849bd72a-fd2d-4118-a42d-a1cadfea66a3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aea5a0c9-4fbe-4fcf-8b65-a757efc15288",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# spark and basic imports\n",
    "from pyspark.sql.functions import col, udf, regexp_extract, explode, lower, length, trim, when, regexp_replace\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "79459d5e-5c94-4590-95f8-3786941a20dd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Reduction of Records and Texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4820ea79-e06b-4352-bec6-af9c7514cadc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'Total': 3635, 'Error': 2730, 'Null': 246}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exploring \"Full Job Description\" column for irrelevant records\n",
    "total_count = indeed_ads.count()\n",
    "error_count = indeed_ads.filter(indeed_ads[\"Full Job Description\"] == \"Error\").count()\n",
    "null_count = indeed_ads.filter(indeed_ads[\"Full Job Description\"].isNull()).count()\n",
    "{\"Total\": total_count, \"Error\": error_count, \"Null\": null_count}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d37ca239-cb3c-48b5-bd59-42a7f127ab96",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "659\n"
     ]
    }
   ],
   "source": [
    "# Keep only records with relevant text in 'Full Job Description' column\n",
    "filtered_indeed_ads = indeed_ads.filter((indeed_ads[\"Full Job Description\"].isNotNull()) & (indeed_ads[\"Full Job Description\"] != \"Error\")).select(\"Title\", \"Company\", \"Full Job Description\", \"Search Word\")\n",
    "print(filtered_indeed_ads.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "acdde7d9-ad26-4efd-ba7c-fa7826ba743c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Removal of urls from descriptions\n",
    "opened_url_pattern = r\"Opened URL.*\"\n",
    "general_url_pattern = r\"http\\S+|www\\S+\"\n",
    "\n",
    "filtered_indeed_ads = filtered_indeed_ads.withColumn(\"Description\",\n",
    "    when(col(\"Full Job Description\").contains(\"Opened URL\"),\n",
    "         trim(regexp_replace(col(\"Full Job Description\"), opened_url_pattern, \"\")))\n",
    "    .otherwise(col(\"Full Job Description\"))\n",
    ")\n",
    "\n",
    "filtered_indeed_ads = filtered_indeed_ads.withColumn(\"Description\",\n",
    "    regexp_replace(col(\"Description\"), general_url_pattern, \"\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d810fcc5-0866-49d2-80db-aeb397eff797",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Dealing with Hebrew\n",
    "Explore Hebrew descriptions, extract relevant English words and translate if neccesary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "161119ef-48a6-4467-9813-db979d6f300b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting deep-translator\n  Obtaining dependency information for deep-translator from https://files.pythonhosted.org/packages/38/3f/61a8ef73236dbea83a1a063a8af2f8e1e41a0df64f122233938391d0f175/deep_translator-1.11.4-py3-none-any.whl.metadata\n  Downloading deep_translator-1.11.4-py3-none-any.whl.metadata (30 kB)\nRequirement already satisfied: beautifulsoup4<5.0.0,>=4.9.1 in /databricks/python3/lib/python3.11/site-packages (from deep-translator) (4.12.2)\nRequirement already satisfied: requests<3.0.0,>=2.23.0 in /databricks/python3/lib/python3.11/site-packages (from deep-translator) (2.31.0)\nRequirement already satisfied: soupsieve>1.2 in /databricks/python3/lib/python3.11/site-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep-translator) (2.4)\nRequirement already satisfied: charset-normalizer<4,>=2 in /databricks/python3/lib/python3.11/site-packages (from requests<3.0.0,>=2.23.0->deep-translator) (2.0.4)\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.11/site-packages (from requests<3.0.0,>=2.23.0->deep-translator) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /databricks/python3/lib/python3.11/site-packages (from requests<3.0.0,>=2.23.0->deep-translator) (1.26.16)\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.11/site-packages (from requests<3.0.0,>=2.23.0->deep-translator) (2023.7.22)\nDownloading deep_translator-1.11.4-py3-none-any.whl (42 kB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/42.3 kB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m42.3/42.3 kB\u001B[0m \u001B[31m2.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hInstalling collected packages: deep-translator\nSuccessfully installed deep-translator-1.11.4\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "pip install deep-translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b47f9dcd-ab33-4790-a22d-60faad3762e6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Title</th><th>Company</th><th>Full Job Description</th><th>Search Word</th><th>Description</th><th>Description_English</th></tr></thead><tbody><tr><td>Data Analytics</td><td>Apple</td><td>Summary Posted: Nov 7, 2024 Role Number: 200577967 We're looking for an exceptional data analyst with a strong background in distributed data processing and a demonstrated ability to turn data into actionable insights. As a data analyst for our Storage Data Analytics team at Apple, you'll play a crucial role in developing the fastest and most efficient SSDs for our products, including the iPhone, iPad, Apple Watch, and new Apple Silicon Macs. If you're passionate about continuously improving the ways we use data to make Apple's products amazing, we want to hear from you! Description On the Storage Data Analytics team, we are responsible for performing ad hoc data analysis, development and maintenance of distributed data pipelines, as well as creation and support of analysis tools. Our team focuses on Apple’s storage solutions. It is small and nimble, able to quickly explore ideas and present them to the storage teams and to leadership. Minimum Qualifications +3 years of experience Ability to lead data investigations and analysis projects with ambiguous requirements Advanced statistic and modeling knowledge Experience visualizing and presenting analyses in tools like Jupyter and Tableau Experience programming in Python in a professional setting Familiarity with distributed computation, storage, and workflow management (e.g. Splunk, Spark, Kubernetes, Kafka, Hadoop, MapReduce, AirFlow etc.) Experience with relational databases and SQL Highly organized, creative, motivated, and passionate about achieving results Curious and have excellent analytical and problem solving skills Excellent written, verbal, and data communication skills Bachelor's or Master's degree in computer science. Preferred Qualifications Familiarity with distributed computation, storage, and workflow management (e.g. Splunk, Spark, Kubernetes, Kafka, Hadoop, MapReduce, AirFlow etc.) Opened URL: https://il.indeed.com/rc/clk?jk=0433bc7e45e694a3&bb=r6UIYw2mow7Pn8IzQwq2_7gXyX4L0a9oUPOLDIseoxAN8l0MRFFfCqpU6vSJRCmVlzxZCXcY6V-lzbB66NkEzDukGjQJgUJrBPff0HR1apFcJos6F0MbonwvLMjHhNz9&xkcb=SoDD67M33wH7H8WWaB0JbzkdCdPP&fccid=8e007f7a76f9cee5&vjs=3</td><td>data</td><td>Summary Posted: Nov 7, 2024 Role Number: 200577967 We're looking for an exceptional data analyst with a strong background in distributed data processing and a demonstrated ability to turn data into actionable insights. As a data analyst for our Storage Data Analytics team at Apple, you'll play a crucial role in developing the fastest and most efficient SSDs for our products, including the iPhone, iPad, Apple Watch, and new Apple Silicon Macs. If you're passionate about continuously improving the ways we use data to make Apple's products amazing, we want to hear from you! Description On the Storage Data Analytics team, we are responsible for performing ad hoc data analysis, development and maintenance of distributed data pipelines, as well as creation and support of analysis tools. Our team focuses on Apple’s storage solutions. It is small and nimble, able to quickly explore ideas and present them to the storage teams and to leadership. Minimum Qualifications +3 years of experience Ability to lead data investigations and analysis projects with ambiguous requirements Advanced statistic and modeling knowledge Experience visualizing and presenting analyses in tools like Jupyter and Tableau Experience programming in Python in a professional setting Familiarity with distributed computation, storage, and workflow management (e.g. Splunk, Spark, Kubernetes, Kafka, Hadoop, MapReduce, AirFlow etc.) Experience with relational databases and SQL Highly organized, creative, motivated, and passionate about achieving results Curious and have excellent analytical and problem solving skills Excellent written, verbal, and data communication skills Bachelor's or Master's degree in computer science. Preferred Qualifications Familiarity with distributed computation, storage, and workflow management (e.g. Splunk, Spark, Kubernetes, Kafka, Hadoop, MapReduce, AirFlow etc.)</td><td>Summary Posted: Nov 7, 2024 Role Number: 200577967 We're looking for an exceptional data analyst with a strong background in distributed data processing and a demonstrated ability to turn data into actionable insights. As a data analyst for our Storage Data Analytics team at Apple, you'll play a crucial role in developing the fastest and most efficient SSDs for our products, including the iPhone, iPad, Apple Watch, and new Apple Silicon Macs. If you're passionate about continuously improving the ways we use data to make Apple's products amazing, we want to hear from you! Description On the Storage Data Analytics team, we are responsible for performing ad hoc data analysis, development and maintenance of distributed data pipelines, as well as creation and support of analysis tools. Our team focuses on Apple’s storage solutions. It is small and nimble, able to quickly explore ideas and present them to the storage teams and to leadership. Minimum Qualifications +3 years of experience Ability to lead data investigations and analysis projects with ambiguous requirements Advanced statistic and modeling knowledge Experience visualizing and presenting analyses in tools like Jupyter and Tableau Experience programming in Python in a professional setting Familiarity with distributed computation, storage, and workflow management (e.g. Splunk, Spark, Kubernetes, Kafka, Hadoop, MapReduce, AirFlow etc.) Experience with relational databases and SQL Highly organized, creative, motivated, and passionate about achieving results Curious and have excellent analytical and problem solving skills Excellent written, verbal, and data communication skills Bachelor's or Master's degree in computer science. Preferred Qualifications Familiarity with distributed computation, storage, and workflow management (e.g. Splunk, Spark, Kubernetes, Kafka, Hadoop, MapReduce, AirFlow etc.)</td></tr><tr><td>Junior Backend Big Data Developer</td><td>ThetaRay</td><td>Israel, Hod HaSharon Description About ThetaRay: ThetaRay is a trailblazer in AI-powered Anti-Money Laundering (AML) solutions, offering cutting-edge technology to fintechs, banks, and regulatory bodies worldwide. Our mission is to enhance trust in financial transactions, ensuring compliant and innovative business growth. Our technology empowers customers to expand into new markets and introduce groundbreaking products. Thetaray is a culture-driven company. Our values are at the heart of our success. By joining us, you'll have the opportunity to embody these values and inspire others through your actions. Why Join ThetaRay? At ThetaRay, you'll be part of a dynamic global team committed to redefining the financial services sector through technological innovation. You will contribute to creating safer financial environments and have the opportunity to work with some of the brightest minds in AI, ML, and financial technology. We offer a collaborative, inclusive, and forward-thinking work environment where your ideas and contributions are valued and encouraged. Join us in our mission to revolutionize the financial world, making it safer and more trustworthy for millions worldwide. Explore exciting career opportunities at ThetaRay – where innovation meets purpose. We are seeking a skilled Junior Backend Big Data Developer to join our global R&D department. About the position Design and develop a scalable data processing and ML pipeline using the latest big data technologies in a fast paced agile environment Investigate new technological areas and understand them in depth through rapid self-learning Demonstrates strong analytical problem-solving skills to support scalable and sustainable design solutions Ability to take ownership of product development including all life cycle stages: translating product requirements into actionable designs and tasks, development, UT, and production troubleshooting Requirements 1-2 years of experience of hands-on development experience Experience developing data-oriented products preferably using Python/Java Experience in data processing FW such as Spark, Pandas, Hadoop, Airflow Experience in Distributed Databases (Such as Elasticsearch, Mongo, Redis, etc) Experience with developing microservices-based architecture Experience working in container-based environments using tools such as K8s, helm Experience working as a software developer in an Agile environment Nice to have: Experience in machine learning FWs such as SKLearn, Tensorflow Experience with RedHat OpenShift Dev Environment knowledge: GIT, Jenkins, Docker Opened URL: https://il.indeed.com/rc/clk?jk=f8a4240257a1f2ce&bb=r6UIYw2mow7Pn8IzQwq2_-W1QCjSWXjTolCGGPP6r1hrgYR_04g-rduMaSln8QXPTKg72oJi8A05b61aBYrHRJnGe_P_Fe_A6kxMxp1ZSL-qNeOaC0lT-K0Lac-PNtP0&xkcb=SoB367M33wH7H8WWaB0IbzkdCdPP&fccid=69237999e36cf5e9&vjs=3</td><td>data</td><td>Israel, Hod HaSharon Description About ThetaRay: ThetaRay is a trailblazer in AI-powered Anti-Money Laundering (AML) solutions, offering cutting-edge technology to fintechs, banks, and regulatory bodies worldwide. Our mission is to enhance trust in financial transactions, ensuring compliant and innovative business growth. Our technology empowers customers to expand into new markets and introduce groundbreaking products. Thetaray is a culture-driven company. Our values are at the heart of our success. By joining us, you'll have the opportunity to embody these values and inspire others through your actions. Why Join ThetaRay? At ThetaRay, you'll be part of a dynamic global team committed to redefining the financial services sector through technological innovation. You will contribute to creating safer financial environments and have the opportunity to work with some of the brightest minds in AI, ML, and financial technology. We offer a collaborative, inclusive, and forward-thinking work environment where your ideas and contributions are valued and encouraged. Join us in our mission to revolutionize the financial world, making it safer and more trustworthy for millions worldwide. Explore exciting career opportunities at ThetaRay – where innovation meets purpose. We are seeking a skilled Junior Backend Big Data Developer to join our global R&D department. About the position Design and develop a scalable data processing and ML pipeline using the latest big data technologies in a fast paced agile environment Investigate new technological areas and understand them in depth through rapid self-learning Demonstrates strong analytical problem-solving skills to support scalable and sustainable design solutions Ability to take ownership of product development including all life cycle stages: translating product requirements into actionable designs and tasks, development, UT, and production troubleshooting Requirements 1-2 years of experience of hands-on development experience Experience developing data-oriented products preferably using Python/Java Experience in data processing FW such as Spark, Pandas, Hadoop, Airflow Experience in Distributed Databases (Such as Elasticsearch, Mongo, Redis, etc) Experience with developing microservices-based architecture Experience working in container-based environments using tools such as K8s, helm Experience working as a software developer in an Agile environment Nice to have: Experience in machine learning FWs such as SKLearn, Tensorflow Experience with RedHat OpenShift Dev Environment knowledge: GIT, Jenkins, Docker</td><td>Israel, Hod HaSharon Description About ThetaRay: ThetaRay is a trailblazer in AI-powered Anti-Money Laundering (AML) solutions, offering cutting-edge technology to fintechs, banks, and regulatory bodies worldwide. Our mission is to enhance trust in financial transactions, ensuring compliant and innovative business growth. Our technology empowers customers to expand into new markets and introduce groundbreaking products. Thetaray is a culture-driven company. Our values are at the heart of our success. By joining us, you'll have the opportunity to embody these values and inspire others through your actions. Why Join ThetaRay? At ThetaRay, you'll be part of a dynamic global team committed to redefining the financial services sector through technological innovation. You will contribute to creating safer financial environments and have the opportunity to work with some of the brightest minds in AI, ML, and financial technology. We offer a collaborative, inclusive, and forward-thinking work environment where your ideas and contributions are valued and encouraged. Join us in our mission to revolutionize the financial world, making it safer and more trustworthy for millions worldwide. Explore exciting career opportunities at ThetaRay – where innovation meets purpose. We are seeking a skilled Junior Backend Big Data Developer to join our global R&D department. About the position Design and develop a scalable data processing and ML pipeline using the latest big data technologies in a fast paced agile environment Investigate new technological areas and understand them in depth through rapid self-learning Demonstrates strong analytical problem-solving skills to support scalable and sustainable design solutions Ability to take ownership of product development including all life cycle stages: translating product requirements into actionable designs and tasks, development, UT, and production troubleshooting Requirements 1-2 years of experience of hands-on development experience Experience developing data-oriented products preferably using Python/Java Experience in data processing FW such as Spark, Pandas, Hadoop, Airflow Experience in Distributed Databases (Such as Elasticsearch, Mongo, Redis, etc) Experience with developing microservices-based architecture Experience working in container-based environments using tools such as K8s, helm Experience working as a software developer in an Agile environment Nice to have: Experience in machine learning FWs such as SKLearn, Tensorflow Experience with RedHat OpenShift Dev Environment knowledge: GIT, Jenkins, Docker</td></tr><tr><td>Data Annotator</td><td>Prisma Photonics</td><td>Description: Prisma-Photonics is a rapidly growing startup company, developing the next-generation smart-infrastructure solution based on novel fiber-sensing technology (smart roads, smart cities, perimeters, grid monitoring, etc.). The company offers an award-winning disruptive solution – a “sensor free” approach to smart infrastructure. The company is VC backed and is in the revenues stage. Combining pioneering technology in optical fiber sensing with state-of-the-art machine learning, we help prevent environmental disasters, protect human lives, and keep critical energy and transportation backbones running smoothly. We are rapidly growing, looking for the best minds and spirits to join us in our journey. We know our products are only as great as the individuals building the hardware and software and harnessing data for good causes! Being a great team member means being eager to learn and grow, able to challenge others while accepting being challenged yourself, and working for the team and product with enthusiasm and passion. We are seeking a detail-oriented and highly technical Data Annotator to join our Data Operations team. The role is full time, on an hourly pay, with the aim of adjusting work hours per need. In this role, you will be responsible for annotating various events on our distinct fiber sensing data, and managing datasets to support various products and projects. You will play a crucial part in ensuring the quality and integrity of our data, contributing to multiple critical initiatives. You will help improve our annotation procedures, techniques and tooling, and work closely with ML and Algo teams as well as Data Engineering. This is a unique opportunity to gain hands-on experience in data operations within a dynamic environment using cutting edge and novel technology. You will join a talented team dedicated to leveraging data for impactful projects. If you are passionate about data and eager to contribute to exciting challenges, this might be the perfect opportunity for you. Key Responsibilities: Data Annotation – Accurately annotate datasets using internal tools, adhering to annotation guidelines and maintaining high standards for consistency and quality.. Quality Assurance – Review and validate annotated data to ensure accuracy and consistency, identify discrepancies, and suggest solutions to improve processes. Continuous improvement – Participate in the continuous improvement of our tools and data operation processes to achieve more accurate models, and more streamlined data flow between the different teams in the company. Data Management – Support the ongoing maintenance of annotated datasets, ensuring data integrity and accessibility, and implementing best-practices to create seamless data flows Requirements: A Bachelor of Science degree or equivalent (STEM fields an advantage). Strong attention to detail and a commitment to maintaining high-quality annotation standards. Good written and verbal skills, with the ability to work effectively with a diverse group of individuals. Availability to work full time when needed. Nice-to-haves: Familiarity with data annotation processes, especially non-structured data (images, video, audio). Experience working with seismic data, heat maps, or spectrograms Familiarity with SQL and data visualization tools. Experience with coding languages, preferably MATLAB and Python. Opened URL: https://il.indeed.com/rc/clk?jk=bc34db8ca4455a09&bb=r6UIYw2mow7Pn8IzQwq2_2KWxyEGo0k-OJpOJwwWN8Jm7Ix9rFlIZvMB9V3E68_9Tw5jXdxlGcRgdwn8R5bozu_4HSOWEd50RAMDfMKBbPpkx12msEPjULZyxC-ZVeo-&xkcb=SoD567M33wH7H8WWaB0PbzkdCdPP&fccid=fa9a43168015ecb7&vjs=3</td><td>data</td><td>Description: Prisma-Photonics is a rapidly growing startup company, developing the next-generation smart-infrastructure solution based on novel fiber-sensing technology (smart roads, smart cities, perimeters, grid monitoring, etc.). The company offers an award-winning disruptive solution – a “sensor free” approach to smart infrastructure. The company is VC backed and is in the revenues stage. Combining pioneering technology in optical fiber sensing with state-of-the-art machine learning, we help prevent environmental disasters, protect human lives, and keep critical energy and transportation backbones running smoothly. We are rapidly growing, looking for the best minds and spirits to join us in our journey. We know our products are only as great as the individuals building the hardware and software and harnessing data for good causes! Being a great team member means being eager to learn and grow, able to challenge others while accepting being challenged yourself, and working for the team and product with enthusiasm and passion. We are seeking a detail-oriented and highly technical Data Annotator to join our Data Operations team. The role is full time, on an hourly pay, with the aim of adjusting work hours per need. In this role, you will be responsible for annotating various events on our distinct fiber sensing data, and managing datasets to support various products and projects. You will play a crucial part in ensuring the quality and integrity of our data, contributing to multiple critical initiatives. You will help improve our annotation procedures, techniques and tooling, and work closely with ML and Algo teams as well as Data Engineering. This is a unique opportunity to gain hands-on experience in data operations within a dynamic environment using cutting edge and novel technology. You will join a talented team dedicated to leveraging data for impactful projects. If you are passionate about data and eager to contribute to exciting challenges, this might be the perfect opportunity for you. Key Responsibilities: Data Annotation – Accurately annotate datasets using internal tools, adhering to annotation guidelines and maintaining high standards for consistency and quality.. Quality Assurance – Review and validate annotated data to ensure accuracy and consistency, identify discrepancies, and suggest solutions to improve processes. Continuous improvement – Participate in the continuous improvement of our tools and data operation processes to achieve more accurate models, and more streamlined data flow between the different teams in the company. Data Management – Support the ongoing maintenance of annotated datasets, ensuring data integrity and accessibility, and implementing best-practices to create seamless data flows Requirements: A Bachelor of Science degree or equivalent (STEM fields an advantage). Strong attention to detail and a commitment to maintaining high-quality annotation standards. Good written and verbal skills, with the ability to work effectively with a diverse group of individuals. Availability to work full time when needed. Nice-to-haves: Familiarity with data annotation processes, especially non-structured data (images, video, audio). Experience working with seismic data, heat maps, or spectrograms Familiarity with SQL and data visualization tools. Experience with coding languages, preferably MATLAB and Python.</td><td>Description: Prisma-Photonics is a rapidly growing startup company, developing the next-generation smart-infrastructure solution based on novel fiber-sensing technology (smart roads, smart cities, perimeters, grid monitoring, etc.). The company offers an award-winning disruptive solution – a “sensor free” approach to smart infrastructure. The company is VC backed and is in the revenues stage. Combining pioneering technology in optical fiber sensing with state-of-the-art machine learning, we help prevent environmental disasters, protect human lives, and keep critical energy and transportation backbones running smoothly. We are rapidly growing, looking for the best minds and spirits to join us in our journey. We know our products are only as great as the individuals building the hardware and software and harnessing data for good causes! Being a great team member means being eager to learn and grow, able to challenge others while accepting being challenged yourself, and working for the team and product with enthusiasm and passion. We are seeking a detail-oriented and highly technical Data Annotator to join our Data Operations team. The role is full time, on an hourly pay, with the aim of adjusting work hours per need. In this role, you will be responsible for annotating various events on our distinct fiber sensing data, and managing datasets to support various products and projects. You will play a crucial part in ensuring the quality and integrity of our data, contributing to multiple critical initiatives. You will help improve our annotation procedures, techniques and tooling, and work closely with ML and Algo teams as well as Data Engineering. This is a unique opportunity to gain hands-on experience in data operations within a dynamic environment using cutting edge and novel technology. You will join a talented team dedicated to leveraging data for impactful projects. If you are passionate about data and eager to contribute to exciting challenges, this might be the perfect opportunity for you. Key Responsibilities: Data Annotation – Accurately annotate datasets using internal tools, adhering to annotation guidelines and maintaining high standards for consistency and quality.. Quality Assurance – Review and validate annotated data to ensure accuracy and consistency, identify discrepancies, and suggest solutions to improve processes. Continuous improvement – Participate in the continuous improvement of our tools and data operation processes to achieve more accurate models, and more streamlined data flow between the different teams in the company. Data Management – Support the ongoing maintenance of annotated datasets, ensuring data integrity and accessibility, and implementing best-practices to create seamless data flows Requirements: A Bachelor of Science degree or equivalent (STEM fields an advantage). Strong attention to detail and a commitment to maintaining high-quality annotation standards. Good written and verbal skills, with the ability to work effectively with a diverse group of individuals. Availability to work full time when needed. Nice-to-haves: Familiarity with data annotation processes, especially non-structured data (images, video, audio). Experience working with seismic data, heat maps, or spectrograms Familiarity with SQL and data visualization tools. Experience with coding languages, preferably MATLAB and Python.</td></tr><tr><td>Marketing Data Analyst</td><td>Plarium</td><td>The Business Performance department at Plarium is in charge of all the analytical aspects of our game operations and strategic planning: From game design, to user acquisition, player behavior, live-ops, and game optimization (such as monetization, retention, etc). We are looking for a data analyst for our Marketing Analytics team. The scope of responsibility of this team includes budget optimization for user acquisition for our games at the scope of tens of million dollars per game, analyses of game profitability and long term potential, analysis of the players behavior, player game funnel and reaction to new game features and offers, and a lot more. Our goal is making sure Plarium brings the best and most relevant players to its games in the most efficient and effective way. Responsibilities Be a focal point for anything related to new players performance and KPIs across our range of games, strategic planning, user segmentation, tests and growth opportunities identification Daily support of ongoing analytical needs of the marketing department managers & teams Establish and monitor success metrics that measure and explain the impact of the marketing activities Design and initiate new features and reports to monitor & give insights on the marketing activity, using the marketing in-house BI system (for example, LTV, ROI forecasting, automatic rules) Run ad-hoc and in-depth analyses of the different Marketing activities and trends Support decision making based on data Collaborate with the game analysis team and the game studios to monitor and optimize our players experience, maximizing their retention in our games What we expect B.A/BSc in a highly quantitative field such as mathematics industrial engineering economics statistics or equivalent academic knowledge At least 2 years of hands-on data analysis and story-telling experience Proven experience with measuring online success and identifying optimization opportunities Excellent understanding of online marketing metrics High proficiency in SQL with demonstrated experience in querying large complex datasets Strong Excel / Google Sheets skills Experience with data visualization tools such as Qlik Sense and Looker A solid grasp of statistical significance models and tools Desired Marketing metrics of user funnel, user acquisition KPI’s What we offer A Workplace Designed for Your Well-Being - Comfortable Environment: Ergonomic chairs and desks to support your health. Beautifully designed spaces that inspire creativity. - On-Site Amenities: Gym, yoga room, and music room for relaxation and rejuvenation. - Delicious Perks: 5-star breakfast to kickstart your day. Freshly made coffee, shakes, and afternoon salads by our in-house barista. - Health & Wellness: Full health insurance coverage for your peace of mind. - Growth Opportunities: Learning and training programs to enhance your personal and professional skills. - Vibrant Culture: Happy hours, team events, and plenty of opportunities to connect with colleagues. Join us and experience a workplace where your well-being, growth, and enjoyment come first! Opened URL: https://il.indeed.com/rc/clk?jk=2b03298659a436f7&bb=r6UIYw2mow7Pn8IzQwq2_wWeK1_evLckj39fLIfBgJ2KNH0z3augA147ODzOJXM4VPM1yn4wZeNukSlYyB-0ehIHUhqYKXcTKfcnYDIqLgoQwawaxa9eNtYV3Qk82DTa&xkcb=SoBN67M33wH7H8WWaB0ObzkdCdPP&fccid=f24b7ff57afa3405&vjs=3</td><td>data</td><td>The Business Performance department at Plarium is in charge of all the analytical aspects of our game operations and strategic planning: From game design, to user acquisition, player behavior, live-ops, and game optimization (such as monetization, retention, etc). We are looking for a data analyst for our Marketing Analytics team. The scope of responsibility of this team includes budget optimization for user acquisition for our games at the scope of tens of million dollars per game, analyses of game profitability and long term potential, analysis of the players behavior, player game funnel and reaction to new game features and offers, and a lot more. Our goal is making sure Plarium brings the best and most relevant players to its games in the most efficient and effective way. Responsibilities Be a focal point for anything related to new players performance and KPIs across our range of games, strategic planning, user segmentation, tests and growth opportunities identification Daily support of ongoing analytical needs of the marketing department managers & teams Establish and monitor success metrics that measure and explain the impact of the marketing activities Design and initiate new features and reports to monitor & give insights on the marketing activity, using the marketing in-house BI system (for example, LTV, ROI forecasting, automatic rules) Run ad-hoc and in-depth analyses of the different Marketing activities and trends Support decision making based on data Collaborate with the game analysis team and the game studios to monitor and optimize our players experience, maximizing their retention in our games What we expect B.A/BSc in a highly quantitative field such as mathematics industrial engineering economics statistics or equivalent academic knowledge At least 2 years of hands-on data analysis and story-telling experience Proven experience with measuring online success and identifying optimization opportunities Excellent understanding of online marketing metrics High proficiency in SQL with demonstrated experience in querying large complex datasets Strong Excel / Google Sheets skills Experience with data visualization tools such as Qlik Sense and Looker A solid grasp of statistical significance models and tools Desired Marketing metrics of user funnel, user acquisition KPI’s What we offer A Workplace Designed for Your Well-Being - Comfortable Environment: Ergonomic chairs and desks to support your health. Beautifully designed spaces that inspire creativity. - On-Site Amenities: Gym, yoga room, and music room for relaxation and rejuvenation. - Delicious Perks: 5-star breakfast to kickstart your day. Freshly made coffee, shakes, and afternoon salads by our in-house barista. - Health & Wellness: Full health insurance coverage for your peace of mind. - Growth Opportunities: Learning and training programs to enhance your personal and professional skills. - Vibrant Culture: Happy hours, team events, and plenty of opportunities to connect with colleagues. Join us and experience a workplace where your well-being, growth, and enjoyment come first!</td><td>The Business Performance department at Plarium is in charge of all the analytical aspects of our game operations and strategic planning: From game design, to user acquisition, player behavior, live-ops, and game optimization (such as monetization, retention, etc). We are looking for a data analyst for our Marketing Analytics team. The scope of responsibility of this team includes budget optimization for user acquisition for our games at the scope of tens of million dollars per game, analyses of game profitability and long term potential, analysis of the players behavior, player game funnel and reaction to new game features and offers, and a lot more. Our goal is making sure Plarium brings the best and most relevant players to its games in the most efficient and effective way. Responsibilities Be a focal point for anything related to new players performance and KPIs across our range of games, strategic planning, user segmentation, tests and growth opportunities identification Daily support of ongoing analytical needs of the marketing department managers & teams Establish and monitor success metrics that measure and explain the impact of the marketing activities Design and initiate new features and reports to monitor & give insights on the marketing activity, using the marketing in-house BI system (for example, LTV, ROI forecasting, automatic rules) Run ad-hoc and in-depth analyses of the different Marketing activities and trends Support decision making based on data Collaborate with the game analysis team and the game studios to monitor and optimize our players experience, maximizing their retention in our games What we expect B.A/BSc in a highly quantitative field such as mathematics industrial engineering economics statistics or equivalent academic knowledge At least 2 years of hands-on data analysis and story-telling experience Proven experience with measuring online success and identifying optimization opportunities Excellent understanding of online marketing metrics High proficiency in SQL with demonstrated experience in querying large complex datasets Strong Excel / Google Sheets skills Experience with data visualization tools such as Qlik Sense and Looker A solid grasp of statistical significance models and tools Desired Marketing metrics of user funnel, user acquisition KPI’s What we offer A Workplace Designed for Your Well-Being - Comfortable Environment: Ergonomic chairs and desks to support your health. Beautifully designed spaces that inspire creativity. - On-Site Amenities: Gym, yoga room, and music room for relaxation and rejuvenation. - Delicious Perks: 5-star breakfast to kickstart your day. Freshly made coffee, shakes, and afternoon salads by our in-house barista. - Health & Wellness: Full health insurance coverage for your peace of mind. - Growth Opportunities: Learning and training programs to enhance your personal and professional skills. - Vibrant Culture: Happy hours, team events, and plenty of opportunities to connect with colleagues. Join us and experience a workplace where your well-being, growth, and enjoyment come first!</td></tr><tr><td>Junior Data Analyst</td><td>aiOla</td><td>aiOla is a high-growth, product-led SaaS startup backed by $45 million in funding from premier investors such as New Era Capital Partners and Hamilton Lane. Our mission is to revolutionize efficiency, intelligence, collaboration, and safety in the industrial sector through our proprietary speech-powered AI technology. Our team spans the US and Israel, bringing together experts in Product, Data Science, Data Engineering, Analytics, Marketing, and Customer Success. At aiOla, we thrive on innovation, collaboration, and a commitment to excellence. We are seeking forward-thinking professionals passionate about pushing the limits of AI and making an impact. Role Overview: We are seeking a passionate and innovative Data Analyst to join our growing Analytics team. This is an exceptional opportunity for a detail-oriented professional to not only analyze data but also play a pivotal role in shaping and enhancing our cutting-edge AI models and products. As a Data Analyst at aiOla, you will dive into complex datasets, uncover actionable insights, and contribute directly to the improvement and monitoring of our proprietary AI technologies. If you thrive in a dynamic environment, this role is perfect for you! Requirements: B.Sc in Industrial Engineering, Data Analytics, Statistics, or a related field. Proficiency in Python, with a strong focus on libraries like Pandas for data manipulation. Solid knowledge of SQL for querying and managing large datasets. Experience with BI tools like Tableau to create dashboards and reports. Excellent communication skills, with fluency in English (written and verbal). 0-1 years of experience in a Data Analyst role- advantage Nice To have: Familiarity with Snowflake or AWS Athena. Experience with Web/App product analytics tools such as Mixpanel. Knowledge of Data Science concepts and metrics, including Speech AI, Large Language Models (LLMs), Natural Language Understanding (NLU), and Automatic Speech Recognition (ASR). Responsibilities: Extract, clean, and analyze data to uncover trends, patterns, and actionable insights. Provide recommendations based on data analysis to support business decisions and drive product improvements. Develop and maintain dashboards and reports using BI tools such as Tableau or other platforms. Optimize data workflows and pipelines using Python and SQL. Collaborate with cross-functional teams, including Product, Data Science, and Engineering, to support data-driven decision-making. Opened URL: https://il.indeed.com/rc/clk?jk=8c0efb63a00ef0d5&bb=r6UIYw2mow7Pn8IzQwq2_xdQrNIprFLEwcJQe8rzWVWb1_NSvbpLXcpcn5TXeAHedsgImdoi_2ey__b10Ys3nn9vr-SRmf6buKLYOFDHfBc8ksA0lyjjiA%3D%3D&xkcb=SoDQ67M33wH7H8WWaB0NbzkdCdPP&fccid=ba07516c418dda52&vjs=3</td><td>data</td><td>aiOla is a high-growth, product-led SaaS startup backed by $45 million in funding from premier investors such as New Era Capital Partners and Hamilton Lane. Our mission is to revolutionize efficiency, intelligence, collaboration, and safety in the industrial sector through our proprietary speech-powered AI technology. Our team spans the US and Israel, bringing together experts in Product, Data Science, Data Engineering, Analytics, Marketing, and Customer Success. At aiOla, we thrive on innovation, collaboration, and a commitment to excellence. We are seeking forward-thinking professionals passionate about pushing the limits of AI and making an impact. Role Overview: We are seeking a passionate and innovative Data Analyst to join our growing Analytics team. This is an exceptional opportunity for a detail-oriented professional to not only analyze data but also play a pivotal role in shaping and enhancing our cutting-edge AI models and products. As a Data Analyst at aiOla, you will dive into complex datasets, uncover actionable insights, and contribute directly to the improvement and monitoring of our proprietary AI technologies. If you thrive in a dynamic environment, this role is perfect for you! Requirements: B.Sc in Industrial Engineering, Data Analytics, Statistics, or a related field. Proficiency in Python, with a strong focus on libraries like Pandas for data manipulation. Solid knowledge of SQL for querying and managing large datasets. Experience with BI tools like Tableau to create dashboards and reports. Excellent communication skills, with fluency in English (written and verbal). 0-1 years of experience in a Data Analyst role- advantage Nice To have: Familiarity with Snowflake or AWS Athena. Experience with Web/App product analytics tools such as Mixpanel. Knowledge of Data Science concepts and metrics, including Speech AI, Large Language Models (LLMs), Natural Language Understanding (NLU), and Automatic Speech Recognition (ASR). Responsibilities: Extract, clean, and analyze data to uncover trends, patterns, and actionable insights. Provide recommendations based on data analysis to support business decisions and drive product improvements. Develop and maintain dashboards and reports using BI tools such as Tableau or other platforms. Optimize data workflows and pipelines using Python and SQL. Collaborate with cross-functional teams, including Product, Data Science, and Engineering, to support data-driven decision-making.</td><td>aiOla is a high-growth, product-led SaaS startup backed by $45 million in funding from premier investors such as New Era Capital Partners and Hamilton Lane. Our mission is to revolutionize efficiency, intelligence, collaboration, and safety in the industrial sector through our proprietary speech-powered AI technology. Our team spans the US and Israel, bringing together experts in Product, Data Science, Data Engineering, Analytics, Marketing, and Customer Success. At aiOla, we thrive on innovation, collaboration, and a commitment to excellence. We are seeking forward-thinking professionals passionate about pushing the limits of AI and making an impact. Role Overview: We are seeking a passionate and innovative Data Analyst to join our growing Analytics team. This is an exceptional opportunity for a detail-oriented professional to not only analyze data but also play a pivotal role in shaping and enhancing our cutting-edge AI models and products. As a Data Analyst at aiOla, you will dive into complex datasets, uncover actionable insights, and contribute directly to the improvement and monitoring of our proprietary AI technologies. If you thrive in a dynamic environment, this role is perfect for you! Requirements: B.Sc in Industrial Engineering, Data Analytics, Statistics, or a related field. Proficiency in Python, with a strong focus on libraries like Pandas for data manipulation. Solid knowledge of SQL for querying and managing large datasets. Experience with BI tools like Tableau to create dashboards and reports. Excellent communication skills, with fluency in English (written and verbal). 0-1 years of experience in a Data Analyst role- advantage Nice To have: Familiarity with Snowflake or AWS Athena. Experience with Web/App product analytics tools such as Mixpanel. Knowledge of Data Science concepts and metrics, including Speech AI, Large Language Models (LLMs), Natural Language Understanding (NLU), and Automatic Speech Recognition (ASR). Responsibilities: Extract, clean, and analyze data to uncover trends, patterns, and actionable insights. Provide recommendations based on data analysis to support business decisions and drive product improvements. Develop and maintain dashboards and reports using BI tools such as Tableau or other platforms. Optimize data workflows and pipelines using Python and SQL. Collaborate with cross-functional teams, including Product, Data Science, and Engineering, to support data-driven decision-making.</td></tr><tr><td>Data Engineer</td><td>Meta</td><td>As a Data Engineer at Meta, you will shape the future of people-facing and business-facing products we build across our entire family of applications (Facebook, Instagram, Messenger, WhatsApp, Reality Labs, Threads). Your technical skills and analytical mindset will be utilized designing and building some of the world's most extensive data sets, helping to craft experiences for billions of people and hundreds of millions of businesses worldwide.In this role, you will collaborate with software engineering, data science, and product management teams to design/build scalable data solutions across Meta to optimize growth, strategy, and user experience for our 3 billion plus users, as well as our internal employee community.You will be at the forefront of identifying and solving some of the most interesting data challenges at a scale few companies can match. By joining Meta, you will become part of a vibrant community dedicated to skill development and career growth in data engineering and beyond.Data Engineering: You will guide teams by building optimal data artifacts (including datasets and visualizations) to address key questions. You will refine our systems, design logging solutions, and create scalable data models. Ensuring data security and quality, and with a strong focus on efficiency, you will suggest architecture and development approaches and data management standards to address complex analytical problems.Product leadership: You will use data to shape product development, identify new opportunities, and tackle upcoming challenges. You'll ensure our products add value for users and businesses, by prioritizing projects, and driving innovative solutions to respond to challenges or opportunities.Communication and influence: You won't simply present data, but tell data-driven stories. You will convince and influence your partners using clear insights and recommendations. You will build credibility through structure and clarity, and be a trusted strategic partner. Data Engineer Responsibilities: Conceptualize and own the data architecture for multiple large-scale projects, while evaluating design and operational cost-benefit tradeoffs within systems Create and contribute to frameworks that improve the efficacy of logging data, while working with data infrastructure to triage issues and resolve Collaborate with engineers, product managers, and data scientists to understand data needs, representing key data insights in a meaningful way Define and manage Service Level Agreements for all data sets in allocated areas of ownership Determine and implement the security model based on privacy requirements, confirm safeguards are followed, address data quality issues, and evolve governance processes within allocated areas of ownership Design, build, and launch collections of sophisticated data models and visualizations that support multiple use cases across different products or domains Solve our most challenging data integration problems, utilizing optimal Extract, Transform, Load (ETL) patterns, frameworks, query techniques, sourcing from structured and unstructured data sources Assist in owning existing processes running in production, optimizing complex code through advanced algorithmic concepts Optimize pipelines, dashboards, frameworks, and systems to facilitate easier development of data artifacts Influence product and cross-functional teams to identify data opportunities to drive impact Mentor team members by giving/receiving actionable feedback Minimum Qualifications: Bachelor's degree in Computer Science, Engineering, relevant technical field, or equivalent 4+ years of experience where the primary responsibility involves working with data. This could include roles such as data analyst, data scientist, data engineer, or similar positions 4+ years of experience (or a minimum of 2+ years with a Ph.D) with SQL, ETL, data modeling, and at least one programming language (e.g., Python, C++, C#, Scala, etc.) About Meta: Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today—beyond the constraints of screens, the limits of distance, and even the rules of physics. Individual compensation is determined by skills, qualifications, experience, and location. Compensation details listed in this posting reflect the base hourly rate, monthly rate, or annual salary only, and do not include bonus, equity or sales incentives, if applicable. In addition to base compensation, Meta offers benefits. Learn more about benefits at Meta. Opened URL: https://il.indeed.com/rc/clk?jk=332ce6560e8316dc&bb=r6UIYw2mow7Pn8IzQwq2_562YukhS6UN3gQsCZxi2egxfUB-GUkmkThkhz4gjqWPCW22mO4kb3LIM8QmQyIpRZmtmdc9AupjQYBTLVDksxFngEUdv3hLf8xgn6T3kHo6&xkcb=SoBk67M33wH7H8WWaB0MbzkdCdPP&fccid=4d28265c01696bc0&vjs=3</td><td>data</td><td>As a Data Engineer at Meta, you will shape the future of people-facing and business-facing products we build across our entire family of applications (Facebook, Instagram, Messenger, WhatsApp, Reality Labs, Threads). Your technical skills and analytical mindset will be utilized designing and building some of the world's most extensive data sets, helping to craft experiences for billions of people and hundreds of millions of businesses worldwide.In this role, you will collaborate with software engineering, data science, and product management teams to design/build scalable data solutions across Meta to optimize growth, strategy, and user experience for our 3 billion plus users, as well as our internal employee community.You will be at the forefront of identifying and solving some of the most interesting data challenges at a scale few companies can match. By joining Meta, you will become part of a vibrant community dedicated to skill development and career growth in data engineering and beyond.Data Engineering: You will guide teams by building optimal data artifacts (including datasets and visualizations) to address key questions. You will refine our systems, design logging solutions, and create scalable data models. Ensuring data security and quality, and with a strong focus on efficiency, you will suggest architecture and development approaches and data management standards to address complex analytical problems.Product leadership: You will use data to shape product development, identify new opportunities, and tackle upcoming challenges. You'll ensure our products add value for users and businesses, by prioritizing projects, and driving innovative solutions to respond to challenges or opportunities.Communication and influence: You won't simply present data, but tell data-driven stories. You will convince and influence your partners using clear insights and recommendations. You will build credibility through structure and clarity, and be a trusted strategic partner. Data Engineer Responsibilities: Conceptualize and own the data architecture for multiple large-scale projects, while evaluating design and operational cost-benefit tradeoffs within systems Create and contribute to frameworks that improve the efficacy of logging data, while working with data infrastructure to triage issues and resolve Collaborate with engineers, product managers, and data scientists to understand data needs, representing key data insights in a meaningful way Define and manage Service Level Agreements for all data sets in allocated areas of ownership Determine and implement the security model based on privacy requirements, confirm safeguards are followed, address data quality issues, and evolve governance processes within allocated areas of ownership Design, build, and launch collections of sophisticated data models and visualizations that support multiple use cases across different products or domains Solve our most challenging data integration problems, utilizing optimal Extract, Transform, Load (ETL) patterns, frameworks, query techniques, sourcing from structured and unstructured data sources Assist in owning existing processes running in production, optimizing complex code through advanced algorithmic concepts Optimize pipelines, dashboards, frameworks, and systems to facilitate easier development of data artifacts Influence product and cross-functional teams to identify data opportunities to drive impact Mentor team members by giving/receiving actionable feedback Minimum Qualifications: Bachelor's degree in Computer Science, Engineering, relevant technical field, or equivalent 4+ years of experience where the primary responsibility involves working with data. This could include roles such as data analyst, data scientist, data engineer, or similar positions 4+ years of experience (or a minimum of 2+ years with a Ph.D) with SQL, ETL, data modeling, and at least one programming language (e.g., Python, C++, C#, Scala, etc.) About Meta: Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today—beyond the constraints of screens, the limits of distance, and even the rules of physics. Individual compensation is determined by skills, qualifications, experience, and location. Compensation details listed in this posting reflect the base hourly rate, monthly rate, or annual salary only, and do not include bonus, equity or sales incentives, if applicable. In addition to base compensation, Meta offers benefits. Learn more about benefits at Meta.</td><td>As a Data Engineer at Meta, you will shape the future of people-facing and business-facing products we build across our entire family of applications (Facebook, Instagram, Messenger, WhatsApp, Reality Labs, Threads). Your technical skills and analytical mindset will be utilized designing and building some of the world's most extensive data sets, helping to craft experiences for billions of people and hundreds of millions of businesses worldwide.In this role, you will collaborate with software engineering, data science, and product management teams to design/build scalable data solutions across Meta to optimize growth, strategy, and user experience for our 3 billion plus users, as well as our internal employee community.You will be at the forefront of identifying and solving some of the most interesting data challenges at a scale few companies can match. By joining Meta, you will become part of a vibrant community dedicated to skill development and career growth in data engineering and beyond.Data Engineering: You will guide teams by building optimal data artifacts (including datasets and visualizations) to address key questions. You will refine our systems, design logging solutions, and create scalable data models. Ensuring data security and quality, and with a strong focus on efficiency, you will suggest architecture and development approaches and data management standards to address complex analytical problems.Product leadership: You will use data to shape product development, identify new opportunities, and tackle upcoming challenges. You'll ensure our products add value for users and businesses, by prioritizing projects, and driving innovative solutions to respond to challenges or opportunities.Communication and influence: You won't simply present data, but tell data-driven stories. You will convince and influence your partners using clear insights and recommendations. You will build credibility through structure and clarity, and be a trusted strategic partner. Data Engineer Responsibilities: Conceptualize and own the data architecture for multiple large-scale projects, while evaluating design and operational cost-benefit tradeoffs within systems Create and contribute to frameworks that improve the efficacy of logging data, while working with data infrastructure to triage issues and resolve Collaborate with engineers, product managers, and data scientists to understand data needs, representing key data insights in a meaningful way Define and manage Service Level Agreements for all data sets in allocated areas of ownership Determine and implement the security model based on privacy requirements, confirm safeguards are followed, address data quality issues, and evolve governance processes within allocated areas of ownership Design, build, and launch collections of sophisticated data models and visualizations that support multiple use cases across different products or domains Solve our most challenging data integration problems, utilizing optimal Extract, Transform, Load (ETL) patterns, frameworks, query techniques, sourcing from structured and unstructured data sources Assist in owning existing processes running in production, optimizing complex code through advanced algorithmic concepts Optimize pipelines, dashboards, frameworks, and systems to facilitate easier development of data artifacts Influence product and cross-functional teams to identify data opportunities to drive impact Mentor team members by giving/receiving actionable feedback Minimum Qualifications: Bachelor's degree in Computer Science, Engineering, relevant technical field, or equivalent 4+ years of experience where the primary responsibility involves working with data. This could include roles such as data analyst, data scientist, data engineer, or similar positions 4+ years of experience (or a minimum of 2+ years with a Ph.D) with SQL, ETL, data modeling, and at least one programming language (e.g., Python, C++, C#, Scala, etc.) About Meta: Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today—beyond the constraints of screens, the limits of distance, and even the rules of physics. Individual compensation is determined by skills, qualifications, experience, and location. Compensation details listed in this posting reflect the base hourly rate, monthly rate, or annual salary only, and do not include bonus, equity or sales incentives, if applicable. In addition to base compensation, Meta offers benefits. Learn more about benefits at Meta.</td></tr><tr><td>Junior Data Engineer</td><td>Aquant</td><td>At Aquant, we empower field service professionals to become heroes using our personalized generative AI platform, Service Co-Pilot. Using historical service data, Aquant equips service leaders, field technicians, and customer service representatives with the precise information they need when they need it—enabling them to make decisions with confidence, reduce costs, and optimize service delivery. Recognized as one of Fast Company's Next Big Things in Tech of 2024 , we are committed to providing cutting-edge AI solutions that tackle the most pressing challenges in manufacturing. Ready to join a team that values innovation, excellence, and above all, its people? Apply today! Aquant's Data Analytics team is looking for a highly skilled Data Engineer who is comfortable with big data and complex data models. As a member of our Data Engineering team, you will: Work with large amounts of data and develop Python code to streamline processes Analyze different data structures and create the required reports out of them Collaborate \\ connect to existing codes Build tools to track data quality on large DB with complicated schemas Monitor the integrity and validity of the customer service data Deep dive into the service data and learn the service world Required skills & background: 2-3 years experience with big datasets BA/B.Sc. in industrial/information systems engineering, statistics or equivalent Hands-on experience with Excel + SQL - must Hands-on experience with Python – must Experience with Azure services - advantage A team player, with excellent collaboration skills Excellent communicator with the ability to deliver high-quality results Fluent English It's not enough to have a cool product, join us because you share our values: These guiding values inspire every Aquant employee. They are how we operate and enable our company as a whole to have a greater impact and achieve our vision: Be Humble and Respectful: We are one team, where collective success is more important than individual ego. Treat your colleagues with respect and empathy, act with good intent, and value everyone's contributions. Be Curious: Keep learning, and asking questions to understand complex situations. Embrace new challenges. Keep an open mind, and be receptive to feedback. Take Ownership: Focus on achieving measurable and meaningful outcomes. Take decisive action, solve problems proactively, and take ownership of projects and results. Act with Integrity: Act with Integrity. Do great things while doing the right thing for your customers and colleagues. Some of our benefits: Vacation your way: We want to make sure you have time to meet your personal needs with generous PTO and flexible vacation planning. Everyone is an owner: We want everyone to feel ownership over their work and what we are building here, which is why we offer equity to full-time employees. Build your career: Every Aquant employee is in control of their career development with our learning stipends, tools, and training. Applicants must be authorized to work for any employer in the Israel. We are unable to sponsor or take over sponsorship of an employment Visa at this time. Aquant is committed to hiring a diverse and talented workforce. Opened URL: https://il.indeed.com/rc/clk?jk=ae2c3d8865d70a20&bb=r6UIYw2mow7Pn8IzQwq2_-VNnSBFDXo8Ynf-6utD7gBjMIDitHzsM1MRE1_A3cWHXQijHHfglfmBI95kAdDXDG8bj1QKQcCe9jGagYeS_BwRE1OhyZy2w5SIATwSfwc1&xkcb=SoCN67M33wH7H8WWaB0DbzkdCdPP&fccid=ba03cd038fd30855&vjs=3</td><td>data</td><td>At Aquant, we empower field service professionals to become heroes using our personalized generative AI platform, Service Co-Pilot. Using historical service data, Aquant equips service leaders, field technicians, and customer service representatives with the precise information they need when they need it—enabling them to make decisions with confidence, reduce costs, and optimize service delivery. Recognized as one of Fast Company's Next Big Things in Tech of 2024 , we are committed to providing cutting-edge AI solutions that tackle the most pressing challenges in manufacturing. Ready to join a team that values innovation, excellence, and above all, its people? Apply today! Aquant's Data Analytics team is looking for a highly skilled Data Engineer who is comfortable with big data and complex data models. As a member of our Data Engineering team, you will: Work with large amounts of data and develop Python code to streamline processes Analyze different data structures and create the required reports out of them Collaborate \\ connect to existing codes Build tools to track data quality on large DB with complicated schemas Monitor the integrity and validity of the customer service data Deep dive into the service data and learn the service world Required skills & background: 2-3 years experience with big datasets BA/B.Sc. in industrial/information systems engineering, statistics or equivalent Hands-on experience with Excel + SQL - must Hands-on experience with Python – must Experience with Azure services - advantage A team player, with excellent collaboration skills Excellent communicator with the ability to deliver high-quality results Fluent English It's not enough to have a cool product, join us because you share our values: These guiding values inspire every Aquant employee. They are how we operate and enable our company as a whole to have a greater impact and achieve our vision: Be Humble and Respectful: We are one team, where collective success is more important than individual ego. Treat your colleagues with respect and empathy, act with good intent, and value everyone's contributions. Be Curious: Keep learning, and asking questions to understand complex situations. Embrace new challenges. Keep an open mind, and be receptive to feedback. Take Ownership: Focus on achieving measurable and meaningful outcomes. Take decisive action, solve problems proactively, and take ownership of projects and results. Act with Integrity: Act with Integrity. Do great things while doing the right thing for your customers and colleagues. Some of our benefits: Vacation your way: We want to make sure you have time to meet your personal needs with generous PTO and flexible vacation planning. Everyone is an owner: We want everyone to feel ownership over their work and what we are building here, which is why we offer equity to full-time employees. Build your career: Every Aquant employee is in control of their career development with our learning stipends, tools, and training. Applicants must be authorized to work for any employer in the Israel. We are unable to sponsor or take over sponsorship of an employment Visa at this time. Aquant is committed to hiring a diverse and talented workforce.</td><td>At Aquant, we empower field service professionals to become heroes using our personalized generative AI platform, Service Co-Pilot. Using historical service data, Aquant equips service leaders, field technicians, and customer service representatives with the precise information they need when they need it—enabling them to make decisions with confidence, reduce costs, and optimize service delivery. Recognized as one of Fast Company's Next Big Things in Tech of 2024 , we are committed to providing cutting-edge AI solutions that tackle the most pressing challenges in manufacturing. Ready to join a team that values innovation, excellence, and above all, its people? Apply today! Aquant's Data Analytics team is looking for a highly skilled Data Engineer who is comfortable with big data and complex data models. As a member of our Data Engineering team, you will: Work with large amounts of data and develop Python code to streamline processes Analyze different data structures and create the required reports out of them Collaborate \\ connect to existing codes Build tools to track data quality on large DB with complicated schemas Monitor the integrity and validity of the customer service data Deep dive into the service data and learn the service world Required skills & background: 2-3 years experience with big datasets BA/B.Sc. in industrial/information systems engineering, statistics or equivalent Hands-on experience with Excel + SQL - must Hands-on experience with Python – must Experience with Azure services - advantage A team player, with excellent collaboration skills Excellent communicator with the ability to deliver high-quality results Fluent English It's not enough to have a cool product, join us because you share our values: These guiding values inspire every Aquant employee. They are how we operate and enable our company as a whole to have a greater impact and achieve our vision: Be Humble and Respectful: We are one team, where collective success is more important than individual ego. Treat your colleagues with respect and empathy, act with good intent, and value everyone's contributions. Be Curious: Keep learning, and asking questions to understand complex situations. Embrace new challenges. Keep an open mind, and be receptive to feedback. Take Ownership: Focus on achieving measurable and meaningful outcomes. Take decisive action, solve problems proactively, and take ownership of projects and results. Act with Integrity: Act with Integrity. Do great things while doing the right thing for your customers and colleagues. Some of our benefits: Vacation your way: We want to make sure you have time to meet your personal needs with generous PTO and flexible vacation planning. Everyone is an owner: We want everyone to feel ownership over their work and what we are building here, which is why we offer equity to full-time employees. Build your career: Every Aquant employee is in control of their career development with our learning stipends, tools, and training. Applicants must be authorized to work for any employer in the Israel. We are unable to sponsor or take over sponsorship of an employment Visa at this time. Aquant is committed to hiring a diverse and talented workforce.</td></tr><tr><td>Data Scientist</td><td>Rubrik Job Board</td><td>About Team & About Role: Rubrik is seeking a Data Scientist to join our Data Research team, part of the Security Apps organization responsible for developing Rubrik’s suite of security products. This is the first data scientist position on the team, requiring a high degree of independence and ownership. You’ll spearhead research and development of ML/AI models that power the features of our security offerings. What You’ll Do: Research and develop ML/AI models in the NLP domain Develop advanced anomaly detection models for threat detection Work closely with data analysts on research, pattern analysis, etc. Work closely with developers on implementation of models as part of features in the product Work with global teams to continuously push our ML infrastructure forward Experience You’ll Need: Bachelor’s degree in Mathematics, Computer Science, or other related field 3 years of experience in data science or a related field Proficiency in programming languages, especially Python Experience with common data science toolkits, such as Jupyter Notebook, Pandas, NumPy, Matplotlib, etc. Demonstrated experience in implementing ML algorithms in production environments, with a focus on anomaly detection and natural language processing. Strong problem-solving skills and analytic capability to develop insights and recommendations Excellent communication skills in Hebrew and English Preferred Qualifications: Master’s degree in Mathematics, Computer Science, or other related field Familiarity with cloud platforms such as AWS, Google Cloud, or Azure Experience working with LLMs Previous experience in the security industry Join Us in Securing the World's Data Rubrik (NYSE: RBRK) is on a mission to secure the world’s data. With Zero Trust Data Security™, we help organizations achieve business resilience against cyberattacks, malicious insiders, and operational disruptions. Rubrik Security Cloud, powered by machine learning, secures data across enterprise, cloud, and SaaS applications. We help organizations uphold data integrity, deliver data availability that withstands adverse conditions, continuously monitor data risks and threats, and restore businesses with their data when infrastructure is attacked. Linkedin | X (formerly Twitter) | Instagram | Rubrik.com Diversity, Equity & Inclusion @ Rubrik At Rubrik we are committed to building and sustaining a culture where people of all backgrounds are valued, know they belong, and believe they can succeed here. Rubrik's goal is to hire and promote the best person for the job, no matter their background. In doing so, Rubrik is committed to correcting systemic processes and cultural norms that have prevented equal representation. This means we review our current efforts with the intent to offer fair hiring, promotion, and compensation opportunities to people from historically underrepresented communities, and strive to create a company culture where all employees feel they can bring their authentic selves to work and be successful. Our DEI strategy focuses on three core areas of our business and culture: Our Company: Build a diverse company that provides equitable access to growth and success for all employees globally. Our Culture: Create an inclusive environment where authenticity thrives and people of all backgrounds feel like they belong. Our Communities: Expand our commitment to diversity, equity, & inclusion within and beyond our company walls to invest in future generations of underrepresented talent and bring innovation to our clients. Equal Opportunity Employer/Veterans/Disabled Rubrik is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, or protected veteran status and will not be discriminated against on the basis of disability. Rubrik provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability or genetics. In addition to federal law requirements, Rubrik complies with applicable state and local laws governing nondiscrimination in employment in every location in which the company has facilities. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training. Federal law requires employers to provide reasonable accommodation to qualified individuals with disabilities. Please contact us at hr@rubrik.com if you require a reasonable accommodation to apply for a job or to perform your job. Examples of reasonable accommodation include making a change to the application process or work procedures, providing documents in an alternate format, using a sign language interpreter, or using specialized equipment. Opened URL: https://il.indeed.com/rc/clk?jk=ad3b38d6d843bb02&bb=r6UIYw2mow7Pn8IzQwq2_yYq9SF7G8SWRQOq2tS0E5s2WTIxqyX5UvFT8u-SbU_SASUW0mVJ_I7cT2iX1zPkHRDbfnLFNxLKcDajKYoqI5cz62T43EBWZ9Z5mO0gfo-W&xkcb=SoA567M33wH7H8WWaB0CbzkdCdPP&fccid=c4e7a75c6cddb35a&vjs=3</td><td>data</td><td>About Team & About Role: Rubrik is seeking a Data Scientist to join our Data Research team, part of the Security Apps organization responsible for developing Rubrik’s suite of security products. This is the first data scientist position on the team, requiring a high degree of independence and ownership. You’ll spearhead research and development of ML/AI models that power the features of our security offerings. What You’ll Do: Research and develop ML/AI models in the NLP domain Develop advanced anomaly detection models for threat detection Work closely with data analysts on research, pattern analysis, etc. Work closely with developers on implementation of models as part of features in the product Work with global teams to continuously push our ML infrastructure forward Experience You’ll Need: Bachelor’s degree in Mathematics, Computer Science, or other related field 3 years of experience in data science or a related field Proficiency in programming languages, especially Python Experience with common data science toolkits, such as Jupyter Notebook, Pandas, NumPy, Matplotlib, etc. Demonstrated experience in implementing ML algorithms in production environments, with a focus on anomaly detection and natural language processing. Strong problem-solving skills and analytic capability to develop insights and recommendations Excellent communication skills in Hebrew and English Preferred Qualifications: Master’s degree in Mathematics, Computer Science, or other related field Familiarity with cloud platforms such as AWS, Google Cloud, or Azure Experience working with LLMs Previous experience in the security industry Join Us in Securing the World's Data Rubrik (NYSE: RBRK) is on a mission to secure the world’s data. With Zero Trust Data Security™, we help organizations achieve business resilience against cyberattacks, malicious insiders, and operational disruptions. Rubrik Security Cloud, powered by machine learning, secures data across enterprise, cloud, and SaaS applications. We help organizations uphold data integrity, deliver data availability that withstands adverse conditions, continuously monitor data risks and threats, and restore businesses with their data when infrastructure is attacked. Linkedin | X (formerly Twitter) | Instagram | Rubrik.com Diversity, Equity & Inclusion @ Rubrik At Rubrik we are committed to building and sustaining a culture where people of all backgrounds are valued, know they belong, and believe they can succeed here. Rubrik's goal is to hire and promote the best person for the job, no matter their background. In doing so, Rubrik is committed to correcting systemic processes and cultural norms that have prevented equal representation. This means we review our current efforts with the intent to offer fair hiring, promotion, and compensation opportunities to people from historically underrepresented communities, and strive to create a company culture where all employees feel they can bring their authentic selves to work and be successful. Our DEI strategy focuses on three core areas of our business and culture: Our Company: Build a diverse company that provides equitable access to growth and success for all employees globally. Our Culture: Create an inclusive environment where authenticity thrives and people of all backgrounds feel like they belong. Our Communities: Expand our commitment to diversity, equity, & inclusion within and beyond our company walls to invest in future generations of underrepresented talent and bring innovation to our clients. Equal Opportunity Employer/Veterans/Disabled Rubrik is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, or protected veteran status and will not be discriminated against on the basis of disability. Rubrik provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability or genetics. In addition to federal law requirements, Rubrik complies with applicable state and local laws governing nondiscrimination in employment in every location in which the company has facilities. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training. Federal law requires employers to provide reasonable accommodation to qualified individuals with disabilities. Please contact us at hr@rubrik.com if you require a reasonable accommodation to apply for a job or to perform your job. Examples of reasonable accommodation include making a change to the application process or work procedures, providing documents in an alternate format, using a sign language interpreter, or using specialized equipment.</td><td>About Team & About Role: Rubrik is seeking a Data Scientist to join our Data Research team, part of the Security Apps organization responsible for developing Rubrik’s suite of security products. This is the first data scientist position on the team, requiring a high degree of independence and ownership. You’ll spearhead research and development of ML/AI models that power the features of our security offerings. What You’ll Do: Research and develop ML/AI models in the NLP domain Develop advanced anomaly detection models for threat detection Work closely with data analysts on research, pattern analysis, etc. Work closely with developers on implementation of models as part of features in the product Work with global teams to continuously push our ML infrastructure forward Experience You’ll Need: Bachelor’s degree in Mathematics, Computer Science, or other related field 3 years of experience in data science or a related field Proficiency in programming languages, especially Python Experience with common data science toolkits, such as Jupyter Notebook, Pandas, NumPy, Matplotlib, etc. Demonstrated experience in implementing ML algorithms in production environments, with a focus on anomaly detection and natural language processing. Strong problem-solving skills and analytic capability to develop insights and recommendations Excellent communication skills in Hebrew and English Preferred Qualifications: Master’s degree in Mathematics, Computer Science, or other related field Familiarity with cloud platforms such as AWS, Google Cloud, or Azure Experience working with LLMs Previous experience in the security industry Join Us in Securing the World's Data Rubrik (NYSE: RBRK) is on a mission to secure the world’s data. With Zero Trust Data Security™, we help organizations achieve business resilience against cyberattacks, malicious insiders, and operational disruptions. Rubrik Security Cloud, powered by machine learning, secures data across enterprise, cloud, and SaaS applications. We help organizations uphold data integrity, deliver data availability that withstands adverse conditions, continuously monitor data risks and threats, and restore businesses with their data when infrastructure is attacked. Linkedin | X (formerly Twitter) | Instagram | Rubrik.com Diversity, Equity & Inclusion @ Rubrik At Rubrik we are committed to building and sustaining a culture where people of all backgrounds are valued, know they belong, and believe they can succeed here. Rubrik's goal is to hire and promote the best person for the job, no matter their background. In doing so, Rubrik is committed to correcting systemic processes and cultural norms that have prevented equal representation. This means we review our current efforts with the intent to offer fair hiring, promotion, and compensation opportunities to people from historically underrepresented communities, and strive to create a company culture where all employees feel they can bring their authentic selves to work and be successful. Our DEI strategy focuses on three core areas of our business and culture: Our Company: Build a diverse company that provides equitable access to growth and success for all employees globally. Our Culture: Create an inclusive environment where authenticity thrives and people of all backgrounds feel like they belong. Our Communities: Expand our commitment to diversity, equity, & inclusion within and beyond our company walls to invest in future generations of underrepresented talent and bring innovation to our clients. Equal Opportunity Employer/Veterans/Disabled Rubrik is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, or protected veteran status and will not be discriminated against on the basis of disability. Rubrik provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability or genetics. In addition to federal law requirements, Rubrik complies with applicable state and local laws governing nondiscrimination in employment in every location in which the company has facilities. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training. Federal law requires employers to provide reasonable accommodation to qualified individuals with disabilities. Please contact us at hr@rubrik.com if you require a reasonable accommodation to apply for a job or to perform your job. Examples of reasonable accommodation include making a change to the application process or work procedures, providing documents in an alternate format, using a sign language interpreter, or using specialized equipment.</td></tr><tr><td>data scientist!</td><td>Horizon Technologies</td><td>לארגון גדול ומוביל טכנולוגית בירושלים דרוש/ה data scientist! עבודה במתכונת היברידית מרובה! תיאור התפקיד: איש מדע נתונים והתממה ימלא תפקיד חשוב במחלקת ביג דאטה ויהיה אחראי על שורה של פעילויות שיאפשרו מחקרי נתונים על מאגרי המשרד וארגונים שעובדים עם המחלקה. יישום מדיניות ההתממה של מחלקת ביג דאטה באמצעות עבודה צמודה עם מהנדסי נתונים שיבצעו את פעולות ההתממה ואף באמצעות ביצוע פעולות אלה בעצמו בכלי ניתוח המוגדרים בתמנ\"ע, כגון SQL, PYTHON, דאטאיקו ואחרים. כמו כן יהיה אחראי על תהליכי בדיקת איכות (QA) ההתממה בסביבה בה בוצעו האנליזות והעיבודים על הנתונים, או בליווי מהנדס נתונים שיבצע פעולות אלה. המערכות שבשימוש SQL, PYTHON, DATAIKU, CLOUDERA, לא מוגבלות לשימוש רק באלה. דרישות: 3 שנות ניסיון ומעלה בתפקידי דאטה מתוכן שנה אחת לפחות ב- data science (תפקידי דאטה: אנליטיקה של נתונים, הנדסת נתונים, מדע נתונים, פיתוח BI) ניסיון בהפעלת כלי התממה טבלאיים (למשל Privitar, Dataiku) - מינימום שנה ניסיון, מינימום עבודה על 30 טבלאות ניסיון בהתממה בתחום הבריאות - חובה. ניסיון בהתממת נתונים טבלאיים חובה. ⁠התממת טקסט חופשי - חובה. התממת טקסט חופשי בעברית - יתרון משמעותי. ניסיון בעבודה על התממה מול חוקרים באקדמיה - יתרון Opened URL: https://il.indeed.com/rc/clk?jk=f90aa7093544f010&bb=r6UIYw2mow7Pn8IzQwq2_xyaGdaoejrhyKNPDULo5mrjaIrPYiIvCcF52gDTKS5ckQ4Tob9j7S8rgIEWt6fB4Q2dVUswzFz8eib5DhxHjVmhwfPeuvoDONJ99fqrpBqv&xkcb=SoCk67M33wH7H8WWaB0BbzkdCdPP&fccid=e32508b84ec45c2b&vjs=3</td><td>data</td><td>לארגון גדול ומוביל טכנולוגית בירושלים דרוש/ה data scientist! עבודה במתכונת היברידית מרובה! תיאור התפקיד: איש מדע נתונים והתממה ימלא תפקיד חשוב במחלקת ביג דאטה ויהיה אחראי על שורה של פעילויות שיאפשרו מחקרי נתונים על מאגרי המשרד וארגונים שעובדים עם המחלקה. יישום מדיניות ההתממה של מחלקת ביג דאטה באמצעות עבודה צמודה עם מהנדסי נתונים שיבצעו את פעולות ההתממה ואף באמצעות ביצוע פעולות אלה בעצמו בכלי ניתוח המוגדרים בתמנ\"ע, כגון SQL, PYTHON, דאטאיקו ואחרים. כמו כן יהיה אחראי על תהליכי בדיקת איכות (QA) ההתממה בסביבה בה בוצעו האנליזות והעיבודים על הנתונים, או בליווי מהנדס נתונים שיבצע פעולות אלה. המערכות שבשימוש SQL, PYTHON, DATAIKU, CLOUDERA, לא מוגבלות לשימוש רק באלה. דרישות: 3 שנות ניסיון ומעלה בתפקידי דאטה מתוכן שנה אחת לפחות ב- data science (תפקידי דאטה: אנליטיקה של נתונים, הנדסת נתונים, מדע נתונים, פיתוח BI) ניסיון בהפעלת כלי התממה טבלאיים (למשל Privitar, Dataiku) - מינימום שנה ניסיון, מינימום עבודה על 30 טבלאות ניסיון בהתממה בתחום הבריאות - חובה. ניסיון בהתממת נתונים טבלאיים חובה. ⁠התממת טקסט חופשי - חובה. התממת טקסט חופשי בעברית - יתרון משמעותי. ניסיון בעבודה על התממה מול חוקרים באקדמיה - יתרון</td><td>A large, technologically leading organization in Jerusalem needs a data scientist! Work in a hybrid multi-tasking format! Job description: A data scientist and data scientist will play an important role in the Big Data department and will be responsible for a series of activities that will enable data research on the office's databases and organizations that work with the department. Implementing the Big Data department's data mining policy by working closely with data engineers who will perform the mining operations and even by performing these operations themselves in analysis tools defined in the Data Mining and Data Analysis Framework, such as SQL, PYTHON, DataIKU, and others. He will also be responsible for the quality assurance (QA) processes of the mining in the environment where the analyses and processing of the data were performed, or accompanied by a data engineer who will perform these operations. The systems used are SQL, PYTHON, DATAIKU, CLOUDERA, but are not limited to these. Requirements: 3 years or more of experience in data roles, including at least one year in data science (data roles: data analytics, data engineering, data science, BI development) Experience operating tabular mining tools (e.g. Privitar, Dataiku) - minimum one year of experience, minimum work on 30 tables Experience in mining in the healthcare field - mandatory. Experience in tabular data mining is mandatory. ⁠Free text mining - mandatory. Free text mining in Hebrew - Significant advantage. Experience working on Tama with researchers in academia - an advantage</td></tr><tr><td>Data Scientist</td><td>Ticomsoft</td><td>jb-19 מספר משרה : עם ניסיון ב Data Scientist דרוש איש/ת פיתוח Evaluating state of art statistical modeling and machine Learning. Big data analysis, Modeling and Reporting. Job Requirements:Requirements: A minimum first degree in computer science/ applied math/ statistics. Strong algorithm development skills. Proven experience with machine learning algorithms – both supervised and unsupervised. Proven experience with optimization algorithms. 5+ years of relevant experience with one of the following: Python, R, Matlab. Strong communication skills, creative, results driven, quick learner. Experience with big data, distributed processing, NoSQL databases – a significant advantage. השם שלך מספר המשרה(חובה) העלאת קו\"ח שתף את המשרה ותן לחברים שלך לעזור Opened URL: https://il.indeed.com/rc/clk?jk=d93f96511474983d&bb=r6UIYw2mow7Pn8IzQwq2_5aHKW3wZhMixewaX6PYd3gfA9lT-ljRyZagyU-B6VRsq5WetHFTiwUEwJhRVi0EoeZ2l1gDnl0VKDEJDOrEiNtxwcGFGMy1pCHdHBhSYAxX&xkcb=SoAQ67M33wH7H8WWaB0AbzkdCdPP&fccid=9c02dc25b0c9c8ac&vjs=3</td><td>data</td><td>jb-19 מספר משרה : עם ניסיון ב Data Scientist דרוש איש/ת פיתוח Evaluating state of art statistical modeling and machine Learning. Big data analysis, Modeling and Reporting. Job Requirements:Requirements: A minimum first degree in computer science/ applied math/ statistics. Strong algorithm development skills. Proven experience with machine learning algorithms – both supervised and unsupervised. Proven experience with optimization algorithms. 5+ years of relevant experience with one of the following: Python, R, Matlab. Strong communication skills, creative, results driven, quick learner. Experience with big data, distributed processing, NoSQL databases – a significant advantage. השם שלך מספר המשרה(חובה) העלאת קו\"ח שתף את המשרה ותן לחברים שלך לעזור</td><td>jb-19 Job Number: With experience in Data Scientist Need a Development Person Evaluating state of art statistical modeling and machine Learning. Big data analysis, Modeling and Reporting. Job Requirements:Requirements: A minimum first degree in computer science/ applied math/ statistics. Strong algorithm development skills. Proven experience with machine learning algorithms – both supervised and unsupervised. Proven experience with optimization algorithms. 5+ years of relevant experience with one of the following: Python, R, Matlab. Strong communication skills, creative, results driven, quick learner. Experience with big data, distributed processing, NoSQL databases – a significant advantage. Your Name Job Number (Required) Upload Resume Share the job and let your friends help</td></tr><tr><td>Customer Data Engineer</td><td>Optimove</td><td>Optimove is a global marketing tech company, recognized as a Leader by Forrester and a Challenger by Gartner. We work with some of the world's most exciting brands, such as Sephora, Staples, and Entain, who love our thought-provoking combination of art and science. With a strong product, a proven business, and the DNA of a vibrant, fast-growing startup, we're on the cusp of our next growth spurt. It's the perfect time to join our team of ~450 thinkers and doers across NYC, LDN, TLV, and other locations, where 2 of every 3 managers were promoted from within. Growing your career with Optimove is basically guaranteed. As a Customer Data Engineer, you will be a part of a strong energetic, and fast-growing global team. You will be an integral part of clients' onboarding and ongoing data requests and projects. You will be working closely with internal PM and CSM teams as well as interacting directly with clients' data teams across different business verticals. Your core responsibilities will involve playing an active role in collaborating with internal teams to construct tailored data transformations and manipulations while working with top-notch technology (Cloud tech etc.) The ideal candidate is an SQL whiz with a strong work ethic, robust analytical and technical capabilities, and highly effective time management skills. We are looking for a master multi-tasker who thrives in challenging, fast-paced environments, with agility and ease. The Customer Data Engineer is a position that brings with it an excellent opportunity to learn and grow within a rapidly expanding company on the cutting edge of Martech. Responsibilities: Develop and support a wide range of data transformations and migrations Construct custom ETL processes: Design and implementation of data pipelines and data marts, access versatile data sources, and apply data quality measures Investigate data mismatches and apply solutions Work side by side and support the Customer Success teams in order to meet customer business needs. Interact with clients to understand business needs and collaborate on project scopes, planning, and execution. Requirements: Graduate with a degree in Industrial Engineering and Management or a similar major Experience with databases and SQL - a Must Outstanding technical and analytical skills Highly motivated with an exceptional work ethic High attention to detail with an ability to work on multiple projects simultaneously Strong interpersonal and communication skills Quick, self-learning capabilities and creativity in problem-solving Preferred: Familiarity with Python Familiarity with Airflow, ETL tools, Snowflake and MSSQL Hands-on with VCS (Git) Opened URL: https://il.indeed.com/rc/clk?jk=2801e9b70cffdf56&bb=r6UIYw2mow7Pn8IzQwq2_w5YrxcEPRyMpab_ptbJnVUDkRmEoNNi7UMraqcjAeiFuNnjUruViO-PX0WlliOY0l-uH1XqjwIaiy7fbwsHkyj9Q3jCnteWwoMjH-QmTHz4&xkcb=SoCe67M33wH7H8WWaB0HbzkdCdPP&fccid=5ad6f11eb660c9a3&vjs=3</td><td>data</td><td>Optimove is a global marketing tech company, recognized as a Leader by Forrester and a Challenger by Gartner. We work with some of the world's most exciting brands, such as Sephora, Staples, and Entain, who love our thought-provoking combination of art and science. With a strong product, a proven business, and the DNA of a vibrant, fast-growing startup, we're on the cusp of our next growth spurt. It's the perfect time to join our team of ~450 thinkers and doers across NYC, LDN, TLV, and other locations, where 2 of every 3 managers were promoted from within. Growing your career with Optimove is basically guaranteed. As a Customer Data Engineer, you will be a part of a strong energetic, and fast-growing global team. You will be an integral part of clients' onboarding and ongoing data requests and projects. You will be working closely with internal PM and CSM teams as well as interacting directly with clients' data teams across different business verticals. Your core responsibilities will involve playing an active role in collaborating with internal teams to construct tailored data transformations and manipulations while working with top-notch technology (Cloud tech etc.) The ideal candidate is an SQL whiz with a strong work ethic, robust analytical and technical capabilities, and highly effective time management skills. We are looking for a master multi-tasker who thrives in challenging, fast-paced environments, with agility and ease. The Customer Data Engineer is a position that brings with it an excellent opportunity to learn and grow within a rapidly expanding company on the cutting edge of Martech. Responsibilities: Develop and support a wide range of data transformations and migrations Construct custom ETL processes: Design and implementation of data pipelines and data marts, access versatile data sources, and apply data quality measures Investigate data mismatches and apply solutions Work side by side and support the Customer Success teams in order to meet customer business needs. Interact with clients to understand business needs and collaborate on project scopes, planning, and execution. Requirements: Graduate with a degree in Industrial Engineering and Management or a similar major Experience with databases and SQL - a Must Outstanding technical and analytical skills Highly motivated with an exceptional work ethic High attention to detail with an ability to work on multiple projects simultaneously Strong interpersonal and communication skills Quick, self-learning capabilities and creativity in problem-solving Preferred: Familiarity with Python Familiarity with Airflow, ETL tools, Snowflake and MSSQL Hands-on with VCS (Git)</td><td>Optimove is a global marketing tech company, recognized as a Leader by Forrester and a Challenger by Gartner. We work with some of the world's most exciting brands, such as Sephora, Staples, and Entain, who love our thought-provoking combination of art and science. With a strong product, a proven business, and the DNA of a vibrant, fast-growing startup, we're on the cusp of our next growth spurt. It's the perfect time to join our team of ~450 thinkers and doers across NYC, LDN, TLV, and other locations, where 2 of every 3 managers were promoted from within. Growing your career with Optimove is basically guaranteed. As a Customer Data Engineer, you will be a part of a strong energetic, and fast-growing global team. You will be an integral part of clients' onboarding and ongoing data requests and projects. You will be working closely with internal PM and CSM teams as well as interacting directly with clients' data teams across different business verticals. Your core responsibilities will involve playing an active role in collaborating with internal teams to construct tailored data transformations and manipulations while working with top-notch technology (Cloud tech etc.) The ideal candidate is an SQL whiz with a strong work ethic, robust analytical and technical capabilities, and highly effective time management skills. We are looking for a master multi-tasker who thrives in challenging, fast-paced environments, with agility and ease. The Customer Data Engineer is a position that brings with it an excellent opportunity to learn and grow within a rapidly expanding company on the cutting edge of Martech. Responsibilities: Develop and support a wide range of data transformations and migrations Construct custom ETL processes: Design and implementation of data pipelines and data marts, access versatile data sources, and apply data quality measures Investigate data mismatches and apply solutions Work side by side and support the Customer Success teams in order to meet customer business needs. Interact with clients to understand business needs and collaborate on project scopes, planning, and execution. Requirements: Graduate with a degree in Industrial Engineering and Management or a similar major Experience with databases and SQL - a Must Outstanding technical and analytical skills Highly motivated with an exceptional work ethic High attention to detail with an ability to work on multiple projects simultaneously Strong interpersonal and communication skills Quick, self-learning capabilities and creativity in problem-solving Preferred: Familiarity with Python Familiarity with Airflow, ETL tools, Snowflake and MSSQL Hands-on with VCS (Git)</td></tr><tr><td>Big Data developer - Python</td><td>Twingo</td><td>Twingo is expanding, seeking an experienced Python developer for challenging work in the world of Big Data. Design, develop & maintain the BIG DATA platform (Vertica). Design, develop & maintain the BIG DATA infrastructure (development, monitoring, installation, integration, etc…) Be part of the dynamic and agile core DBA team. Collaborate with field engineers for the deployment phases. Work on major, challenging projects with enterprise and startup customers. Job location – Herzliya, Israel. Job Requirements: Over 2 years' experience as Python developer in Linux environment. Experience with databases. Undergraduate degree in computer science / engineering or candidates with army service in software development / system administration - a significant advantage. Patient and service-oriented, can fit well into a team, good self-learning skills and lateral, high-pressure work. Experience in working with customers. Opened URL: https://il.indeed.com/rc/clk?jk=c19d1cad9dfac480&bb=r6UIYw2mow7Pn8IzQwq2_1pZAzVOBHM0DYmSIYa34WBvnAamHO4Ok1tcWLDfBqnaqv0QgONqdvfNCabooHoJG0DnY_ci2L47la6OLaltBVelfNRHRTMUwg%3D%3D&xkcb=SoAq67M33wH7H8WWaB0GbzkdCdPP&fccid=734cb5a01ee60f80&vjs=3</td><td>data</td><td>Twingo is expanding, seeking an experienced Python developer for challenging work in the world of Big Data. Design, develop & maintain the BIG DATA platform (Vertica). Design, develop & maintain the BIG DATA infrastructure (development, monitoring, installation, integration, etc…) Be part of the dynamic and agile core DBA team. Collaborate with field engineers for the deployment phases. Work on major, challenging projects with enterprise and startup customers. Job location – Herzliya, Israel. Job Requirements: Over 2 years' experience as Python developer in Linux environment. Experience with databases. Undergraduate degree in computer science / engineering or candidates with army service in software development / system administration - a significant advantage. Patient and service-oriented, can fit well into a team, good self-learning skills and lateral, high-pressure work. Experience in working with customers.</td><td>Twingo is expanding, seeking an experienced Python developer for challenging work in the world of Big Data. Design, develop & maintain the BIG DATA platform (Vertica). Design, develop & maintain the BIG DATA infrastructure (development, monitoring, installation, integration, etc…) Be part of the dynamic and agile core DBA team. Collaborate with field engineers for the deployment phases. Work on major, challenging projects with enterprise and startup customers. Job location – Herzliya, Israel. Job Requirements: Over 2 years' experience as Python developer in Linux environment. Experience with databases. Undergraduate degree in computer science / engineering or candidates with army service in software development / system administration - a significant advantage. Patient and service-oriented, can fit well into a team, good self-learning skills and lateral, high-pressure work. Experience in working with customers.</td></tr><tr><td>Data Center Logistic Technician - Modi'in area</td><td>Microsoft</td><td>** The position is located in Modi'in area ** As a Microsoft Data Center Inventory & Asset Technician (DIAT), you will perform cycle audits, execute incoming/outgoing deliveries, coordinate security escorts for third-party vendors, and document inbound and outbound deliveries. This opportunity will allow you to deepen your knowledge of inventory management principles, warranty process management, data bearing device destruction and advance your career in the process. Microsoft’s Cloud Operations & Innovation (CO+I) is the engine that powers our cloud services. As a CO+I DIAT, you will perform a key role in delivering the core infrastructure and foundational technologies for Microsoft's online services including Bing, Office 365, Xbox, OneDrive, and the Microsoft Azure platform. As a group, CO+I is focused on the personal and professional development of all employees and offers training and opportunities including Career Rotation Programs, Diversity & Inclusion training and events, and professional certifications. Our infrastructure is comprised of a large global portfolio of more than 200 Data Centers in 32 countries and millions of servers. Our foundation is built upon and managed by a team of subject matter experts working to support services for more than 1 billion customers and 20 million businesses in over 90 countries worldwide. With environmental sustainability and optimization at the forefront of our data center design and operations, we continue to grow and evolve as we meet the ever-changing business demands that hold Microsoft as a world-class cloud provider. Microsoft’s mission is to empower every person and every organization on the planet to achieve more. As employees we come together with a growth mindset, innovate to empower others, and collaborate to realize our shared goals. Each day we build on our values of respect, integrity, and accountability to create a culture of inclusion where everyone can thrive at work and beyond. Responsibilities Responsibilities Perform assigned tasks and escalate issues during high-volume work activity or escalation-based situations. Coordinate with suppliers to initiate warranty claim and process failed vendor hardware devices. This includes information processing, packaging, shipment, and receipt of return for Return Merchandise Authorization (RMA) devices following all Service Level Agreements (SLAs) related to RMA warranty process. Leverage process knowledge and best judgment to complete tasks with minimal direct supervision. Maintains a strong focus to understand the impact of their work when completing tickets and assigned Inventory and Asset Management (IAM) tasks. Maintains and steward up-to-date and accurate logical information within various inventory management systems (e.g., configuration management databases, asset management repositories). Ensures detailed physical inventory tracking and staging. Help to reconcile and report inventory discrepancies. Performs destruction of data bearing devices (DBD) following all Service Level Agreements (SLAs) and Microsoft policies as necessary. Notifies management about ordering stock shortages. Escalates any issues to management. Comply with security and data management policies. Embody our culture and values. Qualifications Required Qualifications High School Diploma AND experience warehouse/supply chain in an information technology (IT) environment, inventory management, retail, warehouse management, or a related field.OR equivalent experience. Background Check Requirements: Ability to meet Microsoft, customer and/or government security screening requirements are required for this role. These requirements include, but are not limited to the following specialized security screenings: Microsoft Cloud Background Check: This position will be required to pass the Microsoft Cloud background check upon hire/transfer and every two years thereafter. While not required, we also look for the following Preferred Qualifications: Relevant experience in warehouse/supply chain in an information technology (IT) environment, IT, and/or logistics, operating heavy-load movement equipment (e.g., forklift, pallet jacks, chassis lifts) for a large corporationOR equivalent experience. Microsoft is an equal opportunity employer. Consistent with applicable law, all qualified applicants will receive consideration for employment without regard to age, ancestry, citizenship, color, family or medical care leave, gender identity or expression, genetic information, immigration status, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran or military status, race, ethnicity, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable local laws, regulations and ordinances. If you need assistance and/or a reasonable accommodation due to a disability during the application process, read more about requesting accommodations. Opened URL: https://il.indeed.com/rc/clk?jk=e57b247de9bde4dd&bb=r6UIYw2mow7Pn8IzQwq2__CkT25UDgRwVF_9f7ZaRSjdBIWcrWHk-ex2bdY0zgr_RLIW8YyoIl0crPMjPIZL2bRv0qEOMbn7ATn7Yo8l-gim9tJijJTbi8u6Ls13HnO4&xkcb=SoC367M33wH7H8WWaB0FbzkdCdPP&fccid=a92bc8931562ec31&vjs=3</td><td>data</td><td>** The position is located in Modi'in area ** As a Microsoft Data Center Inventory & Asset Technician (DIAT), you will perform cycle audits, execute incoming/outgoing deliveries, coordinate security escorts for third-party vendors, and document inbound and outbound deliveries. This opportunity will allow you to deepen your knowledge of inventory management principles, warranty process management, data bearing device destruction and advance your career in the process. Microsoft’s Cloud Operations & Innovation (CO+I) is the engine that powers our cloud services. As a CO+I DIAT, you will perform a key role in delivering the core infrastructure and foundational technologies for Microsoft's online services including Bing, Office 365, Xbox, OneDrive, and the Microsoft Azure platform. As a group, CO+I is focused on the personal and professional development of all employees and offers training and opportunities including Career Rotation Programs, Diversity & Inclusion training and events, and professional certifications. Our infrastructure is comprised of a large global portfolio of more than 200 Data Centers in 32 countries and millions of servers. Our foundation is built upon and managed by a team of subject matter experts working to support services for more than 1 billion customers and 20 million businesses in over 90 countries worldwide. With environmental sustainability and optimization at the forefront of our data center design and operations, we continue to grow and evolve as we meet the ever-changing business demands that hold Microsoft as a world-class cloud provider. Microsoft’s mission is to empower every person and every organization on the planet to achieve more. As employees we come together with a growth mindset, innovate to empower others, and collaborate to realize our shared goals. Each day we build on our values of respect, integrity, and accountability to create a culture of inclusion where everyone can thrive at work and beyond. Responsibilities Responsibilities Perform assigned tasks and escalate issues during high-volume work activity or escalation-based situations. Coordinate with suppliers to initiate warranty claim and process failed vendor hardware devices. This includes information processing, packaging, shipment, and receipt of return for Return Merchandise Authorization (RMA) devices following all Service Level Agreements (SLAs) related to RMA warranty process. Leverage process knowledge and best judgment to complete tasks with minimal direct supervision. Maintains a strong focus to understand the impact of their work when completing tickets and assigned Inventory and Asset Management (IAM) tasks. Maintains and steward up-to-date and accurate logical information within various inventory management systems (e.g., configuration management databases, asset management repositories). Ensures detailed physical inventory tracking and staging. Help to reconcile and report inventory discrepancies. Performs destruction of data bearing devices (DBD) following all Service Level Agreements (SLAs) and Microsoft policies as necessary. Notifies management about ordering stock shortages. Escalates any issues to management. Comply with security and data management policies. Embody our culture and values. Qualifications Required Qualifications High School Diploma AND experience warehouse/supply chain in an information technology (IT) environment, inventory management, retail, warehouse management, or a related field.OR equivalent experience. Background Check Requirements: Ability to meet Microsoft, customer and/or government security screening requirements are required for this role. These requirements include, but are not limited to the following specialized security screenings: Microsoft Cloud Background Check: This position will be required to pass the Microsoft Cloud background check upon hire/transfer and every two years thereafter. While not required, we also look for the following Preferred Qualifications: Relevant experience in warehouse/supply chain in an information technology (IT) environment, IT, and/or logistics, operating heavy-load movement equipment (e.g., forklift, pallet jacks, chassis lifts) for a large corporationOR equivalent experience. Microsoft is an equal opportunity employer. Consistent with applicable law, all qualified applicants will receive consideration for employment without regard to age, ancestry, citizenship, color, family or medical care leave, gender identity or expression, genetic information, immigration status, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran or military status, race, ethnicity, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable local laws, regulations and ordinances. If you need assistance and/or a reasonable accommodation due to a disability during the application process, read more about requesting accommodations.</td><td>** The position is located in Modi'in area ** As a Microsoft Data Center Inventory & Asset Technician (DIAT), you will perform cycle audits, execute incoming/outgoing deliveries, coordinate security escorts for third-party vendors, and document inbound and outbound deliveries. This opportunity will allow you to deepen your knowledge of inventory management principles, warranty process management, data bearing device destruction and advance your career in the process. Microsoft’s Cloud Operations & Innovation (CO+I) is the engine that powers our cloud services. As a CO+I DIAT, you will perform a key role in delivering the core infrastructure and foundational technologies for Microsoft's online services including Bing, Office 365, Xbox, OneDrive, and the Microsoft Azure platform. As a group, CO+I is focused on the personal and professional development of all employees and offers training and opportunities including Career Rotation Programs, Diversity & Inclusion training and events, and professional certifications. Our infrastructure is comprised of a large global portfolio of more than 200 Data Centers in 32 countries and millions of servers. Our foundation is built upon and managed by a team of subject matter experts working to support services for more than 1 billion customers and 20 million businesses in over 90 countries worldwide. With environmental sustainability and optimization at the forefront of our data center design and operations, we continue to grow and evolve as we meet the ever-changing business demands that hold Microsoft as a world-class cloud provider. Microsoft’s mission is to empower every person and every organization on the planet to achieve more. As employees we come together with a growth mindset, innovate to empower others, and collaborate to realize our shared goals. Each day we build on our values of respect, integrity, and accountability to create a culture of inclusion where everyone can thrive at work and beyond. Responsibilities Responsibilities Perform assigned tasks and escalate issues during high-volume work activity or escalation-based situations. Coordinate with suppliers to initiate warranty claim and process failed vendor hardware devices. This includes information processing, packaging, shipment, and receipt of return for Return Merchandise Authorization (RMA) devices following all Service Level Agreements (SLAs) related to RMA warranty process. Leverage process knowledge and best judgment to complete tasks with minimal direct supervision. Maintains a strong focus to understand the impact of their work when completing tickets and assigned Inventory and Asset Management (IAM) tasks. Maintains and steward up-to-date and accurate logical information within various inventory management systems (e.g., configuration management databases, asset management repositories). Ensures detailed physical inventory tracking and staging. Help to reconcile and report inventory discrepancies. Performs destruction of data bearing devices (DBD) following all Service Level Agreements (SLAs) and Microsoft policies as necessary. Notifies management about ordering stock shortages. Escalates any issues to management. Comply with security and data management policies. Embody our culture and values. Qualifications Required Qualifications High School Diploma AND experience warehouse/supply chain in an information technology (IT) environment, inventory management, retail, warehouse management, or a related field.OR equivalent experience. Background Check Requirements: Ability to meet Microsoft, customer and/or government security screening requirements are required for this role. These requirements include, but are not limited to the following specialized security screenings: Microsoft Cloud Background Check: This position will be required to pass the Microsoft Cloud background check upon hire/transfer and every two years thereafter. While not required, we also look for the following Preferred Qualifications: Relevant experience in warehouse/supply chain in an information technology (IT) environment, IT, and/or logistics, operating heavy-load movement equipment (e.g., forklift, pallet jacks, chassis lifts) for a large corporationOR equivalent experience. Microsoft is an equal opportunity employer. Consistent with applicable law, all qualified applicants will receive consideration for employment without regard to age, ancestry, citizenship, color, family or medical care leave, gender identity or expression, genetic information, immigration status, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran or military status, race, ethnicity, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable local laws, regulations and ordinances. If you need assistance and/or a reasonable accommodation due to a disability during the application process, read more about requesting accommodations.</td></tr><tr><td>Data scientist</td><td>OSR Enterprises</td><td>DESCRIPTION Our fantastic team at OSR is expanding to meet the growing demand of our customers and we are interested in welcoming a Data Scientist to join our team, and to design and develop proprietary AI models for OSR's industry-leading OEM customers. REQUIREMENTS 4+ years of experience in data science/analytics Strong problem-solving skills with an emphasis on product development Advantage to those who have experience in stock/futures prediction Experience using statistical computer languages (Python) to manipulate data and draw insights from large data sets. Knowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) auto sklearn catboost arima lstm deep learning gan Coding knowledge and experience with javascript python experience with mongodb Opened URL: https://il.indeed.com/rc/clk?jk=bc58153ac4bcd56c&bb=r6UIYw2mow7Pn8IzQwq2_59qcD9-4FNf4ieCxpbzTC4e8P_IgdneHMeW5NnOHVdKbFJpxx8zmc8CgKk3eYBNOXeADXxOt-jD_fy5SqdU9z1p5gmQKZJFg3b3GmIjSI3z&xkcb=SoAD67M33wH7H8WWaB0EbzkdCdPP&fccid=8e007f7a76f9cee5&vjs=3</td><td>data</td><td>DESCRIPTION Our fantastic team at OSR is expanding to meet the growing demand of our customers and we are interested in welcoming a Data Scientist to join our team, and to design and develop proprietary AI models for OSR's industry-leading OEM customers. REQUIREMENTS 4+ years of experience in data science/analytics Strong problem-solving skills with an emphasis on product development Advantage to those who have experience in stock/futures prediction Experience using statistical computer languages (Python) to manipulate data and draw insights from large data sets. Knowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) auto sklearn catboost arima lstm deep learning gan Coding knowledge and experience with javascript python experience with mongodb</td><td>DESCRIPTION Our fantastic team at OSR is expanding to meet the growing demand of our customers and we are interested in welcoming a Data Scientist to join our team, and to design and develop proprietary AI models for OSR's industry-leading OEM customers. REQUIREMENTS 4+ years of experience in data science/analytics Strong problem-solving skills with an emphasis on product development Advantage to those who have experience in stock/futures prediction Experience using statistical computer languages (Python) to manipulate data and draw insights from large data sets. Knowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) auto sklearn catboost arima lstm deep learning gan Coding knowledge and experience with javascript python experience with mongodb</td></tr><tr><td>Data Scientist</td><td>ThetaRay</td><td>Israel, Hod HaSharon Description About ThetaRay: ThetaRay is a trailblazer in AI-powered Anti-Money Laundering (AML) solutions, offering cutting-edge technology to fintechs, banks, and regulatory bodies worldwide. Our mission is to enhance trust in financial transactions, ensuring compliant and innovative business growth. Our technology empowers customers to expand into new markets and introduce groundbreaking products. Why Join ThetaRay? At ThetaRay, you'll be part of a dynamic global team committed to redefining the financial services sector through technological innovation. You will contribute to creating safer financial environments and have the opportunity to work with some of the brightest minds in AI, ML, and financial technology. We offer a collaborative, inclusive, and forward-thinking work environment where your ideas and contributions are valued and encouraged. Join us in our mission to revolutionize the financial world, making it safer and more trustworthy for millions worldwide. Explore exciting career opportunities at ThetaRay – where innovation meets purpose. ThetaRay is looking for a Data Scientist to join our innovative Data team. As a Data Scientist, you will work on customer-facing projects that combine data science with deep knowledge and understanding of machine learning and big data technologies to create solutions for customers’ challenges and needs, defining and developing appropriate technical and business solutions. The Data Scientist will work closely with ThetaRay’s Product Management, Algorithm, Engineering, and Customer Success teams and lead external partners to successful implementations of the ThetaRay platform and solutions. Key Responsibilities Manage and design the Customer-specific technical AI solutions throughout the project life cycle Leverage business knowledge to perform sophisticated feature engineering and enhance model performance. Extract insights and actionable recommendations from large volumes of data, applying advanced analytical methods. Collaborate with customers and partners, building and managing strong technical relationships to ensure project success. Train customers on system usage and monitoring, ensuring they can independently operate and maintain AI solutions. Contribute to product development by providing feedback and requirements to the Product Management team. Requirements Up to 3 years of experience as a data scientist/data engineer/big-data developer. BSc or equivalent in Mathematics, Statistics, Data Science or another related field. Proven professional experience in data analytics for financial services with strong data mining and forensic skills - an advantage. Experience working with customers. Advantage – financial customers. Must have Hands-on experience and knowledge of scripting languages: Python/PySpark as well as DS workflow management tools including MLflow, Airflow, etc. Working experience with Linux OS - an advantage. Fluent English - written and spoken. Core Competencies Able to solve tech problems for customers; improvise; cope with unexpected challenges Able to drive relevant internal functions to deliver/solve a problem for customers/partners A motivated, self-starter who can demonstrate high analytical and technical skills Ability to design creative solutions for complex requirements Ability to learn and lead projects independently, and to work with minimal supervision with customers (tech & business) Strong interpersonal relationship building Ability to execute multiple projects and drive key business results under tight deadlines Title: Data Analytics Company: Apple URL: https://il.indeed.com/rc/clk?jk=ac672ca32924abdf&bb=BGdJhL7PsYZ4SswVjb_w9lUJuctaSIleJFP6t_iTTb9om4BB2JGmxqqcGBGNMHtAbPJKgjTls5s5PdL8YAetIYXUHWb37RZmHYCai3XfMqktmghpR6ZG5w%3D%3D&xkcb=SoC567M33wYFPvxCCB0JbzkdCdPP&fccid=c1099851e9794854&vjs=3  Title: Junior Backend Big Data Developer Company: ThetaRay URL: https://il.indeed.com/rc/clk?jk=0433bc7e45e694a3&bb=BGdJhL7PsYZ4SswVjb_w9tZctL9d9lDO1fzq1peAT0ZLrakcBnhNhkpz-5eXBrhQOSFC7U1ofJm283GSwM8v81b68WUjW80pT7t4nTaUtYSp1gcmuVxU9yrGgWa8yPWS&xkcb=SoAN67M33wYFPvxCCB0IbzkdCdPP&fccid=8e007f7a76f9cee5&vjs=3  Title: Marketing Data Analyst Company: Plarium URL: https://il.indeed.com/rc/clk?jk=bc34db8ca4455a09&bb=BGdJhL7PsYZ4SswVjb_w9t54ZD8t3SitGT5-BfTl4QOKkWGzJj3FVoB1KmERYU_ye23ixJnIkqwGdRTbEiG4AFU0nNSJM28cNKU5UzNphxreBDX9febbck_Atk8H536k&xkcb=SoCD67M33wYFPvxCCB0PbzkdCdPP&fccid=fa9a43168015ecb7&vjs=3  Title: Data Scientist Company: Rubrik Job Board URL: https://il.indeed.com/rc/clk?jk=ae2c3d8865d70a20&bb=BGdJhL7PsYZ4SswVjb_w9o2JtdoEQve4qgkrlC6WwTi3umPZ4B-IFEmImCmMJtmrRr7UFbwi7DQLFjb8OEkfbRDjCFJoiETxYY8Gil9XTBzAGEyi-hMijoaR5UkwCiwa&xkcb=SoA367M33wYFPvxCCB0ObzkdCdPP&fccid=ba03cd038fd30855&vjs=3  Title: Junior Data Engineer Company: Aquant URL: https://il.indeed.com/rc/clk?jk=332ce6560e8316dc&bb=BGdJhL7PsYZ4SswVjb_w9k3DOMfBiaxxMrDVCiRcvrdccE6_iqjDgv5qLhS-o3x635UuE8vbYbn4pXqgJpP8NpynZFuZsS_cVqcS064xogOHbVv-onaq9-Q-nN3pO0OF&xkcb=SoCq67M33wYFPvxCCB0NbzkdCdPP&fccid=4d28265c01696bc0&vjs=3  Title: Big Data developer - Python Company: Twingo URL: https://il.indeed.com/rc/clk?jk=2801e9b70cffdf56&bb=BGdJhL7PsYZ4SswVjb_w9j7v8KuNu2tCLw3g53k_1fAx34okgvYiivAXUx6AL2XLonyRjgN9SPmEl6lYms4CNFfuFGDGZde4q-a1C0pZFlp5U3L5_2t8bgaxhMpJoPA0&xkcb=SoAe67M33wYFPvxCCB0MbzkdCdPP&fccid=5ad6f11eb660c9a3&vjs=3  Title: Data Scientist Company: Ticomsoft URL: https://il.indeed.com/rc/clk?jk=f90aa7093544f010&bb=BGdJhL7PsYZ4SswVjb_w9rgUmDffsY2lAB-5jgHcOEsmKkp6YRm5F_4VD5V22dkVmfCvfcQnwuUDqwDTBx4MT0U0gi31kd_OuX4r3xE7ilgc3UBIYqsyc0JjDLVAFWDS&xkcb=SoD367M33wYFPvxCCB0DbzkdCdPP&fccid=e32508b84ec45c2b&vjs=3  Title: data scientist! Company: Horizon Technologies URL: https://il.indeed.com/rc/clk?jk=ad3b38d6d843bb02&bb=BGdJhL7PsYZ4SswVjb_w9nOnjizfm1DZk6CYD9osf9HXUSfUPMb1a-9ZLsuXCwrlBqeILjvSezyX1-gmyu9geRcfNxMTuMt9HJfOAM8kYQaY_YWwb9fLmjDuI7Y8PDl0&xkcb=SoBD67M33wYFPvxCCB0CbzkdCdPP&fccid=c4e7a75c6cddb35a&vjs=3  Title: Customer Data Engineer Company: Optimove URL: https://il.indeed.com/rc/clk?jk=d93f96511474983d&bb=BGdJhL7PsYZ4SswVjb_w9j-Q9VHk-0XC0eo86uehIDlqFrY6tGtSK3zwot98ERqUmbN6JEPOZD19gLgaU91rm3BX4JC08mLXO9oxy6YaaJkwcUgRNwGqnyopTf6yevoE&xkcb=SoDe67M33wYFPvxCCB0BbzkdCdPP&fccid=9c02dc25b0c9c8ac&vjs=3  Title: Data Scientist Company: ThetaRay URL: https://il.indeed.com/rc/clk?jk=bc58153ac4bcd56c&bb=BGdJhL7PsYZ4SswVjb_w9vfZQAUETolil2lD637eoaYgyheNv5Yu1K2_pxeDq7ZtauWoT8rjUz8Mo78Rv4k6cB1_tw8ArLM2vqiRn7F4qB8YKEBQlXNDmg3YRUxzIzhF&xkcb=SoBq67M33wYFPvxCCB0AbzkdCdPP&fccid=8e007f7a76f9cee5&vjs=3  Title: Data scientist Company: OSR Enterprises URL: https://il.indeed.com/rc/clk?jk=e57b247de9bde4dd&bb=BGdJhL7PsYZ4SswVjb_w9geuj3wgL-obokFcrSGHlAkC6n6bEKkI-JhWdADF0KR3PuWS8PqEEW47j4LdgiDYLppRztwvh7MmUVKul5q6BPFJq86x9mE1eCxb2tYqWjLo&xkcb=SoDk67M33wYFPvxCCB0HbzkdCdPP&fccid=a92bc8931562ec31&vjs=3  Title: Data Annotator Company: Prisma Photonics URL: https://il.indeed.com/rc/clk?jk=f8a4240257a1f2ce&bb=BGdJhL7PsYZ4SswVjb_w9lbsgbppnSXkxtntFoLHwbk8S30ouRCNlIKZphM7G-fpTiKb-oCs66brxMV9mLmnS00daEZteLzNREnL5LOOIXmwnKsyUsJfEzfRfA4oupZd&xkcb=SoBQ67M33wYFPvxCCB0GbzkdCdPP&fccid=69237999e36cf5e9&vjs=3  Title: Data scientist Company: Paretix URL: https://il.indeed.com/rc/clk?jk=84d116dfdbf90062&bb=BGdJhL7PsYZ4SswVjb_w9jqi2ApkupLuiyZ9CJVnUigR0uumxobvqAtSdgFQh9DtZv_NBXfFsftzio8G3d5rlOvt3vz8BnAyeBLlThdizbHEJAHPkAs0PiD6a4aWU6_X&xkcb=SoDN67M33wYFPvxCCB0FbzkdCdPP&fccid=433c536613b198d9&vjs=3  Title: Data Engineer Company: ThriveDX URL: https://il.indeed.com/rc/clk?jk=42faf2905ed04064&bb=BGdJhL7PsYZ4SswVjb_w9sHT2Xwnr5uMDoEbl4dDLhFe0sKArF13GdwKoesVDl6w8YK6meb8KIt6tJRWmOUDFb1gGNBK--fxkSnSEe2URvFzYSgY8HLukAMd4Si2WDBs&xkcb=SoB567M33wYFPvxCCB0EbzkdCdPP&fccid=33301e5fe136476a&vjs=3  Title: Junior Data Analyst Company: DRS RADA TECHNOLOGIES URL: https://il.indeed.com/rc/clk?jk=d3edcab0a733eff6&bb=BGdJhL7PsYZ4SswVjb_w9knVwklo7TRTJolJGWVmUPtFaq-RMmHpMos5LIqwccBefMBf3YBKk19zL9DR8lAEy9CNpEanUkUE-57EEZuhVg8zm_5_yCbEuqMVkxqf2Fx3&xkcb=SoBe67M33wYFPvxCCB0bbzkdCdPP&fccid=3bc7c5a346eb42c1&vjs=3  Opened URL: https://il.indeed.com/rc/clk?jk=ac672ca32924abdf&bb=r6UIYw2mow7Pn8IzQwq2_947tjj67RppMknwoYuJzOzzr9AMXp01AtLsTLDv2CvxbUCGqSnscg1DI_R2JgGAaqdglT_DZvYUPWCd6LL_FsOlpDbDP4x7fQ%3D%3D&xkcb=SoBe67M33wH7H8WWaB0KbzkdCdPP&fccid=c1099851e9794854&vjs=3</td><td>data</td><td>Israel, Hod HaSharon Description About ThetaRay: ThetaRay is a trailblazer in AI-powered Anti-Money Laundering (AML) solutions, offering cutting-edge technology to fintechs, banks, and regulatory bodies worldwide. Our mission is to enhance trust in financial transactions, ensuring compliant and innovative business growth. Our technology empowers customers to expand into new markets and introduce groundbreaking products. Why Join ThetaRay? At ThetaRay, you'll be part of a dynamic global team committed to redefining the financial services sector through technological innovation. You will contribute to creating safer financial environments and have the opportunity to work with some of the brightest minds in AI, ML, and financial technology. We offer a collaborative, inclusive, and forward-thinking work environment where your ideas and contributions are valued and encouraged. Join us in our mission to revolutionize the financial world, making it safer and more trustworthy for millions worldwide. Explore exciting career opportunities at ThetaRay – where innovation meets purpose. ThetaRay is looking for a Data Scientist to join our innovative Data team. As a Data Scientist, you will work on customer-facing projects that combine data science with deep knowledge and understanding of machine learning and big data technologies to create solutions for customers’ challenges and needs, defining and developing appropriate technical and business solutions. The Data Scientist will work closely with ThetaRay’s Product Management, Algorithm, Engineering, and Customer Success teams and lead external partners to successful implementations of the ThetaRay platform and solutions. Key Responsibilities Manage and design the Customer-specific technical AI solutions throughout the project life cycle Leverage business knowledge to perform sophisticated feature engineering and enhance model performance. Extract insights and actionable recommendations from large volumes of data, applying advanced analytical methods. Collaborate with customers and partners, building and managing strong technical relationships to ensure project success. Train customers on system usage and monitoring, ensuring they can independently operate and maintain AI solutions. Contribute to product development by providing feedback and requirements to the Product Management team. Requirements Up to 3 years of experience as a data scientist/data engineer/big-data developer. BSc or equivalent in Mathematics, Statistics, Data Science or another related field. Proven professional experience in data analytics for financial services with strong data mining and forensic skills - an advantage. Experience working with customers. Advantage – financial customers. Must have Hands-on experience and knowledge of scripting languages: Python/PySpark as well as DS workflow management tools including MLflow, Airflow, etc. Working experience with Linux OS - an advantage. Fluent English - written and spoken. Core Competencies Able to solve tech problems for customers; improvise; cope with unexpected challenges Able to drive relevant internal functions to deliver/solve a problem for customers/partners A motivated, self-starter who can demonstrate high analytical and technical skills Ability to design creative solutions for complex requirements Ability to learn and lead projects independently, and to work with minimal supervision with customers (tech & business) Strong interpersonal relationship building Ability to execute multiple projects and drive key business results under tight deadlines Title: Data Analytics Company: Apple URL:   Title: Junior Backend Big Data Developer Company: ThetaRay URL:   Title: Marketing Data Analyst Company: Plarium URL:   Title: Data Scientist Company: Rubrik Job Board URL:   Title: Junior Data Engineer Company: Aquant URL:   Title: Big Data developer - Python Company: Twingo URL:   Title: Data Scientist Company: Ticomsoft URL:   Title: data scientist! Company: Horizon Technologies URL:   Title: Customer Data Engineer Company: Optimove URL:   Title: Data Scientist Company: ThetaRay URL:   Title: Data scientist Company: OSR Enterprises URL:   Title: Data Annotator Company: Prisma Photonics URL:   Title: Data scientist Company: Paretix URL:   Title: Data Engineer Company: ThriveDX URL:   Title: Junior Data Analyst Company: DRS RADA TECHNOLOGIES URL: </td><td>Israel, Hod HaSharon Description About ThetaRay: ThetaRay is a trailblazer in AI-powered Anti-Money Laundering (AML) solutions, offering cutting-edge technology to fintechs, banks, and regulatory bodies worldwide. Our mission is to enhance trust in financial transactions, ensuring compliant and innovative business growth. Our technology empowers customers to expand into new markets and introduce groundbreaking products. Why Join ThetaRay? At ThetaRay, you'll be part of a dynamic global team committed to redefining the financial services sector through technological innovation. You will contribute to creating safer financial environments and have the opportunity to work with some of the brightest minds in AI, ML, and financial technology. We offer a collaborative, inclusive, and forward-thinking work environment where your ideas and contributions are valued and encouraged. Join us in our mission to revolutionize the financial world, making it safer and more trustworthy for millions worldwide. Explore exciting career opportunities at ThetaRay – where innovation meets purpose. ThetaRay is looking for a Data Scientist to join our innovative Data team. As a Data Scientist, you will work on customer-facing projects that combine data science with deep knowledge and understanding of machine learning and big data technologies to create solutions for customers’ challenges and needs, defining and developing appropriate technical and business solutions. The Data Scientist will work closely with ThetaRay’s Product Management, Algorithm, Engineering, and Customer Success teams and lead external partners to successful implementations of the ThetaRay platform and solutions. Key Responsibilities Manage and design the Customer-specific technical AI solutions throughout the project life cycle Leverage business knowledge to perform sophisticated feature engineering and enhance model performance. Extract insights and actionable recommendations from large volumes of data, applying advanced analytical methods. Collaborate with customers and partners, building and managing strong technical relationships to ensure project success. Train customers on system usage and monitoring, ensuring they can independently operate and maintain AI solutions. Contribute to product development by providing feedback and requirements to the Product Management team. Requirements Up to 3 years of experience as a data scientist/data engineer/big-data developer. BSc or equivalent in Mathematics, Statistics, Data Science or another related field. Proven professional experience in data analytics for financial services with strong data mining and forensic skills - an advantage. Experience working with customers. Advantage – financial customers. Must have Hands-on experience and knowledge of scripting languages: Python/PySpark as well as DS workflow management tools including MLflow, Airflow, etc. Working experience with Linux OS - an advantage. Fluent English - written and spoken. Core Competencies Able to solve tech problems for customers; improvise; cope with unexpected challenges Able to drive relevant internal functions to deliver/solve a problem for customers/partners A motivated, self-starter who can demonstrate high analytical and technical skills Ability to design creative solutions for complex requirements Ability to learn and lead projects independently, and to work with minimal supervision with customers (tech & business) Strong interpersonal relationship building Ability to execute multiple projects and drive key business results under tight deadlines Title: Data Analytics Company: Apple URL:   Title: Junior Backend Big Data Developer Company: ThetaRay URL:   Title: Marketing Data Analyst Company: Plarium URL:   Title: Data Scientist Company: Rubrik Job Board URL:   Title: Junior Data Engineer Company: Aquant URL:   Title: Big Data developer - Python Company: Twingo URL:   Title: Data Scientist Company: Ticomsoft URL:   Title: data scientist! Company: Horizon Technologies URL:   Title: Customer Data Engineer Company: Optimove URL:   Title: Data Scientist Company: ThetaRay URL:   Title: Data scientist Company: OSR Enterprises URL:   Title: Data Annotator Company: Prisma Photonics URL:   Title: Data scientist Company: Paretix URL:   Title: Data Engineer Company: ThriveDX URL:   Title: Junior Data Analyst Company: DRS RADA TECHNOLOGIES URL:</td></tr><tr><td>Data Analytics</td><td>. Our values are at the heart of our success. By joining us, you'll have the opportunity to embody these values and inspire others through your actions.</td><td>Summary Posted: Nov 7, 2024 Role Number: 200577967 We're looking for an exceptional data analyst with a strong background in distributed data processing and a demonstrated ability to turn data into actionable insights. As a data analyst for our Storage Data Analytics team at Apple, you'll play a crucial role in developing the fastest and most efficient SSDs for our products, including the iPhone, iPad, Apple Watch, and new Apple Silicon Macs. If you're passionate about continuously improving the ways we use data to make Apple's products amazing, we want to hear from you! Description On the Storage Data Analytics team, we are responsible for performing ad hoc data analysis, development and maintenance of distributed data pipelines, as well as creation and support of analysis tools. Our team focuses on Apple’s storage solutions. It is small and nimble, able to quickly explore ideas and present them to the storage teams and to leadership. Minimum Qualifications +3 years of experience Ability to lead data investigations and analysis projects with ambiguous requirements Advanced statistic and modeling knowledge Experience visualizing and presenting analyses in tools like Jupyter and Tableau Experience programming in Python in a professional setting Familiarity with distributed computation, storage, and workflow management (e.g. Splunk, Spark, Kubernetes, Kafka, Hadoop, MapReduce, AirFlow etc.) Experience with relational databases and SQL Highly organized, creative, motivated, and passionate about achieving results Curious and have excellent analytical and problem solving skills Excellent written, verbal, and data communication skills Bachelor's or Master's degree in computer science. Preferred Qualifications Familiarity with distributed computation, storage, and workflow management (e.g. Splunk, Spark, Kubernetes, Kafka, Hadoop, MapReduce, AirFlow etc.) Opened URL: https://il.indeed.com/rc/clk?jk=0433bc7e45e694a3&bb=r6UIYw2mow7Pn8IzQwq2_7gXyX4L0a9oUPOLDIseoxAN8l0MRFFfCqpU6vSJRCmVlzxZCXcY6V-lzbB66NkEzDukGjQJgUJrBPff0HR1apFcJos6F0MbonwvLMjHhNz9&xkcb=SoDD67M33wH7H8WWaB0JbzkdCdPP&fccid=8e007f7a76f9cee5&vjs=3</td><td>data</td><td>Summary Posted: Nov 7, 2024 Role Number: 200577967 We're looking for an exceptional data analyst with a strong background in distributed data processing and a demonstrated ability to turn data into actionable insights. As a data analyst for our Storage Data Analytics team at Apple, you'll play a crucial role in developing the fastest and most efficient SSDs for our products, including the iPhone, iPad, Apple Watch, and new Apple Silicon Macs. If you're passionate about continuously improving the ways we use data to make Apple's products amazing, we want to hear from you! Description On the Storage Data Analytics team, we are responsible for performing ad hoc data analysis, development and maintenance of distributed data pipelines, as well as creation and support of analysis tools. Our team focuses on Apple’s storage solutions. It is small and nimble, able to quickly explore ideas and present them to the storage teams and to leadership. Minimum Qualifications +3 years of experience Ability to lead data investigations and analysis projects with ambiguous requirements Advanced statistic and modeling knowledge Experience visualizing and presenting analyses in tools like Jupyter and Tableau Experience programming in Python in a professional setting Familiarity with distributed computation, storage, and workflow management (e.g. Splunk, Spark, Kubernetes, Kafka, Hadoop, MapReduce, AirFlow etc.) Experience with relational databases and SQL Highly organized, creative, motivated, and passionate about achieving results Curious and have excellent analytical and problem solving skills Excellent written, verbal, and data communication skills Bachelor's or Master's degree in computer science. Preferred Qualifications Familiarity with distributed computation, storage, and workflow management (e.g. Splunk, Spark, Kubernetes, Kafka, Hadoop, MapReduce, AirFlow etc.)</td><td>Summary Posted: Nov 7, 2024 Role Number: 200577967 We're looking for an exceptional data analyst with a strong background in distributed data processing and a demonstrated ability to turn data into actionable insights. As a data analyst for our Storage Data Analytics team at Apple, you'll play a crucial role in developing the fastest and most efficient SSDs for our products, including the iPhone, iPad, Apple Watch, and new Apple Silicon Macs. If you're passionate about continuously improving the ways we use data to make Apple's products amazing, we want to hear from you! Description On the Storage Data Analytics team, we are responsible for performing ad hoc data analysis, development and maintenance of distributed data pipelines, as well as creation and support of analysis tools. Our team focuses on Apple’s storage solutions. It is small and nimble, able to quickly explore ideas and present them to the storage teams and to leadership. Minimum Qualifications +3 years of experience Ability to lead data investigations and analysis projects with ambiguous requirements Advanced statistic and modeling knowledge Experience visualizing and presenting analyses in tools like Jupyter and Tableau Experience programming in Python in a professional setting Familiarity with distributed computation, storage, and workflow management (e.g. Splunk, Spark, Kubernetes, Kafka, Hadoop, MapReduce, AirFlow etc.) Experience with relational databases and SQL Highly organized, creative, motivated, and passionate about achieving results Curious and have excellent analytical and problem solving skills Excellent written, verbal, and data communication skills Bachelor's or Master's degree in computer science. Preferred Qualifications Familiarity with distributed computation, storage, and workflow management (e.g. Splunk, Spark, Kubernetes, Kafka, Hadoop, MapReduce, AirFlow etc.)</td></tr><tr><td>Junior Backend Big Data Developer</td><td>, developing the next-generation smart-infrastructure solution based on novel fiber-sensing technology (smart roads, smart cities, perimeters, grid monitoring, etc.). The company offers an award-winning disruptive solution – a “sensor free” approach to smart infrastructure. The company is VC backed and is in the revenues stage.</td><td>Israel, Hod HaSharon Description About ThetaRay: ThetaRay is a trailblazer in AI-powered Anti-Money Laundering (AML) solutions, offering cutting-edge technology to fintechs, banks, and regulatory bodies worldwide. Our mission is to enhance trust in financial transactions, ensuring compliant and innovative business growth. Our technology empowers customers to expand into new markets and introduce groundbreaking products. Thetaray is a culture-driven company. Our values are at the heart of our success. By joining us, you'll have the opportunity to embody these values and inspire others through your actions. Why Join ThetaRay? At ThetaRay, you'll be part of a dynamic global team committed to redefining the financial services sector through technological innovation. You will contribute to creating safer financial environments and have the opportunity to work with some of the brightest minds in AI, ML, and financial technology. We offer a collaborative, inclusive, and forward-thinking work environment where your ideas and contributions are valued and encouraged. Join us in our mission to revolutionize the financial world, making it safer and more trustworthy for millions worldwide. Explore exciting career opportunities at ThetaRay – where innovation meets purpose. We are seeking a skilled Junior Backend Big Data Developer to join our global R&D department. About the position Design and develop a scalable data processing and ML pipeline using the latest big data technologies in a fast paced agile environment Investigate new technological areas and understand them in depth through rapid self-learning Demonstrates strong analytical problem-solving skills to support scalable and sustainable design solutions Ability to take ownership of product development including all life cycle stages: translating product requirements into actionable designs and tasks, development, UT, and production troubleshooting Requirements 1-2 years of experience of hands-on development experience Experience developing data-oriented products preferably using Python/Java Experience in data processing FW such as Spark, Pandas, Hadoop, Airflow Experience in Distributed Databases (Such as Elasticsearch, Mongo, Redis, etc) Experience with developing microservices-based architecture Experience working in container-based environments using tools such as K8s, helm Experience working as a software developer in an Agile environment Nice to have: Experience in machine learning FWs such as SKLearn, Tensorflow Experience with RedHat OpenShift Dev Environment knowledge: GIT, Jenkins, Docker Opened URL: https://il.indeed.com/rc/clk?jk=f8a4240257a1f2ce&bb=r6UIYw2mow7Pn8IzQwq2_-W1QCjSWXjTolCGGPP6r1hrgYR_04g-rduMaSln8QXPTKg72oJi8A05b61aBYrHRJnGe_P_Fe_A6kxMxp1ZSL-qNeOaC0lT-K0Lac-PNtP0&xkcb=SoB367M33wH7H8WWaB0IbzkdCdPP&fccid=69237999e36cf5e9&vjs=3</td><td>data</td><td>Israel, Hod HaSharon Description About ThetaRay: ThetaRay is a trailblazer in AI-powered Anti-Money Laundering (AML) solutions, offering cutting-edge technology to fintechs, banks, and regulatory bodies worldwide. Our mission is to enhance trust in financial transactions, ensuring compliant and innovative business growth. Our technology empowers customers to expand into new markets and introduce groundbreaking products. Thetaray is a culture-driven company. Our values are at the heart of our success. By joining us, you'll have the opportunity to embody these values and inspire others through your actions. Why Join ThetaRay? At ThetaRay, you'll be part of a dynamic global team committed to redefining the financial services sector through technological innovation. You will contribute to creating safer financial environments and have the opportunity to work with some of the brightest minds in AI, ML, and financial technology. We offer a collaborative, inclusive, and forward-thinking work environment where your ideas and contributions are valued and encouraged. Join us in our mission to revolutionize the financial world, making it safer and more trustworthy for millions worldwide. Explore exciting career opportunities at ThetaRay – where innovation meets purpose. We are seeking a skilled Junior Backend Big Data Developer to join our global R&D department. About the position Design and develop a scalable data processing and ML pipeline using the latest big data technologies in a fast paced agile environment Investigate new technological areas and understand them in depth through rapid self-learning Demonstrates strong analytical problem-solving skills to support scalable and sustainable design solutions Ability to take ownership of product development including all life cycle stages: translating product requirements into actionable designs and tasks, development, UT, and production troubleshooting Requirements 1-2 years of experience of hands-on development experience Experience developing data-oriented products preferably using Python/Java Experience in data processing FW such as Spark, Pandas, Hadoop, Airflow Experience in Distributed Databases (Such as Elasticsearch, Mongo, Redis, etc) Experience with developing microservices-based architecture Experience working in container-based environments using tools such as K8s, helm Experience working as a software developer in an Agile environment Nice to have: Experience in machine learning FWs such as SKLearn, Tensorflow Experience with RedHat OpenShift Dev Environment knowledge: GIT, Jenkins, Docker</td><td>Israel, Hod HaSharon Description About ThetaRay: ThetaRay is a trailblazer in AI-powered Anti-Money Laundering (AML) solutions, offering cutting-edge technology to fintechs, banks, and regulatory bodies worldwide. Our mission is to enhance trust in financial transactions, ensuring compliant and innovative business growth. Our technology empowers customers to expand into new markets and introduce groundbreaking products. Thetaray is a culture-driven company. Our values are at the heart of our success. By joining us, you'll have the opportunity to embody these values and inspire others through your actions. Why Join ThetaRay? At ThetaRay, you'll be part of a dynamic global team committed to redefining the financial services sector through technological innovation. You will contribute to creating safer financial environments and have the opportunity to work with some of the brightest minds in AI, ML, and financial technology. We offer a collaborative, inclusive, and forward-thinking work environment where your ideas and contributions are valued and encouraged. Join us in our mission to revolutionize the financial world, making it safer and more trustworthy for millions worldwide. Explore exciting career opportunities at ThetaRay – where innovation meets purpose. We are seeking a skilled Junior Backend Big Data Developer to join our global R&D department. About the position Design and develop a scalable data processing and ML pipeline using the latest big data technologies in a fast paced agile environment Investigate new technological areas and understand them in depth through rapid self-learning Demonstrates strong analytical problem-solving skills to support scalable and sustainable design solutions Ability to take ownership of product development including all life cycle stages: translating product requirements into actionable designs and tasks, development, UT, and production troubleshooting Requirements 1-2 years of experience of hands-on development experience Experience developing data-oriented products preferably using Python/Java Experience in data processing FW such as Spark, Pandas, Hadoop, Airflow Experience in Distributed Databases (Such as Elasticsearch, Mongo, Redis, etc) Experience with developing microservices-based architecture Experience working in container-based environments using tools such as K8s, helm Experience working as a software developer in an Agile environment Nice to have: Experience in machine learning FWs such as SKLearn, Tensorflow Experience with RedHat OpenShift Dev Environment knowledge: GIT, Jenkins, Docker</td></tr><tr><td>Marketing Data Analyst</td><td>.</td><td>Description: Prisma-Photonics is a rapidly growing startup company, developing the next-generation smart-infrastructure solution based on novel fiber-sensing technology (smart roads, smart cities, perimeters, grid monitoring, etc.). The company offers an award-winning disruptive solution – a “sensor free” approach to smart infrastructure. The company is VC backed and is in the revenues stage. Combining pioneering technology in optical fiber sensing with state-of-the-art machine learning, we help prevent environmental disasters, protect human lives, and keep critical energy and transportation backbones running smoothly. We are rapidly growing, looking for the best minds and spirits to join us in our journey. We know our products are only as great as the individuals building the hardware and software and harnessing data for good causes! Being a great team member means being eager to learn and grow, able to challenge others while accepting being challenged yourself, and working for the team and product with enthusiasm and passion. We are seeking a detail-oriented and highly technical Data Annotator to join our Data Operations team. The role is full time, on an hourly pay, with the aim of adjusting work hours per need. In this role, you will be responsible for annotating various events on our distinct fiber sensing data, and managing datasets to support various products and projects. You will play a crucial part in ensuring the quality and integrity of our data, contributing to multiple critical initiatives. You will help improve our annotation procedures, techniques and tooling, and work closely with ML and Algo teams as well as Data Engineering. This is a unique opportunity to gain hands-on experience in data operations within a dynamic environment using cutting edge and novel technology. You will join a talented team dedicated to leveraging data for impactful projects. If you are passionate about data and eager to contribute to exciting challenges, this might be the perfect opportunity for you. Key Responsibilities: Data Annotation – Accurately annotate datasets using internal tools, adhering to annotation guidelines and maintaining high standards for consistency and quality.. Quality Assurance – Review and validate annotated data to ensure accuracy and consistency, identify discrepancies, and suggest solutions to improve processes. Continuous improvement – Participate in the continuous improvement of our tools and data operation processes to achieve more accurate models, and more streamlined data flow between the different teams in the company. Data Management – Support the ongoing maintenance of annotated datasets, ensuring data integrity and accessibility, and implementing best-practices to create seamless data flows Requirements: A Bachelor of Science degree or equivalent (STEM fields an advantage). Strong attention to detail and a commitment to maintaining high-quality annotation standards. Good written and verbal skills, with the ability to work effectively with a diverse group of individuals. Availability to work full time when needed. Nice-to-haves: Familiarity with data annotation processes, especially non-structured data (images, video, audio). Experience working with seismic data, heat maps, or spectrograms Familiarity with SQL and data visualization tools. Experience with coding languages, preferably MATLAB and Python. Opened URL: https://il.indeed.com/rc/clk?jk=bc34db8ca4455a09&bb=r6UIYw2mow7Pn8IzQwq2_2KWxyEGo0k-OJpOJwwWN8Jm7Ix9rFlIZvMB9V3E68_9Tw5jXdxlGcRgdwn8R5bozu_4HSOWEd50RAMDfMKBbPpkx12msEPjULZyxC-ZVeo-&xkcb=SoD567M33wH7H8WWaB0PbzkdCdPP&fccid=fa9a43168015ecb7&vjs=3</td><td>data</td><td>Description: Prisma-Photonics is a rapidly growing startup company, developing the next-generation smart-infrastructure solution based on novel fiber-sensing technology (smart roads, smart cities, perimeters, grid monitoring, etc.). The company offers an award-winning disruptive solution – a “sensor free” approach to smart infrastructure. The company is VC backed and is in the revenues stage. Combining pioneering technology in optical fiber sensing with state-of-the-art machine learning, we help prevent environmental disasters, protect human lives, and keep critical energy and transportation backbones running smoothly. We are rapidly growing, looking for the best minds and spirits to join us in our journey. We know our products are only as great as the individuals building the hardware and software and harnessing data for good causes! Being a great team member means being eager to learn and grow, able to challenge others while accepting being challenged yourself, and working for the team and product with enthusiasm and passion. We are seeking a detail-oriented and highly technical Data Annotator to join our Data Operations team. The role is full time, on an hourly pay, with the aim of adjusting work hours per need. In this role, you will be responsible for annotating various events on our distinct fiber sensing data, and managing datasets to support various products and projects. You will play a crucial part in ensuring the quality and integrity of our data, contributing to multiple critical initiatives. You will help improve our annotation procedures, techniques and tooling, and work closely with ML and Algo teams as well as Data Engineering. This is a unique opportunity to gain hands-on experience in data operations within a dynamic environment using cutting edge and novel technology. You will join a talented team dedicated to leveraging data for impactful projects. If you are passionate about data and eager to contribute to exciting challenges, this might be the perfect opportunity for you. Key Responsibilities: Data Annotation – Accurately annotate datasets using internal tools, adhering to annotation guidelines and maintaining high standards for consistency and quality.. Quality Assurance – Review and validate annotated data to ensure accuracy and consistency, identify discrepancies, and suggest solutions to improve processes. Continuous improvement – Participate in the continuous improvement of our tools and data operation processes to achieve more accurate models, and more streamlined data flow between the different teams in the company. Data Management – Support the ongoing maintenance of annotated datasets, ensuring data integrity and accessibility, and implementing best-practices to create seamless data flows Requirements: A Bachelor of Science degree or equivalent (STEM fields an advantage). Strong attention to detail and a commitment to maintaining high-quality annotation standards. Good written and verbal skills, with the ability to work effectively with a diverse group of individuals. Availability to work full time when needed. Nice-to-haves: Familiarity with data annotation processes, especially non-structured data (images, video, audio). Experience working with seismic data, heat maps, or spectrograms Familiarity with SQL and data visualization tools. Experience with coding languages, preferably MATLAB and Python.</td><td>Description: Prisma-Photonics is a rapidly growing startup company, developing the next-generation smart-infrastructure solution based on novel fiber-sensing technology (smart roads, smart cities, perimeters, grid monitoring, etc.). The company offers an award-winning disruptive solution – a “sensor free” approach to smart infrastructure. The company is VC backed and is in the revenues stage. Combining pioneering technology in optical fiber sensing with state-of-the-art machine learning, we help prevent environmental disasters, protect human lives, and keep critical energy and transportation backbones running smoothly. We are rapidly growing, looking for the best minds and spirits to join us in our journey. We know our products are only as great as the individuals building the hardware and software and harnessing data for good causes! Being a great team member means being eager to learn and grow, able to challenge others while accepting being challenged yourself, and working for the team and product with enthusiasm and passion. We are seeking a detail-oriented and highly technical Data Annotator to join our Data Operations team. The role is full time, on an hourly pay, with the aim of adjusting work hours per need. In this role, you will be responsible for annotating various events on our distinct fiber sensing data, and managing datasets to support various products and projects. You will play a crucial part in ensuring the quality and integrity of our data, contributing to multiple critical initiatives. You will help improve our annotation procedures, techniques and tooling, and work closely with ML and Algo teams as well as Data Engineering. This is a unique opportunity to gain hands-on experience in data operations within a dynamic environment using cutting edge and novel technology. You will join a talented team dedicated to leveraging data for impactful projects. If you are passionate about data and eager to contribute to exciting challenges, this might be the perfect opportunity for you. Key Responsibilities: Data Annotation – Accurately annotate datasets using internal tools, adhering to annotation guidelines and maintaining high standards for consistency and quality.. Quality Assurance – Review and validate annotated data to ensure accuracy and consistency, identify discrepancies, and suggest solutions to improve processes. Continuous improvement – Participate in the continuous improvement of our tools and data operation processes to achieve more accurate models, and more streamlined data flow between the different teams in the company. Data Management – Support the ongoing maintenance of annotated datasets, ensuring data integrity and accessibility, and implementing best-practices to create seamless data flows Requirements: A Bachelor of Science degree or equivalent (STEM fields an advantage). Strong attention to detail and a commitment to maintaining high-quality annotation standards. Good written and verbal skills, with the ability to work effectively with a diverse group of individuals. Availability to work full time when needed. Nice-to-haves: Familiarity with data annotation processes, especially non-structured data (images, video, audio). Experience working with seismic data, heat maps, or spectrograms Familiarity with SQL and data visualization tools. Experience with coding languages, preferably MATLAB and Python.</td></tr><tr><td>Data Scientist</td><td>'s Next Big Things in Tech of 2024</td><td>The Business Performance department at Plarium is in charge of all the analytical aspects of our game operations and strategic planning: From game design, to user acquisition, player behavior, live-ops, and game optimization (such as monetization, retention, etc). We are looking for a data analyst for our Marketing Analytics team. The scope of responsibility of this team includes budget optimization for user acquisition for our games at the scope of tens of million dollars per game, analyses of game profitability and long term potential, analysis of the players behavior, player game funnel and reaction to new game features and offers, and a lot more. Our goal is making sure Plarium brings the best and most relevant players to its games in the most efficient and effective way. Responsibilities Be a focal point for anything related to new players performance and KPIs across our range of games, strategic planning, user segmentation, tests and growth opportunities identification Daily support of ongoing analytical needs of the marketing department managers & teams Establish and monitor success metrics that measure and explain the impact of the marketing activities Design and initiate new features and reports to monitor & give insights on the marketing activity, using the marketing in-house BI system (for example, LTV, ROI forecasting, automatic rules) Run ad-hoc and in-depth analyses of the different Marketing activities and trends Support decision making based on data Collaborate with the game analysis team and the game studios to monitor and optimize our players experience, maximizing their retention in our games What we expect B.A/BSc in a highly quantitative field such as mathematics industrial engineering economics statistics or equivalent academic knowledge At least 2 years of hands-on data analysis and story-telling experience Proven experience with measuring online success and identifying optimization opportunities Excellent understanding of online marketing metrics High proficiency in SQL with demonstrated experience in querying large complex datasets Strong Excel / Google Sheets skills Experience with data visualization tools such as Qlik Sense and Looker A solid grasp of statistical significance models and tools Desired Marketing metrics of user funnel, user acquisition KPI’s What we offer A Workplace Designed for Your Well-Being - Comfortable Environment: Ergonomic chairs and desks to support your health. Beautifully designed spaces that inspire creativity. - On-Site Amenities: Gym, yoga room, and music room for relaxation and rejuvenation. - Delicious Perks: 5-star breakfast to kickstart your day. Freshly made coffee, shakes, and afternoon salads by our in-house barista. - Health & Wellness: Full health insurance coverage for your peace of mind. - Growth Opportunities: Learning and training programs to enhance your personal and professional skills. - Vibrant Culture: Happy hours, team events, and plenty of opportunities to connect with colleagues. Join us and experience a workplace where your well-being, growth, and enjoyment come first! Opened URL: https://il.indeed.com/rc/clk?jk=2b03298659a436f7&bb=r6UIYw2mow7Pn8IzQwq2_wWeK1_evLckj39fLIfBgJ2KNH0z3augA147ODzOJXM4VPM1yn4wZeNukSlYyB-0ehIHUhqYKXcTKfcnYDIqLgoQwawaxa9eNtYV3Qk82DTa&xkcb=SoBN67M33wH7H8WWaB0ObzkdCdPP&fccid=f24b7ff57afa3405&vjs=3</td><td>data</td><td>The Business Performance department at Plarium is in charge of all the analytical aspects of our game operations and strategic planning: From game design, to user acquisition, player behavior, live-ops, and game optimization (such as monetization, retention, etc). We are looking for a data analyst for our Marketing Analytics team. The scope of responsibility of this team includes budget optimization for user acquisition for our games at the scope of tens of million dollars per game, analyses of game profitability and long term potential, analysis of the players behavior, player game funnel and reaction to new game features and offers, and a lot more. Our goal is making sure Plarium brings the best and most relevant players to its games in the most efficient and effective way. Responsibilities Be a focal point for anything related to new players performance and KPIs across our range of games, strategic planning, user segmentation, tests and growth opportunities identification Daily support of ongoing analytical needs of the marketing department managers & teams Establish and monitor success metrics that measure and explain the impact of the marketing activities Design and initiate new features and reports to monitor & give insights on the marketing activity, using the marketing in-house BI system (for example, LTV, ROI forecasting, automatic rules) Run ad-hoc and in-depth analyses of the different Marketing activities and trends Support decision making based on data Collaborate with the game analysis team and the game studios to monitor and optimize our players experience, maximizing their retention in our games What we expect B.A/BSc in a highly quantitative field such as mathematics industrial engineering economics statistics or equivalent academic knowledge At least 2 years of hands-on data analysis and story-telling experience Proven experience with measuring online success and identifying optimization opportunities Excellent understanding of online marketing metrics High proficiency in SQL with demonstrated experience in querying large complex datasets Strong Excel / Google Sheets skills Experience with data visualization tools such as Qlik Sense and Looker A solid grasp of statistical significance models and tools Desired Marketing metrics of user funnel, user acquisition KPI’s What we offer A Workplace Designed for Your Well-Being - Comfortable Environment: Ergonomic chairs and desks to support your health. Beautifully designed spaces that inspire creativity. - On-Site Amenities: Gym, yoga room, and music room for relaxation and rejuvenation. - Delicious Perks: 5-star breakfast to kickstart your day. Freshly made coffee, shakes, and afternoon salads by our in-house barista. - Health & Wellness: Full health insurance coverage for your peace of mind. - Growth Opportunities: Learning and training programs to enhance your personal and professional skills. - Vibrant Culture: Happy hours, team events, and plenty of opportunities to connect with colleagues. Join us and experience a workplace where your well-being, growth, and enjoyment come first!</td><td>The Business Performance department at Plarium is in charge of all the analytical aspects of our game operations and strategic planning: From game design, to user acquisition, player behavior, live-ops, and game optimization (such as monetization, retention, etc). We are looking for a data analyst for our Marketing Analytics team. The scope of responsibility of this team includes budget optimization for user acquisition for our games at the scope of tens of million dollars per game, analyses of game profitability and long term potential, analysis of the players behavior, player game funnel and reaction to new game features and offers, and a lot more. Our goal is making sure Plarium brings the best and most relevant players to its games in the most efficient and effective way. Responsibilities Be a focal point for anything related to new players performance and KPIs across our range of games, strategic planning, user segmentation, tests and growth opportunities identification Daily support of ongoing analytical needs of the marketing department managers & teams Establish and monitor success metrics that measure and explain the impact of the marketing activities Design and initiate new features and reports to monitor & give insights on the marketing activity, using the marketing in-house BI system (for example, LTV, ROI forecasting, automatic rules) Run ad-hoc and in-depth analyses of the different Marketing activities and trends Support decision making based on data Collaborate with the game analysis team and the game studios to monitor and optimize our players experience, maximizing their retention in our games What we expect B.A/BSc in a highly quantitative field such as mathematics industrial engineering economics statistics or equivalent academic knowledge At least 2 years of hands-on data analysis and story-telling experience Proven experience with measuring online success and identifying optimization opportunities Excellent understanding of online marketing metrics High proficiency in SQL with demonstrated experience in querying large complex datasets Strong Excel / Google Sheets skills Experience with data visualization tools such as Qlik Sense and Looker A solid grasp of statistical significance models and tools Desired Marketing metrics of user funnel, user acquisition KPI’s What we offer A Workplace Designed for Your Well-Being - Comfortable Environment: Ergonomic chairs and desks to support your health. Beautifully designed spaces that inspire creativity. - On-Site Amenities: Gym, yoga room, and music room for relaxation and rejuvenation. - Delicious Perks: 5-star breakfast to kickstart your day. Freshly made coffee, shakes, and afternoon salads by our in-house barista. - Health & Wellness: Full health insurance coverage for your peace of mind. - Growth Opportunities: Learning and training programs to enhance your personal and professional skills. - Vibrant Culture: Happy hours, team events, and plenty of opportunities to connect with colleagues. Join us and experience a workplace where your well-being, growth, and enjoyment come first!</td></tr><tr><td>Junior Data Engineer</td><td>as a whole to have a greater impact and achieve our vision:</td><td>aiOla is a high-growth, product-led SaaS startup backed by $45 million in funding from premier investors such as New Era Capital Partners and Hamilton Lane. Our mission is to revolutionize efficiency, intelligence, collaboration, and safety in the industrial sector through our proprietary speech-powered AI technology. Our team spans the US and Israel, bringing together experts in Product, Data Science, Data Engineering, Analytics, Marketing, and Customer Success. At aiOla, we thrive on innovation, collaboration, and a commitment to excellence. We are seeking forward-thinking professionals passionate about pushing the limits of AI and making an impact. Role Overview: We are seeking a passionate and innovative Data Analyst to join our growing Analytics team. This is an exceptional opportunity for a detail-oriented professional to not only analyze data but also play a pivotal role in shaping and enhancing our cutting-edge AI models and products. As a Data Analyst at aiOla, you will dive into complex datasets, uncover actionable insights, and contribute directly to the improvement and monitoring of our proprietary AI technologies. If you thrive in a dynamic environment, this role is perfect for you! Requirements: B.Sc in Industrial Engineering, Data Analytics, Statistics, or a related field. Proficiency in Python, with a strong focus on libraries like Pandas for data manipulation. Solid knowledge of SQL for querying and managing large datasets. Experience with BI tools like Tableau to create dashboards and reports. Excellent communication skills, with fluency in English (written and verbal). 0-1 years of experience in a Data Analyst role- advantage Nice To have: Familiarity with Snowflake or AWS Athena. Experience with Web/App product analytics tools such as Mixpanel. Knowledge of Data Science concepts and metrics, including Speech AI, Large Language Models (LLMs), Natural Language Understanding (NLU), and Automatic Speech Recognition (ASR). Responsibilities: Extract, clean, and analyze data to uncover trends, patterns, and actionable insights. Provide recommendations based on data analysis to support business decisions and drive product improvements. Develop and maintain dashboards and reports using BI tools such as Tableau or other platforms. Optimize data workflows and pipelines using Python and SQL. Collaborate with cross-functional teams, including Product, Data Science, and Engineering, to support data-driven decision-making. Opened URL: https://il.indeed.com/rc/clk?jk=8c0efb63a00ef0d5&bb=r6UIYw2mow7Pn8IzQwq2_xdQrNIprFLEwcJQe8rzWVWb1_NSvbpLXcpcn5TXeAHedsgImdoi_2ey__b10Ys3nn9vr-SRmf6buKLYOFDHfBc8ksA0lyjjiA%3D%3D&xkcb=SoDQ67M33wH7H8WWaB0NbzkdCdPP&fccid=ba07516c418dda52&vjs=3</td><td>data</td><td>aiOla is a high-growth, product-led SaaS startup backed by $45 million in funding from premier investors such as New Era Capital Partners and Hamilton Lane. Our mission is to revolutionize efficiency, intelligence, collaboration, and safety in the industrial sector through our proprietary speech-powered AI technology. Our team spans the US and Israel, bringing together experts in Product, Data Science, Data Engineering, Analytics, Marketing, and Customer Success. At aiOla, we thrive on innovation, collaboration, and a commitment to excellence. We are seeking forward-thinking professionals passionate about pushing the limits of AI and making an impact. Role Overview: We are seeking a passionate and innovative Data Analyst to join our growing Analytics team. This is an exceptional opportunity for a detail-oriented professional to not only analyze data but also play a pivotal role in shaping and enhancing our cutting-edge AI models and products. As a Data Analyst at aiOla, you will dive into complex datasets, uncover actionable insights, and contribute directly to the improvement and monitoring of our proprietary AI technologies. If you thrive in a dynamic environment, this role is perfect for you! Requirements: B.Sc in Industrial Engineering, Data Analytics, Statistics, or a related field. Proficiency in Python, with a strong focus on libraries like Pandas for data manipulation. Solid knowledge of SQL for querying and managing large datasets. Experience with BI tools like Tableau to create dashboards and reports. Excellent communication skills, with fluency in English (written and verbal). 0-1 years of experience in a Data Analyst role- advantage Nice To have: Familiarity with Snowflake or AWS Athena. Experience with Web/App product analytics tools such as Mixpanel. Knowledge of Data Science concepts and metrics, including Speech AI, Large Language Models (LLMs), Natural Language Understanding (NLU), and Automatic Speech Recognition (ASR). Responsibilities: Extract, clean, and analyze data to uncover trends, patterns, and actionable insights. Provide recommendations based on data analysis to support business decisions and drive product improvements. Develop and maintain dashboards and reports using BI tools such as Tableau or other platforms. Optimize data workflows and pipelines using Python and SQL. Collaborate with cross-functional teams, including Product, Data Science, and Engineering, to support data-driven decision-making.</td><td>aiOla is a high-growth, product-led SaaS startup backed by $45 million in funding from premier investors such as New Era Capital Partners and Hamilton Lane. Our mission is to revolutionize efficiency, intelligence, collaboration, and safety in the industrial sector through our proprietary speech-powered AI technology. Our team spans the US and Israel, bringing together experts in Product, Data Science, Data Engineering, Analytics, Marketing, and Customer Success. At aiOla, we thrive on innovation, collaboration, and a commitment to excellence. We are seeking forward-thinking professionals passionate about pushing the limits of AI and making an impact. Role Overview: We are seeking a passionate and innovative Data Analyst to join our growing Analytics team. This is an exceptional opportunity for a detail-oriented professional to not only analyze data but also play a pivotal role in shaping and enhancing our cutting-edge AI models and products. As a Data Analyst at aiOla, you will dive into complex datasets, uncover actionable insights, and contribute directly to the improvement and monitoring of our proprietary AI technologies. If you thrive in a dynamic environment, this role is perfect for you! Requirements: B.Sc in Industrial Engineering, Data Analytics, Statistics, or a related field. Proficiency in Python, with a strong focus on libraries like Pandas for data manipulation. Solid knowledge of SQL for querying and managing large datasets. Experience with BI tools like Tableau to create dashboards and reports. Excellent communication skills, with fluency in English (written and verbal). 0-1 years of experience in a Data Analyst role- advantage Nice To have: Familiarity with Snowflake or AWS Athena. Experience with Web/App product analytics tools such as Mixpanel. Knowledge of Data Science concepts and metrics, including Speech AI, Large Language Models (LLMs), Natural Language Understanding (NLU), and Automatic Speech Recognition (ASR). Responsibilities: Extract, clean, and analyze data to uncover trends, patterns, and actionable insights. Provide recommendations based on data analysis to support business decisions and drive product improvements. Develop and maintain dashboards and reports using BI tools such as Tableau or other platforms. Optimize data workflows and pipelines using Python and SQL. Collaborate with cross-functional teams, including Product, Data Science, and Engineering, to support data-driven decision-making.</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "Data Analytics",
         "Apple",
         "Summary Posted: Nov 7, 2024 Role Number: 200577967 We're looking for an exceptional data analyst with a strong background in distributed data processing and a demonstrated ability to turn data into actionable insights. As a data analyst for our Storage Data Analytics team at Apple, you'll play a crucial role in developing the fastest and most efficient SSDs for our products, including the iPhone, iPad, Apple Watch, and new Apple Silicon Macs. If you're passionate about continuously improving the ways we use data to make Apple's products amazing, we want to hear from you! Description On the Storage Data Analytics team, we are responsible for performing ad hoc data analysis, development and maintenance of distributed data pipelines, as well as creation and support of analysis tools. Our team focuses on Apple’s storage solutions. It is small and nimble, able to quickly explore ideas and present them to the storage teams and to leadership. Minimum Qualifications +3 years of experience Ability to lead data investigations and analysis projects with ambiguous requirements Advanced statistic and modeling knowledge Experience visualizing and presenting analyses in tools like Jupyter and Tableau Experience programming in Python in a professional setting Familiarity with distributed computation, storage, and workflow management (e.g. Splunk, Spark, Kubernetes, Kafka, Hadoop, MapReduce, AirFlow etc.) Experience with relational databases and SQL Highly organized, creative, motivated, and passionate about achieving results Curious and have excellent analytical and problem solving skills Excellent written, verbal, and data communication skills Bachelor's or Master's degree in computer science. Preferred Qualifications Familiarity with distributed computation, storage, and workflow management (e.g. Splunk, Spark, Kubernetes, Kafka, Hadoop, MapReduce, AirFlow etc.) Opened URL: https://il.indeed.com/rc/clk?jk=0433bc7e45e694a3&bb=r6UIYw2mow7Pn8IzQwq2_7gXyX4L0a9oUPOLDIseoxAN8l0MRFFfCqpU6vSJRCmVlzxZCXcY6V-lzbB66NkEzDukGjQJgUJrBPff0HR1apFcJos6F0MbonwvLMjHhNz9&xkcb=SoDD67M33wH7H8WWaB0JbzkdCdPP&fccid=8e007f7a76f9cee5&vjs=3",
         "data",
         "Summary Posted: Nov 7, 2024 Role Number: 200577967 We're looking for an exceptional data analyst with a strong background in distributed data processing and a demonstrated ability to turn data into actionable insights. As a data analyst for our Storage Data Analytics team at Apple, you'll play a crucial role in developing the fastest and most efficient SSDs for our products, including the iPhone, iPad, Apple Watch, and new Apple Silicon Macs. If you're passionate about continuously improving the ways we use data to make Apple's products amazing, we want to hear from you! Description On the Storage Data Analytics team, we are responsible for performing ad hoc data analysis, development and maintenance of distributed data pipelines, as well as creation and support of analysis tools. Our team focuses on Apple’s storage solutions. It is small and nimble, able to quickly explore ideas and present them to the storage teams and to leadership. Minimum Qualifications +3 years of experience Ability to lead data investigations and analysis projects with ambiguous requirements Advanced statistic and modeling knowledge Experience visualizing and presenting analyses in tools like Jupyter and Tableau Experience programming in Python in a professional setting Familiarity with distributed computation, storage, and workflow management (e.g. Splunk, Spark, Kubernetes, Kafka, Hadoop, MapReduce, AirFlow etc.) Experience with relational databases and SQL Highly organized, creative, motivated, and passionate about achieving results Curious and have excellent analytical and problem solving skills Excellent written, verbal, and data communication skills Bachelor's or Master's degree in computer science. Preferred Qualifications Familiarity with distributed computation, storage, and workflow management (e.g. Splunk, Spark, Kubernetes, Kafka, Hadoop, MapReduce, AirFlow etc.)",
         "Summary Posted: Nov 7, 2024 Role Number: 200577967 We're looking for an exceptional data analyst with a strong background in distributed data processing and a demonstrated ability to turn data into actionable insights. As a data analyst for our Storage Data Analytics team at Apple, you'll play a crucial role in developing the fastest and most efficient SSDs for our products, including the iPhone, iPad, Apple Watch, and new Apple Silicon Macs. If you're passionate about continuously improving the ways we use data to make Apple's products amazing, we want to hear from you! Description On the Storage Data Analytics team, we are responsible for performing ad hoc data analysis, development and maintenance of distributed data pipelines, as well as creation and support of analysis tools. Our team focuses on Apple’s storage solutions. It is small and nimble, able to quickly explore ideas and present them to the storage teams and to leadership. Minimum Qualifications +3 years of experience Ability to lead data investigations and analysis projects with ambiguous requirements Advanced statistic and modeling knowledge Experience visualizing and presenting analyses in tools like Jupyter and Tableau Experience programming in Python in a professional setting Familiarity with distributed computation, storage, and workflow management (e.g. Splunk, Spark, Kubernetes, Kafka, Hadoop, MapReduce, AirFlow etc.) Experience with relational databases and SQL Highly organized, creative, motivated, and passionate about achieving results Curious and have excellent analytical and problem solving skills Excellent written, verbal, and data communication skills Bachelor's or Master's degree in computer science. Preferred Qualifications Familiarity with distributed computation, storage, and workflow management (e.g. Splunk, Spark, Kubernetes, Kafka, Hadoop, MapReduce, AirFlow etc.)"
        ],
        [
         "Junior Backend Big Data Developer",
         "ThetaRay",
         "Israel, Hod HaSharon Description About ThetaRay: ThetaRay is a trailblazer in AI-powered Anti-Money Laundering (AML) solutions, offering cutting-edge technology to fintechs, banks, and regulatory bodies worldwide. Our mission is to enhance trust in financial transactions, ensuring compliant and innovative business growth. Our technology empowers customers to expand into new markets and introduce groundbreaking products. Thetaray is a culture-driven company. Our values are at the heart of our success. By joining us, you'll have the opportunity to embody these values and inspire others through your actions. Why Join ThetaRay? At ThetaRay, you'll be part of a dynamic global team committed to redefining the financial services sector through technological innovation. You will contribute to creating safer financial environments and have the opportunity to work with some of the brightest minds in AI, ML, and financial technology. We offer a collaborative, inclusive, and forward-thinking work environment where your ideas and contributions are valued and encouraged. Join us in our mission to revolutionize the financial world, making it safer and more trustworthy for millions worldwide. Explore exciting career opportunities at ThetaRay – where innovation meets purpose. We are seeking a skilled Junior Backend Big Data Developer to join our global R&D department. About the position Design and develop a scalable data processing and ML pipeline using the latest big data technologies in a fast paced agile environment Investigate new technological areas and understand them in depth through rapid self-learning Demonstrates strong analytical problem-solving skills to support scalable and sustainable design solutions Ability to take ownership of product development including all life cycle stages: translating product requirements into actionable designs and tasks, development, UT, and production troubleshooting Requirements 1-2 years of experience of hands-on development experience Experience developing data-oriented products preferably using Python/Java Experience in data processing FW such as Spark, Pandas, Hadoop, Airflow Experience in Distributed Databases (Such as Elasticsearch, Mongo, Redis, etc) Experience with developing microservices-based architecture Experience working in container-based environments using tools such as K8s, helm Experience working as a software developer in an Agile environment Nice to have: Experience in machine learning FWs such as SKLearn, Tensorflow Experience with RedHat OpenShift Dev Environment knowledge: GIT, Jenkins, Docker Opened URL: https://il.indeed.com/rc/clk?jk=f8a4240257a1f2ce&bb=r6UIYw2mow7Pn8IzQwq2_-W1QCjSWXjTolCGGPP6r1hrgYR_04g-rduMaSln8QXPTKg72oJi8A05b61aBYrHRJnGe_P_Fe_A6kxMxp1ZSL-qNeOaC0lT-K0Lac-PNtP0&xkcb=SoB367M33wH7H8WWaB0IbzkdCdPP&fccid=69237999e36cf5e9&vjs=3",
         "data",
         "Israel, Hod HaSharon Description About ThetaRay: ThetaRay is a trailblazer in AI-powered Anti-Money Laundering (AML) solutions, offering cutting-edge technology to fintechs, banks, and regulatory bodies worldwide. Our mission is to enhance trust in financial transactions, ensuring compliant and innovative business growth. Our technology empowers customers to expand into new markets and introduce groundbreaking products. Thetaray is a culture-driven company. Our values are at the heart of our success. By joining us, you'll have the opportunity to embody these values and inspire others through your actions. Why Join ThetaRay? At ThetaRay, you'll be part of a dynamic global team committed to redefining the financial services sector through technological innovation. You will contribute to creating safer financial environments and have the opportunity to work with some of the brightest minds in AI, ML, and financial technology. We offer a collaborative, inclusive, and forward-thinking work environment where your ideas and contributions are valued and encouraged. Join us in our mission to revolutionize the financial world, making it safer and more trustworthy for millions worldwide. Explore exciting career opportunities at ThetaRay – where innovation meets purpose. We are seeking a skilled Junior Backend Big Data Developer to join our global R&D department. About the position Design and develop a scalable data processing and ML pipeline using the latest big data technologies in a fast paced agile environment Investigate new technological areas and understand them in depth through rapid self-learning Demonstrates strong analytical problem-solving skills to support scalable and sustainable design solutions Ability to take ownership of product development including all life cycle stages: translating product requirements into actionable designs and tasks, development, UT, and production troubleshooting Requirements 1-2 years of experience of hands-on development experience Experience developing data-oriented products preferably using Python/Java Experience in data processing FW such as Spark, Pandas, Hadoop, Airflow Experience in Distributed Databases (Such as Elasticsearch, Mongo, Redis, etc) Experience with developing microservices-based architecture Experience working in container-based environments using tools such as K8s, helm Experience working as a software developer in an Agile environment Nice to have: Experience in machine learning FWs such as SKLearn, Tensorflow Experience with RedHat OpenShift Dev Environment knowledge: GIT, Jenkins, Docker",
         "Israel, Hod HaSharon Description About ThetaRay: ThetaRay is a trailblazer in AI-powered Anti-Money Laundering (AML) solutions, offering cutting-edge technology to fintechs, banks, and regulatory bodies worldwide. Our mission is to enhance trust in financial transactions, ensuring compliant and innovative business growth. Our technology empowers customers to expand into new markets and introduce groundbreaking products. Thetaray is a culture-driven company. Our values are at the heart of our success. By joining us, you'll have the opportunity to embody these values and inspire others through your actions. Why Join ThetaRay? At ThetaRay, you'll be part of a dynamic global team committed to redefining the financial services sector through technological innovation. You will contribute to creating safer financial environments and have the opportunity to work with some of the brightest minds in AI, ML, and financial technology. We offer a collaborative, inclusive, and forward-thinking work environment where your ideas and contributions are valued and encouraged. Join us in our mission to revolutionize the financial world, making it safer and more trustworthy for millions worldwide. Explore exciting career opportunities at ThetaRay – where innovation meets purpose. We are seeking a skilled Junior Backend Big Data Developer to join our global R&D department. About the position Design and develop a scalable data processing and ML pipeline using the latest big data technologies in a fast paced agile environment Investigate new technological areas and understand them in depth through rapid self-learning Demonstrates strong analytical problem-solving skills to support scalable and sustainable design solutions Ability to take ownership of product development including all life cycle stages: translating product requirements into actionable designs and tasks, development, UT, and production troubleshooting Requirements 1-2 years of experience of hands-on development experience Experience developing data-oriented products preferably using Python/Java Experience in data processing FW such as Spark, Pandas, Hadoop, Airflow Experience in Distributed Databases (Such as Elasticsearch, Mongo, Redis, etc) Experience with developing microservices-based architecture Experience working in container-based environments using tools such as K8s, helm Experience working as a software developer in an Agile environment Nice to have: Experience in machine learning FWs such as SKLearn, Tensorflow Experience with RedHat OpenShift Dev Environment knowledge: GIT, Jenkins, Docker"
        ],
        [
         "Data Annotator",
         "Prisma Photonics",
         "Description: Prisma-Photonics is a rapidly growing startup company, developing the next-generation smart-infrastructure solution based on novel fiber-sensing technology (smart roads, smart cities, perimeters, grid monitoring, etc.). The company offers an award-winning disruptive solution – a “sensor free” approach to smart infrastructure. The company is VC backed and is in the revenues stage. Combining pioneering technology in optical fiber sensing with state-of-the-art machine learning, we help prevent environmental disasters, protect human lives, and keep critical energy and transportation backbones running smoothly. We are rapidly growing, looking for the best minds and spirits to join us in our journey. We know our products are only as great as the individuals building the hardware and software and harnessing data for good causes! Being a great team member means being eager to learn and grow, able to challenge others while accepting being challenged yourself, and working for the team and product with enthusiasm and passion. We are seeking a detail-oriented and highly technical Data Annotator to join our Data Operations team. The role is full time, on an hourly pay, with the aim of adjusting work hours per need. In this role, you will be responsible for annotating various events on our distinct fiber sensing data, and managing datasets to support various products and projects. You will play a crucial part in ensuring the quality and integrity of our data, contributing to multiple critical initiatives. You will help improve our annotation procedures, techniques and tooling, and work closely with ML and Algo teams as well as Data Engineering. This is a unique opportunity to gain hands-on experience in data operations within a dynamic environment using cutting edge and novel technology. You will join a talented team dedicated to leveraging data for impactful projects. If you are passionate about data and eager to contribute to exciting challenges, this might be the perfect opportunity for you. Key Responsibilities: Data Annotation – Accurately annotate datasets using internal tools, adhering to annotation guidelines and maintaining high standards for consistency and quality.. Quality Assurance – Review and validate annotated data to ensure accuracy and consistency, identify discrepancies, and suggest solutions to improve processes. Continuous improvement – Participate in the continuous improvement of our tools and data operation processes to achieve more accurate models, and more streamlined data flow between the different teams in the company. Data Management – Support the ongoing maintenance of annotated datasets, ensuring data integrity and accessibility, and implementing best-practices to create seamless data flows Requirements: A Bachelor of Science degree or equivalent (STEM fields an advantage). Strong attention to detail and a commitment to maintaining high-quality annotation standards. Good written and verbal skills, with the ability to work effectively with a diverse group of individuals. Availability to work full time when needed. Nice-to-haves: Familiarity with data annotation processes, especially non-structured data (images, video, audio). Experience working with seismic data, heat maps, or spectrograms Familiarity with SQL and data visualization tools. Experience with coding languages, preferably MATLAB and Python. Opened URL: https://il.indeed.com/rc/clk?jk=bc34db8ca4455a09&bb=r6UIYw2mow7Pn8IzQwq2_2KWxyEGo0k-OJpOJwwWN8Jm7Ix9rFlIZvMB9V3E68_9Tw5jXdxlGcRgdwn8R5bozu_4HSOWEd50RAMDfMKBbPpkx12msEPjULZyxC-ZVeo-&xkcb=SoD567M33wH7H8WWaB0PbzkdCdPP&fccid=fa9a43168015ecb7&vjs=3",
         "data",
         "Description: Prisma-Photonics is a rapidly growing startup company, developing the next-generation smart-infrastructure solution based on novel fiber-sensing technology (smart roads, smart cities, perimeters, grid monitoring, etc.). The company offers an award-winning disruptive solution – a “sensor free” approach to smart infrastructure. The company is VC backed and is in the revenues stage. Combining pioneering technology in optical fiber sensing with state-of-the-art machine learning, we help prevent environmental disasters, protect human lives, and keep critical energy and transportation backbones running smoothly. We are rapidly growing, looking for the best minds and spirits to join us in our journey. We know our products are only as great as the individuals building the hardware and software and harnessing data for good causes! Being a great team member means being eager to learn and grow, able to challenge others while accepting being challenged yourself, and working for the team and product with enthusiasm and passion. We are seeking a detail-oriented and highly technical Data Annotator to join our Data Operations team. The role is full time, on an hourly pay, with the aim of adjusting work hours per need. In this role, you will be responsible for annotating various events on our distinct fiber sensing data, and managing datasets to support various products and projects. You will play a crucial part in ensuring the quality and integrity of our data, contributing to multiple critical initiatives. You will help improve our annotation procedures, techniques and tooling, and work closely with ML and Algo teams as well as Data Engineering. This is a unique opportunity to gain hands-on experience in data operations within a dynamic environment using cutting edge and novel technology. You will join a talented team dedicated to leveraging data for impactful projects. If you are passionate about data and eager to contribute to exciting challenges, this might be the perfect opportunity for you. Key Responsibilities: Data Annotation – Accurately annotate datasets using internal tools, adhering to annotation guidelines and maintaining high standards for consistency and quality.. Quality Assurance – Review and validate annotated data to ensure accuracy and consistency, identify discrepancies, and suggest solutions to improve processes. Continuous improvement – Participate in the continuous improvement of our tools and data operation processes to achieve more accurate models, and more streamlined data flow between the different teams in the company. Data Management – Support the ongoing maintenance of annotated datasets, ensuring data integrity and accessibility, and implementing best-practices to create seamless data flows Requirements: A Bachelor of Science degree or equivalent (STEM fields an advantage). Strong attention to detail and a commitment to maintaining high-quality annotation standards. Good written and verbal skills, with the ability to work effectively with a diverse group of individuals. Availability to work full time when needed. Nice-to-haves: Familiarity with data annotation processes, especially non-structured data (images, video, audio). Experience working with seismic data, heat maps, or spectrograms Familiarity with SQL and data visualization tools. Experience with coding languages, preferably MATLAB and Python.",
         "Description: Prisma-Photonics is a rapidly growing startup company, developing the next-generation smart-infrastructure solution based on novel fiber-sensing technology (smart roads, smart cities, perimeters, grid monitoring, etc.). The company offers an award-winning disruptive solution – a “sensor free” approach to smart infrastructure. The company is VC backed and is in the revenues stage. Combining pioneering technology in optical fiber sensing with state-of-the-art machine learning, we help prevent environmental disasters, protect human lives, and keep critical energy and transportation backbones running smoothly. We are rapidly growing, looking for the best minds and spirits to join us in our journey. We know our products are only as great as the individuals building the hardware and software and harnessing data for good causes! Being a great team member means being eager to learn and grow, able to challenge others while accepting being challenged yourself, and working for the team and product with enthusiasm and passion. We are seeking a detail-oriented and highly technical Data Annotator to join our Data Operations team. The role is full time, on an hourly pay, with the aim of adjusting work hours per need. In this role, you will be responsible for annotating various events on our distinct fiber sensing data, and managing datasets to support various products and projects. You will play a crucial part in ensuring the quality and integrity of our data, contributing to multiple critical initiatives. You will help improve our annotation procedures, techniques and tooling, and work closely with ML and Algo teams as well as Data Engineering. This is a unique opportunity to gain hands-on experience in data operations within a dynamic environment using cutting edge and novel technology. You will join a talented team dedicated to leveraging data for impactful projects. If you are passionate about data and eager to contribute to exciting challenges, this might be the perfect opportunity for you. Key Responsibilities: Data Annotation – Accurately annotate datasets using internal tools, adhering to annotation guidelines and maintaining high standards for consistency and quality.. Quality Assurance – Review and validate annotated data to ensure accuracy and consistency, identify discrepancies, and suggest solutions to improve processes. Continuous improvement – Participate in the continuous improvement of our tools and data operation processes to achieve more accurate models, and more streamlined data flow between the different teams in the company. Data Management – Support the ongoing maintenance of annotated datasets, ensuring data integrity and accessibility, and implementing best-practices to create seamless data flows Requirements: A Bachelor of Science degree or equivalent (STEM fields an advantage). Strong attention to detail and a commitment to maintaining high-quality annotation standards. Good written and verbal skills, with the ability to work effectively with a diverse group of individuals. Availability to work full time when needed. Nice-to-haves: Familiarity with data annotation processes, especially non-structured data (images, video, audio). Experience working with seismic data, heat maps, or spectrograms Familiarity with SQL and data visualization tools. Experience with coding languages, preferably MATLAB and Python."
        ],
        [
         "Marketing Data Analyst",
         "Plarium",
         "The Business Performance department at Plarium is in charge of all the analytical aspects of our game operations and strategic planning: From game design, to user acquisition, player behavior, live-ops, and game optimization (such as monetization, retention, etc). We are looking for a data analyst for our Marketing Analytics team. The scope of responsibility of this team includes budget optimization for user acquisition for our games at the scope of tens of million dollars per game, analyses of game profitability and long term potential, analysis of the players behavior, player game funnel and reaction to new game features and offers, and a lot more. Our goal is making sure Plarium brings the best and most relevant players to its games in the most efficient and effective way. Responsibilities Be a focal point for anything related to new players performance and KPIs across our range of games, strategic planning, user segmentation, tests and growth opportunities identification Daily support of ongoing analytical needs of the marketing department managers & teams Establish and monitor success metrics that measure and explain the impact of the marketing activities Design and initiate new features and reports to monitor & give insights on the marketing activity, using the marketing in-house BI system (for example, LTV, ROI forecasting, automatic rules) Run ad-hoc and in-depth analyses of the different Marketing activities and trends Support decision making based on data Collaborate with the game analysis team and the game studios to monitor and optimize our players experience, maximizing their retention in our games What we expect B.A/BSc in a highly quantitative field such as mathematics industrial engineering economics statistics or equivalent academic knowledge At least 2 years of hands-on data analysis and story-telling experience Proven experience with measuring online success and identifying optimization opportunities Excellent understanding of online marketing metrics High proficiency in SQL with demonstrated experience in querying large complex datasets Strong Excel / Google Sheets skills Experience with data visualization tools such as Qlik Sense and Looker A solid grasp of statistical significance models and tools Desired Marketing metrics of user funnel, user acquisition KPI’s What we offer A Workplace Designed for Your Well-Being - Comfortable Environment: Ergonomic chairs and desks to support your health. Beautifully designed spaces that inspire creativity. - On-Site Amenities: Gym, yoga room, and music room for relaxation and rejuvenation. - Delicious Perks: 5-star breakfast to kickstart your day. Freshly made coffee, shakes, and afternoon salads by our in-house barista. - Health & Wellness: Full health insurance coverage for your peace of mind. - Growth Opportunities: Learning and training programs to enhance your personal and professional skills. - Vibrant Culture: Happy hours, team events, and plenty of opportunities to connect with colleagues. Join us and experience a workplace where your well-being, growth, and enjoyment come first! Opened URL: https://il.indeed.com/rc/clk?jk=2b03298659a436f7&bb=r6UIYw2mow7Pn8IzQwq2_wWeK1_evLckj39fLIfBgJ2KNH0z3augA147ODzOJXM4VPM1yn4wZeNukSlYyB-0ehIHUhqYKXcTKfcnYDIqLgoQwawaxa9eNtYV3Qk82DTa&xkcb=SoBN67M33wH7H8WWaB0ObzkdCdPP&fccid=f24b7ff57afa3405&vjs=3",
         "data",
         "The Business Performance department at Plarium is in charge of all the analytical aspects of our game operations and strategic planning: From game design, to user acquisition, player behavior, live-ops, and game optimization (such as monetization, retention, etc). We are looking for a data analyst for our Marketing Analytics team. The scope of responsibility of this team includes budget optimization for user acquisition for our games at the scope of tens of million dollars per game, analyses of game profitability and long term potential, analysis of the players behavior, player game funnel and reaction to new game features and offers, and a lot more. Our goal is making sure Plarium brings the best and most relevant players to its games in the most efficient and effective way. Responsibilities Be a focal point for anything related to new players performance and KPIs across our range of games, strategic planning, user segmentation, tests and growth opportunities identification Daily support of ongoing analytical needs of the marketing department managers & teams Establish and monitor success metrics that measure and explain the impact of the marketing activities Design and initiate new features and reports to monitor & give insights on the marketing activity, using the marketing in-house BI system (for example, LTV, ROI forecasting, automatic rules) Run ad-hoc and in-depth analyses of the different Marketing activities and trends Support decision making based on data Collaborate with the game analysis team and the game studios to monitor and optimize our players experience, maximizing their retention in our games What we expect B.A/BSc in a highly quantitative field such as mathematics industrial engineering economics statistics or equivalent academic knowledge At least 2 years of hands-on data analysis and story-telling experience Proven experience with measuring online success and identifying optimization opportunities Excellent understanding of online marketing metrics High proficiency in SQL with demonstrated experience in querying large complex datasets Strong Excel / Google Sheets skills Experience with data visualization tools such as Qlik Sense and Looker A solid grasp of statistical significance models and tools Desired Marketing metrics of user funnel, user acquisition KPI’s What we offer A Workplace Designed for Your Well-Being - Comfortable Environment: Ergonomic chairs and desks to support your health. Beautifully designed spaces that inspire creativity. - On-Site Amenities: Gym, yoga room, and music room for relaxation and rejuvenation. - Delicious Perks: 5-star breakfast to kickstart your day. Freshly made coffee, shakes, and afternoon salads by our in-house barista. - Health & Wellness: Full health insurance coverage for your peace of mind. - Growth Opportunities: Learning and training programs to enhance your personal and professional skills. - Vibrant Culture: Happy hours, team events, and plenty of opportunities to connect with colleagues. Join us and experience a workplace where your well-being, growth, and enjoyment come first!",
         "The Business Performance department at Plarium is in charge of all the analytical aspects of our game operations and strategic planning: From game design, to user acquisition, player behavior, live-ops, and game optimization (such as monetization, retention, etc). We are looking for a data analyst for our Marketing Analytics team. The scope of responsibility of this team includes budget optimization for user acquisition for our games at the scope of tens of million dollars per game, analyses of game profitability and long term potential, analysis of the players behavior, player game funnel and reaction to new game features and offers, and a lot more. Our goal is making sure Plarium brings the best and most relevant players to its games in the most efficient and effective way. Responsibilities Be a focal point for anything related to new players performance and KPIs across our range of games, strategic planning, user segmentation, tests and growth opportunities identification Daily support of ongoing analytical needs of the marketing department managers & teams Establish and monitor success metrics that measure and explain the impact of the marketing activities Design and initiate new features and reports to monitor & give insights on the marketing activity, using the marketing in-house BI system (for example, LTV, ROI forecasting, automatic rules) Run ad-hoc and in-depth analyses of the different Marketing activities and trends Support decision making based on data Collaborate with the game analysis team and the game studios to monitor and optimize our players experience, maximizing their retention in our games What we expect B.A/BSc in a highly quantitative field such as mathematics industrial engineering economics statistics or equivalent academic knowledge At least 2 years of hands-on data analysis and story-telling experience Proven experience with measuring online success and identifying optimization opportunities Excellent understanding of online marketing metrics High proficiency in SQL with demonstrated experience in querying large complex datasets Strong Excel / Google Sheets skills Experience with data visualization tools such as Qlik Sense and Looker A solid grasp of statistical significance models and tools Desired Marketing metrics of user funnel, user acquisition KPI’s What we offer A Workplace Designed for Your Well-Being - Comfortable Environment: Ergonomic chairs and desks to support your health. Beautifully designed spaces that inspire creativity. - On-Site Amenities: Gym, yoga room, and music room for relaxation and rejuvenation. - Delicious Perks: 5-star breakfast to kickstart your day. Freshly made coffee, shakes, and afternoon salads by our in-house barista. - Health & Wellness: Full health insurance coverage for your peace of mind. - Growth Opportunities: Learning and training programs to enhance your personal and professional skills. - Vibrant Culture: Happy hours, team events, and plenty of opportunities to connect with colleagues. Join us and experience a workplace where your well-being, growth, and enjoyment come first!"
        ],
        [
         "Junior Data Analyst",
         "aiOla",
         "aiOla is a high-growth, product-led SaaS startup backed by $45 million in funding from premier investors such as New Era Capital Partners and Hamilton Lane. Our mission is to revolutionize efficiency, intelligence, collaboration, and safety in the industrial sector through our proprietary speech-powered AI technology. Our team spans the US and Israel, bringing together experts in Product, Data Science, Data Engineering, Analytics, Marketing, and Customer Success. At aiOla, we thrive on innovation, collaboration, and a commitment to excellence. We are seeking forward-thinking professionals passionate about pushing the limits of AI and making an impact. Role Overview: We are seeking a passionate and innovative Data Analyst to join our growing Analytics team. This is an exceptional opportunity for a detail-oriented professional to not only analyze data but also play a pivotal role in shaping and enhancing our cutting-edge AI models and products. As a Data Analyst at aiOla, you will dive into complex datasets, uncover actionable insights, and contribute directly to the improvement and monitoring of our proprietary AI technologies. If you thrive in a dynamic environment, this role is perfect for you! Requirements: B.Sc in Industrial Engineering, Data Analytics, Statistics, or a related field. Proficiency in Python, with a strong focus on libraries like Pandas for data manipulation. Solid knowledge of SQL for querying and managing large datasets. Experience with BI tools like Tableau to create dashboards and reports. Excellent communication skills, with fluency in English (written and verbal). 0-1 years of experience in a Data Analyst role- advantage Nice To have: Familiarity with Snowflake or AWS Athena. Experience with Web/App product analytics tools such as Mixpanel. Knowledge of Data Science concepts and metrics, including Speech AI, Large Language Models (LLMs), Natural Language Understanding (NLU), and Automatic Speech Recognition (ASR). Responsibilities: Extract, clean, and analyze data to uncover trends, patterns, and actionable insights. Provide recommendations based on data analysis to support business decisions and drive product improvements. Develop and maintain dashboards and reports using BI tools such as Tableau or other platforms. Optimize data workflows and pipelines using Python and SQL. Collaborate with cross-functional teams, including Product, Data Science, and Engineering, to support data-driven decision-making. Opened URL: https://il.indeed.com/rc/clk?jk=8c0efb63a00ef0d5&bb=r6UIYw2mow7Pn8IzQwq2_xdQrNIprFLEwcJQe8rzWVWb1_NSvbpLXcpcn5TXeAHedsgImdoi_2ey__b10Ys3nn9vr-SRmf6buKLYOFDHfBc8ksA0lyjjiA%3D%3D&xkcb=SoDQ67M33wH7H8WWaB0NbzkdCdPP&fccid=ba07516c418dda52&vjs=3",
         "data",
         "aiOla is a high-growth, product-led SaaS startup backed by $45 million in funding from premier investors such as New Era Capital Partners and Hamilton Lane. Our mission is to revolutionize efficiency, intelligence, collaboration, and safety in the industrial sector through our proprietary speech-powered AI technology. Our team spans the US and Israel, bringing together experts in Product, Data Science, Data Engineering, Analytics, Marketing, and Customer Success. At aiOla, we thrive on innovation, collaboration, and a commitment to excellence. We are seeking forward-thinking professionals passionate about pushing the limits of AI and making an impact. Role Overview: We are seeking a passionate and innovative Data Analyst to join our growing Analytics team. This is an exceptional opportunity for a detail-oriented professional to not only analyze data but also play a pivotal role in shaping and enhancing our cutting-edge AI models and products. As a Data Analyst at aiOla, you will dive into complex datasets, uncover actionable insights, and contribute directly to the improvement and monitoring of our proprietary AI technologies. If you thrive in a dynamic environment, this role is perfect for you! Requirements: B.Sc in Industrial Engineering, Data Analytics, Statistics, or a related field. Proficiency in Python, with a strong focus on libraries like Pandas for data manipulation. Solid knowledge of SQL for querying and managing large datasets. Experience with BI tools like Tableau to create dashboards and reports. Excellent communication skills, with fluency in English (written and verbal). 0-1 years of experience in a Data Analyst role- advantage Nice To have: Familiarity with Snowflake or AWS Athena. Experience with Web/App product analytics tools such as Mixpanel. Knowledge of Data Science concepts and metrics, including Speech AI, Large Language Models (LLMs), Natural Language Understanding (NLU), and Automatic Speech Recognition (ASR). Responsibilities: Extract, clean, and analyze data to uncover trends, patterns, and actionable insights. Provide recommendations based on data analysis to support business decisions and drive product improvements. Develop and maintain dashboards and reports using BI tools such as Tableau or other platforms. Optimize data workflows and pipelines using Python and SQL. Collaborate with cross-functional teams, including Product, Data Science, and Engineering, to support data-driven decision-making.",
         "aiOla is a high-growth, product-led SaaS startup backed by $45 million in funding from premier investors such as New Era Capital Partners and Hamilton Lane. Our mission is to revolutionize efficiency, intelligence, collaboration, and safety in the industrial sector through our proprietary speech-powered AI technology. Our team spans the US and Israel, bringing together experts in Product, Data Science, Data Engineering, Analytics, Marketing, and Customer Success. At aiOla, we thrive on innovation, collaboration, and a commitment to excellence. We are seeking forward-thinking professionals passionate about pushing the limits of AI and making an impact. Role Overview: We are seeking a passionate and innovative Data Analyst to join our growing Analytics team. This is an exceptional opportunity for a detail-oriented professional to not only analyze data but also play a pivotal role in shaping and enhancing our cutting-edge AI models and products. As a Data Analyst at aiOla, you will dive into complex datasets, uncover actionable insights, and contribute directly to the improvement and monitoring of our proprietary AI technologies. If you thrive in a dynamic environment, this role is perfect for you! Requirements: B.Sc in Industrial Engineering, Data Analytics, Statistics, or a related field. Proficiency in Python, with a strong focus on libraries like Pandas for data manipulation. Solid knowledge of SQL for querying and managing large datasets. Experience with BI tools like Tableau to create dashboards and reports. Excellent communication skills, with fluency in English (written and verbal). 0-1 years of experience in a Data Analyst role- advantage Nice To have: Familiarity with Snowflake or AWS Athena. Experience with Web/App product analytics tools such as Mixpanel. Knowledge of Data Science concepts and metrics, including Speech AI, Large Language Models (LLMs), Natural Language Understanding (NLU), and Automatic Speech Recognition (ASR). Responsibilities: Extract, clean, and analyze data to uncover trends, patterns, and actionable insights. Provide recommendations based on data analysis to support business decisions and drive product improvements. Develop and maintain dashboards and reports using BI tools such as Tableau or other platforms. Optimize data workflows and pipelines using Python and SQL. Collaborate with cross-functional teams, including Product, Data Science, and Engineering, to support data-driven decision-making."
        ],
        [
         "Data Engineer",
         "Meta",
         "As a Data Engineer at Meta, you will shape the future of people-facing and business-facing products we build across our entire family of applications (Facebook, Instagram, Messenger, WhatsApp, Reality Labs, Threads). Your technical skills and analytical mindset will be utilized designing and building some of the world's most extensive data sets, helping to craft experiences for billions of people and hundreds of millions of businesses worldwide.In this role, you will collaborate with software engineering, data science, and product management teams to design/build scalable data solutions across Meta to optimize growth, strategy, and user experience for our 3 billion plus users, as well as our internal employee community.You will be at the forefront of identifying and solving some of the most interesting data challenges at a scale few companies can match. By joining Meta, you will become part of a vibrant community dedicated to skill development and career growth in data engineering and beyond.Data Engineering: You will guide teams by building optimal data artifacts (including datasets and visualizations) to address key questions. You will refine our systems, design logging solutions, and create scalable data models. Ensuring data security and quality, and with a strong focus on efficiency, you will suggest architecture and development approaches and data management standards to address complex analytical problems.Product leadership: You will use data to shape product development, identify new opportunities, and tackle upcoming challenges. You'll ensure our products add value for users and businesses, by prioritizing projects, and driving innovative solutions to respond to challenges or opportunities.Communication and influence: You won't simply present data, but tell data-driven stories. You will convince and influence your partners using clear insights and recommendations. You will build credibility through structure and clarity, and be a trusted strategic partner. Data Engineer Responsibilities: Conceptualize and own the data architecture for multiple large-scale projects, while evaluating design and operational cost-benefit tradeoffs within systems Create and contribute to frameworks that improve the efficacy of logging data, while working with data infrastructure to triage issues and resolve Collaborate with engineers, product managers, and data scientists to understand data needs, representing key data insights in a meaningful way Define and manage Service Level Agreements for all data sets in allocated areas of ownership Determine and implement the security model based on privacy requirements, confirm safeguards are followed, address data quality issues, and evolve governance processes within allocated areas of ownership Design, build, and launch collections of sophisticated data models and visualizations that support multiple use cases across different products or domains Solve our most challenging data integration problems, utilizing optimal Extract, Transform, Load (ETL) patterns, frameworks, query techniques, sourcing from structured and unstructured data sources Assist in owning existing processes running in production, optimizing complex code through advanced algorithmic concepts Optimize pipelines, dashboards, frameworks, and systems to facilitate easier development of data artifacts Influence product and cross-functional teams to identify data opportunities to drive impact Mentor team members by giving/receiving actionable feedback Minimum Qualifications: Bachelor's degree in Computer Science, Engineering, relevant technical field, or equivalent 4+ years of experience where the primary responsibility involves working with data. This could include roles such as data analyst, data scientist, data engineer, or similar positions 4+ years of experience (or a minimum of 2+ years with a Ph.D) with SQL, ETL, data modeling, and at least one programming language (e.g., Python, C++, C#, Scala, etc.) About Meta: Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today—beyond the constraints of screens, the limits of distance, and even the rules of physics. Individual compensation is determined by skills, qualifications, experience, and location. Compensation details listed in this posting reflect the base hourly rate, monthly rate, or annual salary only, and do not include bonus, equity or sales incentives, if applicable. In addition to base compensation, Meta offers benefits. Learn more about benefits at Meta. Opened URL: https://il.indeed.com/rc/clk?jk=332ce6560e8316dc&bb=r6UIYw2mow7Pn8IzQwq2_562YukhS6UN3gQsCZxi2egxfUB-GUkmkThkhz4gjqWPCW22mO4kb3LIM8QmQyIpRZmtmdc9AupjQYBTLVDksxFngEUdv3hLf8xgn6T3kHo6&xkcb=SoBk67M33wH7H8WWaB0MbzkdCdPP&fccid=4d28265c01696bc0&vjs=3",
         "data",
         "As a Data Engineer at Meta, you will shape the future of people-facing and business-facing products we build across our entire family of applications (Facebook, Instagram, Messenger, WhatsApp, Reality Labs, Threads). Your technical skills and analytical mindset will be utilized designing and building some of the world's most extensive data sets, helping to craft experiences for billions of people and hundreds of millions of businesses worldwide.In this role, you will collaborate with software engineering, data science, and product management teams to design/build scalable data solutions across Meta to optimize growth, strategy, and user experience for our 3 billion plus users, as well as our internal employee community.You will be at the forefront of identifying and solving some of the most interesting data challenges at a scale few companies can match. By joining Meta, you will become part of a vibrant community dedicated to skill development and career growth in data engineering and beyond.Data Engineering: You will guide teams by building optimal data artifacts (including datasets and visualizations) to address key questions. You will refine our systems, design logging solutions, and create scalable data models. Ensuring data security and quality, and with a strong focus on efficiency, you will suggest architecture and development approaches and data management standards to address complex analytical problems.Product leadership: You will use data to shape product development, identify new opportunities, and tackle upcoming challenges. You'll ensure our products add value for users and businesses, by prioritizing projects, and driving innovative solutions to respond to challenges or opportunities.Communication and influence: You won't simply present data, but tell data-driven stories. You will convince and influence your partners using clear insights and recommendations. You will build credibility through structure and clarity, and be a trusted strategic partner. Data Engineer Responsibilities: Conceptualize and own the data architecture for multiple large-scale projects, while evaluating design and operational cost-benefit tradeoffs within systems Create and contribute to frameworks that improve the efficacy of logging data, while working with data infrastructure to triage issues and resolve Collaborate with engineers, product managers, and data scientists to understand data needs, representing key data insights in a meaningful way Define and manage Service Level Agreements for all data sets in allocated areas of ownership Determine and implement the security model based on privacy requirements, confirm safeguards are followed, address data quality issues, and evolve governance processes within allocated areas of ownership Design, build, and launch collections of sophisticated data models and visualizations that support multiple use cases across different products or domains Solve our most challenging data integration problems, utilizing optimal Extract, Transform, Load (ETL) patterns, frameworks, query techniques, sourcing from structured and unstructured data sources Assist in owning existing processes running in production, optimizing complex code through advanced algorithmic concepts Optimize pipelines, dashboards, frameworks, and systems to facilitate easier development of data artifacts Influence product and cross-functional teams to identify data opportunities to drive impact Mentor team members by giving/receiving actionable feedback Minimum Qualifications: Bachelor's degree in Computer Science, Engineering, relevant technical field, or equivalent 4+ years of experience where the primary responsibility involves working with data. This could include roles such as data analyst, data scientist, data engineer, or similar positions 4+ years of experience (or a minimum of 2+ years with a Ph.D) with SQL, ETL, data modeling, and at least one programming language (e.g., Python, C++, C#, Scala, etc.) About Meta: Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today—beyond the constraints of screens, the limits of distance, and even the rules of physics. Individual compensation is determined by skills, qualifications, experience, and location. Compensation details listed in this posting reflect the base hourly rate, monthly rate, or annual salary only, and do not include bonus, equity or sales incentives, if applicable. In addition to base compensation, Meta offers benefits. Learn more about benefits at Meta.",
         "As a Data Engineer at Meta, you will shape the future of people-facing and business-facing products we build across our entire family of applications (Facebook, Instagram, Messenger, WhatsApp, Reality Labs, Threads). Your technical skills and analytical mindset will be utilized designing and building some of the world's most extensive data sets, helping to craft experiences for billions of people and hundreds of millions of businesses worldwide.In this role, you will collaborate with software engineering, data science, and product management teams to design/build scalable data solutions across Meta to optimize growth, strategy, and user experience for our 3 billion plus users, as well as our internal employee community.You will be at the forefront of identifying and solving some of the most interesting data challenges at a scale few companies can match. By joining Meta, you will become part of a vibrant community dedicated to skill development and career growth in data engineering and beyond.Data Engineering: You will guide teams by building optimal data artifacts (including datasets and visualizations) to address key questions. You will refine our systems, design logging solutions, and create scalable data models. Ensuring data security and quality, and with a strong focus on efficiency, you will suggest architecture and development approaches and data management standards to address complex analytical problems.Product leadership: You will use data to shape product development, identify new opportunities, and tackle upcoming challenges. You'll ensure our products add value for users and businesses, by prioritizing projects, and driving innovative solutions to respond to challenges or opportunities.Communication and influence: You won't simply present data, but tell data-driven stories. You will convince and influence your partners using clear insights and recommendations. You will build credibility through structure and clarity, and be a trusted strategic partner. Data Engineer Responsibilities: Conceptualize and own the data architecture for multiple large-scale projects, while evaluating design and operational cost-benefit tradeoffs within systems Create and contribute to frameworks that improve the efficacy of logging data, while working with data infrastructure to triage issues and resolve Collaborate with engineers, product managers, and data scientists to understand data needs, representing key data insights in a meaningful way Define and manage Service Level Agreements for all data sets in allocated areas of ownership Determine and implement the security model based on privacy requirements, confirm safeguards are followed, address data quality issues, and evolve governance processes within allocated areas of ownership Design, build, and launch collections of sophisticated data models and visualizations that support multiple use cases across different products or domains Solve our most challenging data integration problems, utilizing optimal Extract, Transform, Load (ETL) patterns, frameworks, query techniques, sourcing from structured and unstructured data sources Assist in owning existing processes running in production, optimizing complex code through advanced algorithmic concepts Optimize pipelines, dashboards, frameworks, and systems to facilitate easier development of data artifacts Influence product and cross-functional teams to identify data opportunities to drive impact Mentor team members by giving/receiving actionable feedback Minimum Qualifications: Bachelor's degree in Computer Science, Engineering, relevant technical field, or equivalent 4+ years of experience where the primary responsibility involves working with data. This could include roles such as data analyst, data scientist, data engineer, or similar positions 4+ years of experience (or a minimum of 2+ years with a Ph.D) with SQL, ETL, data modeling, and at least one programming language (e.g., Python, C++, C#, Scala, etc.) About Meta: Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today—beyond the constraints of screens, the limits of distance, and even the rules of physics. Individual compensation is determined by skills, qualifications, experience, and location. Compensation details listed in this posting reflect the base hourly rate, monthly rate, or annual salary only, and do not include bonus, equity or sales incentives, if applicable. In addition to base compensation, Meta offers benefits. Learn more about benefits at Meta."
        ],
        [
         "Junior Data Engineer",
         "Aquant",
         "At Aquant, we empower field service professionals to become heroes using our personalized generative AI platform, Service Co-Pilot. Using historical service data, Aquant equips service leaders, field technicians, and customer service representatives with the precise information they need when they need it—enabling them to make decisions with confidence, reduce costs, and optimize service delivery. Recognized as one of Fast Company's Next Big Things in Tech of 2024 , we are committed to providing cutting-edge AI solutions that tackle the most pressing challenges in manufacturing. Ready to join a team that values innovation, excellence, and above all, its people? Apply today! Aquant's Data Analytics team is looking for a highly skilled Data Engineer who is comfortable with big data and complex data models. As a member of our Data Engineering team, you will: Work with large amounts of data and develop Python code to streamline processes Analyze different data structures and create the required reports out of them Collaborate \\ connect to existing codes Build tools to track data quality on large DB with complicated schemas Monitor the integrity and validity of the customer service data Deep dive into the service data and learn the service world Required skills & background: 2-3 years experience with big datasets BA/B.Sc. in industrial/information systems engineering, statistics or equivalent Hands-on experience with Excel + SQL - must Hands-on experience with Python – must Experience with Azure services - advantage A team player, with excellent collaboration skills Excellent communicator with the ability to deliver high-quality results Fluent English It's not enough to have a cool product, join us because you share our values: These guiding values inspire every Aquant employee. They are how we operate and enable our company as a whole to have a greater impact and achieve our vision: Be Humble and Respectful: We are one team, where collective success is more important than individual ego. Treat your colleagues with respect and empathy, act with good intent, and value everyone's contributions. Be Curious: Keep learning, and asking questions to understand complex situations. Embrace new challenges. Keep an open mind, and be receptive to feedback. Take Ownership: Focus on achieving measurable and meaningful outcomes. Take decisive action, solve problems proactively, and take ownership of projects and results. Act with Integrity: Act with Integrity. Do great things while doing the right thing for your customers and colleagues. Some of our benefits: Vacation your way: We want to make sure you have time to meet your personal needs with generous PTO and flexible vacation planning. Everyone is an owner: We want everyone to feel ownership over their work and what we are building here, which is why we offer equity to full-time employees. Build your career: Every Aquant employee is in control of their career development with our learning stipends, tools, and training. Applicants must be authorized to work for any employer in the Israel. We are unable to sponsor or take over sponsorship of an employment Visa at this time. Aquant is committed to hiring a diverse and talented workforce. Opened URL: https://il.indeed.com/rc/clk?jk=ae2c3d8865d70a20&bb=r6UIYw2mow7Pn8IzQwq2_-VNnSBFDXo8Ynf-6utD7gBjMIDitHzsM1MRE1_A3cWHXQijHHfglfmBI95kAdDXDG8bj1QKQcCe9jGagYeS_BwRE1OhyZy2w5SIATwSfwc1&xkcb=SoCN67M33wH7H8WWaB0DbzkdCdPP&fccid=ba03cd038fd30855&vjs=3",
         "data",
         "At Aquant, we empower field service professionals to become heroes using our personalized generative AI platform, Service Co-Pilot. Using historical service data, Aquant equips service leaders, field technicians, and customer service representatives with the precise information they need when they need it—enabling them to make decisions with confidence, reduce costs, and optimize service delivery. Recognized as one of Fast Company's Next Big Things in Tech of 2024 , we are committed to providing cutting-edge AI solutions that tackle the most pressing challenges in manufacturing. Ready to join a team that values innovation, excellence, and above all, its people? Apply today! Aquant's Data Analytics team is looking for a highly skilled Data Engineer who is comfortable with big data and complex data models. As a member of our Data Engineering team, you will: Work with large amounts of data and develop Python code to streamline processes Analyze different data structures and create the required reports out of them Collaborate \\ connect to existing codes Build tools to track data quality on large DB with complicated schemas Monitor the integrity and validity of the customer service data Deep dive into the service data and learn the service world Required skills & background: 2-3 years experience with big datasets BA/B.Sc. in industrial/information systems engineering, statistics or equivalent Hands-on experience with Excel + SQL - must Hands-on experience with Python – must Experience with Azure services - advantage A team player, with excellent collaboration skills Excellent communicator with the ability to deliver high-quality results Fluent English It's not enough to have a cool product, join us because you share our values: These guiding values inspire every Aquant employee. They are how we operate and enable our company as a whole to have a greater impact and achieve our vision: Be Humble and Respectful: We are one team, where collective success is more important than individual ego. Treat your colleagues with respect and empathy, act with good intent, and value everyone's contributions. Be Curious: Keep learning, and asking questions to understand complex situations. Embrace new challenges. Keep an open mind, and be receptive to feedback. Take Ownership: Focus on achieving measurable and meaningful outcomes. Take decisive action, solve problems proactively, and take ownership of projects and results. Act with Integrity: Act with Integrity. Do great things while doing the right thing for your customers and colleagues. Some of our benefits: Vacation your way: We want to make sure you have time to meet your personal needs with generous PTO and flexible vacation planning. Everyone is an owner: We want everyone to feel ownership over their work and what we are building here, which is why we offer equity to full-time employees. Build your career: Every Aquant employee is in control of their career development with our learning stipends, tools, and training. Applicants must be authorized to work for any employer in the Israel. We are unable to sponsor or take over sponsorship of an employment Visa at this time. Aquant is committed to hiring a diverse and talented workforce.",
         "At Aquant, we empower field service professionals to become heroes using our personalized generative AI platform, Service Co-Pilot. Using historical service data, Aquant equips service leaders, field technicians, and customer service representatives with the precise information they need when they need it—enabling them to make decisions with confidence, reduce costs, and optimize service delivery. Recognized as one of Fast Company's Next Big Things in Tech of 2024 , we are committed to providing cutting-edge AI solutions that tackle the most pressing challenges in manufacturing. Ready to join a team that values innovation, excellence, and above all, its people? Apply today! Aquant's Data Analytics team is looking for a highly skilled Data Engineer who is comfortable with big data and complex data models. As a member of our Data Engineering team, you will: Work with large amounts of data and develop Python code to streamline processes Analyze different data structures and create the required reports out of them Collaborate \\ connect to existing codes Build tools to track data quality on large DB with complicated schemas Monitor the integrity and validity of the customer service data Deep dive into the service data and learn the service world Required skills & background: 2-3 years experience with big datasets BA/B.Sc. in industrial/information systems engineering, statistics or equivalent Hands-on experience with Excel + SQL - must Hands-on experience with Python – must Experience with Azure services - advantage A team player, with excellent collaboration skills Excellent communicator with the ability to deliver high-quality results Fluent English It's not enough to have a cool product, join us because you share our values: These guiding values inspire every Aquant employee. They are how we operate and enable our company as a whole to have a greater impact and achieve our vision: Be Humble and Respectful: We are one team, where collective success is more important than individual ego. Treat your colleagues with respect and empathy, act with good intent, and value everyone's contributions. Be Curious: Keep learning, and asking questions to understand complex situations. Embrace new challenges. Keep an open mind, and be receptive to feedback. Take Ownership: Focus on achieving measurable and meaningful outcomes. Take decisive action, solve problems proactively, and take ownership of projects and results. Act with Integrity: Act with Integrity. Do great things while doing the right thing for your customers and colleagues. Some of our benefits: Vacation your way: We want to make sure you have time to meet your personal needs with generous PTO and flexible vacation planning. Everyone is an owner: We want everyone to feel ownership over their work and what we are building here, which is why we offer equity to full-time employees. Build your career: Every Aquant employee is in control of their career development with our learning stipends, tools, and training. Applicants must be authorized to work for any employer in the Israel. We are unable to sponsor or take over sponsorship of an employment Visa at this time. Aquant is committed to hiring a diverse and talented workforce."
        ],
        [
         "Data Scientist",
         "Rubrik Job Board",
         "About Team & About Role: Rubrik is seeking a Data Scientist to join our Data Research team, part of the Security Apps organization responsible for developing Rubrik’s suite of security products. This is the first data scientist position on the team, requiring a high degree of independence and ownership. You’ll spearhead research and development of ML/AI models that power the features of our security offerings. What You’ll Do: Research and develop ML/AI models in the NLP domain Develop advanced anomaly detection models for threat detection Work closely with data analysts on research, pattern analysis, etc. Work closely with developers on implementation of models as part of features in the product Work with global teams to continuously push our ML infrastructure forward Experience You’ll Need: Bachelor’s degree in Mathematics, Computer Science, or other related field 3 years of experience in data science or a related field Proficiency in programming languages, especially Python Experience with common data science toolkits, such as Jupyter Notebook, Pandas, NumPy, Matplotlib, etc. Demonstrated experience in implementing ML algorithms in production environments, with a focus on anomaly detection and natural language processing. Strong problem-solving skills and analytic capability to develop insights and recommendations Excellent communication skills in Hebrew and English Preferred Qualifications: Master’s degree in Mathematics, Computer Science, or other related field Familiarity with cloud platforms such as AWS, Google Cloud, or Azure Experience working with LLMs Previous experience in the security industry Join Us in Securing the World's Data Rubrik (NYSE: RBRK) is on a mission to secure the world’s data. With Zero Trust Data Security™, we help organizations achieve business resilience against cyberattacks, malicious insiders, and operational disruptions. Rubrik Security Cloud, powered by machine learning, secures data across enterprise, cloud, and SaaS applications. We help organizations uphold data integrity, deliver data availability that withstands adverse conditions, continuously monitor data risks and threats, and restore businesses with their data when infrastructure is attacked. Linkedin | X (formerly Twitter) | Instagram | Rubrik.com Diversity, Equity & Inclusion @ Rubrik At Rubrik we are committed to building and sustaining a culture where people of all backgrounds are valued, know they belong, and believe they can succeed here. Rubrik's goal is to hire and promote the best person for the job, no matter their background. In doing so, Rubrik is committed to correcting systemic processes and cultural norms that have prevented equal representation. This means we review our current efforts with the intent to offer fair hiring, promotion, and compensation opportunities to people from historically underrepresented communities, and strive to create a company culture where all employees feel they can bring their authentic selves to work and be successful. Our DEI strategy focuses on three core areas of our business and culture: Our Company: Build a diverse company that provides equitable access to growth and success for all employees globally. Our Culture: Create an inclusive environment where authenticity thrives and people of all backgrounds feel like they belong. Our Communities: Expand our commitment to diversity, equity, & inclusion within and beyond our company walls to invest in future generations of underrepresented talent and bring innovation to our clients. Equal Opportunity Employer/Veterans/Disabled Rubrik is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, or protected veteran status and will not be discriminated against on the basis of disability. Rubrik provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability or genetics. In addition to federal law requirements, Rubrik complies with applicable state and local laws governing nondiscrimination in employment in every location in which the company has facilities. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training. Federal law requires employers to provide reasonable accommodation to qualified individuals with disabilities. Please contact us at hr@rubrik.com if you require a reasonable accommodation to apply for a job or to perform your job. Examples of reasonable accommodation include making a change to the application process or work procedures, providing documents in an alternate format, using a sign language interpreter, or using specialized equipment. Opened URL: https://il.indeed.com/rc/clk?jk=ad3b38d6d843bb02&bb=r6UIYw2mow7Pn8IzQwq2_yYq9SF7G8SWRQOq2tS0E5s2WTIxqyX5UvFT8u-SbU_SASUW0mVJ_I7cT2iX1zPkHRDbfnLFNxLKcDajKYoqI5cz62T43EBWZ9Z5mO0gfo-W&xkcb=SoA567M33wH7H8WWaB0CbzkdCdPP&fccid=c4e7a75c6cddb35a&vjs=3",
         "data",
         "About Team & About Role: Rubrik is seeking a Data Scientist to join our Data Research team, part of the Security Apps organization responsible for developing Rubrik’s suite of security products. This is the first data scientist position on the team, requiring a high degree of independence and ownership. You’ll spearhead research and development of ML/AI models that power the features of our security offerings. What You’ll Do: Research and develop ML/AI models in the NLP domain Develop advanced anomaly detection models for threat detection Work closely with data analysts on research, pattern analysis, etc. Work closely with developers on implementation of models as part of features in the product Work with global teams to continuously push our ML infrastructure forward Experience You’ll Need: Bachelor’s degree in Mathematics, Computer Science, or other related field 3 years of experience in data science or a related field Proficiency in programming languages, especially Python Experience with common data science toolkits, such as Jupyter Notebook, Pandas, NumPy, Matplotlib, etc. Demonstrated experience in implementing ML algorithms in production environments, with a focus on anomaly detection and natural language processing. Strong problem-solving skills and analytic capability to develop insights and recommendations Excellent communication skills in Hebrew and English Preferred Qualifications: Master’s degree in Mathematics, Computer Science, or other related field Familiarity with cloud platforms such as AWS, Google Cloud, or Azure Experience working with LLMs Previous experience in the security industry Join Us in Securing the World's Data Rubrik (NYSE: RBRK) is on a mission to secure the world’s data. With Zero Trust Data Security™, we help organizations achieve business resilience against cyberattacks, malicious insiders, and operational disruptions. Rubrik Security Cloud, powered by machine learning, secures data across enterprise, cloud, and SaaS applications. We help organizations uphold data integrity, deliver data availability that withstands adverse conditions, continuously monitor data risks and threats, and restore businesses with their data when infrastructure is attacked. Linkedin | X (formerly Twitter) | Instagram | Rubrik.com Diversity, Equity & Inclusion @ Rubrik At Rubrik we are committed to building and sustaining a culture where people of all backgrounds are valued, know they belong, and believe they can succeed here. Rubrik's goal is to hire and promote the best person for the job, no matter their background. In doing so, Rubrik is committed to correcting systemic processes and cultural norms that have prevented equal representation. This means we review our current efforts with the intent to offer fair hiring, promotion, and compensation opportunities to people from historically underrepresented communities, and strive to create a company culture where all employees feel they can bring their authentic selves to work and be successful. Our DEI strategy focuses on three core areas of our business and culture: Our Company: Build a diverse company that provides equitable access to growth and success for all employees globally. Our Culture: Create an inclusive environment where authenticity thrives and people of all backgrounds feel like they belong. Our Communities: Expand our commitment to diversity, equity, & inclusion within and beyond our company walls to invest in future generations of underrepresented talent and bring innovation to our clients. Equal Opportunity Employer/Veterans/Disabled Rubrik is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, or protected veteran status and will not be discriminated against on the basis of disability. Rubrik provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability or genetics. In addition to federal law requirements, Rubrik complies with applicable state and local laws governing nondiscrimination in employment in every location in which the company has facilities. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training. Federal law requires employers to provide reasonable accommodation to qualified individuals with disabilities. Please contact us at hr@rubrik.com if you require a reasonable accommodation to apply for a job or to perform your job. Examples of reasonable accommodation include making a change to the application process or work procedures, providing documents in an alternate format, using a sign language interpreter, or using specialized equipment.",
         "About Team & About Role: Rubrik is seeking a Data Scientist to join our Data Research team, part of the Security Apps organization responsible for developing Rubrik’s suite of security products. This is the first data scientist position on the team, requiring a high degree of independence and ownership. You’ll spearhead research and development of ML/AI models that power the features of our security offerings. What You’ll Do: Research and develop ML/AI models in the NLP domain Develop advanced anomaly detection models for threat detection Work closely with data analysts on research, pattern analysis, etc. Work closely with developers on implementation of models as part of features in the product Work with global teams to continuously push our ML infrastructure forward Experience You’ll Need: Bachelor’s degree in Mathematics, Computer Science, or other related field 3 years of experience in data science or a related field Proficiency in programming languages, especially Python Experience with common data science toolkits, such as Jupyter Notebook, Pandas, NumPy, Matplotlib, etc. Demonstrated experience in implementing ML algorithms in production environments, with a focus on anomaly detection and natural language processing. Strong problem-solving skills and analytic capability to develop insights and recommendations Excellent communication skills in Hebrew and English Preferred Qualifications: Master’s degree in Mathematics, Computer Science, or other related field Familiarity with cloud platforms such as AWS, Google Cloud, or Azure Experience working with LLMs Previous experience in the security industry Join Us in Securing the World's Data Rubrik (NYSE: RBRK) is on a mission to secure the world’s data. With Zero Trust Data Security™, we help organizations achieve business resilience against cyberattacks, malicious insiders, and operational disruptions. Rubrik Security Cloud, powered by machine learning, secures data across enterprise, cloud, and SaaS applications. We help organizations uphold data integrity, deliver data availability that withstands adverse conditions, continuously monitor data risks and threats, and restore businesses with their data when infrastructure is attacked. Linkedin | X (formerly Twitter) | Instagram | Rubrik.com Diversity, Equity & Inclusion @ Rubrik At Rubrik we are committed to building and sustaining a culture where people of all backgrounds are valued, know they belong, and believe they can succeed here. Rubrik's goal is to hire and promote the best person for the job, no matter their background. In doing so, Rubrik is committed to correcting systemic processes and cultural norms that have prevented equal representation. This means we review our current efforts with the intent to offer fair hiring, promotion, and compensation opportunities to people from historically underrepresented communities, and strive to create a company culture where all employees feel they can bring their authentic selves to work and be successful. Our DEI strategy focuses on three core areas of our business and culture: Our Company: Build a diverse company that provides equitable access to growth and success for all employees globally. Our Culture: Create an inclusive environment where authenticity thrives and people of all backgrounds feel like they belong. Our Communities: Expand our commitment to diversity, equity, & inclusion within and beyond our company walls to invest in future generations of underrepresented talent and bring innovation to our clients. Equal Opportunity Employer/Veterans/Disabled Rubrik is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, or protected veteran status and will not be discriminated against on the basis of disability. Rubrik provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability or genetics. In addition to federal law requirements, Rubrik complies with applicable state and local laws governing nondiscrimination in employment in every location in which the company has facilities. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training. Federal law requires employers to provide reasonable accommodation to qualified individuals with disabilities. Please contact us at hr@rubrik.com if you require a reasonable accommodation to apply for a job or to perform your job. Examples of reasonable accommodation include making a change to the application process or work procedures, providing documents in an alternate format, using a sign language interpreter, or using specialized equipment."
        ],
        [
         "data scientist!",
         "Horizon Technologies",
         "לארגון גדול ומוביל טכנולוגית בירושלים דרוש/ה data scientist! עבודה במתכונת היברידית מרובה! תיאור התפקיד: איש מדע נתונים והתממה ימלא תפקיד חשוב במחלקת ביג דאטה ויהיה אחראי על שורה של פעילויות שיאפשרו מחקרי נתונים על מאגרי המשרד וארגונים שעובדים עם המחלקה. יישום מדיניות ההתממה של מחלקת ביג דאטה באמצעות עבודה צמודה עם מהנדסי נתונים שיבצעו את פעולות ההתממה ואף באמצעות ביצוע פעולות אלה בעצמו בכלי ניתוח המוגדרים בתמנ\"ע, כגון SQL, PYTHON, דאטאיקו ואחרים. כמו כן יהיה אחראי על תהליכי בדיקת איכות (QA) ההתממה בסביבה בה בוצעו האנליזות והעיבודים על הנתונים, או בליווי מהנדס נתונים שיבצע פעולות אלה. המערכות שבשימוש SQL, PYTHON, DATAIKU, CLOUDERA, לא מוגבלות לשימוש רק באלה. דרישות: 3 שנות ניסיון ומעלה בתפקידי דאטה מתוכן שנה אחת לפחות ב- data science (תפקידי דאטה: אנליטיקה של נתונים, הנדסת נתונים, מדע נתונים, פיתוח BI) ניסיון בהפעלת כלי התממה טבלאיים (למשל Privitar, Dataiku) - מינימום שנה ניסיון, מינימום עבודה על 30 טבלאות ניסיון בהתממה בתחום הבריאות - חובה. ניסיון בהתממת נתונים טבלאיים חובה. ⁠התממת טקסט חופשי - חובה. התממת טקסט חופשי בעברית - יתרון משמעותי. ניסיון בעבודה על התממה מול חוקרים באקדמיה - יתרון Opened URL: https://il.indeed.com/rc/clk?jk=f90aa7093544f010&bb=r6UIYw2mow7Pn8IzQwq2_xyaGdaoejrhyKNPDULo5mrjaIrPYiIvCcF52gDTKS5ckQ4Tob9j7S8rgIEWt6fB4Q2dVUswzFz8eib5DhxHjVmhwfPeuvoDONJ99fqrpBqv&xkcb=SoCk67M33wH7H8WWaB0BbzkdCdPP&fccid=e32508b84ec45c2b&vjs=3",
         "data",
         "לארגון גדול ומוביל טכנולוגית בירושלים דרוש/ה data scientist! עבודה במתכונת היברידית מרובה! תיאור התפקיד: איש מדע נתונים והתממה ימלא תפקיד חשוב במחלקת ביג דאטה ויהיה אחראי על שורה של פעילויות שיאפשרו מחקרי נתונים על מאגרי המשרד וארגונים שעובדים עם המחלקה. יישום מדיניות ההתממה של מחלקת ביג דאטה באמצעות עבודה צמודה עם מהנדסי נתונים שיבצעו את פעולות ההתממה ואף באמצעות ביצוע פעולות אלה בעצמו בכלי ניתוח המוגדרים בתמנ\"ע, כגון SQL, PYTHON, דאטאיקו ואחרים. כמו כן יהיה אחראי על תהליכי בדיקת איכות (QA) ההתממה בסביבה בה בוצעו האנליזות והעיבודים על הנתונים, או בליווי מהנדס נתונים שיבצע פעולות אלה. המערכות שבשימוש SQL, PYTHON, DATAIKU, CLOUDERA, לא מוגבלות לשימוש רק באלה. דרישות: 3 שנות ניסיון ומעלה בתפקידי דאטה מתוכן שנה אחת לפחות ב- data science (תפקידי דאטה: אנליטיקה של נתונים, הנדסת נתונים, מדע נתונים, פיתוח BI) ניסיון בהפעלת כלי התממה טבלאיים (למשל Privitar, Dataiku) - מינימום שנה ניסיון, מינימום עבודה על 30 טבלאות ניסיון בהתממה בתחום הבריאות - חובה. ניסיון בהתממת נתונים טבלאיים חובה. ⁠התממת טקסט חופשי - חובה. התממת טקסט חופשי בעברית - יתרון משמעותי. ניסיון בעבודה על התממה מול חוקרים באקדמיה - יתרון",
         "A large, technologically leading organization in Jerusalem needs a data scientist! Work in a hybrid multi-tasking format! Job description: A data scientist and data scientist will play an important role in the Big Data department and will be responsible for a series of activities that will enable data research on the office's databases and organizations that work with the department. Implementing the Big Data department's data mining policy by working closely with data engineers who will perform the mining operations and even by performing these operations themselves in analysis tools defined in the Data Mining and Data Analysis Framework, such as SQL, PYTHON, DataIKU, and others. He will also be responsible for the quality assurance (QA) processes of the mining in the environment where the analyses and processing of the data were performed, or accompanied by a data engineer who will perform these operations. The systems used are SQL, PYTHON, DATAIKU, CLOUDERA, but are not limited to these. Requirements: 3 years or more of experience in data roles, including at least one year in data science (data roles: data analytics, data engineering, data science, BI development) Experience operating tabular mining tools (e.g. Privitar, Dataiku) - minimum one year of experience, minimum work on 30 tables Experience in mining in the healthcare field - mandatory. Experience in tabular data mining is mandatory. ⁠Free text mining - mandatory. Free text mining in Hebrew - Significant advantage. Experience working on Tama with researchers in academia - an advantage"
        ],
        [
         "Data Scientist",
         "Ticomsoft",
         "jb-19 מספר משרה : עם ניסיון ב Data Scientist דרוש איש/ת פיתוח Evaluating state of art statistical modeling and machine Learning. Big data analysis, Modeling and Reporting. Job Requirements:Requirements: A minimum first degree in computer science/ applied math/ statistics. Strong algorithm development skills. Proven experience with machine learning algorithms – both supervised and unsupervised. Proven experience with optimization algorithms. 5+ years of relevant experience with one of the following: Python, R, Matlab. Strong communication skills, creative, results driven, quick learner. Experience with big data, distributed processing, NoSQL databases – a significant advantage. השם שלך מספר המשרה(חובה) העלאת קו\"ח שתף את המשרה ותן לחברים שלך לעזור Opened URL: https://il.indeed.com/rc/clk?jk=d93f96511474983d&bb=r6UIYw2mow7Pn8IzQwq2_5aHKW3wZhMixewaX6PYd3gfA9lT-ljRyZagyU-B6VRsq5WetHFTiwUEwJhRVi0EoeZ2l1gDnl0VKDEJDOrEiNtxwcGFGMy1pCHdHBhSYAxX&xkcb=SoAQ67M33wH7H8WWaB0AbzkdCdPP&fccid=9c02dc25b0c9c8ac&vjs=3",
         "data",
         "jb-19 מספר משרה : עם ניסיון ב Data Scientist דרוש איש/ת פיתוח Evaluating state of art statistical modeling and machine Learning. Big data analysis, Modeling and Reporting. Job Requirements:Requirements: A minimum first degree in computer science/ applied math/ statistics. Strong algorithm development skills. Proven experience with machine learning algorithms – both supervised and unsupervised. Proven experience with optimization algorithms. 5+ years of relevant experience with one of the following: Python, R, Matlab. Strong communication skills, creative, results driven, quick learner. Experience with big data, distributed processing, NoSQL databases – a significant advantage. השם שלך מספר המשרה(חובה) העלאת קו\"ח שתף את המשרה ותן לחברים שלך לעזור",
         "jb-19 Job Number: With experience in Data Scientist Need a Development Person Evaluating state of art statistical modeling and machine Learning. Big data analysis, Modeling and Reporting. Job Requirements:Requirements: A minimum first degree in computer science/ applied math/ statistics. Strong algorithm development skills. Proven experience with machine learning algorithms – both supervised and unsupervised. Proven experience with optimization algorithms. 5+ years of relevant experience with one of the following: Python, R, Matlab. Strong communication skills, creative, results driven, quick learner. Experience with big data, distributed processing, NoSQL databases – a significant advantage. Your Name Job Number (Required) Upload Resume Share the job and let your friends help"
        ],
        [
         "Customer Data Engineer",
         "Optimove",
         "Optimove is a global marketing tech company, recognized as a Leader by Forrester and a Challenger by Gartner. We work with some of the world's most exciting brands, such as Sephora, Staples, and Entain, who love our thought-provoking combination of art and science. With a strong product, a proven business, and the DNA of a vibrant, fast-growing startup, we're on the cusp of our next growth spurt. It's the perfect time to join our team of ~450 thinkers and doers across NYC, LDN, TLV, and other locations, where 2 of every 3 managers were promoted from within. Growing your career with Optimove is basically guaranteed. As a Customer Data Engineer, you will be a part of a strong energetic, and fast-growing global team. You will be an integral part of clients' onboarding and ongoing data requests and projects. You will be working closely with internal PM and CSM teams as well as interacting directly with clients' data teams across different business verticals. Your core responsibilities will involve playing an active role in collaborating with internal teams to construct tailored data transformations and manipulations while working with top-notch technology (Cloud tech etc.) The ideal candidate is an SQL whiz with a strong work ethic, robust analytical and technical capabilities, and highly effective time management skills. We are looking for a master multi-tasker who thrives in challenging, fast-paced environments, with agility and ease. The Customer Data Engineer is a position that brings with it an excellent opportunity to learn and grow within a rapidly expanding company on the cutting edge of Martech. Responsibilities: Develop and support a wide range of data transformations and migrations Construct custom ETL processes: Design and implementation of data pipelines and data marts, access versatile data sources, and apply data quality measures Investigate data mismatches and apply solutions Work side by side and support the Customer Success teams in order to meet customer business needs. Interact with clients to understand business needs and collaborate on project scopes, planning, and execution. Requirements: Graduate with a degree in Industrial Engineering and Management or a similar major Experience with databases and SQL - a Must Outstanding technical and analytical skills Highly motivated with an exceptional work ethic High attention to detail with an ability to work on multiple projects simultaneously Strong interpersonal and communication skills Quick, self-learning capabilities and creativity in problem-solving Preferred: Familiarity with Python Familiarity with Airflow, ETL tools, Snowflake and MSSQL Hands-on with VCS (Git) Opened URL: https://il.indeed.com/rc/clk?jk=2801e9b70cffdf56&bb=r6UIYw2mow7Pn8IzQwq2_w5YrxcEPRyMpab_ptbJnVUDkRmEoNNi7UMraqcjAeiFuNnjUruViO-PX0WlliOY0l-uH1XqjwIaiy7fbwsHkyj9Q3jCnteWwoMjH-QmTHz4&xkcb=SoCe67M33wH7H8WWaB0HbzkdCdPP&fccid=5ad6f11eb660c9a3&vjs=3",
         "data",
         "Optimove is a global marketing tech company, recognized as a Leader by Forrester and a Challenger by Gartner. We work with some of the world's most exciting brands, such as Sephora, Staples, and Entain, who love our thought-provoking combination of art and science. With a strong product, a proven business, and the DNA of a vibrant, fast-growing startup, we're on the cusp of our next growth spurt. It's the perfect time to join our team of ~450 thinkers and doers across NYC, LDN, TLV, and other locations, where 2 of every 3 managers were promoted from within. Growing your career with Optimove is basically guaranteed. As a Customer Data Engineer, you will be a part of a strong energetic, and fast-growing global team. You will be an integral part of clients' onboarding and ongoing data requests and projects. You will be working closely with internal PM and CSM teams as well as interacting directly with clients' data teams across different business verticals. Your core responsibilities will involve playing an active role in collaborating with internal teams to construct tailored data transformations and manipulations while working with top-notch technology (Cloud tech etc.) The ideal candidate is an SQL whiz with a strong work ethic, robust analytical and technical capabilities, and highly effective time management skills. We are looking for a master multi-tasker who thrives in challenging, fast-paced environments, with agility and ease. The Customer Data Engineer is a position that brings with it an excellent opportunity to learn and grow within a rapidly expanding company on the cutting edge of Martech. Responsibilities: Develop and support a wide range of data transformations and migrations Construct custom ETL processes: Design and implementation of data pipelines and data marts, access versatile data sources, and apply data quality measures Investigate data mismatches and apply solutions Work side by side and support the Customer Success teams in order to meet customer business needs. Interact with clients to understand business needs and collaborate on project scopes, planning, and execution. Requirements: Graduate with a degree in Industrial Engineering and Management or a similar major Experience with databases and SQL - a Must Outstanding technical and analytical skills Highly motivated with an exceptional work ethic High attention to detail with an ability to work on multiple projects simultaneously Strong interpersonal and communication skills Quick, self-learning capabilities and creativity in problem-solving Preferred: Familiarity with Python Familiarity with Airflow, ETL tools, Snowflake and MSSQL Hands-on with VCS (Git)",
         "Optimove is a global marketing tech company, recognized as a Leader by Forrester and a Challenger by Gartner. We work with some of the world's most exciting brands, such as Sephora, Staples, and Entain, who love our thought-provoking combination of art and science. With a strong product, a proven business, and the DNA of a vibrant, fast-growing startup, we're on the cusp of our next growth spurt. It's the perfect time to join our team of ~450 thinkers and doers across NYC, LDN, TLV, and other locations, where 2 of every 3 managers were promoted from within. Growing your career with Optimove is basically guaranteed. As a Customer Data Engineer, you will be a part of a strong energetic, and fast-growing global team. You will be an integral part of clients' onboarding and ongoing data requests and projects. You will be working closely with internal PM and CSM teams as well as interacting directly with clients' data teams across different business verticals. Your core responsibilities will involve playing an active role in collaborating with internal teams to construct tailored data transformations and manipulations while working with top-notch technology (Cloud tech etc.) The ideal candidate is an SQL whiz with a strong work ethic, robust analytical and technical capabilities, and highly effective time management skills. We are looking for a master multi-tasker who thrives in challenging, fast-paced environments, with agility and ease. The Customer Data Engineer is a position that brings with it an excellent opportunity to learn and grow within a rapidly expanding company on the cutting edge of Martech. Responsibilities: Develop and support a wide range of data transformations and migrations Construct custom ETL processes: Design and implementation of data pipelines and data marts, access versatile data sources, and apply data quality measures Investigate data mismatches and apply solutions Work side by side and support the Customer Success teams in order to meet customer business needs. Interact with clients to understand business needs and collaborate on project scopes, planning, and execution. Requirements: Graduate with a degree in Industrial Engineering and Management or a similar major Experience with databases and SQL - a Must Outstanding technical and analytical skills Highly motivated with an exceptional work ethic High attention to detail with an ability to work on multiple projects simultaneously Strong interpersonal and communication skills Quick, self-learning capabilities and creativity in problem-solving Preferred: Familiarity with Python Familiarity with Airflow, ETL tools, Snowflake and MSSQL Hands-on with VCS (Git)"
        ],
        [
         "Big Data developer - Python",
         "Twingo",
         "Twingo is expanding, seeking an experienced Python developer for challenging work in the world of Big Data. Design, develop & maintain the BIG DATA platform (Vertica). Design, develop & maintain the BIG DATA infrastructure (development, monitoring, installation, integration, etc…) Be part of the dynamic and agile core DBA team. Collaborate with field engineers for the deployment phases. Work on major, challenging projects with enterprise and startup customers. Job location – Herzliya, Israel. Job Requirements: Over 2 years' experience as Python developer in Linux environment. Experience with databases. Undergraduate degree in computer science / engineering or candidates with army service in software development / system administration - a significant advantage. Patient and service-oriented, can fit well into a team, good self-learning skills and lateral, high-pressure work. Experience in working with customers. Opened URL: https://il.indeed.com/rc/clk?jk=c19d1cad9dfac480&bb=r6UIYw2mow7Pn8IzQwq2_1pZAzVOBHM0DYmSIYa34WBvnAamHO4Ok1tcWLDfBqnaqv0QgONqdvfNCabooHoJG0DnY_ci2L47la6OLaltBVelfNRHRTMUwg%3D%3D&xkcb=SoAq67M33wH7H8WWaB0GbzkdCdPP&fccid=734cb5a01ee60f80&vjs=3",
         "data",
         "Twingo is expanding, seeking an experienced Python developer for challenging work in the world of Big Data. Design, develop & maintain the BIG DATA platform (Vertica). Design, develop & maintain the BIG DATA infrastructure (development, monitoring, installation, integration, etc…) Be part of the dynamic and agile core DBA team. Collaborate with field engineers for the deployment phases. Work on major, challenging projects with enterprise and startup customers. Job location – Herzliya, Israel. Job Requirements: Over 2 years' experience as Python developer in Linux environment. Experience with databases. Undergraduate degree in computer science / engineering or candidates with army service in software development / system administration - a significant advantage. Patient and service-oriented, can fit well into a team, good self-learning skills and lateral, high-pressure work. Experience in working with customers.",
         "Twingo is expanding, seeking an experienced Python developer for challenging work in the world of Big Data. Design, develop & maintain the BIG DATA platform (Vertica). Design, develop & maintain the BIG DATA infrastructure (development, monitoring, installation, integration, etc…) Be part of the dynamic and agile core DBA team. Collaborate with field engineers for the deployment phases. Work on major, challenging projects with enterprise and startup customers. Job location – Herzliya, Israel. Job Requirements: Over 2 years' experience as Python developer in Linux environment. Experience with databases. Undergraduate degree in computer science / engineering or candidates with army service in software development / system administration - a significant advantage. Patient and service-oriented, can fit well into a team, good self-learning skills and lateral, high-pressure work. Experience in working with customers."
        ],
        [
         "Data Center Logistic Technician - Modi'in area",
         "Microsoft",
         "** The position is located in Modi'in area ** As a Microsoft Data Center Inventory & Asset Technician (DIAT), you will perform cycle audits, execute incoming/outgoing deliveries, coordinate security escorts for third-party vendors, and document inbound and outbound deliveries. This opportunity will allow you to deepen your knowledge of inventory management principles, warranty process management, data bearing device destruction and advance your career in the process. Microsoft’s Cloud Operations & Innovation (CO+I) is the engine that powers our cloud services. As a CO+I DIAT, you will perform a key role in delivering the core infrastructure and foundational technologies for Microsoft's online services including Bing, Office 365, Xbox, OneDrive, and the Microsoft Azure platform. As a group, CO+I is focused on the personal and professional development of all employees and offers training and opportunities including Career Rotation Programs, Diversity & Inclusion training and events, and professional certifications. Our infrastructure is comprised of a large global portfolio of more than 200 Data Centers in 32 countries and millions of servers. Our foundation is built upon and managed by a team of subject matter experts working to support services for more than 1 billion customers and 20 million businesses in over 90 countries worldwide. With environmental sustainability and optimization at the forefront of our data center design and operations, we continue to grow and evolve as we meet the ever-changing business demands that hold Microsoft as a world-class cloud provider. Microsoft’s mission is to empower every person and every organization on the planet to achieve more. As employees we come together with a growth mindset, innovate to empower others, and collaborate to realize our shared goals. Each day we build on our values of respect, integrity, and accountability to create a culture of inclusion where everyone can thrive at work and beyond. Responsibilities Responsibilities Perform assigned tasks and escalate issues during high-volume work activity or escalation-based situations. Coordinate with suppliers to initiate warranty claim and process failed vendor hardware devices. This includes information processing, packaging, shipment, and receipt of return for Return Merchandise Authorization (RMA) devices following all Service Level Agreements (SLAs) related to RMA warranty process. Leverage process knowledge and best judgment to complete tasks with minimal direct supervision. Maintains a strong focus to understand the impact of their work when completing tickets and assigned Inventory and Asset Management (IAM) tasks. Maintains and steward up-to-date and accurate logical information within various inventory management systems (e.g., configuration management databases, asset management repositories). Ensures detailed physical inventory tracking and staging. Help to reconcile and report inventory discrepancies. Performs destruction of data bearing devices (DBD) following all Service Level Agreements (SLAs) and Microsoft policies as necessary. Notifies management about ordering stock shortages. Escalates any issues to management. Comply with security and data management policies. Embody our culture and values. Qualifications Required Qualifications High School Diploma AND experience warehouse/supply chain in an information technology (IT) environment, inventory management, retail, warehouse management, or a related field.OR equivalent experience. Background Check Requirements: Ability to meet Microsoft, customer and/or government security screening requirements are required for this role. These requirements include, but are not limited to the following specialized security screenings: Microsoft Cloud Background Check: This position will be required to pass the Microsoft Cloud background check upon hire/transfer and every two years thereafter. While not required, we also look for the following Preferred Qualifications: Relevant experience in warehouse/supply chain in an information technology (IT) environment, IT, and/or logistics, operating heavy-load movement equipment (e.g., forklift, pallet jacks, chassis lifts) for a large corporationOR equivalent experience. Microsoft is an equal opportunity employer. Consistent with applicable law, all qualified applicants will receive consideration for employment without regard to age, ancestry, citizenship, color, family or medical care leave, gender identity or expression, genetic information, immigration status, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran or military status, race, ethnicity, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable local laws, regulations and ordinances. If you need assistance and/or a reasonable accommodation due to a disability during the application process, read more about requesting accommodations. Opened URL: https://il.indeed.com/rc/clk?jk=e57b247de9bde4dd&bb=r6UIYw2mow7Pn8IzQwq2__CkT25UDgRwVF_9f7ZaRSjdBIWcrWHk-ex2bdY0zgr_RLIW8YyoIl0crPMjPIZL2bRv0qEOMbn7ATn7Yo8l-gim9tJijJTbi8u6Ls13HnO4&xkcb=SoC367M33wH7H8WWaB0FbzkdCdPP&fccid=a92bc8931562ec31&vjs=3",
         "data",
         "** The position is located in Modi'in area ** As a Microsoft Data Center Inventory & Asset Technician (DIAT), you will perform cycle audits, execute incoming/outgoing deliveries, coordinate security escorts for third-party vendors, and document inbound and outbound deliveries. This opportunity will allow you to deepen your knowledge of inventory management principles, warranty process management, data bearing device destruction and advance your career in the process. Microsoft’s Cloud Operations & Innovation (CO+I) is the engine that powers our cloud services. As a CO+I DIAT, you will perform a key role in delivering the core infrastructure and foundational technologies for Microsoft's online services including Bing, Office 365, Xbox, OneDrive, and the Microsoft Azure platform. As a group, CO+I is focused on the personal and professional development of all employees and offers training and opportunities including Career Rotation Programs, Diversity & Inclusion training and events, and professional certifications. Our infrastructure is comprised of a large global portfolio of more than 200 Data Centers in 32 countries and millions of servers. Our foundation is built upon and managed by a team of subject matter experts working to support services for more than 1 billion customers and 20 million businesses in over 90 countries worldwide. With environmental sustainability and optimization at the forefront of our data center design and operations, we continue to grow and evolve as we meet the ever-changing business demands that hold Microsoft as a world-class cloud provider. Microsoft’s mission is to empower every person and every organization on the planet to achieve more. As employees we come together with a growth mindset, innovate to empower others, and collaborate to realize our shared goals. Each day we build on our values of respect, integrity, and accountability to create a culture of inclusion where everyone can thrive at work and beyond. Responsibilities Responsibilities Perform assigned tasks and escalate issues during high-volume work activity or escalation-based situations. Coordinate with suppliers to initiate warranty claim and process failed vendor hardware devices. This includes information processing, packaging, shipment, and receipt of return for Return Merchandise Authorization (RMA) devices following all Service Level Agreements (SLAs) related to RMA warranty process. Leverage process knowledge and best judgment to complete tasks with minimal direct supervision. Maintains a strong focus to understand the impact of their work when completing tickets and assigned Inventory and Asset Management (IAM) tasks. Maintains and steward up-to-date and accurate logical information within various inventory management systems (e.g., configuration management databases, asset management repositories). Ensures detailed physical inventory tracking and staging. Help to reconcile and report inventory discrepancies. Performs destruction of data bearing devices (DBD) following all Service Level Agreements (SLAs) and Microsoft policies as necessary. Notifies management about ordering stock shortages. Escalates any issues to management. Comply with security and data management policies. Embody our culture and values. Qualifications Required Qualifications High School Diploma AND experience warehouse/supply chain in an information technology (IT) environment, inventory management, retail, warehouse management, or a related field.OR equivalent experience. Background Check Requirements: Ability to meet Microsoft, customer and/or government security screening requirements are required for this role. These requirements include, but are not limited to the following specialized security screenings: Microsoft Cloud Background Check: This position will be required to pass the Microsoft Cloud background check upon hire/transfer and every two years thereafter. While not required, we also look for the following Preferred Qualifications: Relevant experience in warehouse/supply chain in an information technology (IT) environment, IT, and/or logistics, operating heavy-load movement equipment (e.g., forklift, pallet jacks, chassis lifts) for a large corporationOR equivalent experience. Microsoft is an equal opportunity employer. Consistent with applicable law, all qualified applicants will receive consideration for employment without regard to age, ancestry, citizenship, color, family or medical care leave, gender identity or expression, genetic information, immigration status, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran or military status, race, ethnicity, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable local laws, regulations and ordinances. If you need assistance and/or a reasonable accommodation due to a disability during the application process, read more about requesting accommodations.",
         "** The position is located in Modi'in area ** As a Microsoft Data Center Inventory & Asset Technician (DIAT), you will perform cycle audits, execute incoming/outgoing deliveries, coordinate security escorts for third-party vendors, and document inbound and outbound deliveries. This opportunity will allow you to deepen your knowledge of inventory management principles, warranty process management, data bearing device destruction and advance your career in the process. Microsoft’s Cloud Operations & Innovation (CO+I) is the engine that powers our cloud services. As a CO+I DIAT, you will perform a key role in delivering the core infrastructure and foundational technologies for Microsoft's online services including Bing, Office 365, Xbox, OneDrive, and the Microsoft Azure platform. As a group, CO+I is focused on the personal and professional development of all employees and offers training and opportunities including Career Rotation Programs, Diversity & Inclusion training and events, and professional certifications. Our infrastructure is comprised of a large global portfolio of more than 200 Data Centers in 32 countries and millions of servers. Our foundation is built upon and managed by a team of subject matter experts working to support services for more than 1 billion customers and 20 million businesses in over 90 countries worldwide. With environmental sustainability and optimization at the forefront of our data center design and operations, we continue to grow and evolve as we meet the ever-changing business demands that hold Microsoft as a world-class cloud provider. Microsoft’s mission is to empower every person and every organization on the planet to achieve more. As employees we come together with a growth mindset, innovate to empower others, and collaborate to realize our shared goals. Each day we build on our values of respect, integrity, and accountability to create a culture of inclusion where everyone can thrive at work and beyond. Responsibilities Responsibilities Perform assigned tasks and escalate issues during high-volume work activity or escalation-based situations. Coordinate with suppliers to initiate warranty claim and process failed vendor hardware devices. This includes information processing, packaging, shipment, and receipt of return for Return Merchandise Authorization (RMA) devices following all Service Level Agreements (SLAs) related to RMA warranty process. Leverage process knowledge and best judgment to complete tasks with minimal direct supervision. Maintains a strong focus to understand the impact of their work when completing tickets and assigned Inventory and Asset Management (IAM) tasks. Maintains and steward up-to-date and accurate logical information within various inventory management systems (e.g., configuration management databases, asset management repositories). Ensures detailed physical inventory tracking and staging. Help to reconcile and report inventory discrepancies. Performs destruction of data bearing devices (DBD) following all Service Level Agreements (SLAs) and Microsoft policies as necessary. Notifies management about ordering stock shortages. Escalates any issues to management. Comply with security and data management policies. Embody our culture and values. Qualifications Required Qualifications High School Diploma AND experience warehouse/supply chain in an information technology (IT) environment, inventory management, retail, warehouse management, or a related field.OR equivalent experience. Background Check Requirements: Ability to meet Microsoft, customer and/or government security screening requirements are required for this role. These requirements include, but are not limited to the following specialized security screenings: Microsoft Cloud Background Check: This position will be required to pass the Microsoft Cloud background check upon hire/transfer and every two years thereafter. While not required, we also look for the following Preferred Qualifications: Relevant experience in warehouse/supply chain in an information technology (IT) environment, IT, and/or logistics, operating heavy-load movement equipment (e.g., forklift, pallet jacks, chassis lifts) for a large corporationOR equivalent experience. Microsoft is an equal opportunity employer. Consistent with applicable law, all qualified applicants will receive consideration for employment without regard to age, ancestry, citizenship, color, family or medical care leave, gender identity or expression, genetic information, immigration status, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran or military status, race, ethnicity, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable local laws, regulations and ordinances. If you need assistance and/or a reasonable accommodation due to a disability during the application process, read more about requesting accommodations."
        ],
        [
         "Data scientist",
         "OSR Enterprises",
         "DESCRIPTION Our fantastic team at OSR is expanding to meet the growing demand of our customers and we are interested in welcoming a Data Scientist to join our team, and to design and develop proprietary AI models for OSR's industry-leading OEM customers. REQUIREMENTS 4+ years of experience in data science/analytics Strong problem-solving skills with an emphasis on product development Advantage to those who have experience in stock/futures prediction Experience using statistical computer languages (Python) to manipulate data and draw insights from large data sets. Knowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) auto sklearn catboost arima lstm deep learning gan Coding knowledge and experience with javascript python experience with mongodb Opened URL: https://il.indeed.com/rc/clk?jk=bc58153ac4bcd56c&bb=r6UIYw2mow7Pn8IzQwq2_59qcD9-4FNf4ieCxpbzTC4e8P_IgdneHMeW5NnOHVdKbFJpxx8zmc8CgKk3eYBNOXeADXxOt-jD_fy5SqdU9z1p5gmQKZJFg3b3GmIjSI3z&xkcb=SoAD67M33wH7H8WWaB0EbzkdCdPP&fccid=8e007f7a76f9cee5&vjs=3",
         "data",
         "DESCRIPTION Our fantastic team at OSR is expanding to meet the growing demand of our customers and we are interested in welcoming a Data Scientist to join our team, and to design and develop proprietary AI models for OSR's industry-leading OEM customers. REQUIREMENTS 4+ years of experience in data science/analytics Strong problem-solving skills with an emphasis on product development Advantage to those who have experience in stock/futures prediction Experience using statistical computer languages (Python) to manipulate data and draw insights from large data sets. Knowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) auto sklearn catboost arima lstm deep learning gan Coding knowledge and experience with javascript python experience with mongodb",
         "DESCRIPTION Our fantastic team at OSR is expanding to meet the growing demand of our customers and we are interested in welcoming a Data Scientist to join our team, and to design and develop proprietary AI models for OSR's industry-leading OEM customers. REQUIREMENTS 4+ years of experience in data science/analytics Strong problem-solving skills with an emphasis on product development Advantage to those who have experience in stock/futures prediction Experience using statistical computer languages (Python) to manipulate data and draw insights from large data sets. Knowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) auto sklearn catboost arima lstm deep learning gan Coding knowledge and experience with javascript python experience with mongodb"
        ],
        [
         "Data Scientist",
         "ThetaRay",
         "Israel, Hod HaSharon Description About ThetaRay: ThetaRay is a trailblazer in AI-powered Anti-Money Laundering (AML) solutions, offering cutting-edge technology to fintechs, banks, and regulatory bodies worldwide. Our mission is to enhance trust in financial transactions, ensuring compliant and innovative business growth. Our technology empowers customers to expand into new markets and introduce groundbreaking products. Why Join ThetaRay? At ThetaRay, you'll be part of a dynamic global team committed to redefining the financial services sector through technological innovation. You will contribute to creating safer financial environments and have the opportunity to work with some of the brightest minds in AI, ML, and financial technology. We offer a collaborative, inclusive, and forward-thinking work environment where your ideas and contributions are valued and encouraged. Join us in our mission to revolutionize the financial world, making it safer and more trustworthy for millions worldwide. Explore exciting career opportunities at ThetaRay – where innovation meets purpose. ThetaRay is looking for a Data Scientist to join our innovative Data team. As a Data Scientist, you will work on customer-facing projects that combine data science with deep knowledge and understanding of machine learning and big data technologies to create solutions for customers’ challenges and needs, defining and developing appropriate technical and business solutions. The Data Scientist will work closely with ThetaRay’s Product Management, Algorithm, Engineering, and Customer Success teams and lead external partners to successful implementations of the ThetaRay platform and solutions. Key Responsibilities Manage and design the Customer-specific technical AI solutions throughout the project life cycle Leverage business knowledge to perform sophisticated feature engineering and enhance model performance. Extract insights and actionable recommendations from large volumes of data, applying advanced analytical methods. Collaborate with customers and partners, building and managing strong technical relationships to ensure project success. Train customers on system usage and monitoring, ensuring they can independently operate and maintain AI solutions. Contribute to product development by providing feedback and requirements to the Product Management team. Requirements Up to 3 years of experience as a data scientist/data engineer/big-data developer. BSc or equivalent in Mathematics, Statistics, Data Science or another related field. Proven professional experience in data analytics for financial services with strong data mining and forensic skills - an advantage. Experience working with customers. Advantage – financial customers. Must have Hands-on experience and knowledge of scripting languages: Python/PySpark as well as DS workflow management tools including MLflow, Airflow, etc. Working experience with Linux OS - an advantage. Fluent English - written and spoken. Core Competencies Able to solve tech problems for customers; improvise; cope with unexpected challenges Able to drive relevant internal functions to deliver/solve a problem for customers/partners A motivated, self-starter who can demonstrate high analytical and technical skills Ability to design creative solutions for complex requirements Ability to learn and lead projects independently, and to work with minimal supervision with customers (tech & business) Strong interpersonal relationship building Ability to execute multiple projects and drive key business results under tight deadlines Title: Data Analytics Company: Apple URL: https://il.indeed.com/rc/clk?jk=ac672ca32924abdf&bb=BGdJhL7PsYZ4SswVjb_w9lUJuctaSIleJFP6t_iTTb9om4BB2JGmxqqcGBGNMHtAbPJKgjTls5s5PdL8YAetIYXUHWb37RZmHYCai3XfMqktmghpR6ZG5w%3D%3D&xkcb=SoC567M33wYFPvxCCB0JbzkdCdPP&fccid=c1099851e9794854&vjs=3  Title: Junior Backend Big Data Developer Company: ThetaRay URL: https://il.indeed.com/rc/clk?jk=0433bc7e45e694a3&bb=BGdJhL7PsYZ4SswVjb_w9tZctL9d9lDO1fzq1peAT0ZLrakcBnhNhkpz-5eXBrhQOSFC7U1ofJm283GSwM8v81b68WUjW80pT7t4nTaUtYSp1gcmuVxU9yrGgWa8yPWS&xkcb=SoAN67M33wYFPvxCCB0IbzkdCdPP&fccid=8e007f7a76f9cee5&vjs=3  Title: Marketing Data Analyst Company: Plarium URL: https://il.indeed.com/rc/clk?jk=bc34db8ca4455a09&bb=BGdJhL7PsYZ4SswVjb_w9t54ZD8t3SitGT5-BfTl4QOKkWGzJj3FVoB1KmERYU_ye23ixJnIkqwGdRTbEiG4AFU0nNSJM28cNKU5UzNphxreBDX9febbck_Atk8H536k&xkcb=SoCD67M33wYFPvxCCB0PbzkdCdPP&fccid=fa9a43168015ecb7&vjs=3  Title: Data Scientist Company: Rubrik Job Board URL: https://il.indeed.com/rc/clk?jk=ae2c3d8865d70a20&bb=BGdJhL7PsYZ4SswVjb_w9o2JtdoEQve4qgkrlC6WwTi3umPZ4B-IFEmImCmMJtmrRr7UFbwi7DQLFjb8OEkfbRDjCFJoiETxYY8Gil9XTBzAGEyi-hMijoaR5UkwCiwa&xkcb=SoA367M33wYFPvxCCB0ObzkdCdPP&fccid=ba03cd038fd30855&vjs=3  Title: Junior Data Engineer Company: Aquant URL: https://il.indeed.com/rc/clk?jk=332ce6560e8316dc&bb=BGdJhL7PsYZ4SswVjb_w9k3DOMfBiaxxMrDVCiRcvrdccE6_iqjDgv5qLhS-o3x635UuE8vbYbn4pXqgJpP8NpynZFuZsS_cVqcS064xogOHbVv-onaq9-Q-nN3pO0OF&xkcb=SoCq67M33wYFPvxCCB0NbzkdCdPP&fccid=4d28265c01696bc0&vjs=3  Title: Big Data developer - Python Company: Twingo URL: https://il.indeed.com/rc/clk?jk=2801e9b70cffdf56&bb=BGdJhL7PsYZ4SswVjb_w9j7v8KuNu2tCLw3g53k_1fAx34okgvYiivAXUx6AL2XLonyRjgN9SPmEl6lYms4CNFfuFGDGZde4q-a1C0pZFlp5U3L5_2t8bgaxhMpJoPA0&xkcb=SoAe67M33wYFPvxCCB0MbzkdCdPP&fccid=5ad6f11eb660c9a3&vjs=3  Title: Data Scientist Company: Ticomsoft URL: https://il.indeed.com/rc/clk?jk=f90aa7093544f010&bb=BGdJhL7PsYZ4SswVjb_w9rgUmDffsY2lAB-5jgHcOEsmKkp6YRm5F_4VD5V22dkVmfCvfcQnwuUDqwDTBx4MT0U0gi31kd_OuX4r3xE7ilgc3UBIYqsyc0JjDLVAFWDS&xkcb=SoD367M33wYFPvxCCB0DbzkdCdPP&fccid=e32508b84ec45c2b&vjs=3  Title: data scientist! Company: Horizon Technologies URL: https://il.indeed.com/rc/clk?jk=ad3b38d6d843bb02&bb=BGdJhL7PsYZ4SswVjb_w9nOnjizfm1DZk6CYD9osf9HXUSfUPMb1a-9ZLsuXCwrlBqeILjvSezyX1-gmyu9geRcfNxMTuMt9HJfOAM8kYQaY_YWwb9fLmjDuI7Y8PDl0&xkcb=SoBD67M33wYFPvxCCB0CbzkdCdPP&fccid=c4e7a75c6cddb35a&vjs=3  Title: Customer Data Engineer Company: Optimove URL: https://il.indeed.com/rc/clk?jk=d93f96511474983d&bb=BGdJhL7PsYZ4SswVjb_w9j-Q9VHk-0XC0eo86uehIDlqFrY6tGtSK3zwot98ERqUmbN6JEPOZD19gLgaU91rm3BX4JC08mLXO9oxy6YaaJkwcUgRNwGqnyopTf6yevoE&xkcb=SoDe67M33wYFPvxCCB0BbzkdCdPP&fccid=9c02dc25b0c9c8ac&vjs=3  Title: Data Scientist Company: ThetaRay URL: https://il.indeed.com/rc/clk?jk=bc58153ac4bcd56c&bb=BGdJhL7PsYZ4SswVjb_w9vfZQAUETolil2lD637eoaYgyheNv5Yu1K2_pxeDq7ZtauWoT8rjUz8Mo78Rv4k6cB1_tw8ArLM2vqiRn7F4qB8YKEBQlXNDmg3YRUxzIzhF&xkcb=SoBq67M33wYFPvxCCB0AbzkdCdPP&fccid=8e007f7a76f9cee5&vjs=3  Title: Data scientist Company: OSR Enterprises URL: https://il.indeed.com/rc/clk?jk=e57b247de9bde4dd&bb=BGdJhL7PsYZ4SswVjb_w9geuj3wgL-obokFcrSGHlAkC6n6bEKkI-JhWdADF0KR3PuWS8PqEEW47j4LdgiDYLppRztwvh7MmUVKul5q6BPFJq86x9mE1eCxb2tYqWjLo&xkcb=SoDk67M33wYFPvxCCB0HbzkdCdPP&fccid=a92bc8931562ec31&vjs=3  Title: Data Annotator Company: Prisma Photonics URL: https://il.indeed.com/rc/clk?jk=f8a4240257a1f2ce&bb=BGdJhL7PsYZ4SswVjb_w9lbsgbppnSXkxtntFoLHwbk8S30ouRCNlIKZphM7G-fpTiKb-oCs66brxMV9mLmnS00daEZteLzNREnL5LOOIXmwnKsyUsJfEzfRfA4oupZd&xkcb=SoBQ67M33wYFPvxCCB0GbzkdCdPP&fccid=69237999e36cf5e9&vjs=3  Title: Data scientist Company: Paretix URL: https://il.indeed.com/rc/clk?jk=84d116dfdbf90062&bb=BGdJhL7PsYZ4SswVjb_w9jqi2ApkupLuiyZ9CJVnUigR0uumxobvqAtSdgFQh9DtZv_NBXfFsftzio8G3d5rlOvt3vz8BnAyeBLlThdizbHEJAHPkAs0PiD6a4aWU6_X&xkcb=SoDN67M33wYFPvxCCB0FbzkdCdPP&fccid=433c536613b198d9&vjs=3  Title: Data Engineer Company: ThriveDX URL: https://il.indeed.com/rc/clk?jk=42faf2905ed04064&bb=BGdJhL7PsYZ4SswVjb_w9sHT2Xwnr5uMDoEbl4dDLhFe0sKArF13GdwKoesVDl6w8YK6meb8KIt6tJRWmOUDFb1gGNBK--fxkSnSEe2URvFzYSgY8HLukAMd4Si2WDBs&xkcb=SoB567M33wYFPvxCCB0EbzkdCdPP&fccid=33301e5fe136476a&vjs=3  Title: Junior Data Analyst Company: DRS RADA TECHNOLOGIES URL: https://il.indeed.com/rc/clk?jk=d3edcab0a733eff6&bb=BGdJhL7PsYZ4SswVjb_w9knVwklo7TRTJolJGWVmUPtFaq-RMmHpMos5LIqwccBefMBf3YBKk19zL9DR8lAEy9CNpEanUkUE-57EEZuhVg8zm_5_yCbEuqMVkxqf2Fx3&xkcb=SoBe67M33wYFPvxCCB0bbzkdCdPP&fccid=3bc7c5a346eb42c1&vjs=3  Opened URL: https://il.indeed.com/rc/clk?jk=ac672ca32924abdf&bb=r6UIYw2mow7Pn8IzQwq2_947tjj67RppMknwoYuJzOzzr9AMXp01AtLsTLDv2CvxbUCGqSnscg1DI_R2JgGAaqdglT_DZvYUPWCd6LL_FsOlpDbDP4x7fQ%3D%3D&xkcb=SoBe67M33wH7H8WWaB0KbzkdCdPP&fccid=c1099851e9794854&vjs=3",
         "data",
         "Israel, Hod HaSharon Description About ThetaRay: ThetaRay is a trailblazer in AI-powered Anti-Money Laundering (AML) solutions, offering cutting-edge technology to fintechs, banks, and regulatory bodies worldwide. Our mission is to enhance trust in financial transactions, ensuring compliant and innovative business growth. Our technology empowers customers to expand into new markets and introduce groundbreaking products. Why Join ThetaRay? At ThetaRay, you'll be part of a dynamic global team committed to redefining the financial services sector through technological innovation. You will contribute to creating safer financial environments and have the opportunity to work with some of the brightest minds in AI, ML, and financial technology. We offer a collaborative, inclusive, and forward-thinking work environment where your ideas and contributions are valued and encouraged. Join us in our mission to revolutionize the financial world, making it safer and more trustworthy for millions worldwide. Explore exciting career opportunities at ThetaRay – where innovation meets purpose. ThetaRay is looking for a Data Scientist to join our innovative Data team. As a Data Scientist, you will work on customer-facing projects that combine data science with deep knowledge and understanding of machine learning and big data technologies to create solutions for customers’ challenges and needs, defining and developing appropriate technical and business solutions. The Data Scientist will work closely with ThetaRay’s Product Management, Algorithm, Engineering, and Customer Success teams and lead external partners to successful implementations of the ThetaRay platform and solutions. Key Responsibilities Manage and design the Customer-specific technical AI solutions throughout the project life cycle Leverage business knowledge to perform sophisticated feature engineering and enhance model performance. Extract insights and actionable recommendations from large volumes of data, applying advanced analytical methods. Collaborate with customers and partners, building and managing strong technical relationships to ensure project success. Train customers on system usage and monitoring, ensuring they can independently operate and maintain AI solutions. Contribute to product development by providing feedback and requirements to the Product Management team. Requirements Up to 3 years of experience as a data scientist/data engineer/big-data developer. BSc or equivalent in Mathematics, Statistics, Data Science or another related field. Proven professional experience in data analytics for financial services with strong data mining and forensic skills - an advantage. Experience working with customers. Advantage – financial customers. Must have Hands-on experience and knowledge of scripting languages: Python/PySpark as well as DS workflow management tools including MLflow, Airflow, etc. Working experience with Linux OS - an advantage. Fluent English - written and spoken. Core Competencies Able to solve tech problems for customers; improvise; cope with unexpected challenges Able to drive relevant internal functions to deliver/solve a problem for customers/partners A motivated, self-starter who can demonstrate high analytical and technical skills Ability to design creative solutions for complex requirements Ability to learn and lead projects independently, and to work with minimal supervision with customers (tech & business) Strong interpersonal relationship building Ability to execute multiple projects and drive key business results under tight deadlines Title: Data Analytics Company: Apple URL:   Title: Junior Backend Big Data Developer Company: ThetaRay URL:   Title: Marketing Data Analyst Company: Plarium URL:   Title: Data Scientist Company: Rubrik Job Board URL:   Title: Junior Data Engineer Company: Aquant URL:   Title: Big Data developer - Python Company: Twingo URL:   Title: Data Scientist Company: Ticomsoft URL:   Title: data scientist! Company: Horizon Technologies URL:   Title: Customer Data Engineer Company: Optimove URL:   Title: Data Scientist Company: ThetaRay URL:   Title: Data scientist Company: OSR Enterprises URL:   Title: Data Annotator Company: Prisma Photonics URL:   Title: Data scientist Company: Paretix URL:   Title: Data Engineer Company: ThriveDX URL:   Title: Junior Data Analyst Company: DRS RADA TECHNOLOGIES URL: ",
         "Israel, Hod HaSharon Description About ThetaRay: ThetaRay is a trailblazer in AI-powered Anti-Money Laundering (AML) solutions, offering cutting-edge technology to fintechs, banks, and regulatory bodies worldwide. Our mission is to enhance trust in financial transactions, ensuring compliant and innovative business growth. Our technology empowers customers to expand into new markets and introduce groundbreaking products. Why Join ThetaRay? At ThetaRay, you'll be part of a dynamic global team committed to redefining the financial services sector through technological innovation. You will contribute to creating safer financial environments and have the opportunity to work with some of the brightest minds in AI, ML, and financial technology. We offer a collaborative, inclusive, and forward-thinking work environment where your ideas and contributions are valued and encouraged. Join us in our mission to revolutionize the financial world, making it safer and more trustworthy for millions worldwide. Explore exciting career opportunities at ThetaRay – where innovation meets purpose. ThetaRay is looking for a Data Scientist to join our innovative Data team. As a Data Scientist, you will work on customer-facing projects that combine data science with deep knowledge and understanding of machine learning and big data technologies to create solutions for customers’ challenges and needs, defining and developing appropriate technical and business solutions. The Data Scientist will work closely with ThetaRay’s Product Management, Algorithm, Engineering, and Customer Success teams and lead external partners to successful implementations of the ThetaRay platform and solutions. Key Responsibilities Manage and design the Customer-specific technical AI solutions throughout the project life cycle Leverage business knowledge to perform sophisticated feature engineering and enhance model performance. Extract insights and actionable recommendations from large volumes of data, applying advanced analytical methods. Collaborate with customers and partners, building and managing strong technical relationships to ensure project success. Train customers on system usage and monitoring, ensuring they can independently operate and maintain AI solutions. Contribute to product development by providing feedback and requirements to the Product Management team. Requirements Up to 3 years of experience as a data scientist/data engineer/big-data developer. BSc or equivalent in Mathematics, Statistics, Data Science or another related field. Proven professional experience in data analytics for financial services with strong data mining and forensic skills - an advantage. Experience working with customers. Advantage – financial customers. Must have Hands-on experience and knowledge of scripting languages: Python/PySpark as well as DS workflow management tools including MLflow, Airflow, etc. Working experience with Linux OS - an advantage. Fluent English - written and spoken. Core Competencies Able to solve tech problems for customers; improvise; cope with unexpected challenges Able to drive relevant internal functions to deliver/solve a problem for customers/partners A motivated, self-starter who can demonstrate high analytical and technical skills Ability to design creative solutions for complex requirements Ability to learn and lead projects independently, and to work with minimal supervision with customers (tech & business) Strong interpersonal relationship building Ability to execute multiple projects and drive key business results under tight deadlines Title: Data Analytics Company: Apple URL:   Title: Junior Backend Big Data Developer Company: ThetaRay URL:   Title: Marketing Data Analyst Company: Plarium URL:   Title: Data Scientist Company: Rubrik Job Board URL:   Title: Junior Data Engineer Company: Aquant URL:   Title: Big Data developer - Python Company: Twingo URL:   Title: Data Scientist Company: Ticomsoft URL:   Title: data scientist! Company: Horizon Technologies URL:   Title: Customer Data Engineer Company: Optimove URL:   Title: Data Scientist Company: ThetaRay URL:   Title: Data scientist Company: OSR Enterprises URL:   Title: Data Annotator Company: Prisma Photonics URL:   Title: Data scientist Company: Paretix URL:   Title: Data Engineer Company: ThriveDX URL:   Title: Junior Data Analyst Company: DRS RADA TECHNOLOGIES URL:"
        ],
        [
         "Data Analytics",
         ". Our values are at the heart of our success. By joining us, you'll have the opportunity to embody these values and inspire others through your actions.",
         "Summary Posted: Nov 7, 2024 Role Number: 200577967 We're looking for an exceptional data analyst with a strong background in distributed data processing and a demonstrated ability to turn data into actionable insights. As a data analyst for our Storage Data Analytics team at Apple, you'll play a crucial role in developing the fastest and most efficient SSDs for our products, including the iPhone, iPad, Apple Watch, and new Apple Silicon Macs. If you're passionate about continuously improving the ways we use data to make Apple's products amazing, we want to hear from you! Description On the Storage Data Analytics team, we are responsible for performing ad hoc data analysis, development and maintenance of distributed data pipelines, as well as creation and support of analysis tools. Our team focuses on Apple’s storage solutions. It is small and nimble, able to quickly explore ideas and present them to the storage teams and to leadership. Minimum Qualifications +3 years of experience Ability to lead data investigations and analysis projects with ambiguous requirements Advanced statistic and modeling knowledge Experience visualizing and presenting analyses in tools like Jupyter and Tableau Experience programming in Python in a professional setting Familiarity with distributed computation, storage, and workflow management (e.g. Splunk, Spark, Kubernetes, Kafka, Hadoop, MapReduce, AirFlow etc.) Experience with relational databases and SQL Highly organized, creative, motivated, and passionate about achieving results Curious and have excellent analytical and problem solving skills Excellent written, verbal, and data communication skills Bachelor's or Master's degree in computer science. Preferred Qualifications Familiarity with distributed computation, storage, and workflow management (e.g. Splunk, Spark, Kubernetes, Kafka, Hadoop, MapReduce, AirFlow etc.) Opened URL: https://il.indeed.com/rc/clk?jk=0433bc7e45e694a3&bb=r6UIYw2mow7Pn8IzQwq2_7gXyX4L0a9oUPOLDIseoxAN8l0MRFFfCqpU6vSJRCmVlzxZCXcY6V-lzbB66NkEzDukGjQJgUJrBPff0HR1apFcJos6F0MbonwvLMjHhNz9&xkcb=SoDD67M33wH7H8WWaB0JbzkdCdPP&fccid=8e007f7a76f9cee5&vjs=3",
         "data",
         "Summary Posted: Nov 7, 2024 Role Number: 200577967 We're looking for an exceptional data analyst with a strong background in distributed data processing and a demonstrated ability to turn data into actionable insights. As a data analyst for our Storage Data Analytics team at Apple, you'll play a crucial role in developing the fastest and most efficient SSDs for our products, including the iPhone, iPad, Apple Watch, and new Apple Silicon Macs. If you're passionate about continuously improving the ways we use data to make Apple's products amazing, we want to hear from you! Description On the Storage Data Analytics team, we are responsible for performing ad hoc data analysis, development and maintenance of distributed data pipelines, as well as creation and support of analysis tools. Our team focuses on Apple’s storage solutions. It is small and nimble, able to quickly explore ideas and present them to the storage teams and to leadership. Minimum Qualifications +3 years of experience Ability to lead data investigations and analysis projects with ambiguous requirements Advanced statistic and modeling knowledge Experience visualizing and presenting analyses in tools like Jupyter and Tableau Experience programming in Python in a professional setting Familiarity with distributed computation, storage, and workflow management (e.g. Splunk, Spark, Kubernetes, Kafka, Hadoop, MapReduce, AirFlow etc.) Experience with relational databases and SQL Highly organized, creative, motivated, and passionate about achieving results Curious and have excellent analytical and problem solving skills Excellent written, verbal, and data communication skills Bachelor's or Master's degree in computer science. Preferred Qualifications Familiarity with distributed computation, storage, and workflow management (e.g. Splunk, Spark, Kubernetes, Kafka, Hadoop, MapReduce, AirFlow etc.)",
         "Summary Posted: Nov 7, 2024 Role Number: 200577967 We're looking for an exceptional data analyst with a strong background in distributed data processing and a demonstrated ability to turn data into actionable insights. As a data analyst for our Storage Data Analytics team at Apple, you'll play a crucial role in developing the fastest and most efficient SSDs for our products, including the iPhone, iPad, Apple Watch, and new Apple Silicon Macs. If you're passionate about continuously improving the ways we use data to make Apple's products amazing, we want to hear from you! Description On the Storage Data Analytics team, we are responsible for performing ad hoc data analysis, development and maintenance of distributed data pipelines, as well as creation and support of analysis tools. Our team focuses on Apple’s storage solutions. It is small and nimble, able to quickly explore ideas and present them to the storage teams and to leadership. Minimum Qualifications +3 years of experience Ability to lead data investigations and analysis projects with ambiguous requirements Advanced statistic and modeling knowledge Experience visualizing and presenting analyses in tools like Jupyter and Tableau Experience programming in Python in a professional setting Familiarity with distributed computation, storage, and workflow management (e.g. Splunk, Spark, Kubernetes, Kafka, Hadoop, MapReduce, AirFlow etc.) Experience with relational databases and SQL Highly organized, creative, motivated, and passionate about achieving results Curious and have excellent analytical and problem solving skills Excellent written, verbal, and data communication skills Bachelor's or Master's degree in computer science. Preferred Qualifications Familiarity with distributed computation, storage, and workflow management (e.g. Splunk, Spark, Kubernetes, Kafka, Hadoop, MapReduce, AirFlow etc.)"
        ],
        [
         "Junior Backend Big Data Developer",
         ", developing the next-generation smart-infrastructure solution based on novel fiber-sensing technology (smart roads, smart cities, perimeters, grid monitoring, etc.). The company offers an award-winning disruptive solution – a “sensor free” approach to smart infrastructure. The company is VC backed and is in the revenues stage.",
         "Israel, Hod HaSharon Description About ThetaRay: ThetaRay is a trailblazer in AI-powered Anti-Money Laundering (AML) solutions, offering cutting-edge technology to fintechs, banks, and regulatory bodies worldwide. Our mission is to enhance trust in financial transactions, ensuring compliant and innovative business growth. Our technology empowers customers to expand into new markets and introduce groundbreaking products. Thetaray is a culture-driven company. Our values are at the heart of our success. By joining us, you'll have the opportunity to embody these values and inspire others through your actions. Why Join ThetaRay? At ThetaRay, you'll be part of a dynamic global team committed to redefining the financial services sector through technological innovation. You will contribute to creating safer financial environments and have the opportunity to work with some of the brightest minds in AI, ML, and financial technology. We offer a collaborative, inclusive, and forward-thinking work environment where your ideas and contributions are valued and encouraged. Join us in our mission to revolutionize the financial world, making it safer and more trustworthy for millions worldwide. Explore exciting career opportunities at ThetaRay – where innovation meets purpose. We are seeking a skilled Junior Backend Big Data Developer to join our global R&D department. About the position Design and develop a scalable data processing and ML pipeline using the latest big data technologies in a fast paced agile environment Investigate new technological areas and understand them in depth through rapid self-learning Demonstrates strong analytical problem-solving skills to support scalable and sustainable design solutions Ability to take ownership of product development including all life cycle stages: translating product requirements into actionable designs and tasks, development, UT, and production troubleshooting Requirements 1-2 years of experience of hands-on development experience Experience developing data-oriented products preferably using Python/Java Experience in data processing FW such as Spark, Pandas, Hadoop, Airflow Experience in Distributed Databases (Such as Elasticsearch, Mongo, Redis, etc) Experience with developing microservices-based architecture Experience working in container-based environments using tools such as K8s, helm Experience working as a software developer in an Agile environment Nice to have: Experience in machine learning FWs such as SKLearn, Tensorflow Experience with RedHat OpenShift Dev Environment knowledge: GIT, Jenkins, Docker Opened URL: https://il.indeed.com/rc/clk?jk=f8a4240257a1f2ce&bb=r6UIYw2mow7Pn8IzQwq2_-W1QCjSWXjTolCGGPP6r1hrgYR_04g-rduMaSln8QXPTKg72oJi8A05b61aBYrHRJnGe_P_Fe_A6kxMxp1ZSL-qNeOaC0lT-K0Lac-PNtP0&xkcb=SoB367M33wH7H8WWaB0IbzkdCdPP&fccid=69237999e36cf5e9&vjs=3",
         "data",
         "Israel, Hod HaSharon Description About ThetaRay: ThetaRay is a trailblazer in AI-powered Anti-Money Laundering (AML) solutions, offering cutting-edge technology to fintechs, banks, and regulatory bodies worldwide. Our mission is to enhance trust in financial transactions, ensuring compliant and innovative business growth. Our technology empowers customers to expand into new markets and introduce groundbreaking products. Thetaray is a culture-driven company. Our values are at the heart of our success. By joining us, you'll have the opportunity to embody these values and inspire others through your actions. Why Join ThetaRay? At ThetaRay, you'll be part of a dynamic global team committed to redefining the financial services sector through technological innovation. You will contribute to creating safer financial environments and have the opportunity to work with some of the brightest minds in AI, ML, and financial technology. We offer a collaborative, inclusive, and forward-thinking work environment where your ideas and contributions are valued and encouraged. Join us in our mission to revolutionize the financial world, making it safer and more trustworthy for millions worldwide. Explore exciting career opportunities at ThetaRay – where innovation meets purpose. We are seeking a skilled Junior Backend Big Data Developer to join our global R&D department. About the position Design and develop a scalable data processing and ML pipeline using the latest big data technologies in a fast paced agile environment Investigate new technological areas and understand them in depth through rapid self-learning Demonstrates strong analytical problem-solving skills to support scalable and sustainable design solutions Ability to take ownership of product development including all life cycle stages: translating product requirements into actionable designs and tasks, development, UT, and production troubleshooting Requirements 1-2 years of experience of hands-on development experience Experience developing data-oriented products preferably using Python/Java Experience in data processing FW such as Spark, Pandas, Hadoop, Airflow Experience in Distributed Databases (Such as Elasticsearch, Mongo, Redis, etc) Experience with developing microservices-based architecture Experience working in container-based environments using tools such as K8s, helm Experience working as a software developer in an Agile environment Nice to have: Experience in machine learning FWs such as SKLearn, Tensorflow Experience with RedHat OpenShift Dev Environment knowledge: GIT, Jenkins, Docker",
         "Israel, Hod HaSharon Description About ThetaRay: ThetaRay is a trailblazer in AI-powered Anti-Money Laundering (AML) solutions, offering cutting-edge technology to fintechs, banks, and regulatory bodies worldwide. Our mission is to enhance trust in financial transactions, ensuring compliant and innovative business growth. Our technology empowers customers to expand into new markets and introduce groundbreaking products. Thetaray is a culture-driven company. Our values are at the heart of our success. By joining us, you'll have the opportunity to embody these values and inspire others through your actions. Why Join ThetaRay? At ThetaRay, you'll be part of a dynamic global team committed to redefining the financial services sector through technological innovation. You will contribute to creating safer financial environments and have the opportunity to work with some of the brightest minds in AI, ML, and financial technology. We offer a collaborative, inclusive, and forward-thinking work environment where your ideas and contributions are valued and encouraged. Join us in our mission to revolutionize the financial world, making it safer and more trustworthy for millions worldwide. Explore exciting career opportunities at ThetaRay – where innovation meets purpose. We are seeking a skilled Junior Backend Big Data Developer to join our global R&D department. About the position Design and develop a scalable data processing and ML pipeline using the latest big data technologies in a fast paced agile environment Investigate new technological areas and understand them in depth through rapid self-learning Demonstrates strong analytical problem-solving skills to support scalable and sustainable design solutions Ability to take ownership of product development including all life cycle stages: translating product requirements into actionable designs and tasks, development, UT, and production troubleshooting Requirements 1-2 years of experience of hands-on development experience Experience developing data-oriented products preferably using Python/Java Experience in data processing FW such as Spark, Pandas, Hadoop, Airflow Experience in Distributed Databases (Such as Elasticsearch, Mongo, Redis, etc) Experience with developing microservices-based architecture Experience working in container-based environments using tools such as K8s, helm Experience working as a software developer in an Agile environment Nice to have: Experience in machine learning FWs such as SKLearn, Tensorflow Experience with RedHat OpenShift Dev Environment knowledge: GIT, Jenkins, Docker"
        ],
        [
         "Marketing Data Analyst",
         ".",
         "Description: Prisma-Photonics is a rapidly growing startup company, developing the next-generation smart-infrastructure solution based on novel fiber-sensing technology (smart roads, smart cities, perimeters, grid monitoring, etc.). The company offers an award-winning disruptive solution – a “sensor free” approach to smart infrastructure. The company is VC backed and is in the revenues stage. Combining pioneering technology in optical fiber sensing with state-of-the-art machine learning, we help prevent environmental disasters, protect human lives, and keep critical energy and transportation backbones running smoothly. We are rapidly growing, looking for the best minds and spirits to join us in our journey. We know our products are only as great as the individuals building the hardware and software and harnessing data for good causes! Being a great team member means being eager to learn and grow, able to challenge others while accepting being challenged yourself, and working for the team and product with enthusiasm and passion. We are seeking a detail-oriented and highly technical Data Annotator to join our Data Operations team. The role is full time, on an hourly pay, with the aim of adjusting work hours per need. In this role, you will be responsible for annotating various events on our distinct fiber sensing data, and managing datasets to support various products and projects. You will play a crucial part in ensuring the quality and integrity of our data, contributing to multiple critical initiatives. You will help improve our annotation procedures, techniques and tooling, and work closely with ML and Algo teams as well as Data Engineering. This is a unique opportunity to gain hands-on experience in data operations within a dynamic environment using cutting edge and novel technology. You will join a talented team dedicated to leveraging data for impactful projects. If you are passionate about data and eager to contribute to exciting challenges, this might be the perfect opportunity for you. Key Responsibilities: Data Annotation – Accurately annotate datasets using internal tools, adhering to annotation guidelines and maintaining high standards for consistency and quality.. Quality Assurance – Review and validate annotated data to ensure accuracy and consistency, identify discrepancies, and suggest solutions to improve processes. Continuous improvement – Participate in the continuous improvement of our tools and data operation processes to achieve more accurate models, and more streamlined data flow between the different teams in the company. Data Management – Support the ongoing maintenance of annotated datasets, ensuring data integrity and accessibility, and implementing best-practices to create seamless data flows Requirements: A Bachelor of Science degree or equivalent (STEM fields an advantage). Strong attention to detail and a commitment to maintaining high-quality annotation standards. Good written and verbal skills, with the ability to work effectively with a diverse group of individuals. Availability to work full time when needed. Nice-to-haves: Familiarity with data annotation processes, especially non-structured data (images, video, audio). Experience working with seismic data, heat maps, or spectrograms Familiarity with SQL and data visualization tools. Experience with coding languages, preferably MATLAB and Python. Opened URL: https://il.indeed.com/rc/clk?jk=bc34db8ca4455a09&bb=r6UIYw2mow7Pn8IzQwq2_2KWxyEGo0k-OJpOJwwWN8Jm7Ix9rFlIZvMB9V3E68_9Tw5jXdxlGcRgdwn8R5bozu_4HSOWEd50RAMDfMKBbPpkx12msEPjULZyxC-ZVeo-&xkcb=SoD567M33wH7H8WWaB0PbzkdCdPP&fccid=fa9a43168015ecb7&vjs=3",
         "data",
         "Description: Prisma-Photonics is a rapidly growing startup company, developing the next-generation smart-infrastructure solution based on novel fiber-sensing technology (smart roads, smart cities, perimeters, grid monitoring, etc.). The company offers an award-winning disruptive solution – a “sensor free” approach to smart infrastructure. The company is VC backed and is in the revenues stage. Combining pioneering technology in optical fiber sensing with state-of-the-art machine learning, we help prevent environmental disasters, protect human lives, and keep critical energy and transportation backbones running smoothly. We are rapidly growing, looking for the best minds and spirits to join us in our journey. We know our products are only as great as the individuals building the hardware and software and harnessing data for good causes! Being a great team member means being eager to learn and grow, able to challenge others while accepting being challenged yourself, and working for the team and product with enthusiasm and passion. We are seeking a detail-oriented and highly technical Data Annotator to join our Data Operations team. The role is full time, on an hourly pay, with the aim of adjusting work hours per need. In this role, you will be responsible for annotating various events on our distinct fiber sensing data, and managing datasets to support various products and projects. You will play a crucial part in ensuring the quality and integrity of our data, contributing to multiple critical initiatives. You will help improve our annotation procedures, techniques and tooling, and work closely with ML and Algo teams as well as Data Engineering. This is a unique opportunity to gain hands-on experience in data operations within a dynamic environment using cutting edge and novel technology. You will join a talented team dedicated to leveraging data for impactful projects. If you are passionate about data and eager to contribute to exciting challenges, this might be the perfect opportunity for you. Key Responsibilities: Data Annotation – Accurately annotate datasets using internal tools, adhering to annotation guidelines and maintaining high standards for consistency and quality.. Quality Assurance – Review and validate annotated data to ensure accuracy and consistency, identify discrepancies, and suggest solutions to improve processes. Continuous improvement – Participate in the continuous improvement of our tools and data operation processes to achieve more accurate models, and more streamlined data flow between the different teams in the company. Data Management – Support the ongoing maintenance of annotated datasets, ensuring data integrity and accessibility, and implementing best-practices to create seamless data flows Requirements: A Bachelor of Science degree or equivalent (STEM fields an advantage). Strong attention to detail and a commitment to maintaining high-quality annotation standards. Good written and verbal skills, with the ability to work effectively with a diverse group of individuals. Availability to work full time when needed. Nice-to-haves: Familiarity with data annotation processes, especially non-structured data (images, video, audio). Experience working with seismic data, heat maps, or spectrograms Familiarity with SQL and data visualization tools. Experience with coding languages, preferably MATLAB and Python.",
         "Description: Prisma-Photonics is a rapidly growing startup company, developing the next-generation smart-infrastructure solution based on novel fiber-sensing technology (smart roads, smart cities, perimeters, grid monitoring, etc.). The company offers an award-winning disruptive solution – a “sensor free” approach to smart infrastructure. The company is VC backed and is in the revenues stage. Combining pioneering technology in optical fiber sensing with state-of-the-art machine learning, we help prevent environmental disasters, protect human lives, and keep critical energy and transportation backbones running smoothly. We are rapidly growing, looking for the best minds and spirits to join us in our journey. We know our products are only as great as the individuals building the hardware and software and harnessing data for good causes! Being a great team member means being eager to learn and grow, able to challenge others while accepting being challenged yourself, and working for the team and product with enthusiasm and passion. We are seeking a detail-oriented and highly technical Data Annotator to join our Data Operations team. The role is full time, on an hourly pay, with the aim of adjusting work hours per need. In this role, you will be responsible for annotating various events on our distinct fiber sensing data, and managing datasets to support various products and projects. You will play a crucial part in ensuring the quality and integrity of our data, contributing to multiple critical initiatives. You will help improve our annotation procedures, techniques and tooling, and work closely with ML and Algo teams as well as Data Engineering. This is a unique opportunity to gain hands-on experience in data operations within a dynamic environment using cutting edge and novel technology. You will join a talented team dedicated to leveraging data for impactful projects. If you are passionate about data and eager to contribute to exciting challenges, this might be the perfect opportunity for you. Key Responsibilities: Data Annotation – Accurately annotate datasets using internal tools, adhering to annotation guidelines and maintaining high standards for consistency and quality.. Quality Assurance – Review and validate annotated data to ensure accuracy and consistency, identify discrepancies, and suggest solutions to improve processes. Continuous improvement – Participate in the continuous improvement of our tools and data operation processes to achieve more accurate models, and more streamlined data flow between the different teams in the company. Data Management – Support the ongoing maintenance of annotated datasets, ensuring data integrity and accessibility, and implementing best-practices to create seamless data flows Requirements: A Bachelor of Science degree or equivalent (STEM fields an advantage). Strong attention to detail and a commitment to maintaining high-quality annotation standards. Good written and verbal skills, with the ability to work effectively with a diverse group of individuals. Availability to work full time when needed. Nice-to-haves: Familiarity with data annotation processes, especially non-structured data (images, video, audio). Experience working with seismic data, heat maps, or spectrograms Familiarity with SQL and data visualization tools. Experience with coding languages, preferably MATLAB and Python."
        ],
        [
         "Data Scientist",
         "'s Next Big Things in Tech of 2024",
         "The Business Performance department at Plarium is in charge of all the analytical aspects of our game operations and strategic planning: From game design, to user acquisition, player behavior, live-ops, and game optimization (such as monetization, retention, etc). We are looking for a data analyst for our Marketing Analytics team. The scope of responsibility of this team includes budget optimization for user acquisition for our games at the scope of tens of million dollars per game, analyses of game profitability and long term potential, analysis of the players behavior, player game funnel and reaction to new game features and offers, and a lot more. Our goal is making sure Plarium brings the best and most relevant players to its games in the most efficient and effective way. Responsibilities Be a focal point for anything related to new players performance and KPIs across our range of games, strategic planning, user segmentation, tests and growth opportunities identification Daily support of ongoing analytical needs of the marketing department managers & teams Establish and monitor success metrics that measure and explain the impact of the marketing activities Design and initiate new features and reports to monitor & give insights on the marketing activity, using the marketing in-house BI system (for example, LTV, ROI forecasting, automatic rules) Run ad-hoc and in-depth analyses of the different Marketing activities and trends Support decision making based on data Collaborate with the game analysis team and the game studios to monitor and optimize our players experience, maximizing their retention in our games What we expect B.A/BSc in a highly quantitative field such as mathematics industrial engineering economics statistics or equivalent academic knowledge At least 2 years of hands-on data analysis and story-telling experience Proven experience with measuring online success and identifying optimization opportunities Excellent understanding of online marketing metrics High proficiency in SQL with demonstrated experience in querying large complex datasets Strong Excel / Google Sheets skills Experience with data visualization tools such as Qlik Sense and Looker A solid grasp of statistical significance models and tools Desired Marketing metrics of user funnel, user acquisition KPI’s What we offer A Workplace Designed for Your Well-Being - Comfortable Environment: Ergonomic chairs and desks to support your health. Beautifully designed spaces that inspire creativity. - On-Site Amenities: Gym, yoga room, and music room for relaxation and rejuvenation. - Delicious Perks: 5-star breakfast to kickstart your day. Freshly made coffee, shakes, and afternoon salads by our in-house barista. - Health & Wellness: Full health insurance coverage for your peace of mind. - Growth Opportunities: Learning and training programs to enhance your personal and professional skills. - Vibrant Culture: Happy hours, team events, and plenty of opportunities to connect with colleagues. Join us and experience a workplace where your well-being, growth, and enjoyment come first! Opened URL: https://il.indeed.com/rc/clk?jk=2b03298659a436f7&bb=r6UIYw2mow7Pn8IzQwq2_wWeK1_evLckj39fLIfBgJ2KNH0z3augA147ODzOJXM4VPM1yn4wZeNukSlYyB-0ehIHUhqYKXcTKfcnYDIqLgoQwawaxa9eNtYV3Qk82DTa&xkcb=SoBN67M33wH7H8WWaB0ObzkdCdPP&fccid=f24b7ff57afa3405&vjs=3",
         "data",
         "The Business Performance department at Plarium is in charge of all the analytical aspects of our game operations and strategic planning: From game design, to user acquisition, player behavior, live-ops, and game optimization (such as monetization, retention, etc). We are looking for a data analyst for our Marketing Analytics team. The scope of responsibility of this team includes budget optimization for user acquisition for our games at the scope of tens of million dollars per game, analyses of game profitability and long term potential, analysis of the players behavior, player game funnel and reaction to new game features and offers, and a lot more. Our goal is making sure Plarium brings the best and most relevant players to its games in the most efficient and effective way. Responsibilities Be a focal point for anything related to new players performance and KPIs across our range of games, strategic planning, user segmentation, tests and growth opportunities identification Daily support of ongoing analytical needs of the marketing department managers & teams Establish and monitor success metrics that measure and explain the impact of the marketing activities Design and initiate new features and reports to monitor & give insights on the marketing activity, using the marketing in-house BI system (for example, LTV, ROI forecasting, automatic rules) Run ad-hoc and in-depth analyses of the different Marketing activities and trends Support decision making based on data Collaborate with the game analysis team and the game studios to monitor and optimize our players experience, maximizing their retention in our games What we expect B.A/BSc in a highly quantitative field such as mathematics industrial engineering economics statistics or equivalent academic knowledge At least 2 years of hands-on data analysis and story-telling experience Proven experience with measuring online success and identifying optimization opportunities Excellent understanding of online marketing metrics High proficiency in SQL with demonstrated experience in querying large complex datasets Strong Excel / Google Sheets skills Experience with data visualization tools such as Qlik Sense and Looker A solid grasp of statistical significance models and tools Desired Marketing metrics of user funnel, user acquisition KPI’s What we offer A Workplace Designed for Your Well-Being - Comfortable Environment: Ergonomic chairs and desks to support your health. Beautifully designed spaces that inspire creativity. - On-Site Amenities: Gym, yoga room, and music room for relaxation and rejuvenation. - Delicious Perks: 5-star breakfast to kickstart your day. Freshly made coffee, shakes, and afternoon salads by our in-house barista. - Health & Wellness: Full health insurance coverage for your peace of mind. - Growth Opportunities: Learning and training programs to enhance your personal and professional skills. - Vibrant Culture: Happy hours, team events, and plenty of opportunities to connect with colleagues. Join us and experience a workplace where your well-being, growth, and enjoyment come first!",
         "The Business Performance department at Plarium is in charge of all the analytical aspects of our game operations and strategic planning: From game design, to user acquisition, player behavior, live-ops, and game optimization (such as monetization, retention, etc). We are looking for a data analyst for our Marketing Analytics team. The scope of responsibility of this team includes budget optimization for user acquisition for our games at the scope of tens of million dollars per game, analyses of game profitability and long term potential, analysis of the players behavior, player game funnel and reaction to new game features and offers, and a lot more. Our goal is making sure Plarium brings the best and most relevant players to its games in the most efficient and effective way. Responsibilities Be a focal point for anything related to new players performance and KPIs across our range of games, strategic planning, user segmentation, tests and growth opportunities identification Daily support of ongoing analytical needs of the marketing department managers & teams Establish and monitor success metrics that measure and explain the impact of the marketing activities Design and initiate new features and reports to monitor & give insights on the marketing activity, using the marketing in-house BI system (for example, LTV, ROI forecasting, automatic rules) Run ad-hoc and in-depth analyses of the different Marketing activities and trends Support decision making based on data Collaborate with the game analysis team and the game studios to monitor and optimize our players experience, maximizing their retention in our games What we expect B.A/BSc in a highly quantitative field such as mathematics industrial engineering economics statistics or equivalent academic knowledge At least 2 years of hands-on data analysis and story-telling experience Proven experience with measuring online success and identifying optimization opportunities Excellent understanding of online marketing metrics High proficiency in SQL with demonstrated experience in querying large complex datasets Strong Excel / Google Sheets skills Experience with data visualization tools such as Qlik Sense and Looker A solid grasp of statistical significance models and tools Desired Marketing metrics of user funnel, user acquisition KPI’s What we offer A Workplace Designed for Your Well-Being - Comfortable Environment: Ergonomic chairs and desks to support your health. Beautifully designed spaces that inspire creativity. - On-Site Amenities: Gym, yoga room, and music room for relaxation and rejuvenation. - Delicious Perks: 5-star breakfast to kickstart your day. Freshly made coffee, shakes, and afternoon salads by our in-house barista. - Health & Wellness: Full health insurance coverage for your peace of mind. - Growth Opportunities: Learning and training programs to enhance your personal and professional skills. - Vibrant Culture: Happy hours, team events, and plenty of opportunities to connect with colleagues. Join us and experience a workplace where your well-being, growth, and enjoyment come first!"
        ],
        [
         "Junior Data Engineer",
         "as a whole to have a greater impact and achieve our vision:",
         "aiOla is a high-growth, product-led SaaS startup backed by $45 million in funding from premier investors such as New Era Capital Partners and Hamilton Lane. Our mission is to revolutionize efficiency, intelligence, collaboration, and safety in the industrial sector through our proprietary speech-powered AI technology. Our team spans the US and Israel, bringing together experts in Product, Data Science, Data Engineering, Analytics, Marketing, and Customer Success. At aiOla, we thrive on innovation, collaboration, and a commitment to excellence. We are seeking forward-thinking professionals passionate about pushing the limits of AI and making an impact. Role Overview: We are seeking a passionate and innovative Data Analyst to join our growing Analytics team. This is an exceptional opportunity for a detail-oriented professional to not only analyze data but also play a pivotal role in shaping and enhancing our cutting-edge AI models and products. As a Data Analyst at aiOla, you will dive into complex datasets, uncover actionable insights, and contribute directly to the improvement and monitoring of our proprietary AI technologies. If you thrive in a dynamic environment, this role is perfect for you! Requirements: B.Sc in Industrial Engineering, Data Analytics, Statistics, or a related field. Proficiency in Python, with a strong focus on libraries like Pandas for data manipulation. Solid knowledge of SQL for querying and managing large datasets. Experience with BI tools like Tableau to create dashboards and reports. Excellent communication skills, with fluency in English (written and verbal). 0-1 years of experience in a Data Analyst role- advantage Nice To have: Familiarity with Snowflake or AWS Athena. Experience with Web/App product analytics tools such as Mixpanel. Knowledge of Data Science concepts and metrics, including Speech AI, Large Language Models (LLMs), Natural Language Understanding (NLU), and Automatic Speech Recognition (ASR). Responsibilities: Extract, clean, and analyze data to uncover trends, patterns, and actionable insights. Provide recommendations based on data analysis to support business decisions and drive product improvements. Develop and maintain dashboards and reports using BI tools such as Tableau or other platforms. Optimize data workflows and pipelines using Python and SQL. Collaborate with cross-functional teams, including Product, Data Science, and Engineering, to support data-driven decision-making. Opened URL: https://il.indeed.com/rc/clk?jk=8c0efb63a00ef0d5&bb=r6UIYw2mow7Pn8IzQwq2_xdQrNIprFLEwcJQe8rzWVWb1_NSvbpLXcpcn5TXeAHedsgImdoi_2ey__b10Ys3nn9vr-SRmf6buKLYOFDHfBc8ksA0lyjjiA%3D%3D&xkcb=SoDQ67M33wH7H8WWaB0NbzkdCdPP&fccid=ba07516c418dda52&vjs=3",
         "data",
         "aiOla is a high-growth, product-led SaaS startup backed by $45 million in funding from premier investors such as New Era Capital Partners and Hamilton Lane. Our mission is to revolutionize efficiency, intelligence, collaboration, and safety in the industrial sector through our proprietary speech-powered AI technology. Our team spans the US and Israel, bringing together experts in Product, Data Science, Data Engineering, Analytics, Marketing, and Customer Success. At aiOla, we thrive on innovation, collaboration, and a commitment to excellence. We are seeking forward-thinking professionals passionate about pushing the limits of AI and making an impact. Role Overview: We are seeking a passionate and innovative Data Analyst to join our growing Analytics team. This is an exceptional opportunity for a detail-oriented professional to not only analyze data but also play a pivotal role in shaping and enhancing our cutting-edge AI models and products. As a Data Analyst at aiOla, you will dive into complex datasets, uncover actionable insights, and contribute directly to the improvement and monitoring of our proprietary AI technologies. If you thrive in a dynamic environment, this role is perfect for you! Requirements: B.Sc in Industrial Engineering, Data Analytics, Statistics, or a related field. Proficiency in Python, with a strong focus on libraries like Pandas for data manipulation. Solid knowledge of SQL for querying and managing large datasets. Experience with BI tools like Tableau to create dashboards and reports. Excellent communication skills, with fluency in English (written and verbal). 0-1 years of experience in a Data Analyst role- advantage Nice To have: Familiarity with Snowflake or AWS Athena. Experience with Web/App product analytics tools such as Mixpanel. Knowledge of Data Science concepts and metrics, including Speech AI, Large Language Models (LLMs), Natural Language Understanding (NLU), and Automatic Speech Recognition (ASR). Responsibilities: Extract, clean, and analyze data to uncover trends, patterns, and actionable insights. Provide recommendations based on data analysis to support business decisions and drive product improvements. Develop and maintain dashboards and reports using BI tools such as Tableau or other platforms. Optimize data workflows and pipelines using Python and SQL. Collaborate with cross-functional teams, including Product, Data Science, and Engineering, to support data-driven decision-making.",
         "aiOla is a high-growth, product-led SaaS startup backed by $45 million in funding from premier investors such as New Era Capital Partners and Hamilton Lane. Our mission is to revolutionize efficiency, intelligence, collaboration, and safety in the industrial sector through our proprietary speech-powered AI technology. Our team spans the US and Israel, bringing together experts in Product, Data Science, Data Engineering, Analytics, Marketing, and Customer Success. At aiOla, we thrive on innovation, collaboration, and a commitment to excellence. We are seeking forward-thinking professionals passionate about pushing the limits of AI and making an impact. Role Overview: We are seeking a passionate and innovative Data Analyst to join our growing Analytics team. This is an exceptional opportunity for a detail-oriented professional to not only analyze data but also play a pivotal role in shaping and enhancing our cutting-edge AI models and products. As a Data Analyst at aiOla, you will dive into complex datasets, uncover actionable insights, and contribute directly to the improvement and monitoring of our proprietary AI technologies. If you thrive in a dynamic environment, this role is perfect for you! Requirements: B.Sc in Industrial Engineering, Data Analytics, Statistics, or a related field. Proficiency in Python, with a strong focus on libraries like Pandas for data manipulation. Solid knowledge of SQL for querying and managing large datasets. Experience with BI tools like Tableau to create dashboards and reports. Excellent communication skills, with fluency in English (written and verbal). 0-1 years of experience in a Data Analyst role- advantage Nice To have: Familiarity with Snowflake or AWS Athena. Experience with Web/App product analytics tools such as Mixpanel. Knowledge of Data Science concepts and metrics, including Speech AI, Large Language Models (LLMs), Natural Language Understanding (NLU), and Automatic Speech Recognition (ASR). Responsibilities: Extract, clean, and analyze data to uncover trends, patterns, and actionable insights. Provide recommendations based on data analysis to support business decisions and drive product improvements. Develop and maintain dashboards and reports using BI tools such as Tableau or other platforms. Optimize data workflows and pipelines using Python and SQL. Collaborate with cross-functional teams, including Product, Data Science, and Engineering, to support data-driven decision-making."
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "Title",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Company",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Full Job Description",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Search Word",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Description",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Description_English",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from deep_translator import GoogleTranslator\n",
    "\n",
    "def translate_to_english(text):\n",
    "    if not text:\n",
    "        return text  # Skip empty descriptions\n",
    "    try:\n",
    "        return GoogleTranslator(source='auto', target='en').translate(text)\n",
    "    except Exception as e:\n",
    "        return text  # Return original text if translation fails\n",
    "    \n",
    "translate_udf = udf(translate_to_english, StringType())\n",
    "translated_ads = filtered_indeed_ads.withColumn(\"Description_English\", translate_udf(col(\"Description\")))\n",
    "\n",
    "translated_ads.limit(20).display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cffe99a6-def7-4fea-b1df-ae80ec8e771a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Requirements Sections\n",
    "Extract the requirements section from each record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "96db273b-d480-4264-a64b-3cde5e9a84b6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Extract only requirements texts\n",
    "requirements_headers = [\"minimum requirements\", \"minimum qualifications\", \"qualifications\", \"required skills & background\", \"on your resume\", \"about you\", \"who we are looking for\", \"skills & experience\", \"what you will need\", \"what you need\", \"what you bring to the table\", \"what we expect\", \"skills and/or certifications\", \"requirements\", \"essential skills\", \"required skills\", \"required background\", \"skills include\", \"position specifications\", \"required\", \"background\", \"experience\"]\n",
    "\n",
    "def extract_requirements(description):\n",
    "    if not description:\n",
    "        return \"\"\n",
    "    description_lower = description.lower()\n",
    "    for header in requirements_headers:     # Extract by order of requirements_headers\n",
    "        match = re.search(rf\"{header}\\s*[-:]*\\s*(?![,.])(.+)\", description_lower)\n",
    "        if match:\n",
    "            start_index = match.start(1)\n",
    "            end_index = match.end(1)\n",
    "            # Return the corresponding text from the original description\n",
    "            return description[start_index:end_index].strip()\n",
    "    return \"\"  # If no header is found, return an empty string\n",
    "\n",
    "extract_requirements_udf = udf(lambda desc: extract_requirements(desc), StringType())\n",
    "requirements_df = translated_ads.withColumn(\"Requirements_Text\", extract_requirements_udf(col(\"Description_English\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "db09eebd-2f7c-44ff-997b-61ccf160d0f4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Description_English</th><th>Requirements_Text</th></tr></thead><tbody><tr><td>We thank all individuals for their applications. As an equal opportunity employer, we encourage applications from all qualified individuals and specifically applicants from traditionally underrepresented groups – including Indigenous persons, newcomers, and persons with disabilities – who may contribute to the continued diversification of our organization.</td><td></td></tr><tr><td>We thank all individuals for their applications. As an equal opportunity employer, we encourage applications from all qualified individuals and specifically applicants from traditionally underrepresented groups – including Indigenous persons, newcomers, and persons with disabilities – who may contribute to the continued diversification of our organization.</td><td></td></tr><tr><td>We thank all individuals for their applications. As an equal opportunity employer, we encourage applications from all qualified individuals and specifically applicants from traditionally underrepresented groups – including Indigenous persons, newcomers, and persons with disabilities – who may contribute to the continued diversification of our organization.</td><td></td></tr><tr><td>We thank all individuals for their applications. As an equal opportunity employer, we encourage applications from all qualified individuals and specifically applicants from traditionally underrepresented groups – including Indigenous persons, newcomers, and persons with disabilities – who may contribute to the continued diversification of our organization.</td><td></td></tr><tr><td>We thank all individuals for their applications. As an equal opportunity employer, we encourage applications from all qualified individuals and specifically applicants from traditionally underrepresented groups – including Indigenous persons, newcomers, and persons with disabilities – who may contribute to the continued diversification of our organization.</td><td></td></tr><tr><td>We thank all individuals for their applications. As an equal opportunity employer, we encourage applications from all qualified individuals and specifically applicants from traditionally underrepresented groups – including Indigenous persons, newcomers, and persons with disabilities – who may contribute to the continued diversification of our organization.</td><td></td></tr><tr><td>We thank all individuals for their applications. As an equal opportunity employer, we encourage applications from all qualified individuals and specifically applicants from traditionally underrepresented groups – including Indigenous persons, newcomers, and persons with disabilities – who may contribute to the continued diversification of our organization.</td><td></td></tr><tr><td>We thank all individuals for their applications. As an equal opportunity employer, we encourage applications from all qualified individuals and specifically applicants from traditionally underrepresented groups – including Indigenous persons, newcomers, and persons with disabilities – who may contribute to the continued diversification of our organization.</td><td></td></tr><tr><td>We thank all individuals for their applications. As an equal opportunity employer, we encourage applications from all qualified individuals and specifically applicants from traditionally underrepresented groups – including Indigenous persons, newcomers, and persons with disabilities – who may contribute to the continued diversification of our organization.</td><td></td></tr><tr><td>Training provided where necessary. Dot Dot Loans are looking for a Data Analyst to join our team. In this role, you will analyse data, find patterns, and help the company make better decisions. You will work with different teams to ensure we use data effectively. Responsibilities Study data to find trends and insights to help the business. Use SQL to access and extract data from databases. Create and manage easy-to-understand dashboards with tools like Tableau and Power BI. Work with teams to understand their data needs and provide solutions. Write reports that explain your findings and give useful recommendations. Help with projects by providing data analysis during different stages. Use VBA to automate repetitive tasks and improve reporting. Check data regularly to make sure it’s accurate. Share your findings clearly, even with people who don’t have technical knowledge. Join our team and help us use data to grow and improve our business! Job Types: Full-time, Part-time, Permanent, Fixed term contract, Temp to perm Contract length: 12 months Expected hours: 15 – 40 per week Additional pay: Bonus scheme Performance bonus Yearly bonus Benefits: Language training provided Work from home Schedule: Day shift Monday to Friday No weekends Overtime Weekend availability Weekends only Application question(s): Research Dot Dot Loans and tell us in a brief summary what we do and how you might be a good fit for the role and the brand. Work Location: Remote</td><td></td></tr><tr><td>Training provided where necessary. Dot Dot Loans are looking for a Data Analyst to join our team. In this role, you will analyse data, find patterns, and help the company make better decisions. You will work with different teams to ensure we use data effectively. Responsibilities Study data to find trends and insights to help the business. Use SQL to access and extract data from databases. Create and manage easy-to-understand dashboards with tools like Tableau and Power BI. Work with teams to understand their data needs and provide solutions. Write reports that explain your findings and give useful recommendations. Help with projects by providing data analysis during different stages. Use VBA to automate repetitive tasks and improve reporting. Check data regularly to make sure it’s accurate. Share your findings clearly, even with people who don’t have technical knowledge. Join our team and help us use data to grow and improve our business! Job Types: Full-time, Part-time, Permanent, Fixed term contract, Temp to perm Contract length: 12 months Expected hours: 15 – 40 per week Additional pay: Bonus scheme Performance bonus Yearly bonus Benefits: Language training provided Work from home Schedule: Day shift Monday to Friday No weekends Overtime Weekend availability Weekends only Application question(s): Research Dot Dot Loans and tell us in a brief summary what we do and how you might be a good fit for the role and the brand. Work Location: Remote</td><td></td></tr><tr><td>Training provided where necessary. Dot Dot Loans are looking for a Data Analyst to join our team. In this role, you will analyse data, find patterns, and help the company make better decisions. You will work with different teams to ensure we use data effectively. Responsibilities Study data to find trends and insights to help the business. Use SQL to access and extract data from databases. Create and manage easy-to-understand dashboards with tools like Tableau and Power BI. Work with teams to understand their data needs and provide solutions. Write reports that explain your findings and give useful recommendations. Help with projects by providing data analysis during different stages. Use VBA to automate repetitive tasks and improve reporting. Check data regularly to make sure it’s accurate. Share your findings clearly, even with people who don’t have technical knowledge. Join our team and help us use data to grow and improve our business! Job Types: Full-time, Part-time, Permanent, Fixed term contract, Temp to perm Contract length: 12 months Expected hours: 15 – 40 per week Additional pay: Bonus scheme Performance bonus Yearly bonus Benefits: Language training provided Work from home Schedule: Day shift Monday to Friday No weekends Overtime Weekend availability Weekends only Application question(s): Research Dot Dot Loans and tell us in a brief summary what we do and how you might be a good fit for the role and the brand. Work Location: Remote</td><td></td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "We thank all individuals for their applications. As an equal opportunity employer, we encourage applications from all qualified individuals and specifically applicants from traditionally underrepresented groups – including Indigenous persons, newcomers, and persons with disabilities – who may contribute to the continued diversification of our organization.",
         ""
        ],
        [
         "We thank all individuals for their applications. As an equal opportunity employer, we encourage applications from all qualified individuals and specifically applicants from traditionally underrepresented groups – including Indigenous persons, newcomers, and persons with disabilities – who may contribute to the continued diversification of our organization.",
         ""
        ],
        [
         "We thank all individuals for their applications. As an equal opportunity employer, we encourage applications from all qualified individuals and specifically applicants from traditionally underrepresented groups – including Indigenous persons, newcomers, and persons with disabilities – who may contribute to the continued diversification of our organization.",
         ""
        ],
        [
         "We thank all individuals for their applications. As an equal opportunity employer, we encourage applications from all qualified individuals and specifically applicants from traditionally underrepresented groups – including Indigenous persons, newcomers, and persons with disabilities – who may contribute to the continued diversification of our organization.",
         ""
        ],
        [
         "We thank all individuals for their applications. As an equal opportunity employer, we encourage applications from all qualified individuals and specifically applicants from traditionally underrepresented groups – including Indigenous persons, newcomers, and persons with disabilities – who may contribute to the continued diversification of our organization.",
         ""
        ],
        [
         "We thank all individuals for their applications. As an equal opportunity employer, we encourage applications from all qualified individuals and specifically applicants from traditionally underrepresented groups – including Indigenous persons, newcomers, and persons with disabilities – who may contribute to the continued diversification of our organization.",
         ""
        ],
        [
         "We thank all individuals for their applications. As an equal opportunity employer, we encourage applications from all qualified individuals and specifically applicants from traditionally underrepresented groups – including Indigenous persons, newcomers, and persons with disabilities – who may contribute to the continued diversification of our organization.",
         ""
        ],
        [
         "We thank all individuals for their applications. As an equal opportunity employer, we encourage applications from all qualified individuals and specifically applicants from traditionally underrepresented groups – including Indigenous persons, newcomers, and persons with disabilities – who may contribute to the continued diversification of our organization.",
         ""
        ],
        [
         "We thank all individuals for their applications. As an equal opportunity employer, we encourage applications from all qualified individuals and specifically applicants from traditionally underrepresented groups – including Indigenous persons, newcomers, and persons with disabilities – who may contribute to the continued diversification of our organization.",
         ""
        ],
        [
         "Training provided where necessary. Dot Dot Loans are looking for a Data Analyst to join our team. In this role, you will analyse data, find patterns, and help the company make better decisions. You will work with different teams to ensure we use data effectively. Responsibilities Study data to find trends and insights to help the business. Use SQL to access and extract data from databases. Create and manage easy-to-understand dashboards with tools like Tableau and Power BI. Work with teams to understand their data needs and provide solutions. Write reports that explain your findings and give useful recommendations. Help with projects by providing data analysis during different stages. Use VBA to automate repetitive tasks and improve reporting. Check data regularly to make sure it’s accurate. Share your findings clearly, even with people who don’t have technical knowledge. Join our team and help us use data to grow and improve our business! Job Types: Full-time, Part-time, Permanent, Fixed term contract, Temp to perm Contract length: 12 months Expected hours: 15 – 40 per week Additional pay: Bonus scheme Performance bonus Yearly bonus Benefits: Language training provided Work from home Schedule: Day shift Monday to Friday No weekends Overtime Weekend availability Weekends only Application question(s): Research Dot Dot Loans and tell us in a brief summary what we do and how you might be a good fit for the role and the brand. Work Location: Remote",
         ""
        ],
        [
         "Training provided where necessary. Dot Dot Loans are looking for a Data Analyst to join our team. In this role, you will analyse data, find patterns, and help the company make better decisions. You will work with different teams to ensure we use data effectively. Responsibilities Study data to find trends and insights to help the business. Use SQL to access and extract data from databases. Create and manage easy-to-understand dashboards with tools like Tableau and Power BI. Work with teams to understand their data needs and provide solutions. Write reports that explain your findings and give useful recommendations. Help with projects by providing data analysis during different stages. Use VBA to automate repetitive tasks and improve reporting. Check data regularly to make sure it’s accurate. Share your findings clearly, even with people who don’t have technical knowledge. Join our team and help us use data to grow and improve our business! Job Types: Full-time, Part-time, Permanent, Fixed term contract, Temp to perm Contract length: 12 months Expected hours: 15 – 40 per week Additional pay: Bonus scheme Performance bonus Yearly bonus Benefits: Language training provided Work from home Schedule: Day shift Monday to Friday No weekends Overtime Weekend availability Weekends only Application question(s): Research Dot Dot Loans and tell us in a brief summary what we do and how you might be a good fit for the role and the brand. Work Location: Remote",
         ""
        ],
        [
         "Training provided where necessary. Dot Dot Loans are looking for a Data Analyst to join our team. In this role, you will analyse data, find patterns, and help the company make better decisions. You will work with different teams to ensure we use data effectively. Responsibilities Study data to find trends and insights to help the business. Use SQL to access and extract data from databases. Create and manage easy-to-understand dashboards with tools like Tableau and Power BI. Work with teams to understand their data needs and provide solutions. Write reports that explain your findings and give useful recommendations. Help with projects by providing data analysis during different stages. Use VBA to automate repetitive tasks and improve reporting. Check data regularly to make sure it’s accurate. Share your findings clearly, even with people who don’t have technical knowledge. Join our team and help us use data to grow and improve our business! Job Types: Full-time, Part-time, Permanent, Fixed term contract, Temp to perm Contract length: 12 months Expected hours: 15 – 40 per week Additional pay: Bonus scheme Performance bonus Yearly bonus Benefits: Language training provided Work from home Schedule: Day shift Monday to Friday No weekends Overtime Weekend availability Weekends only Application question(s): Research Dot Dot Loans and tell us in a brief summary what we do and how you might be a good fit for the role and the brand. Work Location: Remote",
         ""
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "Description_English",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Requirements_Text",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Observe records with no extracted requirements to check for relevance\n",
    "empty_requirements = requirements_df.filter(col(\"Requirements_Text\").isNull() | (col(\"Requirements_Text\") == \"\"))\n",
    "display(empty_requirements.select(\"Description_English\", \"Requirements_Text\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "24ab621e-4902-42b1-b35a-2ad0296ecf9c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "647\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Description_English</th><th>Requirements_Text</th></tr></thead><tbody><tr><td>Summary Posted: Nov 7, 2024 Role Number: 200577967 We're looking for an exceptional data analyst with a strong background in distributed data processing and a demonstrated ability to turn data into actionable insights. As a data analyst for our Storage Data Analytics team at Apple, you'll play a crucial role in developing the fastest and most efficient SSDs for our products, including the iPhone, iPad, Apple Watch, and new Apple Silicon Macs. If you're passionate about continuously improving the ways we use data to make Apple's products amazing, we want to hear from you! Description On the Storage Data Analytics team, we are responsible for performing ad hoc data analysis, development and maintenance of distributed data pipelines, as well as creation and support of analysis tools. Our team focuses on Apple’s storage solutions. It is small and nimble, able to quickly explore ideas and present them to the storage teams and to leadership. Minimum Qualifications +3 years of experience Ability to lead data investigations and analysis projects with ambiguous requirements Advanced statistic and modeling knowledge Experience visualizing and presenting analyses in tools like Jupyter and Tableau Experience programming in Python in a professional setting Familiarity with distributed computation, storage, and workflow management (e.g. Splunk, Spark, Kubernetes, Kafka, Hadoop, MapReduce, AirFlow etc.) Experience with relational databases and SQL Highly organized, creative, motivated, and passionate about achieving results Curious and have excellent analytical and problem solving skills Excellent written, verbal, and data communication skills Bachelor's or Master's degree in computer science. Preferred Qualifications Familiarity with distributed computation, storage, and workflow management (e.g. Splunk, Spark, Kubernetes, Kafka, Hadoop, MapReduce, AirFlow etc.)</td><td>+3 years of experience Ability to lead data investigations and analysis projects with ambiguous requirements Advanced statistic and modeling knowledge Experience visualizing and presenting analyses in tools like Jupyter and Tableau Experience programming in Python in a professional setting Familiarity with distributed computation, storage, and workflow management (e.g. Splunk, Spark, Kubernetes, Kafka, Hadoop, MapReduce, AirFlow etc.) Experience with relational databases and SQL Highly organized, creative, motivated, and passionate about achieving results Curious and have excellent analytical and problem solving skills Excellent written, verbal, and data communication skills Bachelor's or Master's degree in computer science. Preferred Qualifications Familiarity with distributed computation, storage, and workflow management (e.g. Splunk, Spark, Kubernetes, Kafka, Hadoop, MapReduce, AirFlow etc.)</td></tr><tr><td>Israel, Hod HaSharon Description About ThetaRay: ThetaRay is a trailblazer in AI-powered Anti-Money Laundering (AML) solutions, offering cutting-edge technology to fintechs, banks, and regulatory bodies worldwide. Our mission is to enhance trust in financial transactions, ensuring compliant and innovative business growth. Our technology empowers customers to expand into new markets and introduce groundbreaking products. Thetaray is a culture-driven company. Our values are at the heart of our success. By joining us, you'll have the opportunity to embody these values and inspire others through your actions. Why Join ThetaRay? At ThetaRay, you'll be part of a dynamic global team committed to redefining the financial services sector through technological innovation. You will contribute to creating safer financial environments and have the opportunity to work with some of the brightest minds in AI, ML, and financial technology. We offer a collaborative, inclusive, and forward-thinking work environment where your ideas and contributions are valued and encouraged. Join us in our mission to revolutionize the financial world, making it safer and more trustworthy for millions worldwide. Explore exciting career opportunities at ThetaRay – where innovation meets purpose. We are seeking a skilled Junior Backend Big Data Developer to join our global R&D department. About the position Design and develop a scalable data processing and ML pipeline using the latest big data technologies in a fast paced agile environment Investigate new technological areas and understand them in depth through rapid self-learning Demonstrates strong analytical problem-solving skills to support scalable and sustainable design solutions Ability to take ownership of product development including all life cycle stages: translating product requirements into actionable designs and tasks, development, UT, and production troubleshooting Requirements 1-2 years of experience of hands-on development experience Experience developing data-oriented products preferably using Python/Java Experience in data processing FW such as Spark, Pandas, Hadoop, Airflow Experience in Distributed Databases (Such as Elasticsearch, Mongo, Redis, etc) Experience with developing microservices-based architecture Experience working in container-based environments using tools such as K8s, helm Experience working as a software developer in an Agile environment Nice to have: Experience in machine learning FWs such as SKLearn, Tensorflow Experience with RedHat OpenShift Dev Environment knowledge: GIT, Jenkins, Docker</td><td>into actionable designs and tasks, development, UT, and production troubleshooting Requirements 1-2 years of experience of hands-on development experience Experience developing data-oriented products preferably using Python/Java Experience in data processing FW such as Spark, Pandas, Hadoop, Airflow Experience in Distributed Databases (Such as Elasticsearch, Mongo, Redis, etc) Experience with developing microservices-based architecture Experience working in container-based environments using tools such as K8s, helm Experience working as a software developer in an Agile environment Nice to have: Experience in machine learning FWs such as SKLearn, Tensorflow Experience with RedHat OpenShift Dev Environment knowledge: GIT, Jenkins, Docker</td></tr><tr><td>Description: Prisma-Photonics is a rapidly growing startup company, developing the next-generation smart-infrastructure solution based on novel fiber-sensing technology (smart roads, smart cities, perimeters, grid monitoring, etc.). The company offers an award-winning disruptive solution – a “sensor free” approach to smart infrastructure. The company is VC backed and is in the revenues stage. Combining pioneering technology in optical fiber sensing with state-of-the-art machine learning, we help prevent environmental disasters, protect human lives, and keep critical energy and transportation backbones running smoothly. We are rapidly growing, looking for the best minds and spirits to join us in our journey. We know our products are only as great as the individuals building the hardware and software and harnessing data for good causes! Being a great team member means being eager to learn and grow, able to challenge others while accepting being challenged yourself, and working for the team and product with enthusiasm and passion. We are seeking a detail-oriented and highly technical Data Annotator to join our Data Operations team. The role is full time, on an hourly pay, with the aim of adjusting work hours per need. In this role, you will be responsible for annotating various events on our distinct fiber sensing data, and managing datasets to support various products and projects. You will play a crucial part in ensuring the quality and integrity of our data, contributing to multiple critical initiatives. You will help improve our annotation procedures, techniques and tooling, and work closely with ML and Algo teams as well as Data Engineering. This is a unique opportunity to gain hands-on experience in data operations within a dynamic environment using cutting edge and novel technology. You will join a talented team dedicated to leveraging data for impactful projects. If you are passionate about data and eager to contribute to exciting challenges, this might be the perfect opportunity for you. Key Responsibilities: Data Annotation – Accurately annotate datasets using internal tools, adhering to annotation guidelines and maintaining high standards for consistency and quality.. Quality Assurance – Review and validate annotated data to ensure accuracy and consistency, identify discrepancies, and suggest solutions to improve processes. Continuous improvement – Participate in the continuous improvement of our tools and data operation processes to achieve more accurate models, and more streamlined data flow between the different teams in the company. Data Management – Support the ongoing maintenance of annotated datasets, ensuring data integrity and accessibility, and implementing best-practices to create seamless data flows Requirements: A Bachelor of Science degree or equivalent (STEM fields an advantage). Strong attention to detail and a commitment to maintaining high-quality annotation standards. Good written and verbal skills, with the ability to work effectively with a diverse group of individuals. Availability to work full time when needed. Nice-to-haves: Familiarity with data annotation processes, especially non-structured data (images, video, audio). Experience working with seismic data, heat maps, or spectrograms Familiarity with SQL and data visualization tools. Experience with coding languages, preferably MATLAB and Python.</td><td>A Bachelor of Science degree or equivalent (STEM fields an advantage). Strong attention to detail and a commitment to maintaining high-quality annotation standards. Good written and verbal skills, with the ability to work effectively with a diverse group of individuals. Availability to work full time when needed. Nice-to-haves: Familiarity with data annotation processes, especially non-structured data (images, video, audio). Experience working with seismic data, heat maps, or spectrograms Familiarity with SQL and data visualization tools. Experience with coding languages, preferably MATLAB and Python.</td></tr><tr><td>The Business Performance department at Plarium is in charge of all the analytical aspects of our game operations and strategic planning: From game design, to user acquisition, player behavior, live-ops, and game optimization (such as monetization, retention, etc). We are looking for a data analyst for our Marketing Analytics team. The scope of responsibility of this team includes budget optimization for user acquisition for our games at the scope of tens of million dollars per game, analyses of game profitability and long term potential, analysis of the players behavior, player game funnel and reaction to new game features and offers, and a lot more. Our goal is making sure Plarium brings the best and most relevant players to its games in the most efficient and effective way. Responsibilities Be a focal point for anything related to new players performance and KPIs across our range of games, strategic planning, user segmentation, tests and growth opportunities identification Daily support of ongoing analytical needs of the marketing department managers & teams Establish and monitor success metrics that measure and explain the impact of the marketing activities Design and initiate new features and reports to monitor & give insights on the marketing activity, using the marketing in-house BI system (for example, LTV, ROI forecasting, automatic rules) Run ad-hoc and in-depth analyses of the different Marketing activities and trends Support decision making based on data Collaborate with the game analysis team and the game studios to monitor and optimize our players experience, maximizing their retention in our games What we expect B.A/BSc in a highly quantitative field such as mathematics industrial engineering economics statistics or equivalent academic knowledge At least 2 years of hands-on data analysis and story-telling experience Proven experience with measuring online success and identifying optimization opportunities Excellent understanding of online marketing metrics High proficiency in SQL with demonstrated experience in querying large complex datasets Strong Excel / Google Sheets skills Experience with data visualization tools such as Qlik Sense and Looker A solid grasp of statistical significance models and tools Desired Marketing metrics of user funnel, user acquisition KPI’s What we offer A Workplace Designed for Your Well-Being - Comfortable Environment: Ergonomic chairs and desks to support your health. Beautifully designed spaces that inspire creativity. - On-Site Amenities: Gym, yoga room, and music room for relaxation and rejuvenation. - Delicious Perks: 5-star breakfast to kickstart your day. Freshly made coffee, shakes, and afternoon salads by our in-house barista. - Health & Wellness: Full health insurance coverage for your peace of mind. - Growth Opportunities: Learning and training programs to enhance your personal and professional skills. - Vibrant Culture: Happy hours, team events, and plenty of opportunities to connect with colleagues. Join us and experience a workplace where your well-being, growth, and enjoyment come first!</td><td>B.A/BSc in a highly quantitative field such as mathematics industrial engineering economics statistics or equivalent academic knowledge At least 2 years of hands-on data analysis and story-telling experience Proven experience with measuring online success and identifying optimization opportunities Excellent understanding of online marketing metrics High proficiency in SQL with demonstrated experience in querying large complex datasets Strong Excel / Google Sheets skills Experience with data visualization tools such as Qlik Sense and Looker A solid grasp of statistical significance models and tools Desired Marketing metrics of user funnel, user acquisition KPI’s What we offer A Workplace Designed for Your Well-Being - Comfortable Environment: Ergonomic chairs and desks to support your health. Beautifully designed spaces that inspire creativity. - On-Site Amenities: Gym, yoga room, and music room for relaxation and rejuvenation. - Delicious Perks: 5-star breakfast to kickstart your day. Freshly made coffee, shakes, and afternoon salads by our in-house barista. - Health & Wellness: Full health insurance coverage for your peace of mind. - Growth Opportunities: Learning and training programs to enhance your personal and professional skills. - Vibrant Culture: Happy hours, team events, and plenty of opportunities to connect with colleagues. Join us and experience a workplace where your well-being, growth, and enjoyment come first!</td></tr><tr><td>aiOla is a high-growth, product-led SaaS startup backed by $45 million in funding from premier investors such as New Era Capital Partners and Hamilton Lane. Our mission is to revolutionize efficiency, intelligence, collaboration, and safety in the industrial sector through our proprietary speech-powered AI technology. Our team spans the US and Israel, bringing together experts in Product, Data Science, Data Engineering, Analytics, Marketing, and Customer Success. At aiOla, we thrive on innovation, collaboration, and a commitment to excellence. We are seeking forward-thinking professionals passionate about pushing the limits of AI and making an impact. Role Overview: We are seeking a passionate and innovative Data Analyst to join our growing Analytics team. This is an exceptional opportunity for a detail-oriented professional to not only analyze data but also play a pivotal role in shaping and enhancing our cutting-edge AI models and products. As a Data Analyst at aiOla, you will dive into complex datasets, uncover actionable insights, and contribute directly to the improvement and monitoring of our proprietary AI technologies. If you thrive in a dynamic environment, this role is perfect for you! Requirements: B.Sc in Industrial Engineering, Data Analytics, Statistics, or a related field. Proficiency in Python, with a strong focus on libraries like Pandas for data manipulation. Solid knowledge of SQL for querying and managing large datasets. Experience with BI tools like Tableau to create dashboards and reports. Excellent communication skills, with fluency in English (written and verbal). 0-1 years of experience in a Data Analyst role- advantage Nice To have: Familiarity with Snowflake or AWS Athena. Experience with Web/App product analytics tools such as Mixpanel. Knowledge of Data Science concepts and metrics, including Speech AI, Large Language Models (LLMs), Natural Language Understanding (NLU), and Automatic Speech Recognition (ASR). Responsibilities: Extract, clean, and analyze data to uncover trends, patterns, and actionable insights. Provide recommendations based on data analysis to support business decisions and drive product improvements. Develop and maintain dashboards and reports using BI tools such as Tableau or other platforms. Optimize data workflows and pipelines using Python and SQL. Collaborate with cross-functional teams, including Product, Data Science, and Engineering, to support data-driven decision-making.</td><td>B.Sc in Industrial Engineering, Data Analytics, Statistics, or a related field. Proficiency in Python, with a strong focus on libraries like Pandas for data manipulation. Solid knowledge of SQL for querying and managing large datasets. Experience with BI tools like Tableau to create dashboards and reports. Excellent communication skills, with fluency in English (written and verbal). 0-1 years of experience in a Data Analyst role- advantage Nice To have: Familiarity with Snowflake or AWS Athena. Experience with Web/App product analytics tools such as Mixpanel. Knowledge of Data Science concepts and metrics, including Speech AI, Large Language Models (LLMs), Natural Language Understanding (NLU), and Automatic Speech Recognition (ASR). Responsibilities: Extract, clean, and analyze data to uncover trends, patterns, and actionable insights. Provide recommendations based on data analysis to support business decisions and drive product improvements. Develop and maintain dashboards and reports using BI tools such as Tableau or other platforms. Optimize data workflows and pipelines using Python and SQL. Collaborate with cross-functional teams, including Product, Data Science, and Engineering, to support data-driven decision-making.</td></tr><tr><td>As a Data Engineer at Meta, you will shape the future of people-facing and business-facing products we build across our entire family of applications (Facebook, Instagram, Messenger, WhatsApp, Reality Labs, Threads). Your technical skills and analytical mindset will be utilized designing and building some of the world's most extensive data sets, helping to craft experiences for billions of people and hundreds of millions of businesses worldwide.In this role, you will collaborate with software engineering, data science, and product management teams to design/build scalable data solutions across Meta to optimize growth, strategy, and user experience for our 3 billion plus users, as well as our internal employee community.You will be at the forefront of identifying and solving some of the most interesting data challenges at a scale few companies can match. By joining Meta, you will become part of a vibrant community dedicated to skill development and career growth in data engineering and beyond.Data Engineering: You will guide teams by building optimal data artifacts (including datasets and visualizations) to address key questions. You will refine our systems, design logging solutions, and create scalable data models. Ensuring data security and quality, and with a strong focus on efficiency, you will suggest architecture and development approaches and data management standards to address complex analytical problems.Product leadership: You will use data to shape product development, identify new opportunities, and tackle upcoming challenges. You'll ensure our products add value for users and businesses, by prioritizing projects, and driving innovative solutions to respond to challenges or opportunities.Communication and influence: You won't simply present data, but tell data-driven stories. You will convince and influence your partners using clear insights and recommendations. You will build credibility through structure and clarity, and be a trusted strategic partner. Data Engineer Responsibilities: Conceptualize and own the data architecture for multiple large-scale projects, while evaluating design and operational cost-benefit tradeoffs within systems Create and contribute to frameworks that improve the efficacy of logging data, while working with data infrastructure to triage issues and resolve Collaborate with engineers, product managers, and data scientists to understand data needs, representing key data insights in a meaningful way Define and manage Service Level Agreements for all data sets in allocated areas of ownership Determine and implement the security model based on privacy requirements, confirm safeguards are followed, address data quality issues, and evolve governance processes within allocated areas of ownership Design, build, and launch collections of sophisticated data models and visualizations that support multiple use cases across different products or domains Solve our most challenging data integration problems, utilizing optimal Extract, Transform, Load (ETL) patterns, frameworks, query techniques, sourcing from structured and unstructured data sources Assist in owning existing processes running in production, optimizing complex code through advanced algorithmic concepts Optimize pipelines, dashboards, frameworks, and systems to facilitate easier development of data artifacts Influence product and cross-functional teams to identify data opportunities to drive impact Mentor team members by giving/receiving actionable feedback Minimum Qualifications: Bachelor's degree in Computer Science, Engineering, relevant technical field, or equivalent 4+ years of experience where the primary responsibility involves working with data. This could include roles such as data analyst, data scientist, data engineer, or similar positions 4+ years of experience (or a minimum of 2+ years with a Ph.D) with SQL, ETL, data modeling, and at least one programming language (e.g., Python, C++, C#, Scala, etc.) About Meta: Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today—beyond the constraints of screens, the limits of distance, and even the rules of physics. Individual compensation is determined by skills, qualifications, experience, and location. Compensation details listed in this posting reflect the base hourly rate, monthly rate, or annual salary only, and do not include bonus, equity or sales incentives, if applicable. In addition to base compensation, Meta offers benefits. Learn more about benefits at Meta.</td><td>Bachelor's degree in Computer Science, Engineering, relevant technical field, or equivalent 4+ years of experience where the primary responsibility involves working with data. This could include roles such as data analyst, data scientist, data engineer, or similar positions 4+ years of experience (or a minimum of 2+ years with a Ph.D) with SQL, ETL, data modeling, and at least one programming language (e.g., Python, C++, C#, Scala, etc.) About Meta: Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today—beyond the constraints of screens, the limits of distance, and even the rules of physics. Individual compensation is determined by skills, qualifications, experience, and location. Compensation details listed in this posting reflect the base hourly rate, monthly rate, or annual salary only, and do not include bonus, equity or sales incentives, if applicable. In addition to base compensation, Meta offers benefits. Learn more about benefits at Meta.</td></tr><tr><td>At Aquant, we empower field service professionals to become heroes using our personalized generative AI platform, Service Co-Pilot. Using historical service data, Aquant equips service leaders, field technicians, and customer service representatives with the precise information they need when they need it—enabling them to make decisions with confidence, reduce costs, and optimize service delivery. Recognized as one of Fast Company's Next Big Things in Tech of 2024 , we are committed to providing cutting-edge AI solutions that tackle the most pressing challenges in manufacturing. Ready to join a team that values innovation, excellence, and above all, its people? Apply today! Aquant's Data Analytics team is looking for a highly skilled Data Engineer who is comfortable with big data and complex data models. As a member of our Data Engineering team, you will: Work with large amounts of data and develop Python code to streamline processes Analyze different data structures and create the required reports out of them Collaborate \\ connect to existing codes Build tools to track data quality on large DB with complicated schemas Monitor the integrity and validity of the customer service data Deep dive into the service data and learn the service world Required skills & background: 2-3 years experience with big datasets BA/B.Sc. in industrial/information systems engineering, statistics or equivalent Hands-on experience with Excel + SQL - must Hands-on experience with Python – must Experience with Azure services - advantage A team player, with excellent collaboration skills Excellent communicator with the ability to deliver high-quality results Fluent English It's not enough to have a cool product, join us because you share our values: These guiding values inspire every Aquant employee. They are how we operate and enable our company as a whole to have a greater impact and achieve our vision: Be Humble and Respectful: We are one team, where collective success is more important than individual ego. Treat your colleagues with respect and empathy, act with good intent, and value everyone's contributions. Be Curious: Keep learning, and asking questions to understand complex situations. Embrace new challenges. Keep an open mind, and be receptive to feedback. Take Ownership: Focus on achieving measurable and meaningful outcomes. Take decisive action, solve problems proactively, and take ownership of projects and results. Act with Integrity: Act with Integrity. Do great things while doing the right thing for your customers and colleagues. Some of our benefits: Vacation your way: We want to make sure you have time to meet your personal needs with generous PTO and flexible vacation planning. Everyone is an owner: We want everyone to feel ownership over their work and what we are building here, which is why we offer equity to full-time employees. Build your career: Every Aquant employee is in control of their career development with our learning stipends, tools, and training. Applicants must be authorized to work for any employer in the Israel. We are unable to sponsor or take over sponsorship of an employment Visa at this time. Aquant is committed to hiring a diverse and talented workforce.</td><td>2-3 years experience with big datasets BA/B.Sc. in industrial/information systems engineering, statistics or equivalent Hands-on experience with Excel + SQL - must Hands-on experience with Python – must Experience with Azure services - advantage A team player, with excellent collaboration skills Excellent communicator with the ability to deliver high-quality results Fluent English It's not enough to have a cool product, join us because you share our values: These guiding values inspire every Aquant employee. They are how we operate and enable our company as a whole to have a greater impact and achieve our vision: Be Humble and Respectful: We are one team, where collective success is more important than individual ego. Treat your colleagues with respect and empathy, act with good intent, and value everyone's contributions. Be Curious: Keep learning, and asking questions to understand complex situations. Embrace new challenges. Keep an open mind, and be receptive to feedback. Take Ownership: Focus on achieving measurable and meaningful outcomes. Take decisive action, solve problems proactively, and take ownership of projects and results. Act with Integrity: Act with Integrity. Do great things while doing the right thing for your customers and colleagues. Some of our benefits: Vacation your way: We want to make sure you have time to meet your personal needs with generous PTO and flexible vacation planning. Everyone is an owner: We want everyone to feel ownership over their work and what we are building here, which is why we offer equity to full-time employees. Build your career: Every Aquant employee is in control of their career development with our learning stipends, tools, and training. Applicants must be authorized to work for any employer in the Israel. We are unable to sponsor or take over sponsorship of an employment Visa at this time. Aquant is committed to hiring a diverse and talented workforce.</td></tr><tr><td>About Team & About Role: Rubrik is seeking a Data Scientist to join our Data Research team, part of the Security Apps organization responsible for developing Rubrik’s suite of security products. This is the first data scientist position on the team, requiring a high degree of independence and ownership. You’ll spearhead research and development of ML/AI models that power the features of our security offerings. What You’ll Do: Research and develop ML/AI models in the NLP domain Develop advanced anomaly detection models for threat detection Work closely with data analysts on research, pattern analysis, etc. Work closely with developers on implementation of models as part of features in the product Work with global teams to continuously push our ML infrastructure forward Experience You’ll Need: Bachelor’s degree in Mathematics, Computer Science, or other related field 3 years of experience in data science or a related field Proficiency in programming languages, especially Python Experience with common data science toolkits, such as Jupyter Notebook, Pandas, NumPy, Matplotlib, etc. Demonstrated experience in implementing ML algorithms in production environments, with a focus on anomaly detection and natural language processing. Strong problem-solving skills and analytic capability to develop insights and recommendations Excellent communication skills in Hebrew and English Preferred Qualifications: Master’s degree in Mathematics, Computer Science, or other related field Familiarity with cloud platforms such as AWS, Google Cloud, or Azure Experience working with LLMs Previous experience in the security industry Join Us in Securing the World's Data Rubrik (NYSE: RBRK) is on a mission to secure the world’s data. With Zero Trust Data Security™, we help organizations achieve business resilience against cyberattacks, malicious insiders, and operational disruptions. Rubrik Security Cloud, powered by machine learning, secures data across enterprise, cloud, and SaaS applications. We help organizations uphold data integrity, deliver data availability that withstands adverse conditions, continuously monitor data risks and threats, and restore businesses with their data when infrastructure is attacked. Linkedin | X (formerly Twitter) | Instagram | Rubrik.com Diversity, Equity & Inclusion @ Rubrik At Rubrik we are committed to building and sustaining a culture where people of all backgrounds are valued, know they belong, and believe they can succeed here. Rubrik's goal is to hire and promote the best person for the job, no matter their background. In doing so, Rubrik is committed to correcting systemic processes and cultural norms that have prevented equal representation. This means we review our current efforts with the intent to offer fair hiring, promotion, and compensation opportunities to people from historically underrepresented communities, and strive to create a company culture where all employees feel they can bring their authentic selves to work and be successful. Our DEI strategy focuses on three core areas of our business and culture: Our Company: Build a diverse company that provides equitable access to growth and success for all employees globally. Our Culture: Create an inclusive environment where authenticity thrives and people of all backgrounds feel like they belong. Our Communities: Expand our commitment to diversity, equity, & inclusion within and beyond our company walls to invest in future generations of underrepresented talent and bring innovation to our clients. Equal Opportunity Employer/Veterans/Disabled Rubrik is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, or protected veteran status and will not be discriminated against on the basis of disability. Rubrik provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability or genetics. In addition to federal law requirements, Rubrik complies with applicable state and local laws governing nondiscrimination in employment in every location in which the company has facilities. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training. Federal law requires employers to provide reasonable accommodation to qualified individuals with disabilities. Please contact us at hr@rubrik.com if you require a reasonable accommodation to apply for a job or to perform your job. Examples of reasonable accommodation include making a change to the application process or work procedures, providing documents in an alternate format, using a sign language interpreter, or using specialized equipment.</td><td>Master’s degree in Mathematics, Computer Science, or other related field Familiarity with cloud platforms such as AWS, Google Cloud, or Azure Experience working with LLMs Previous experience in the security industry Join Us in Securing the World's Data Rubrik (NYSE: RBRK) is on a mission to secure the world’s data. With Zero Trust Data Security™, we help organizations achieve business resilience against cyberattacks, malicious insiders, and operational disruptions. Rubrik Security Cloud, powered by machine learning, secures data across enterprise, cloud, and SaaS applications. We help organizations uphold data integrity, deliver data availability that withstands adverse conditions, continuously monitor data risks and threats, and restore businesses with their data when infrastructure is attacked. Linkedin | X (formerly Twitter) | Instagram | Rubrik.com Diversity, Equity & Inclusion @ Rubrik At Rubrik we are committed to building and sustaining a culture where people of all backgrounds are valued, know they belong, and believe they can succeed here. Rubrik's goal is to hire and promote the best person for the job, no matter their background. In doing so, Rubrik is committed to correcting systemic processes and cultural norms that have prevented equal representation. This means we review our current efforts with the intent to offer fair hiring, promotion, and compensation opportunities to people from historically underrepresented communities, and strive to create a company culture where all employees feel they can bring their authentic selves to work and be successful. Our DEI strategy focuses on three core areas of our business and culture: Our Company: Build a diverse company that provides equitable access to growth and success for all employees globally. Our Culture: Create an inclusive environment where authenticity thrives and people of all backgrounds feel like they belong. Our Communities: Expand our commitment to diversity, equity, & inclusion within and beyond our company walls to invest in future generations of underrepresented talent and bring innovation to our clients. Equal Opportunity Employer/Veterans/Disabled Rubrik is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, or protected veteran status and will not be discriminated against on the basis of disability. Rubrik provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability or genetics. In addition to federal law requirements, Rubrik complies with applicable state and local laws governing nondiscrimination in employment in every location in which the company has facilities. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training. Federal law requires employers to provide reasonable accommodation to qualified individuals with disabilities. Please contact us at hr@rubrik.com if you require a reasonable accommodation to apply for a job or to perform your job. Examples of reasonable accommodation include making a change to the application process or work procedures, providing documents in an alternate format, using a sign language interpreter, or using specialized equipment.</td></tr><tr><td>A large, technologically leading organization in Jerusalem needs a data scientist! Work in a hybrid multi-tasking format! Job description: A data scientist and data scientist will play an important role in the Big Data department and will be responsible for a series of activities that will enable data research on the office's databases and organizations that work with the department. Implementing the Big Data department's data mining policy by working closely with data engineers who will perform the mining operations and even by performing these operations themselves in analysis tools defined in the Data Mining Act, such as SQL, PYTHON, Dataiku, and others. He will also be responsible for the quality assurance (QA) processes of the mining in the environment where the analyses and processing of the data were performed, or accompanied by a data engineer who will perform these operations. The systems used are SQL, PYTHON, DATAIKU, CLOUDERA, but are not limited to these. Requirements: 3 years or more of experience in data roles, including at least one year in data science (data roles: data analytics, data engineering, data science, BI development) Experience operating tabular mining tools (e.g. Privitar, Dataiku) - minimum one year of experience, minimum work on 30 tables Experience in mining in the healthcare field - mandatory. Experience in tabular data mining is mandatory. ⁠Free text mining - mandatory. Free text mining in Hebrew - Significant advantage. Experience working on Tama with researchers in academia - an advantage</td><td>3 years or more of experience in data roles, including at least one year in data science (data roles: data analytics, data engineering, data science, BI development) Experience operating tabular mining tools (e.g. Privitar, Dataiku) - minimum one year of experience, minimum work on 30 tables Experience in mining in the healthcare field - mandatory. Experience in tabular data mining is mandatory. ⁠Free text mining - mandatory. Free text mining in Hebrew - Significant advantage. Experience working on Tama with researchers in academia - an advantage</td></tr><tr><td>jb-19 Job Number: With experience in Data Scientist Need a Development Person Evaluating state of art statistical modeling and machine Learning. Big data analysis, Modeling and Reporting. Job Requirements:Requirements: A minimum first degree in computer science/ applied math/ statistics. Strong algorithm development skills. Proven experience with machine learning algorithms – both supervised and unsupervised. Proven experience with optimization algorithms. 5+ years of relevant experience with one of the following: Python, R, Matlab. Strong communication skills, creative, results driven, quick learner. Experience with big data, distributed processing, NoSQL databases – a significant advantage. Your Name Job Number (Required) Upload Resume Share the job and let your friends help</td><td>Requirements: A minimum first degree in computer science/ applied math/ statistics. Strong algorithm development skills. Proven experience with machine learning algorithms – both supervised and unsupervised. Proven experience with optimization algorithms. 5+ years of relevant experience with one of the following: Python, R, Matlab. Strong communication skills, creative, results driven, quick learner. Experience with big data, distributed processing, NoSQL databases – a significant advantage. Your Name Job Number (Required) Upload Resume Share the job and let your friends help</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "Summary Posted: Nov 7, 2024 Role Number: 200577967 We're looking for an exceptional data analyst with a strong background in distributed data processing and a demonstrated ability to turn data into actionable insights. As a data analyst for our Storage Data Analytics team at Apple, you'll play a crucial role in developing the fastest and most efficient SSDs for our products, including the iPhone, iPad, Apple Watch, and new Apple Silicon Macs. If you're passionate about continuously improving the ways we use data to make Apple's products amazing, we want to hear from you! Description On the Storage Data Analytics team, we are responsible for performing ad hoc data analysis, development and maintenance of distributed data pipelines, as well as creation and support of analysis tools. Our team focuses on Apple’s storage solutions. It is small and nimble, able to quickly explore ideas and present them to the storage teams and to leadership. Minimum Qualifications +3 years of experience Ability to lead data investigations and analysis projects with ambiguous requirements Advanced statistic and modeling knowledge Experience visualizing and presenting analyses in tools like Jupyter and Tableau Experience programming in Python in a professional setting Familiarity with distributed computation, storage, and workflow management (e.g. Splunk, Spark, Kubernetes, Kafka, Hadoop, MapReduce, AirFlow etc.) Experience with relational databases and SQL Highly organized, creative, motivated, and passionate about achieving results Curious and have excellent analytical and problem solving skills Excellent written, verbal, and data communication skills Bachelor's or Master's degree in computer science. Preferred Qualifications Familiarity with distributed computation, storage, and workflow management (e.g. Splunk, Spark, Kubernetes, Kafka, Hadoop, MapReduce, AirFlow etc.)",
         "+3 years of experience Ability to lead data investigations and analysis projects with ambiguous requirements Advanced statistic and modeling knowledge Experience visualizing and presenting analyses in tools like Jupyter and Tableau Experience programming in Python in a professional setting Familiarity with distributed computation, storage, and workflow management (e.g. Splunk, Spark, Kubernetes, Kafka, Hadoop, MapReduce, AirFlow etc.) Experience with relational databases and SQL Highly organized, creative, motivated, and passionate about achieving results Curious and have excellent analytical and problem solving skills Excellent written, verbal, and data communication skills Bachelor's or Master's degree in computer science. Preferred Qualifications Familiarity with distributed computation, storage, and workflow management (e.g. Splunk, Spark, Kubernetes, Kafka, Hadoop, MapReduce, AirFlow etc.)"
        ],
        [
         "Israel, Hod HaSharon Description About ThetaRay: ThetaRay is a trailblazer in AI-powered Anti-Money Laundering (AML) solutions, offering cutting-edge technology to fintechs, banks, and regulatory bodies worldwide. Our mission is to enhance trust in financial transactions, ensuring compliant and innovative business growth. Our technology empowers customers to expand into new markets and introduce groundbreaking products. Thetaray is a culture-driven company. Our values are at the heart of our success. By joining us, you'll have the opportunity to embody these values and inspire others through your actions. Why Join ThetaRay? At ThetaRay, you'll be part of a dynamic global team committed to redefining the financial services sector through technological innovation. You will contribute to creating safer financial environments and have the opportunity to work with some of the brightest minds in AI, ML, and financial technology. We offer a collaborative, inclusive, and forward-thinking work environment where your ideas and contributions are valued and encouraged. Join us in our mission to revolutionize the financial world, making it safer and more trustworthy for millions worldwide. Explore exciting career opportunities at ThetaRay – where innovation meets purpose. We are seeking a skilled Junior Backend Big Data Developer to join our global R&D department. About the position Design and develop a scalable data processing and ML pipeline using the latest big data technologies in a fast paced agile environment Investigate new technological areas and understand them in depth through rapid self-learning Demonstrates strong analytical problem-solving skills to support scalable and sustainable design solutions Ability to take ownership of product development including all life cycle stages: translating product requirements into actionable designs and tasks, development, UT, and production troubleshooting Requirements 1-2 years of experience of hands-on development experience Experience developing data-oriented products preferably using Python/Java Experience in data processing FW such as Spark, Pandas, Hadoop, Airflow Experience in Distributed Databases (Such as Elasticsearch, Mongo, Redis, etc) Experience with developing microservices-based architecture Experience working in container-based environments using tools such as K8s, helm Experience working as a software developer in an Agile environment Nice to have: Experience in machine learning FWs such as SKLearn, Tensorflow Experience with RedHat OpenShift Dev Environment knowledge: GIT, Jenkins, Docker",
         "into actionable designs and tasks, development, UT, and production troubleshooting Requirements 1-2 years of experience of hands-on development experience Experience developing data-oriented products preferably using Python/Java Experience in data processing FW such as Spark, Pandas, Hadoop, Airflow Experience in Distributed Databases (Such as Elasticsearch, Mongo, Redis, etc) Experience with developing microservices-based architecture Experience working in container-based environments using tools such as K8s, helm Experience working as a software developer in an Agile environment Nice to have: Experience in machine learning FWs such as SKLearn, Tensorflow Experience with RedHat OpenShift Dev Environment knowledge: GIT, Jenkins, Docker"
        ],
        [
         "Description: Prisma-Photonics is a rapidly growing startup company, developing the next-generation smart-infrastructure solution based on novel fiber-sensing technology (smart roads, smart cities, perimeters, grid monitoring, etc.). The company offers an award-winning disruptive solution – a “sensor free” approach to smart infrastructure. The company is VC backed and is in the revenues stage. Combining pioneering technology in optical fiber sensing with state-of-the-art machine learning, we help prevent environmental disasters, protect human lives, and keep critical energy and transportation backbones running smoothly. We are rapidly growing, looking for the best minds and spirits to join us in our journey. We know our products are only as great as the individuals building the hardware and software and harnessing data for good causes! Being a great team member means being eager to learn and grow, able to challenge others while accepting being challenged yourself, and working for the team and product with enthusiasm and passion. We are seeking a detail-oriented and highly technical Data Annotator to join our Data Operations team. The role is full time, on an hourly pay, with the aim of adjusting work hours per need. In this role, you will be responsible for annotating various events on our distinct fiber sensing data, and managing datasets to support various products and projects. You will play a crucial part in ensuring the quality and integrity of our data, contributing to multiple critical initiatives. You will help improve our annotation procedures, techniques and tooling, and work closely with ML and Algo teams as well as Data Engineering. This is a unique opportunity to gain hands-on experience in data operations within a dynamic environment using cutting edge and novel technology. You will join a talented team dedicated to leveraging data for impactful projects. If you are passionate about data and eager to contribute to exciting challenges, this might be the perfect opportunity for you. Key Responsibilities: Data Annotation – Accurately annotate datasets using internal tools, adhering to annotation guidelines and maintaining high standards for consistency and quality.. Quality Assurance – Review and validate annotated data to ensure accuracy and consistency, identify discrepancies, and suggest solutions to improve processes. Continuous improvement – Participate in the continuous improvement of our tools and data operation processes to achieve more accurate models, and more streamlined data flow between the different teams in the company. Data Management – Support the ongoing maintenance of annotated datasets, ensuring data integrity and accessibility, and implementing best-practices to create seamless data flows Requirements: A Bachelor of Science degree or equivalent (STEM fields an advantage). Strong attention to detail and a commitment to maintaining high-quality annotation standards. Good written and verbal skills, with the ability to work effectively with a diverse group of individuals. Availability to work full time when needed. Nice-to-haves: Familiarity with data annotation processes, especially non-structured data (images, video, audio). Experience working with seismic data, heat maps, or spectrograms Familiarity with SQL and data visualization tools. Experience with coding languages, preferably MATLAB and Python.",
         "A Bachelor of Science degree or equivalent (STEM fields an advantage). Strong attention to detail and a commitment to maintaining high-quality annotation standards. Good written and verbal skills, with the ability to work effectively with a diverse group of individuals. Availability to work full time when needed. Nice-to-haves: Familiarity with data annotation processes, especially non-structured data (images, video, audio). Experience working with seismic data, heat maps, or spectrograms Familiarity with SQL and data visualization tools. Experience with coding languages, preferably MATLAB and Python."
        ],
        [
         "The Business Performance department at Plarium is in charge of all the analytical aspects of our game operations and strategic planning: From game design, to user acquisition, player behavior, live-ops, and game optimization (such as monetization, retention, etc). We are looking for a data analyst for our Marketing Analytics team. The scope of responsibility of this team includes budget optimization for user acquisition for our games at the scope of tens of million dollars per game, analyses of game profitability and long term potential, analysis of the players behavior, player game funnel and reaction to new game features and offers, and a lot more. Our goal is making sure Plarium brings the best and most relevant players to its games in the most efficient and effective way. Responsibilities Be a focal point for anything related to new players performance and KPIs across our range of games, strategic planning, user segmentation, tests and growth opportunities identification Daily support of ongoing analytical needs of the marketing department managers & teams Establish and monitor success metrics that measure and explain the impact of the marketing activities Design and initiate new features and reports to monitor & give insights on the marketing activity, using the marketing in-house BI system (for example, LTV, ROI forecasting, automatic rules) Run ad-hoc and in-depth analyses of the different Marketing activities and trends Support decision making based on data Collaborate with the game analysis team and the game studios to monitor and optimize our players experience, maximizing their retention in our games What we expect B.A/BSc in a highly quantitative field such as mathematics industrial engineering economics statistics or equivalent academic knowledge At least 2 years of hands-on data analysis and story-telling experience Proven experience with measuring online success and identifying optimization opportunities Excellent understanding of online marketing metrics High proficiency in SQL with demonstrated experience in querying large complex datasets Strong Excel / Google Sheets skills Experience with data visualization tools such as Qlik Sense and Looker A solid grasp of statistical significance models and tools Desired Marketing metrics of user funnel, user acquisition KPI’s What we offer A Workplace Designed for Your Well-Being - Comfortable Environment: Ergonomic chairs and desks to support your health. Beautifully designed spaces that inspire creativity. - On-Site Amenities: Gym, yoga room, and music room for relaxation and rejuvenation. - Delicious Perks: 5-star breakfast to kickstart your day. Freshly made coffee, shakes, and afternoon salads by our in-house barista. - Health & Wellness: Full health insurance coverage for your peace of mind. - Growth Opportunities: Learning and training programs to enhance your personal and professional skills. - Vibrant Culture: Happy hours, team events, and plenty of opportunities to connect with colleagues. Join us and experience a workplace where your well-being, growth, and enjoyment come first!",
         "B.A/BSc in a highly quantitative field such as mathematics industrial engineering economics statistics or equivalent academic knowledge At least 2 years of hands-on data analysis and story-telling experience Proven experience with measuring online success and identifying optimization opportunities Excellent understanding of online marketing metrics High proficiency in SQL with demonstrated experience in querying large complex datasets Strong Excel / Google Sheets skills Experience with data visualization tools such as Qlik Sense and Looker A solid grasp of statistical significance models and tools Desired Marketing metrics of user funnel, user acquisition KPI’s What we offer A Workplace Designed for Your Well-Being - Comfortable Environment: Ergonomic chairs and desks to support your health. Beautifully designed spaces that inspire creativity. - On-Site Amenities: Gym, yoga room, and music room for relaxation and rejuvenation. - Delicious Perks: 5-star breakfast to kickstart your day. Freshly made coffee, shakes, and afternoon salads by our in-house barista. - Health & Wellness: Full health insurance coverage for your peace of mind. - Growth Opportunities: Learning and training programs to enhance your personal and professional skills. - Vibrant Culture: Happy hours, team events, and plenty of opportunities to connect with colleagues. Join us and experience a workplace where your well-being, growth, and enjoyment come first!"
        ],
        [
         "aiOla is a high-growth, product-led SaaS startup backed by $45 million in funding from premier investors such as New Era Capital Partners and Hamilton Lane. Our mission is to revolutionize efficiency, intelligence, collaboration, and safety in the industrial sector through our proprietary speech-powered AI technology. Our team spans the US and Israel, bringing together experts in Product, Data Science, Data Engineering, Analytics, Marketing, and Customer Success. At aiOla, we thrive on innovation, collaboration, and a commitment to excellence. We are seeking forward-thinking professionals passionate about pushing the limits of AI and making an impact. Role Overview: We are seeking a passionate and innovative Data Analyst to join our growing Analytics team. This is an exceptional opportunity for a detail-oriented professional to not only analyze data but also play a pivotal role in shaping and enhancing our cutting-edge AI models and products. As a Data Analyst at aiOla, you will dive into complex datasets, uncover actionable insights, and contribute directly to the improvement and monitoring of our proprietary AI technologies. If you thrive in a dynamic environment, this role is perfect for you! Requirements: B.Sc in Industrial Engineering, Data Analytics, Statistics, or a related field. Proficiency in Python, with a strong focus on libraries like Pandas for data manipulation. Solid knowledge of SQL for querying and managing large datasets. Experience with BI tools like Tableau to create dashboards and reports. Excellent communication skills, with fluency in English (written and verbal). 0-1 years of experience in a Data Analyst role- advantage Nice To have: Familiarity with Snowflake or AWS Athena. Experience with Web/App product analytics tools such as Mixpanel. Knowledge of Data Science concepts and metrics, including Speech AI, Large Language Models (LLMs), Natural Language Understanding (NLU), and Automatic Speech Recognition (ASR). Responsibilities: Extract, clean, and analyze data to uncover trends, patterns, and actionable insights. Provide recommendations based on data analysis to support business decisions and drive product improvements. Develop and maintain dashboards and reports using BI tools such as Tableau or other platforms. Optimize data workflows and pipelines using Python and SQL. Collaborate with cross-functional teams, including Product, Data Science, and Engineering, to support data-driven decision-making.",
         "B.Sc in Industrial Engineering, Data Analytics, Statistics, or a related field. Proficiency in Python, with a strong focus on libraries like Pandas for data manipulation. Solid knowledge of SQL for querying and managing large datasets. Experience with BI tools like Tableau to create dashboards and reports. Excellent communication skills, with fluency in English (written and verbal). 0-1 years of experience in a Data Analyst role- advantage Nice To have: Familiarity with Snowflake or AWS Athena. Experience with Web/App product analytics tools such as Mixpanel. Knowledge of Data Science concepts and metrics, including Speech AI, Large Language Models (LLMs), Natural Language Understanding (NLU), and Automatic Speech Recognition (ASR). Responsibilities: Extract, clean, and analyze data to uncover trends, patterns, and actionable insights. Provide recommendations based on data analysis to support business decisions and drive product improvements. Develop and maintain dashboards and reports using BI tools such as Tableau or other platforms. Optimize data workflows and pipelines using Python and SQL. Collaborate with cross-functional teams, including Product, Data Science, and Engineering, to support data-driven decision-making."
        ],
        [
         "As a Data Engineer at Meta, you will shape the future of people-facing and business-facing products we build across our entire family of applications (Facebook, Instagram, Messenger, WhatsApp, Reality Labs, Threads). Your technical skills and analytical mindset will be utilized designing and building some of the world's most extensive data sets, helping to craft experiences for billions of people and hundreds of millions of businesses worldwide.In this role, you will collaborate with software engineering, data science, and product management teams to design/build scalable data solutions across Meta to optimize growth, strategy, and user experience for our 3 billion plus users, as well as our internal employee community.You will be at the forefront of identifying and solving some of the most interesting data challenges at a scale few companies can match. By joining Meta, you will become part of a vibrant community dedicated to skill development and career growth in data engineering and beyond.Data Engineering: You will guide teams by building optimal data artifacts (including datasets and visualizations) to address key questions. You will refine our systems, design logging solutions, and create scalable data models. Ensuring data security and quality, and with a strong focus on efficiency, you will suggest architecture and development approaches and data management standards to address complex analytical problems.Product leadership: You will use data to shape product development, identify new opportunities, and tackle upcoming challenges. You'll ensure our products add value for users and businesses, by prioritizing projects, and driving innovative solutions to respond to challenges or opportunities.Communication and influence: You won't simply present data, but tell data-driven stories. You will convince and influence your partners using clear insights and recommendations. You will build credibility through structure and clarity, and be a trusted strategic partner. Data Engineer Responsibilities: Conceptualize and own the data architecture for multiple large-scale projects, while evaluating design and operational cost-benefit tradeoffs within systems Create and contribute to frameworks that improve the efficacy of logging data, while working with data infrastructure to triage issues and resolve Collaborate with engineers, product managers, and data scientists to understand data needs, representing key data insights in a meaningful way Define and manage Service Level Agreements for all data sets in allocated areas of ownership Determine and implement the security model based on privacy requirements, confirm safeguards are followed, address data quality issues, and evolve governance processes within allocated areas of ownership Design, build, and launch collections of sophisticated data models and visualizations that support multiple use cases across different products or domains Solve our most challenging data integration problems, utilizing optimal Extract, Transform, Load (ETL) patterns, frameworks, query techniques, sourcing from structured and unstructured data sources Assist in owning existing processes running in production, optimizing complex code through advanced algorithmic concepts Optimize pipelines, dashboards, frameworks, and systems to facilitate easier development of data artifacts Influence product and cross-functional teams to identify data opportunities to drive impact Mentor team members by giving/receiving actionable feedback Minimum Qualifications: Bachelor's degree in Computer Science, Engineering, relevant technical field, or equivalent 4+ years of experience where the primary responsibility involves working with data. This could include roles such as data analyst, data scientist, data engineer, or similar positions 4+ years of experience (or a minimum of 2+ years with a Ph.D) with SQL, ETL, data modeling, and at least one programming language (e.g., Python, C++, C#, Scala, etc.) About Meta: Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today—beyond the constraints of screens, the limits of distance, and even the rules of physics. Individual compensation is determined by skills, qualifications, experience, and location. Compensation details listed in this posting reflect the base hourly rate, monthly rate, or annual salary only, and do not include bonus, equity or sales incentives, if applicable. In addition to base compensation, Meta offers benefits. Learn more about benefits at Meta.",
         "Bachelor's degree in Computer Science, Engineering, relevant technical field, or equivalent 4+ years of experience where the primary responsibility involves working with data. This could include roles such as data analyst, data scientist, data engineer, or similar positions 4+ years of experience (or a minimum of 2+ years with a Ph.D) with SQL, ETL, data modeling, and at least one programming language (e.g., Python, C++, C#, Scala, etc.) About Meta: Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today—beyond the constraints of screens, the limits of distance, and even the rules of physics. Individual compensation is determined by skills, qualifications, experience, and location. Compensation details listed in this posting reflect the base hourly rate, monthly rate, or annual salary only, and do not include bonus, equity or sales incentives, if applicable. In addition to base compensation, Meta offers benefits. Learn more about benefits at Meta."
        ],
        [
         "At Aquant, we empower field service professionals to become heroes using our personalized generative AI platform, Service Co-Pilot. Using historical service data, Aquant equips service leaders, field technicians, and customer service representatives with the precise information they need when they need it—enabling them to make decisions with confidence, reduce costs, and optimize service delivery. Recognized as one of Fast Company's Next Big Things in Tech of 2024 , we are committed to providing cutting-edge AI solutions that tackle the most pressing challenges in manufacturing. Ready to join a team that values innovation, excellence, and above all, its people? Apply today! Aquant's Data Analytics team is looking for a highly skilled Data Engineer who is comfortable with big data and complex data models. As a member of our Data Engineering team, you will: Work with large amounts of data and develop Python code to streamline processes Analyze different data structures and create the required reports out of them Collaborate \\ connect to existing codes Build tools to track data quality on large DB with complicated schemas Monitor the integrity and validity of the customer service data Deep dive into the service data and learn the service world Required skills & background: 2-3 years experience with big datasets BA/B.Sc. in industrial/information systems engineering, statistics or equivalent Hands-on experience with Excel + SQL - must Hands-on experience with Python – must Experience with Azure services - advantage A team player, with excellent collaboration skills Excellent communicator with the ability to deliver high-quality results Fluent English It's not enough to have a cool product, join us because you share our values: These guiding values inspire every Aquant employee. They are how we operate and enable our company as a whole to have a greater impact and achieve our vision: Be Humble and Respectful: We are one team, where collective success is more important than individual ego. Treat your colleagues with respect and empathy, act with good intent, and value everyone's contributions. Be Curious: Keep learning, and asking questions to understand complex situations. Embrace new challenges. Keep an open mind, and be receptive to feedback. Take Ownership: Focus on achieving measurable and meaningful outcomes. Take decisive action, solve problems proactively, and take ownership of projects and results. Act with Integrity: Act with Integrity. Do great things while doing the right thing for your customers and colleagues. Some of our benefits: Vacation your way: We want to make sure you have time to meet your personal needs with generous PTO and flexible vacation planning. Everyone is an owner: We want everyone to feel ownership over their work and what we are building here, which is why we offer equity to full-time employees. Build your career: Every Aquant employee is in control of their career development with our learning stipends, tools, and training. Applicants must be authorized to work for any employer in the Israel. We are unable to sponsor or take over sponsorship of an employment Visa at this time. Aquant is committed to hiring a diverse and talented workforce.",
         "2-3 years experience with big datasets BA/B.Sc. in industrial/information systems engineering, statistics or equivalent Hands-on experience with Excel + SQL - must Hands-on experience with Python – must Experience with Azure services - advantage A team player, with excellent collaboration skills Excellent communicator with the ability to deliver high-quality results Fluent English It's not enough to have a cool product, join us because you share our values: These guiding values inspire every Aquant employee. They are how we operate and enable our company as a whole to have a greater impact and achieve our vision: Be Humble and Respectful: We are one team, where collective success is more important than individual ego. Treat your colleagues with respect and empathy, act with good intent, and value everyone's contributions. Be Curious: Keep learning, and asking questions to understand complex situations. Embrace new challenges. Keep an open mind, and be receptive to feedback. Take Ownership: Focus on achieving measurable and meaningful outcomes. Take decisive action, solve problems proactively, and take ownership of projects and results. Act with Integrity: Act with Integrity. Do great things while doing the right thing for your customers and colleagues. Some of our benefits: Vacation your way: We want to make sure you have time to meet your personal needs with generous PTO and flexible vacation planning. Everyone is an owner: We want everyone to feel ownership over their work and what we are building here, which is why we offer equity to full-time employees. Build your career: Every Aquant employee is in control of their career development with our learning stipends, tools, and training. Applicants must be authorized to work for any employer in the Israel. We are unable to sponsor or take over sponsorship of an employment Visa at this time. Aquant is committed to hiring a diverse and talented workforce."
        ],
        [
         "About Team & About Role: Rubrik is seeking a Data Scientist to join our Data Research team, part of the Security Apps organization responsible for developing Rubrik’s suite of security products. This is the first data scientist position on the team, requiring a high degree of independence and ownership. You’ll spearhead research and development of ML/AI models that power the features of our security offerings. What You’ll Do: Research and develop ML/AI models in the NLP domain Develop advanced anomaly detection models for threat detection Work closely with data analysts on research, pattern analysis, etc. Work closely with developers on implementation of models as part of features in the product Work with global teams to continuously push our ML infrastructure forward Experience You’ll Need: Bachelor’s degree in Mathematics, Computer Science, or other related field 3 years of experience in data science or a related field Proficiency in programming languages, especially Python Experience with common data science toolkits, such as Jupyter Notebook, Pandas, NumPy, Matplotlib, etc. Demonstrated experience in implementing ML algorithms in production environments, with a focus on anomaly detection and natural language processing. Strong problem-solving skills and analytic capability to develop insights and recommendations Excellent communication skills in Hebrew and English Preferred Qualifications: Master’s degree in Mathematics, Computer Science, or other related field Familiarity with cloud platforms such as AWS, Google Cloud, or Azure Experience working with LLMs Previous experience in the security industry Join Us in Securing the World's Data Rubrik (NYSE: RBRK) is on a mission to secure the world’s data. With Zero Trust Data Security™, we help organizations achieve business resilience against cyberattacks, malicious insiders, and operational disruptions. Rubrik Security Cloud, powered by machine learning, secures data across enterprise, cloud, and SaaS applications. We help organizations uphold data integrity, deliver data availability that withstands adverse conditions, continuously monitor data risks and threats, and restore businesses with their data when infrastructure is attacked. Linkedin | X (formerly Twitter) | Instagram | Rubrik.com Diversity, Equity & Inclusion @ Rubrik At Rubrik we are committed to building and sustaining a culture where people of all backgrounds are valued, know they belong, and believe they can succeed here. Rubrik's goal is to hire and promote the best person for the job, no matter their background. In doing so, Rubrik is committed to correcting systemic processes and cultural norms that have prevented equal representation. This means we review our current efforts with the intent to offer fair hiring, promotion, and compensation opportunities to people from historically underrepresented communities, and strive to create a company culture where all employees feel they can bring their authentic selves to work and be successful. Our DEI strategy focuses on three core areas of our business and culture: Our Company: Build a diverse company that provides equitable access to growth and success for all employees globally. Our Culture: Create an inclusive environment where authenticity thrives and people of all backgrounds feel like they belong. Our Communities: Expand our commitment to diversity, equity, & inclusion within and beyond our company walls to invest in future generations of underrepresented talent and bring innovation to our clients. Equal Opportunity Employer/Veterans/Disabled Rubrik is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, or protected veteran status and will not be discriminated against on the basis of disability. Rubrik provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability or genetics. In addition to federal law requirements, Rubrik complies with applicable state and local laws governing nondiscrimination in employment in every location in which the company has facilities. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training. Federal law requires employers to provide reasonable accommodation to qualified individuals with disabilities. Please contact us at hr@rubrik.com if you require a reasonable accommodation to apply for a job or to perform your job. Examples of reasonable accommodation include making a change to the application process or work procedures, providing documents in an alternate format, using a sign language interpreter, or using specialized equipment.",
         "Master’s degree in Mathematics, Computer Science, or other related field Familiarity with cloud platforms such as AWS, Google Cloud, or Azure Experience working with LLMs Previous experience in the security industry Join Us in Securing the World's Data Rubrik (NYSE: RBRK) is on a mission to secure the world’s data. With Zero Trust Data Security™, we help organizations achieve business resilience against cyberattacks, malicious insiders, and operational disruptions. Rubrik Security Cloud, powered by machine learning, secures data across enterprise, cloud, and SaaS applications. We help organizations uphold data integrity, deliver data availability that withstands adverse conditions, continuously monitor data risks and threats, and restore businesses with their data when infrastructure is attacked. Linkedin | X (formerly Twitter) | Instagram | Rubrik.com Diversity, Equity & Inclusion @ Rubrik At Rubrik we are committed to building and sustaining a culture where people of all backgrounds are valued, know they belong, and believe they can succeed here. Rubrik's goal is to hire and promote the best person for the job, no matter their background. In doing so, Rubrik is committed to correcting systemic processes and cultural norms that have prevented equal representation. This means we review our current efforts with the intent to offer fair hiring, promotion, and compensation opportunities to people from historically underrepresented communities, and strive to create a company culture where all employees feel they can bring their authentic selves to work and be successful. Our DEI strategy focuses on three core areas of our business and culture: Our Company: Build a diverse company that provides equitable access to growth and success for all employees globally. Our Culture: Create an inclusive environment where authenticity thrives and people of all backgrounds feel like they belong. Our Communities: Expand our commitment to diversity, equity, & inclusion within and beyond our company walls to invest in future generations of underrepresented talent and bring innovation to our clients. Equal Opportunity Employer/Veterans/Disabled Rubrik is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, or protected veteran status and will not be discriminated against on the basis of disability. Rubrik provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability or genetics. In addition to federal law requirements, Rubrik complies with applicable state and local laws governing nondiscrimination in employment in every location in which the company has facilities. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training. Federal law requires employers to provide reasonable accommodation to qualified individuals with disabilities. Please contact us at hr@rubrik.com if you require a reasonable accommodation to apply for a job or to perform your job. Examples of reasonable accommodation include making a change to the application process or work procedures, providing documents in an alternate format, using a sign language interpreter, or using specialized equipment."
        ],
        [
         "A large, technologically leading organization in Jerusalem needs a data scientist! Work in a hybrid multi-tasking format! Job description: A data scientist and data scientist will play an important role in the Big Data department and will be responsible for a series of activities that will enable data research on the office's databases and organizations that work with the department. Implementing the Big Data department's data mining policy by working closely with data engineers who will perform the mining operations and even by performing these operations themselves in analysis tools defined in the Data Mining Act, such as SQL, PYTHON, Dataiku, and others. He will also be responsible for the quality assurance (QA) processes of the mining in the environment where the analyses and processing of the data were performed, or accompanied by a data engineer who will perform these operations. The systems used are SQL, PYTHON, DATAIKU, CLOUDERA, but are not limited to these. Requirements: 3 years or more of experience in data roles, including at least one year in data science (data roles: data analytics, data engineering, data science, BI development) Experience operating tabular mining tools (e.g. Privitar, Dataiku) - minimum one year of experience, minimum work on 30 tables Experience in mining in the healthcare field - mandatory. Experience in tabular data mining is mandatory. ⁠Free text mining - mandatory. Free text mining in Hebrew - Significant advantage. Experience working on Tama with researchers in academia - an advantage",
         "3 years or more of experience in data roles, including at least one year in data science (data roles: data analytics, data engineering, data science, BI development) Experience operating tabular mining tools (e.g. Privitar, Dataiku) - minimum one year of experience, minimum work on 30 tables Experience in mining in the healthcare field - mandatory. Experience in tabular data mining is mandatory. ⁠Free text mining - mandatory. Free text mining in Hebrew - Significant advantage. Experience working on Tama with researchers in academia - an advantage"
        ],
        [
         "jb-19 Job Number: With experience in Data Scientist Need a Development Person Evaluating state of art statistical modeling and machine Learning. Big data analysis, Modeling and Reporting. Job Requirements:Requirements: A minimum first degree in computer science/ applied math/ statistics. Strong algorithm development skills. Proven experience with machine learning algorithms – both supervised and unsupervised. Proven experience with optimization algorithms. 5+ years of relevant experience with one of the following: Python, R, Matlab. Strong communication skills, creative, results driven, quick learner. Experience with big data, distributed processing, NoSQL databases – a significant advantage. Your Name Job Number (Required) Upload Resume Share the job and let your friends help",
         "Requirements: A minimum first degree in computer science/ applied math/ statistics. Strong algorithm development skills. Proven experience with machine learning algorithms – both supervised and unsupervised. Proven experience with optimization algorithms. 5+ years of relevant experience with one of the following: Python, R, Matlab. Strong communication skills, creative, results driven, quick learner. Experience with big data, distributed processing, NoSQL databases – a significant advantage. Your Name Job Number (Required) Upload Resume Share the job and let your friends help"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "Description_English",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Requirements_Text",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Filter out descriptions without clear requirements to extract\n",
    "requirements_df = requirements_df.filter(col(\"Requirements_Text\").isNotNull() & (col(\"Requirements_Text\") != \"\"))\n",
    "print(requirements_df.count())\n",
    "requirements_df.select(\"Description_English\", \"Requirements_Text\").limit(10).display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6baf0dd0-7108-4150-a0ea-fe3e3620486d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Title</th><th>Company</th><th>Full Job Description</th><th>Search Word</th><th>Description</th><th>Description_English</th><th>Requirements_Text</th><th>Token_Count</th></tr></thead><tbody><tr><td>null</td><td>events and celebrations</td><td>Job Description Data Scientist (GenAI) We're hiring an exceptional Data Scientist to join our growing team of data science & AI experts! In this role, you’ll have the opportunity to design and deploy end-to-end AIML solutions that push the boundaries of financial technology, using advanced techniques in Generative AI, NLP, and predictive modeling. You’ll tackle complex business challenges, automate manual processes and help Tipalti maintain its edge in driving innovation across the fintech landscape. The ideal candidate is a problem solver with a strong technical background who thrives on transforming complex business challenges into scalable AIML solutions. Why join Tipalti Tipalti is one of the world’s fastest-growing fintech companies. We free finance professionals to lead by modernizing the entire payables operation. We are a well-funded, late-stage start-up backed by high-profile investors. Our 2021 Series F funding round raised $270 million, valuing us at over $8.3 billion. With total funding of just over $550 million, and with more than 4000 global customers, Tipalti is one of the most valuable private fintech companies in the world. At Tipalti, we pride ourselves on our collaborative culture, the quality of our product and the capabilities of our people. Tipaltians are passionate about the work they do, and keen to get the job done. Tipalti oﬀers competitive benefits, a flexible workplace, career coaching, and an environment where diverse individuals can thrive and make an impact. Our culture ensures everyone checks their egos at the door and stands ready to reach for success together. Founded in Israel in 2010, Tipalti is a global business headquartered in the San Francisco Bay Area (Foster City) with offices in Tel Aviv, Plano, Toronto, Vancouver, London, Amsterdam and Tbilisi. In This Role, You Will Be Responsible For End-to-End Solution Development Designing, developing, and deploying robust AIML solutions that address key challenges in the fintech space, from data preprocessing through production deployment. Gen AI & NLP Applications Building and fine-tuning generative AI models for innovative applications, including LLMs for text generation, summarization, categorization and document processing. Applying NLP techniques to analyze unstructured data, uncover insights, and enable capabilities like sentiment analysis, entity recognition, and text classification. Predictive Modeling Creating predictive models that forecast critical business outcomes, identify trends, and provide actionable insights to optimize decision-making. Model Deployment and Optimization Implementing best practices for model deployment, monitoring, and continuous improvement to ensure high performance and scalability of AI solutions in production. Cross-Functional Collaboration Partnering with key stakeholders across departments to understand business requirements, align on objectives, and deliver impactful solutions. About You Bachelor’s degree in Computer Science, Engineering, Mathematics, Physics, Statistics or a related field, with focus on AIML. 3+ years of hands-on experience in data science or AI engineering, ideally within the fintech industry or a related sector, with a track record of deploying impactful AIML solutions. Strong technical skills Proficiency in Python and SQL for data manipulation, analysis, and model building. Deep experience with LLMs and prompt engineering, including systematic evaluation of enterprise AI solutions Experience with building RAG systems and Conversational chatbots - Advantage Strong experience with machine learning libraries such as TensorFlow, PyTorch, or scikit-learn. Experience with cloud platforms (AWS, GCP, or Azure) for model deployment and MLOps practices. Analytical Mindset You’re adept at statistical analysis, understand key machine learning algorithms, and can evaluate models with a critical eye. Project Management You can manage and prioritize multiple tasks, balancing short-term and long-term goals to deliver timely, high-impact results. Our tech teams are the engine behind our business. Tipalti’s tech ecosystem is extremely rich and we continually add new features to our products, ensuring that we respond to our clients’ needs at scale. Our tech teams retain a fast-paced, start-up vibe that encourages innovation and critical thinking. At Tipalti, you’ll have the opportunity to work with a diverse, global team of engineers, developers and product leaders who are collectively building the future of our best-in-class product suite as we transform financial operations for the future. Interested in learning more about us Tipalti is the only company handling both global partner payments and accounts payable workflows for high-velocity companies across the entire financial operations cycle onboarding and managing global suppliers, instituting procurement controls, streamlining invoice processing and approvals, executing payments around the world, and reconciling payables data across a multi-subsidiary finance organization. Tipalti enables companies to scale quickly by making payables strategic with operational, compliance, and financial controls. Through Tipalti, our clients can efficiently and securely pay thousands of partners and suppliers in 196 countries within minutes. Tipalti is fueled by a commitment to our customers and a desire to build lasting connections. Our client portfolio includes high-velocity businesses such as Amazon Twitch, GoDaddy, Roku, WordPress.com, and ZipRecruiter. We work hard for our 98% customer retention rate which is built on trust, reliability and innovation. Tipalti means we handled it - a mission to which we are constantly committed. #LI-AA1 #LI-hybrid Interested in learning more about us Tipalti is the only company handling both global partner payments and accounts payable workflows for high-velocity companies across the entire financial operations cycle onboarding and managing global suppliers, instituting procurement controls, streamlining invoice processing and approvals, executing payments around the world, and reconciling payables data across a multi-subsidiary finance organization. Tipalti enables companies to scale quickly by making payables strategic with operational, compliance, and financial controls. Through Tipalti, our clients can efficiently and securely pay thousands of partners and suppliers in 196 countries within minutes. Tipalti is fueled by a commitment to our customers and a desire to build lasting connections. Our client portfolio includes high-velocity businesses such as Amazon Twitch, GoDaddy, Roku, WordPress.com, and ZipRecruiter. We work hard for our 98% customer retention rate which is built on trust, reliability and innovation. Tipalti means we handled it - a mission to which we are constantly committed. Accommodations Tipalti champions inclusive teams, in which every voice counts. We are committed to recruiting diverse candidates with varied personal experiences and abilities. We welcome applications from candidates belonging to historically underrepresented or disadvantaged groups, and maintain an equitable Talent Acquisition process that is free from discrimination. As an equal opportunities employer, Tipalti complies with employment and human rights laws across the various jurisdictions in which we operate. Should you require reasonable adjustments or accommodations during the recruitment process, including access to alternate formats of materials, meeting spaces, or other accommodations that could better enable your full participation, please reach out to hr@tipalti.com for assistance. Privacy We are committed to protecting the privacy interests of job applicants and candidates. For more information about our privacy practices during our Talent Acquisition process, please refer to our Job Candidate Privacy Notice below Opened URL httpsil.indeed.comrcclkjk=2f56ea143e968cf4&bb=zk7LYUIixjhkbKO7XrB0tlDEjZfP-jhN3oJXLsQv5a7cbHU5xos_zXSpDDtJtOGYPQlFPEKIl6j6alQiN500YEFPMZ1N2Y4PgeROuVHOyDIOMeYOs-kZhFFOCkHjDxMw&xkcb=SoDk67M33wfbB8xCCB0FbzkdCdPP&fccid=c26e6911bfdb0c15&vjs=3</td><td>ds</td><td>Job Description Data Scientist (GenAI) We're hiring an exceptional Data Scientist to join our growing team of data science & AI experts! In this role, you’ll have the opportunity to design and deploy end-to-end AIML solutions that push the boundaries of financial technology, using advanced techniques in Generative AI, NLP, and predictive modeling. You’ll tackle complex business challenges, automate manual processes and help Tipalti maintain its edge in driving innovation across the fintech landscape. The ideal candidate is a problem solver with a strong technical background who thrives on transforming complex business challenges into scalable AIML solutions. Why join Tipalti Tipalti is one of the world’s fastest-growing fintech companies. We free finance professionals to lead by modernizing the entire payables operation. We are a well-funded, late-stage start-up backed by high-profile investors. Our 2021 Series F funding round raised $270 million, valuing us at over $8.3 billion. With total funding of just over $550 million, and with more than 4000 global customers, Tipalti is one of the most valuable private fintech companies in the world. At Tipalti, we pride ourselves on our collaborative culture, the quality of our product and the capabilities of our people. Tipaltians are passionate about the work they do, and keen to get the job done. Tipalti oﬀers competitive benefits, a flexible workplace, career coaching, and an environment where diverse individuals can thrive and make an impact. Our culture ensures everyone checks their egos at the door and stands ready to reach for success together. Founded in Israel in 2010, Tipalti is a global business headquartered in the San Francisco Bay Area (Foster City) with offices in Tel Aviv, Plano, Toronto, Vancouver, London, Amsterdam and Tbilisi. In This Role, You Will Be Responsible For End-to-End Solution Development Designing, developing, and deploying robust AIML solutions that address key challenges in the fintech space, from data preprocessing through production deployment. Gen AI & NLP Applications Building and fine-tuning generative AI models for innovative applications, including LLMs for text generation, summarization, categorization and document processing. Applying NLP techniques to analyze unstructured data, uncover insights, and enable capabilities like sentiment analysis, entity recognition, and text classification. Predictive Modeling Creating predictive models that forecast critical business outcomes, identify trends, and provide actionable insights to optimize decision-making. Model Deployment and Optimization Implementing best practices for model deployment, monitoring, and continuous improvement to ensure high performance and scalability of AI solutions in production. Cross-Functional Collaboration Partnering with key stakeholders across departments to understand business requirements, align on objectives, and deliver impactful solutions. About You Bachelor’s degree in Computer Science, Engineering, Mathematics, Physics, Statistics or a related field, with focus on AIML. 3+ years of hands-on experience in data science or AI engineering, ideally within the fintech industry or a related sector, with a track record of deploying impactful AIML solutions. Strong technical skills Proficiency in Python and SQL for data manipulation, analysis, and model building. Deep experience with LLMs and prompt engineering, including systematic evaluation of enterprise AI solutions Experience with building RAG systems and Conversational chatbots - Advantage Strong experience with machine learning libraries such as TensorFlow, PyTorch, or scikit-learn. Experience with cloud platforms (AWS, GCP, or Azure) for model deployment and MLOps practices. Analytical Mindset You’re adept at statistical analysis, understand key machine learning algorithms, and can evaluate models with a critical eye. Project Management You can manage and prioritize multiple tasks, balancing short-term and long-term goals to deliver timely, high-impact results. Our tech teams are the engine behind our business. Tipalti’s tech ecosystem is extremely rich and we continually add new features to our products, ensuring that we respond to our clients’ needs at scale. Our tech teams retain a fast-paced, start-up vibe that encourages innovation and critical thinking. At Tipalti, you’ll have the opportunity to work with a diverse, global team of engineers, developers and product leaders who are collectively building the future of our best-in-class product suite as we transform financial operations for the future. Interested in learning more about us Tipalti is the only company handling both global partner payments and accounts payable workflows for high-velocity companies across the entire financial operations cycle onboarding and managing global suppliers, instituting procurement controls, streamlining invoice processing and approvals, executing payments around the world, and reconciling payables data across a multi-subsidiary finance organization. Tipalti enables companies to scale quickly by making payables strategic with operational, compliance, and financial controls. Through Tipalti, our clients can efficiently and securely pay thousands of partners and suppliers in 196 countries within minutes. Tipalti is fueled by a commitment to our customers and a desire to build lasting connections. Our client portfolio includes high-velocity businesses such as Amazon Twitch, GoDaddy, Roku, WordPress.com, and ZipRecruiter. We work hard for our 98% customer retention rate which is built on trust, reliability and innovation. Tipalti means we handled it - a mission to which we are constantly committed. #LI-AA1 #LI-hybrid Interested in learning more about us Tipalti is the only company handling both global partner payments and accounts payable workflows for high-velocity companies across the entire financial operations cycle onboarding and managing global suppliers, instituting procurement controls, streamlining invoice processing and approvals, executing payments around the world, and reconciling payables data across a multi-subsidiary finance organization. Tipalti enables companies to scale quickly by making payables strategic with operational, compliance, and financial controls. Through Tipalti, our clients can efficiently and securely pay thousands of partners and suppliers in 196 countries within minutes. Tipalti is fueled by a commitment to our customers and a desire to build lasting connections. Our client portfolio includes high-velocity businesses such as Amazon Twitch, GoDaddy, Roku, WordPress.com, and ZipRecruiter. We work hard for our 98% customer retention rate which is built on trust, reliability and innovation. Tipalti means we handled it - a mission to which we are constantly committed. Accommodations Tipalti champions inclusive teams, in which every voice counts. We are committed to recruiting diverse candidates with varied personal experiences and abilities. We welcome applications from candidates belonging to historically underrepresented or disadvantaged groups, and maintain an equitable Talent Acquisition process that is free from discrimination. As an equal opportunities employer, Tipalti complies with employment and human rights laws across the various jurisdictions in which we operate. Should you require reasonable adjustments or accommodations during the recruitment process, including access to alternate formats of materials, meeting spaces, or other accommodations that could better enable your full participation, please reach out to hr@tipalti.com for assistance. Privacy We are committed to protecting the privacy interests of job applicants and candidates. For more information about our privacy practices during our Talent Acquisition process, please refer to our Job Candidate Privacy Notice below</td><td>Job Description Data Scientist (GenAI) We're hiring an exceptional Data Scientist to join our growing team of data science & AI experts! In this role, you’ll have the opportunity to design and deploy end-to-end AIML solutions that push the boundaries of financial technology, using advanced techniques in Generative AI, NLP, and predictive modeling. You’ll tackle complex business challenges, automate manual processes and help Tipalti maintain its edge in driving innovation across the fintech landscape. The ideal candidate is a problem solver with a strong technical background who thrives on transforming complex business challenges into scalable AIML solutions. Why join Tipalti Tipalti is one of the world’s fastest-growing fintech companies. We free finance professionals to lead by modernizing the entire payables operation. We are a well-funded, late-stage start-up backed by high-profile investors. Our 2021 Series F funding round raised $270 million, valuing us at over $8.3 billion. With total funding of just over $550 million, and with more than 4000 global customers, Tipalti is one of the most valuable private fintech companies in the world. At Tipalti, we pride ourselves on our collaborative culture, the quality of our product and the capabilities of our people. Tipaltians are passionate about the work they do, and keen to get the job done. Tipalti oﬀers competitive benefits, a flexible workplace, career coaching, and an environment where diverse individuals can thrive and make an impact. Our culture ensures everyone checks their egos at the door and stands ready to reach for success together. Founded in Israel in 2010, Tipalti is a global business headquartered in the San Francisco Bay Area (Foster City) with offices in Tel Aviv, Plano, Toronto, Vancouver, London, Amsterdam and Tbilisi. In This Role, You Will Be Responsible For End-to-End Solution Development Designing, developing, and deploying robust AIML solutions that address key challenges in the fintech space, from data preprocessing through production deployment. Gen AI & NLP Applications Building and fine-tuning generative AI models for innovative applications, including LLMs for text generation, summarization, categorization and document processing. Applying NLP techniques to analyze unstructured data, uncover insights, and enable capabilities like sentiment analysis, entity recognition, and text classification. Predictive Modeling Creating predictive models that forecast critical business outcomes, identify trends, and provide actionable insights to optimize decision-making. Model Deployment and Optimization Implementing best practices for model deployment, monitoring, and continuous improvement to ensure high performance and scalability of AI solutions in production. Cross-Functional Collaboration Partnering with key stakeholders across departments to understand business requirements, align on objectives, and deliver impactful solutions. About You Bachelor’s degree in Computer Science, Engineering, Mathematics, Physics, Statistics or a related field, with focus on AIML. 3+ years of hands-on experience in data science or AI engineering, ideally within the fintech industry or a related sector, with a track record of deploying impactful AIML solutions. Strong technical skills Proficiency in Python and SQL for data manipulation, analysis, and model building. Deep experience with LLMs and prompt engineering, including systematic evaluation of enterprise AI solutions Experience with building RAG systems and Conversational chatbots - Advantage Strong experience with machine learning libraries such as TensorFlow, PyTorch, or scikit-learn. Experience with cloud platforms (AWS, GCP, or Azure) for model deployment and MLOps practices. Analytical Mindset You’re adept at statistical analysis, understand key machine learning algorithms, and can evaluate models with a critical eye. Project Management You can manage and prioritize multiple tasks, balancing short-term and long-term goals to deliver timely, high-impact results. Our tech teams are the engine behind our business. Tipalti’s tech ecosystem is extremely rich and we continually add new features to our products, ensuring that we respond to our clients’ needs at scale. Our tech teams retain a fast-paced, start-up vibe that encourages innovation and critical thinking. At Tipalti, you’ll have the opportunity to work with a diverse, global team of engineers, developers and product leaders who are collectively building the future of our best-in-class product suite as we transform financial operations for the future. Interested in learning more about us Tipalti is the only company handling both global partner payments and accounts payable workflows for high-velocity companies across the entire financial operations cycle onboarding and managing global suppliers, instituting procurement controls, streamlining invoice processing and approvals, executing payments around the world, and reconciling payables data across a multi-subsidiary finance organization. Tipalti enables companies to scale quickly by making payables strategic with operational, compliance, and financial controls. Through Tipalti, our clients can efficiently and securely pay thousands of partners and suppliers in 196 countries within minutes. Tipalti is fueled by a commitment to our customers and a desire to build lasting connections. Our client portfolio includes high-velocity businesses such as Amazon Twitch, GoDaddy, Roku, WordPress.com, and ZipRecruiter. We work hard for our 98% customer retention rate which is built on trust, reliability and innovation. Tipalti means we handled it - a mission to which we are constantly committed. #LI-AA1 #LI-hybrid Interested in learning more about us Tipalti is the only company handling both global partner payments and accounts payable workflows for high-velocity companies across the entire financial operations cycle onboarding and managing global suppliers, instituting procurement controls, streamlining invoice processing and approvals, executing payments around the world, and reconciling payables data across a multi-subsidiary finance organization. Tipalti enables companies to scale quickly by making payables strategic with operational, compliance, and financial controls. Through Tipalti, our clients can efficiently and securely pay thousands of partners and suppliers in 196 countries within minutes. Tipalti is fueled by a commitment to our customers and a desire to build lasting connections. Our client portfolio includes high-velocity businesses such as Amazon Twitch, GoDaddy, Roku, WordPress.com, and ZipRecruiter. We work hard for our 98% customer retention rate which is built on trust, reliability and innovation. Tipalti means we handled it - a mission to which we are constantly committed. Accommodations Tipalti champions inclusive teams, in which every voice counts. We are committed to recruiting diverse candidates with varied personal experiences and abilities. We welcome applications from candidates belonging to historically underrepresented or disadvantaged groups, and maintain an equitable Talent Acquisition process that is free from discrimination. As an equal opportunities employer, Tipalti complies with employment and human rights laws across the various jurisdictions in which we operate. Should you require reasonable adjustments or accommodations during the recruitment process, including access to alternate formats of materials, meeting spaces, or other accommodations that could better enable your full participation, please reach out to hr@tipalti.com for assistance. Privacy We are committed to protecting the privacy interests of job applicants and candidates. For more information about our privacy practices during our Talent Acquisition process, please refer to our Job Candidate Privacy Notice below</td><td>Bachelor’s degree in Computer Science, Engineering, Mathematics, Physics, Statistics or a related field, with focus on AIML. 3+ years of hands-on experience in data science or AI engineering, ideally within the fintech industry or a related sector, with a track record of deploying impactful AIML solutions. Strong technical skills Proficiency in Python and SQL for data manipulation, analysis, and model building. Deep experience with LLMs and prompt engineering, including systematic evaluation of enterprise AI solutions Experience with building RAG systems and Conversational chatbots - Advantage Strong experience with machine learning libraries such as TensorFlow, PyTorch, or scikit-learn. Experience with cloud platforms (AWS, GCP, or Azure) for model deployment and MLOps practices. Analytical Mindset You’re adept at statistical analysis, understand key machine learning algorithms, and can evaluate models with a critical eye. Project Management You can manage and prioritize multiple tasks, balancing short-term and long-term goals to deliver timely, high-impact results. Our tech teams are the engine behind our business. Tipalti’s tech ecosystem is extremely rich and we continually add new features to our products, ensuring that we respond to our clients’ needs at scale. Our tech teams retain a fast-paced, start-up vibe that encourages innovation and critical thinking. At Tipalti, you’ll have the opportunity to work with a diverse, global team of engineers, developers and product leaders who are collectively building the future of our best-in-class product suite as we transform financial operations for the future. Interested in learning more about us Tipalti is the only company handling both global partner payments and accounts payable workflows for high-velocity companies across the entire financial operations cycle onboarding and managing global suppliers, instituting procurement controls, streamlining invoice processing and approvals, executing payments around the world, and reconciling payables data across a multi-subsidiary finance organization. Tipalti enables companies to scale quickly by making payables strategic with operational, compliance, and financial controls. Through Tipalti, our clients can efficiently and securely pay thousands of partners and suppliers in 196 countries within minutes. Tipalti is fueled by a commitment to our customers and a desire to build lasting connections. Our client portfolio includes high-velocity businesses such as Amazon Twitch, GoDaddy, Roku, WordPress.com, and ZipRecruiter. We work hard for our 98% customer retention rate which is built on trust, reliability and innovation. Tipalti means we handled it - a mission to which we are constantly committed. #LI-AA1 #LI-hybrid Interested in learning more about us Tipalti is the only company handling both global partner payments and accounts payable workflows for high-velocity companies across the entire financial operations cycle onboarding and managing global suppliers, instituting procurement controls, streamlining invoice processing and approvals, executing payments around the world, and reconciling payables data across a multi-subsidiary finance organization. Tipalti enables companies to scale quickly by making payables strategic with operational, compliance, and financial controls. Through Tipalti, our clients can efficiently and securely pay thousands of partners and suppliers in 196 countries within minutes. Tipalti is fueled by a commitment to our customers and a desire to build lasting connections. Our client portfolio includes high-velocity businesses such as Amazon Twitch, GoDaddy, Roku, WordPress.com, and ZipRecruiter. We work hard for our 98% customer retention rate which is built on trust, reliability and innovation. Tipalti means we handled it - a mission to which we are constantly committed. Accommodations Tipalti champions inclusive teams, in which every voice counts. We are committed to recruiting diverse candidates with varied personal experiences and abilities. We welcome applications from candidates belonging to historically underrepresented or disadvantaged groups, and maintain an equitable Talent Acquisition process that is free from discrimination. As an equal opportunities employer, Tipalti complies with employment and human rights laws across the various jurisdictions in which we operate. Should you require reasonable adjustments or accommodations during the recruitment process, including access to alternate formats of materials, meeting spaces, or other accommodations that could better enable your full participation, please reach out to hr@tipalti.com for assistance. Privacy We are committed to protecting the privacy interests of job applicants and candidates. For more information about our privacy practices during our Talent Acquisition process, please refer to our Job Candidate Privacy Notice below</td><td>684</td></tr><tr><td>Data Engineer</td><td>The Helper Bees</td><td>Description: Join our winning team, recently honored as #67 on Forbes’ list of America’s Best Startup Employers for 2024! About The Helper Bees The Helper Bees’ mission is to help people stay home longer through data-driven services that transform both the payer and the care-recipient experience. At The Helper Bees, we are reshaping how care is delivered to aging individuals by leveraging innovative technology and insightful data solutions. We maintain multiple SaaS products and payment solutions through our web applications (internal and external facing), a mobile app, and reporting integrations. As part of our growing Data Engineering team, you’ll iterate quickly, have a high impact, and be challenged to design and implement cutting-edge solutions. At THB, we define our company culture through our Core Values: Quickly iterate through solutions: We move at a fast pace which requires quick iterations to find a path to a repeatable solution. Seek ways to create immediate impact: Be thoughtful and proactive in how you make an impact on your team. Actively look for ways to make a fast, positive impact. Bee the teammate you want to work with: We work as a team, help each other, and encourage each other. Ask questions, answer questions: You can't iterate through solutions if you don't ask the right questions, which is why there is an expectation that questions should be asked. When you know the answer, being a good teammate means chiming in to get others up to speed. Take the time to celebrate wins: It's so easy for a team that is heads down to forget about all the great things they've accomplished. That's why we make it a priority to remind ourselves to create space to celebrate wins, big or small. Job Summary We are seeking a motivated Data Engineer to join our team and help improve our tools, processes, and technical infrastructure. In this role, you will ensure the availability and quality of our data while contributing to the design, implementation, and maintenance of The Helper Bees’ products. You’ll collaborate across teams to create scalable and optimized software systems and play a key role in refining our development processes. This position offers a unique opportunity to learn and leverage cutting-edge AI development tools to enhance coding efficiency and develop advanced data tools and solutions. Supervisory Responsibilities: None Key Responsibilities Data Infrastructure: Design, implement, and maintain data pipelines, ensuring data availability, quality, and scalability. Product Development: Build and enhance products using Python, SQL, and modern technologies. AI Integration: Leverage cutting-edge AI tools, including Cursor, ChatGPT, and Claude to improve development processes, automate workflows, and create innovative data solutions. Collaboration: Communicate across departments to design, build, test, and implement new features and enhancements. Code Excellence: Produce quality, testable, and maintainable code while participating in code reviews. Problem Solving: Debug complex issues, interact with stakeholders, and design viable solutions with clear trade-offs. Process Optimization: Contribute to improving development processes, including deployment, on-call systems, and sprint planning. Team Growth: Collaborate within the development team to help each other grow and continuously learn. Stakeholder Engagement: Partner with analysts, scientists, and IT to ensure alignment and deliver data-driven solutions. Other duties as assigned/necessary Performance Metrics Code Quality: Maintain high coding standards through regular code reviews and adherence to best practices. Development Efficiency: Deliver high-quality features and fixes within efficient timeframes. Bug Resolution Time: Reduce the time taken to identify and resolve issues. System Scalability: Optimize system performance to handle increasing user demands. Collaboration: Foster a collaborative environment that encourages teamwork and knowledge sharing. Customer Satisfaction: Incorporate stakeholder feedback to improve solutions and enhance the customer experience. Continuous Learning: Pursue opportunities for skill development and share knowledge with the team. Requirements: Required Skills & Qualifications Technical Tools: Experience with in Python and/or SQL. Experience with Bash, Shell scripting, Big Query, Airflow, and is a plus. Programming: Cleaning data using code-based approach. AI Proficiency: Interest or experience in using AI tools for coding and development of data solutions. Soft Skills: Problem-solving, cross-team collaboration, data storytelling, and stakeholder engagement. Adaptability: Thrives in a fast-paced startup environment and embraces change. Proactivity: Self-directed, organized, and able to prioritize effectively. Collaboration: Ability to work effectively with cross-functional teams. Education & Experience: A bachelor’s degree is required, and a graduate degree is preferred. Relevant experience in data engineering, software development, STEM, or related fields. Strong experience with SQL and Python is highly desirable. Mindset: A passion for innovation, continuous improvement, and delivering high-quality results from messy data. Preferred Qualifications Familiarity with cloud-based solutions (e.g., Google Cloud Platform, Azure). Experience with ETL processes and tools. Experience building data visualization reports and dashboards Knowledge of modern data storage solutions and database management systems. Exposure to DevOps practices and tools for deployment and monitoring. Why Join Us? Work with a talented, collaborative team dedicated to making a difference. Gain exposure to innovative technologies and opportunities for growth. Learn and utilize cutting-edge AI tools to enhance your development skills and create impactful solutions. Be part of a company that values your contributions and encourages professional development. Join a rapidly expanding health-tech startup (~200 employees and growing) with a state-of-the-art technology office located in Hyde Park, offering a variety of exceptional benefits. Career Progression Timeline In 3 months: Gain a comprehensive understanding of our data infrastructure, technical stacks, and development cycles. Actively participate in team meetings and contribute to the development of new data pipelines. Begin leveraging AI tools, such as Cursor and ChatGPT, to enhance coding efficiency and workflow automation. In 6 months: Contribute to product enhancements and data reporting Collaborate effectively with cross-functional teams, providing insights and solutions for data-related challenges. Demonstrate proficiency in utilizing AI tools for coding and development, actively sharing knowledge with the team. In 12 months: Contribute to data engineering projects, ensuring scalability and performance optimization. Mentor non-technical internal partners to improve company-wide data literacy Contribute to the integration of advanced AI solutions into our development processes, contributing to the company's technological advancement. Physical Requirements: Ability to remain at your designated workstation for the duration of the workday Constantly operates a computer and other office productivity machinery, such as a phone and Voice over Internet Protocol (VoIP). The ability to communicate information and ideas so others will understand. Must be able to exchange accurate information in these situations. The ability to observe details at close range (typically on a computer screen) This position offers the flexibility of remote work at approved locations within the United States. Candidates must have a reliable internet connection and a designated work environment conducive to professional phone calls and sensitive data. Enjoy the convenience and comfort of working remotely while contributing to our team's success. Apply Today If you’re ready to take on challenging problems, contribute to impactful solutions, and grow as a data engineer, we’d love to hear from you. Join us at The Helper Bees and be part of a team that’s making a meaningful difference every day! The Helper Bees is committed to building a workplace where diversity, equity, and inclusion are valued and prioritized. We are an equal opportunity employer that welcomes all qualified applicants without discrimination based on race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or any non-merit based or legally protected grounds. The Helper Bees provides reasonable accommodations to qualified individuals with disabilities during the job application and interview process. To request accommodation, please let your recruiter know. As part of our standard hiring process, selected candidates may be required to undergo a background check and/or drug screen. The Helper Bees adheres to applicable federal, state, and local laws regarding these screenings, and the results will be considered in accordance with applicable regulations. The Helper Bees was recently made aware of a fraudulent entity posing as our organization and requesting personal information. Please be aware of and protect yourself from scams. Visit thehelperbees.com/careers to view all current job openings. Title: Junior Data Analyst Company: Curacao URL: https://www.indeed.com/pagead/clk?mo=r&ad=-6NYlbfkN0Aq-L5QtgCSXItUR-L7wo_YpcMWMcXbWnKpokPTLYWJk00hIQTwrRAUWMrpcxD4pwN6x-e9cnjRHCoaks6Dcg8QCGHyMkaYmHVMqcsMJtQqSjmImu6WGs5p5vCcpE2-CI15N0E8AbGD3yVS9xEHzBgfQUYd4GSBmD72CNRYeHM9H9PWqAAVtEx1R0S1ZzkqfjGDtp2QdPRY7DsiPImVGKS38M0HWeFgke4S_jsaf60ECq913qNbNgfgbdGMG1XTF1EZttwp3V7XLVaz3NoQly4IkDMzNW8y1ItfMhOn5s-Q_3FqP1DWP-yV5z7tKpScnPltd2hs_MePtbVWuhWpWCAvxqG8ZHnkhDcF2MNcbT5E9FZQdWbVIagw9c9ojMN_Nh1nGuU3zpUeZwU5YVsiQUKKnOmoAZwTrfTrd4zGioNwHgLXWMa7_dfNDkjqnfYZrl0maaH2euLhE328LW5iF0XIvZS3xgcpKiCul4Dp6N99bhD9KdG176KNCe_WwWWbFGKODRcXKugHVrqeov8H2fnGZDBtdPb17-MuLk7S6TJojU8pxdrYhIHxe-f9TSxAqxUNOXLWRWoMzEyosHKf5WBn1m5Lm--X1wB9iqgl43DM-dYINN6V2uw7&xkcb=SoCZ6_M33zC0QjygyR0LbzkdCdPP&camk=ethIe0s0hecgR0GfLS0rMw==&p=0&fvj=0&vjs=3  Title: Data Engineer Company: The Helper Bees URL: https://www.indeed.com/rc/clk?jk=6253474d1b58f413&bb=PoicSlG4oL4KE_mzfAfPJQkIIUr906XH83FgvCImzLRo_KbBAPJJqTbRCgC0sB6KQhnawYgVPRMSBCOWgvavXShvmNK4soVgF9Ps3nHZzOogM0sa-6i_wdIQ2fBIUtVg&xkcb=SoDZ67M33zC0QjygyR0KbzkdCdPP&fccid=8ce618308adea162&vjs=3  Title: Full-time Parts manager and farm data processor. Company: Broughton Farm Operations, LLC. URL: https://www.indeed.com/pagead/clk?mo=r&ad=-6NYlbfkN0Ce8sur-WsqcuJMUqQHPG5JjXNycrhCnmbCp4c_D_ButZkF_gTtnBVK85GrGLECNO3rIlBKOfzAtyZOQVTzelX9C8yOhOTinNcV9BZnRXTTjGL8A3Oq1Cl7IGC2Xzpg7tEA0_r43KM3DpNRvwbs3I3uyrVCJB2vHXaqG7klLxsrPgWZJ2WYjg6tSATO4jC_gAaCGDII7rbhbn_dTUaM9P75wYzTC2ozUeGifr0lfPd65OzIXKfPDYXlkLl5qrTmdGg9Rkvo_0eNGQ4_oL2nvYB4zdISAv5bXWjR-edYUMnsMweH28DCMre4kEAHDy9y9cr74mPTCRONjv_9TMy4cKabNfmC-Jf_KCNel0pj8cqyLXzdM2IXPZ3nPOzRImz1QL0vDqpACFlVtwjkji1oecA9k-Ct6JgVFjmXcvHhVtOKNxLyMPC_DvDcdnNxfTf68GUtsKLbJdTasg3zOA5Yx6VeqakPeJQdbUM8SvavC0EfIHiLjg2P8KtudMWnnhm9iE4mRkFBIpO06I3u1fwov2HXPqJR_KuCmX0zg2AsVNWDolGd7MQq2fL8vTqWZmImBY0_jESWcdf1nyAXKCSnIknRB6vjrMv4133NYwk78OwzmBPPyuOM-85E0vTSs2K444g4lH0vHndxyjLpN5JdnHf0rULZR5KoqzDia4KHXx6rFaKAt4f4bET5&xkcb=SoCw6_M33zC0QjygyR0JbzkdCdPP&camk=nUmJqO2E8rjB9PLQ-tQq_A==&p=2&fvj=0&vjs=3  Title: AI Data Engineer Company: Scully Company URL: https://www.indeed.com/pagead/clk?mo=r&ad=-6NYlbfkN0B0AU1f8KL9plP4iOu5S7KeQNBJvzuLdrovCp0hxvT8W3VRUq-0M1DwmsMXGNv3Vgc8rE7QIt-RapnAZ7wyj5fBABOpDoowk-H_nYWyLvNUWpWWY47YbJnAhj1YP_uV8yJhbabCHVBsGcfeDblRmLdVOfc9z89CztqtuJVDX3aTf8e1E5d2kH6Y060f5XWwMiYix9Epv9uQNmKbbRRPvkZDwTFpQuFCETcW1kf2lR9moxcUiIY09YArmQCHT3bnS-8vqIOj0pggWLoLRqZu7oB7LdZlvaxRtqrup8RsE89BZlSi58dBduIak_MwotVqtsOSCoXYyyyjMRW0RXsDsq0o1cQuhaw7nnjOf2BqFfKjNU1JeMdJ7_DrmjY8sOlrYGZy0XEpJ7Q6Lg-Unhx7n2o0q8l4JFq4uRY3fx-fy2UKHj0bWM4zPy6CcxaNSLCtuJGMv_tIjASAkqAh3UUM62prbn4eUtl-cVH2hCPeERc117AF7D5Zjym-8uvsq5cfMHuWn_JVXJV02uRZHb9wZmhKdt5iSORZY1nkqB824f0ESwAY2DCyQ6VCu2_PU4x-srms_1_S97zPRAe82jJ41yf5Q8jrgBvjCX1JXBrnTpCaQ42K2SshVTyt-XA3PfiYs4I-RWZ2_KmCDDsWOgG_pojJkr5M4TJXC5cIGywm_fRXaxyNwey3HdEtErFud3RiiLwUMOSNb1jdF9Kc1p7fG1fQkhYxD1CDDdM=&xkcb=SoAE6_M33zC0QjygyR0IbzkdCdPP&camk=nUmJqO2E8rgrZNC7156Nog==&p=3&fvj=0&vjs=3  Title: FBI Special Agent: Data Science & Intelligence Expertise Company: Federal Bureau of Investigation URL: https://www.indeed.com/pagead/clk?mo=r&ad=-6NYlbfkN0D5o2Oz3HqsSm2luAX6nIBL6zkznp9GLNwT6U20ynRgySMR2FkhZ1fxxY3hN9eOu-R0sb6uPSdXFH8qzEDJCtXBD2fYjEVZpzNm8nf5ZGyPDNmKAaV7GFRLjyyPflEoyPjNumqkZxNEOlL8xus8VfncfJpOXeBaqBR8Wya3y9f0kdNp-YhVvjHSznZKy1axj92iUL6RkjMO13c6jIk2yqHausQuGG23AZcPr6IOojd5vOW4U07WXGECmpV-Zk1meXzK0EfsAWEtbmGtoYfpKWd7FuEVGrxe9wu_lwvY3Z2iHq0JR-hGt7FXaU_ZpG_qVNfXSvNIRiF28thcfgDVaGAfrXw_IsyE0g6BRYI1sdECwhusB1d8F8d1JHbilKzxibS0Ar5VDN9iWnTOIgrienkvQ93Ytj7TvedgypOXJywgWISb-NMA1ByKuhqTT4tDzg9DXKY18OcUpRpvntc0FJv3lg1MrwYfKWeRJ9vdm4ybz9uzskCw8ndv8f6snUZtVwyOvY3KrC0TJjDND1-zAFGQKJnMGOdQbUWW1PXoyc-TQtGcZpMyW24PHtIA6KTdhtiLSKG-hK8EcQp6a0zo9qcSvyMLVMGur4t1WkTiXqKtUWVcBRBATHzz1e_B-SZpDqOts25iL2xFiukvUNBhCg2_mZ5lkscvkWg8XpP8mDhzMAzkoIo5EKSe1CiBMYJpEzp-8YLfqCQDv37lOLzKCBPlvOcGcNcyLLM1fqDUUH5p6aDJ5n7rREsbhqTdybwXHjHaefGUIjGd6_Ykr4xCc7dfc1HO9pnJYJ7JRwX11qR5pNOZTJ__FiW-9HcBR05o30XrKlXWjXLL9ICveJ2vMGtLDWni7mq4WzG33vDAbDUQ-e53kgYGb6CqfSWqNAbb_XO3FCFj4N9y-5_5pfC4516-8smBRTMuAgcRXNwy2lc4df6boRMkLm6mzoLvt1TnDro=&xkcb=SoCK6_M33zC0QjygyR0PbzkdCdPP&camk=ethIe0s0hefZAnnQPddW2w==&p=4&fvj=0&vjs=3  Title: Data Engineer I (R-17233) Company: Dun & Bradstreet URL: https://www.indeed.com/rc/clk?jk=f039623f105630f2&bb=PoicSlG4oL4KE_mzfAfPJQLW9-QeUhNE-LnLhssjIUMi376plMIitIVnT7mHsSmSASycmHVr1VH9VhABennBaEtofFSreiRn1aJqF_U3sMJHaSkapKMA8gFQ9MK55n2-&xkcb=SoDK67M33zC0QjygyR0ObzkdCdPP&fccid=fa0ca3b638673d62&vjs=3  Title: CREATIVE DATA ENGINEER Company: Cella URL: https://www.indeed.com/rc/clk?jk=b0c723def39603d4&bb=PoicSlG4oL4KE_mzfAfPJVAExLkVvzav5xGULH5rInxqP_VOZvp7gIYKHqCbThZnz74iHJSrpwyLvY_tDnNB1qNot1o3pgaCTHDhUgiodMvTePfp19wkaz-MSGJlus8W&xkcb=SoBX67M33zC0QjygyR0NbzkdCdPP&fccid=d306bce47a67346c&vjs=3  Title: Data Engineer Company: Index Analytics Llc URL: https://www.indeed.com/rc/clk?jk=7b85b76ecc3b54d6&bb=PoicSlG4oL4KE_mzfAfPJY4Dgjs89jD-8RFjiEfPnEzhc0hOX-aSPF40EqrIu8YiA6s8Oq_eiggSWYMvfK_q8EeLkdvssJJ_JWyu_ecKBnzuC3rVCeLzZQFP83W9ZrAp&xkcb=SoDj67M33zC0QjygyR0MbzkdCdPP&fccid=8cbf9de34e58e41b&vjs=3  Title: Data Engineer/ SQL Company: VForce InfoTech URL: https://www.indeed.com/pagead/clk?mo=r&ad=-6NYlbfkN0BoslJVGns8qfR_aOiNbQuDVC0Y27-j1RL-pKQzTNZtWfIQva2k7RlVGWpZ7oj2R4ylb0Kg62Z-SSkwYRUxa-meEqsK1kednCikHmTaN33bQ8F7ZO1559Ws-z4x_C6rberdZi12TNcKAKpFQ-fC374Vr6z8Tz5SEhqXzVJ9scX7NDOuRvRL1euuXx2pN7UO-zJFnmF3cdV8gSYjf92zw3w6knkC0a7D6QKwaiuNfF8d8LSlcVEBDQicLusNAknWYtrdmnMHIsVOq_zx4V6Q68LZIZ8-hsB3D5LzxOtpbB30gr8Waq9BKKStfa4TAhKtPKm2-77Q2PvvefnqIrXBfwMwenjvUVCDO8HxnDiSAGnRkjql6noSIKV63FaAqqlG5o83048tf683Ij-onLSNCaatFys1NzNnPAEcoVWEkCcPifpyJXTFUm0SiTXYLKythW23AdZBJ-3LEvZZ7b_MW4O2NwN_pOiQzKv98z1mRk54efuwg9UHUN42Vs-fCAt61v3E64QjIupY2azYZilCmGbKIMqxswiGEjmg0dCvLdhuhTfAgL5gGTu_PL6y6ZPTc3XqIrd3d8Vjsx1egEoWyoaz98z1fSxb6okVmi63g9anVZ6zrxqft6OI&xkcb=SoD-6_M33zC0QjygyR0DbzkdCdPP&camk=ethIe0s0hedRVYebutXmHw==&p=8&fvj=0&vjs=3  Title: Data Analyst Company: Fix-It 24/7 URL: https://www.indeed.com/rc/clk?jk=06050d41e9f16407&bb=PoicSlG4oL4KE_mzfAfPJcNDVm6or-NNAyXlZWh9lXFRtdo0uyvpn7kUUMr_VtjQOlrGg4zo5d1KEwrEdT-eRV_WQR4VBjrpc_vXphj0PfPcm7USRlPWyO_RNSeTtTup&xkcb=SoC-67M33zC0QjygyR0CbzkdCdPP&fccid=61e4e7d2ce056d37&vjs=3  Title: Data Analyst Company: Munich Re Specialty - North America URL: https://www.indeed.com/rc/clk?jk=ab2d8d19d1cd0ba2&bb=PoicSlG4oL4KE_mzfAfPJavgGXVCAXmVEBSucc3YFraHOlH2kh32HgjVOBeNG3FI-7-vWYmOqtpAvRLhliZCWkEocJRMdjsG-X-9NAVX2fEUvg7YbkQtOg%3D%3D&xkcb=SoAj67M33zC0QjygyR0BbzkdCdPP&fccid=dd616958bd9ddc12&vjs=3  Title: Data Engineer Company: KesarWeb URL: https://www.indeed.com/rc/clk?jk=375bf3b4e704091b&bb=PoicSlG4oL4KE_mzfAfPJfbKlByUIdhRJLa8Sz_HeJa00xcyA3EGfchbV2MZ7DteGJm1-OJRhhwuYN8722Kq2t8l5gXe4PhqDfaVlyiLT4ELXjZ4iAfmQVcBEBGAvyUR&xkcb=SoCX67M33zC0QjygyR0AbzkdCdPP&fccid=36a6953a97504177&cmp=KesarWeb&ti=Data+Engineer&vjs=3  Title: Junior Data Analyst Company: BIGEYE Agency URL: https://www.indeed.com/rc/clk?jk=1bd637c0266670f9&bb=PoicSlG4oL4KE_mzfAfPJdZcwBLmA7r48FTyouCeFKZuoODWqcYrY4l_U-Yz8_g20Z_JVOmOFiNGhiVABTH9V7kNbeQ2PdEBVvpUnwQuZjd_MNBMsCTdde1-ab6iBRLu&xkcb=SoAZ67M33zC0QjygyR0HbzkdCdPP&fccid=a82b8d0828c4dc85&vjs=3  Title: Data Engineer Company: Intone Networks URL: https://www.indeed.com/rc/clk?jk=672fe0f4f3692aaf&bb=PoicSlG4oL4KE_mzfAfPJRxx6B42VjRnVyQUl8_FL0gQ_sXGmkaKqW7FmZGQ8Rz823_QPS2sPW000nZdYp_BwyZnhbKLYiG3rRPH7zQTOEOry731wTWVwFQjWhlKq_wD&xkcb=SoCt67M33zC0QjygyR0GbzkdCdPP&fccid=3ed0572c448b2368&vjs=3  Title: Data Engineer Company: Tixr URL: https://www.indeed.com/rc/clk?jk=8c7fc3318df61439&bb=PoicSlG4oL4KE_mzfAfPJQdkRLvimhkRu14iVvKd8Qu_VLxH_uafJx7tpA2cEyVgnS2nunvTq1lqeVlMtSm-Tem2fhZgxEKXtxHcfj92jEN68X-999n3_Bbt_VCOnYKy&xkcb=SoAw67M33zC0QjygyR0FbzkdCdPP&fccid=e0708763009091cb&vjs=3</td><td>data</td><td>Description: Join our winning team, recently honored as #67 on Forbes’ list of America’s Best Startup Employers for 2024! About The Helper Bees The Helper Bees’ mission is to help people stay home longer through data-driven services that transform both the payer and the care-recipient experience. At The Helper Bees, we are reshaping how care is delivered to aging individuals by leveraging innovative technology and insightful data solutions. We maintain multiple SaaS products and payment solutions through our web applications (internal and external facing), a mobile app, and reporting integrations. As part of our growing Data Engineering team, you’ll iterate quickly, have a high impact, and be challenged to design and implement cutting-edge solutions. At THB, we define our company culture through our Core Values: Quickly iterate through solutions: We move at a fast pace which requires quick iterations to find a path to a repeatable solution. Seek ways to create immediate impact: Be thoughtful and proactive in how you make an impact on your team. Actively look for ways to make a fast, positive impact. Bee the teammate you want to work with: We work as a team, help each other, and encourage each other. Ask questions, answer questions: You can't iterate through solutions if you don't ask the right questions, which is why there is an expectation that questions should be asked. When you know the answer, being a good teammate means chiming in to get others up to speed. Take the time to celebrate wins: It's so easy for a team that is heads down to forget about all the great things they've accomplished. That's why we make it a priority to remind ourselves to create space to celebrate wins, big or small. Job Summary We are seeking a motivated Data Engineer to join our team and help improve our tools, processes, and technical infrastructure. In this role, you will ensure the availability and quality of our data while contributing to the design, implementation, and maintenance of The Helper Bees’ products. You’ll collaborate across teams to create scalable and optimized software systems and play a key role in refining our development processes. This position offers a unique opportunity to learn and leverage cutting-edge AI development tools to enhance coding efficiency and develop advanced data tools and solutions. Supervisory Responsibilities: None Key Responsibilities Data Infrastructure: Design, implement, and maintain data pipelines, ensuring data availability, quality, and scalability. Product Development: Build and enhance products using Python, SQL, and modern technologies. AI Integration: Leverage cutting-edge AI tools, including Cursor, ChatGPT, and Claude to improve development processes, automate workflows, and create innovative data solutions. Collaboration: Communicate across departments to design, build, test, and implement new features and enhancements. Code Excellence: Produce quality, testable, and maintainable code while participating in code reviews. Problem Solving: Debug complex issues, interact with stakeholders, and design viable solutions with clear trade-offs. Process Optimization: Contribute to improving development processes, including deployment, on-call systems, and sprint planning. Team Growth: Collaborate within the development team to help each other grow and continuously learn. Stakeholder Engagement: Partner with analysts, scientists, and IT to ensure alignment and deliver data-driven solutions. Other duties as assigned/necessary Performance Metrics Code Quality: Maintain high coding standards through regular code reviews and adherence to best practices. Development Efficiency: Deliver high-quality features and fixes within efficient timeframes. Bug Resolution Time: Reduce the time taken to identify and resolve issues. System Scalability: Optimize system performance to handle increasing user demands. Collaboration: Foster a collaborative environment that encourages teamwork and knowledge sharing. Customer Satisfaction: Incorporate stakeholder feedback to improve solutions and enhance the customer experience. Continuous Learning: Pursue opportunities for skill development and share knowledge with the team. Requirements: Required Skills & Qualifications Technical Tools: Experience with in Python and/or SQL. Experience with Bash, Shell scripting, Big Query, Airflow, and is a plus. Programming: Cleaning data using code-based approach. AI Proficiency: Interest or experience in using AI tools for coding and development of data solutions. Soft Skills: Problem-solving, cross-team collaboration, data storytelling, and stakeholder engagement. Adaptability: Thrives in a fast-paced startup environment and embraces change. Proactivity: Self-directed, organized, and able to prioritize effectively. Collaboration: Ability to work effectively with cross-functional teams. Education & Experience: A bachelor’s degree is required, and a graduate degree is preferred. Relevant experience in data engineering, software development, STEM, or related fields. Strong experience with SQL and Python is highly desirable. Mindset: A passion for innovation, continuous improvement, and delivering high-quality results from messy data. Preferred Qualifications Familiarity with cloud-based solutions (e.g., Google Cloud Platform, Azure). Experience with ETL processes and tools. Experience building data visualization reports and dashboards Knowledge of modern data storage solutions and database management systems. Exposure to DevOps practices and tools for deployment and monitoring. Why Join Us? Work with a talented, collaborative team dedicated to making a difference. Gain exposure to innovative technologies and opportunities for growth. Learn and utilize cutting-edge AI tools to enhance your development skills and create impactful solutions. Be part of a company that values your contributions and encourages professional development. Join a rapidly expanding health-tech startup (~200 employees and growing) with a state-of-the-art technology office located in Hyde Park, offering a variety of exceptional benefits. Career Progression Timeline In 3 months: Gain a comprehensive understanding of our data infrastructure, technical stacks, and development cycles. Actively participate in team meetings and contribute to the development of new data pipelines. Begin leveraging AI tools, such as Cursor and ChatGPT, to enhance coding efficiency and workflow automation. In 6 months: Contribute to product enhancements and data reporting Collaborate effectively with cross-functional teams, providing insights and solutions for data-related challenges. Demonstrate proficiency in utilizing AI tools for coding and development, actively sharing knowledge with the team. In 12 months: Contribute to data engineering projects, ensuring scalability and performance optimization. Mentor non-technical internal partners to improve company-wide data literacy Contribute to the integration of advanced AI solutions into our development processes, contributing to the company's technological advancement. Physical Requirements: Ability to remain at your designated workstation for the duration of the workday Constantly operates a computer and other office productivity machinery, such as a phone and Voice over Internet Protocol (VoIP). The ability to communicate information and ideas so others will understand. Must be able to exchange accurate information in these situations. The ability to observe details at close range (typically on a computer screen) This position offers the flexibility of remote work at approved locations within the United States. Candidates must have a reliable internet connection and a designated work environment conducive to professional phone calls and sensitive data. Enjoy the convenience and comfort of working remotely while contributing to our team's success. Apply Today If you’re ready to take on challenging problems, contribute to impactful solutions, and grow as a data engineer, we’d love to hear from you. Join us at The Helper Bees and be part of a team that’s making a meaningful difference every day! The Helper Bees is committed to building a workplace where diversity, equity, and inclusion are valued and prioritized. We are an equal opportunity employer that welcomes all qualified applicants without discrimination based on race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or any non-merit based or legally protected grounds. The Helper Bees provides reasonable accommodations to qualified individuals with disabilities during the job application and interview process. To request accommodation, please let your recruiter know. As part of our standard hiring process, selected candidates may be required to undergo a background check and/or drug screen. The Helper Bees adheres to applicable federal, state, and local laws regarding these screenings, and the results will be considered in accordance with applicable regulations. The Helper Bees was recently made aware of a fraudulent entity posing as our organization and requesting personal information. Please be aware of and protect yourself from scams. Visit thehelperbees.com/careers to view all current job openings. Title: Junior Data Analyst Company: Curacao URL:   Title: Data Engineer Company: The Helper Bees URL:   Title: Full-time Parts manager and farm data processor. Company: Broughton Farm Operations, LLC. URL:   Title: AI Data Engineer Company: Scully Company URL:   Title: FBI Special Agent: Data Science & Intelligence Expertise Company: Federal Bureau of Investigation URL:   Title: Data Engineer I (R-17233) Company: Dun & Bradstreet URL:   Title: CREATIVE DATA ENGINEER Company: Cella URL:   Title: Data Engineer Company: Index Analytics Llc URL:   Title: Data Engineer/ SQL Company: VForce InfoTech URL:   Title: Data Analyst Company: Fix-It 24/7 URL:   Title: Data Analyst Company: Munich Re Specialty - North America URL:   Title: Data Engineer Company: KesarWeb URL:   Title: Junior Data Analyst Company: BIGEYE Agency URL:   Title: Data Engineer Company: Intone Networks URL:   Title: Data Engineer Company: Tixr URL: </td><td>Description: Join our winning team, recently honored as #67 on Forbes’ list of America’s Best Startup Employers for 2024! About The Helper Bees The Helper Bees’ mission is to help people stay home longer through data-driven services that transform both the payer and the care-recipient experience. At The Helper Bees, we are reshaping how care is delivered to aging individuals by leveraging innovative technology and insightful data solutions. We maintain multiple SaaS products and payment solutions through our web applications (internal and external facing), a mobile app, and reporting integrations. As part of our growing Data Engineering team, you’ll iterate quickly, have a high impact, and be challenged to design and implement cutting-edge solutions. At THB, we define our company culture through our Core Values: Quickly iterate through solutions: We move at a fast pace which requires quick iterations to find a path to a repeatable solution. Seek ways to create immediate impact: Be thoughtful and proactive in how you make an impact on your team. Actively look for ways to make a fast, positive impact. Bee the teammate you want to work with: We work as a team, help each other, and encourage each other. Ask questions, answer questions: You can't iterate through solutions if you don't ask the right questions, which is why there is an expectation that questions should be asked. When you know the answer, being a good teammate means chiming in to get others up to speed. Take the time to celebrate wins: It's so easy for a team that is heads down to forget about all the great things they've accomplished. That's why we make it a priority to remind ourselves to create space to celebrate wins, big or small. Job Summary We are seeking a motivated Data Engineer to join our team and help improve our tools, processes, and technical infrastructure. In this role, you will ensure the availability and quality of our data while contributing to the design, implementation, and maintenance of The Helper Bees’ products. You’ll collaborate across teams to create scalable and optimized software systems and play a key role in refining our development processes. This position offers a unique opportunity to learn and leverage cutting-edge AI development tools to enhance coding efficiency and develop advanced data tools and solutions. Supervisory Responsibilities: None Key Responsibilities Data Infrastructure: Design, implement, and maintain data pipelines, ensuring data availability, quality, and scalability. Product Development: Build and enhance products using Python, SQL, and modern technologies. AI Integration: Leverage cutting-edge AI tools, including Cursor, ChatGPT, and Claude to improve development processes, automate workflows, and create innovative data solutions. Collaboration: Communicate across departments to design, build, test, and implement new features and enhancements. Code Excellence: Produce quality, testable, and maintainable code while participating in code reviews. Problem Solving: Debug complex issues, interact with stakeholders, and design viable solutions with clear trade-offs. Process Optimization: Contribute to improving development processes, including deployment, on-call systems, and sprint planning. Team Growth: Collaborate within the development team to help each other grow and continuously learn. Stakeholder Engagement: Partner with analysts, scientists, and IT to ensure alignment and deliver data-driven solutions. Other duties as assigned/necessary Performance Metrics Code Quality: Maintain high coding standards through regular code reviews and adherence to best practices. Development Efficiency: Deliver high-quality features and fixes within efficient timeframes. Bug Resolution Time: Reduce the time taken to identify and resolve issues. System Scalability: Optimize system performance to handle increasing user demands. Collaboration: Foster a collaborative environment that encourages teamwork and knowledge sharing. Customer Satisfaction: Incorporate stakeholder feedback to improve solutions and enhance the customer experience. Continuous Learning: Pursue opportunities for skill development and share knowledge with the team. Requirements: Required Skills & Qualifications Technical Tools: Experience with in Python and/or SQL. Experience with Bash, Shell scripting, Big Query, Airflow, and is a plus. Programming: Cleaning data using code-based approach. AI Proficiency: Interest or experience in using AI tools for coding and development of data solutions. Soft Skills: Problem-solving, cross-team collaboration, data storytelling, and stakeholder engagement. Adaptability: Thrives in a fast-paced startup environment and embraces change. Proactivity: Self-directed, organized, and able to prioritize effectively. Collaboration: Ability to work effectively with cross-functional teams. Education & Experience: A bachelor’s degree is required, and a graduate degree is preferred. Relevant experience in data engineering, software development, STEM, or related fields. Strong experience with SQL and Python is highly desirable. Mindset: A passion for innovation, continuous improvement, and delivering high-quality results from messy data. Preferred Qualifications Familiarity with cloud-based solutions (e.g., Google Cloud Platform, Azure). Experience with ETL processes and tools. Experience building data visualization reports and dashboards Knowledge of modern data storage solutions and database management systems. Exposure to DevOps practices and tools for deployment and monitoring. Why Join Us? Work with a talented, collaborative team dedicated to making a difference. Gain exposure to innovative technologies and opportunities for growth. Learn and utilize cutting-edge AI tools to enhance your development skills and create impactful solutions. Be part of a company that values your contributions and encourages professional development. Join a rapidly expanding health-tech startup (~200 employees and growing) with a state-of-the-art technology office located in Hyde Park, offering a variety of exceptional benefits. Career Progression Timeline In 3 months: Gain a comprehensive understanding of our data infrastructure, technical stacks, and development cycles. Actively participate in team meetings and contribute to the development of new data pipelines. Begin leveraging AI tools, such as Cursor and ChatGPT, to enhance coding efficiency and workflow automation. In 6 months: Contribute to product enhancements and data reporting Collaborate effectively with cross-functional teams, providing insights and solutions for data-related challenges. Demonstrate proficiency in utilizing AI tools for coding and development, actively sharing knowledge with the team. In 12 months: Contribute to data engineering projects, ensuring scalability and performance optimization. Mentor non-technical internal partners to improve company-wide data literacy Contribute to the integration of advanced AI solutions into our development processes, contributing to the company's technological advancement. Physical Requirements: Ability to remain at your designated workstation for the duration of the workday Constantly operates a computer and other office productivity machinery, such as a phone and Voice over Internet Protocol (VoIP). The ability to communicate information and ideas so others will understand. Must be able to exchange accurate information in these situations. The ability to observe details at close range (typically on a computer screen) This position offers the flexibility of remote work at approved locations within the United States. Candidates must have a reliable internet connection and a designated work environment conducive to professional phone calls and sensitive data. Enjoy the convenience and comfort of working remotely while contributing to our team's success. Apply Today If you’re ready to take on challenging problems, contribute to impactful solutions, and grow as a data engineer, we’d love to hear from you. Join us at The Helper Bees and be part of a team that’s making a meaningful difference every day! The Helper Bees is committed to building a workplace where diversity, equity, and inclusion are valued and prioritized. We are an equal opportunity employer that welcomes all qualified applicants without discrimination based on race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or any non-merit based or legally protected grounds. The Helper Bees provides reasonable accommodations to qualified individuals with disabilities during the job application and interview process. To request accommodation, please let your recruiter know. As part of our standard hiring process, selected candidates may be required to undergo a background check and/or drug screen. The Helper Bees adheres to applicable federal, state, and local laws regarding these screenings, and the results will be considered in accordance with applicable regulations. The Helper Bees was recently made aware of a fraudulent entity posing as our organization and requesting personal information. Please be aware of and protect yourself from scams. Visit thehelperbees.com/careers to view all current job openings. Title: Junior Data Analyst Company: Curacao URL:   Title: Data Engineer Company: The Helper Bees URL:   Title: Full-time Parts manager and farm data processor. Company: Broughton Farm Operations, LLC. URL:   Title: AI Data Engineer Company: Scully Company URL:   Title: FBI Special Agent: Data Science & Intelligence Expertise Company: Federal Bureau of Investigation URL:   Title: Data Engineer I (R-17233) Company: Dun & Bradstreet URL:   Title: CREATIVE DATA ENGINEER Company: Cella URL:   Title: Data Engineer Company: Index Analytics Llc URL:   Title: Data Engineer/ SQL Company: VForce InfoTech URL:   Title: Data Analyst Company: Fix-It 24/7 URL:   Title: Data Analyst Company: Munich Re Specialty - North America URL:   Title: Data Engineer Company: KesarWeb URL:   Title: Junior Data Analyst Company: BIGEYE Agency URL:   Title: Data Engineer Company: Intone Networks URL:   Title: Data Engineer Company: Tixr URL: </td><td>Technical Tools: Experience with in Python and/or SQL. Experience with Bash, Shell scripting, Big Query, Airflow, and is a plus. Programming: Cleaning data using code-based approach. AI Proficiency: Interest or experience in using AI tools for coding and development of data solutions. Soft Skills: Problem-solving, cross-team collaboration, data storytelling, and stakeholder engagement. Adaptability: Thrives in a fast-paced startup environment and embraces change. Proactivity: Self-directed, organized, and able to prioritize effectively. Collaboration: Ability to work effectively with cross-functional teams. Education & Experience: A bachelor’s degree is required, and a graduate degree is preferred. Relevant experience in data engineering, software development, STEM, or related fields. Strong experience with SQL and Python is highly desirable. Mindset: A passion for innovation, continuous improvement, and delivering high-quality results from messy data. Preferred Qualifications Familiarity with cloud-based solutions (e.g., Google Cloud Platform, Azure). Experience with ETL processes and tools. Experience building data visualization reports and dashboards Knowledge of modern data storage solutions and database management systems. Exposure to DevOps practices and tools for deployment and monitoring. Why Join Us? Work with a talented, collaborative team dedicated to making a difference. Gain exposure to innovative technologies and opportunities for growth. Learn and utilize cutting-edge AI tools to enhance your development skills and create impactful solutions. Be part of a company that values your contributions and encourages professional development. Join a rapidly expanding health-tech startup (~200 employees and growing) with a state-of-the-art technology office located in Hyde Park, offering a variety of exceptional benefits. Career Progression Timeline In 3 months: Gain a comprehensive understanding of our data infrastructure, technical stacks, and development cycles. Actively participate in team meetings and contribute to the development of new data pipelines. Begin leveraging AI tools, such as Cursor and ChatGPT, to enhance coding efficiency and workflow automation. In 6 months: Contribute to product enhancements and data reporting Collaborate effectively with cross-functional teams, providing insights and solutions for data-related challenges. Demonstrate proficiency in utilizing AI tools for coding and development, actively sharing knowledge with the team. In 12 months: Contribute to data engineering projects, ensuring scalability and performance optimization. Mentor non-technical internal partners to improve company-wide data literacy Contribute to the integration of advanced AI solutions into our development processes, contributing to the company's technological advancement. Physical Requirements: Ability to remain at your designated workstation for the duration of the workday Constantly operates a computer and other office productivity machinery, such as a phone and Voice over Internet Protocol (VoIP). The ability to communicate information and ideas so others will understand. Must be able to exchange accurate information in these situations. The ability to observe details at close range (typically on a computer screen) This position offers the flexibility of remote work at approved locations within the United States. Candidates must have a reliable internet connection and a designated work environment conducive to professional phone calls and sensitive data. Enjoy the convenience and comfort of working remotely while contributing to our team's success. Apply Today If you’re ready to take on challenging problems, contribute to impactful solutions, and grow as a data engineer, we’d love to hear from you. Join us at The Helper Bees and be part of a team that’s making a meaningful difference every day! The Helper Bees is committed to building a workplace where diversity, equity, and inclusion are valued and prioritized. We are an equal opportunity employer that welcomes all qualified applicants without discrimination based on race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or any non-merit based or legally protected grounds. The Helper Bees provides reasonable accommodations to qualified individuals with disabilities during the job application and interview process. To request accommodation, please let your recruiter know. As part of our standard hiring process, selected candidates may be required to undergo a background check and/or drug screen. The Helper Bees adheres to applicable federal, state, and local laws regarding these screenings, and the results will be considered in accordance with applicable regulations. The Helper Bees was recently made aware of a fraudulent entity posing as our organization and requesting personal information. Please be aware of and protect yourself from scams. Visit thehelperbees.com/careers to view all current job openings. Title: Junior Data Analyst Company: Curacao URL:   Title: Data Engineer Company: The Helper Bees URL:   Title: Full-time Parts manager and farm data processor. Company: Broughton Farm Operations, LLC. URL:   Title: AI Data Engineer Company: Scully Company URL:   Title: FBI Special Agent: Data Science & Intelligence Expertise Company: Federal Bureau of Investigation URL:   Title: Data Engineer I (R-17233) Company: Dun & Bradstreet URL:   Title: CREATIVE DATA ENGINEER Company: Cella URL:   Title: Data Engineer Company: Index Analytics Llc URL:   Title: Data Engineer/ SQL Company: VForce InfoTech URL:   Title: Data Analyst Company: Fix-It 24/7 URL:   Title: Data Analyst Company: Munich Re Specialty - North America URL:   Title: Data Engineer Company: KesarWeb URL:   Title: Junior Data Analyst Company: BIGEYE Agency URL:   Title: Data Engineer Company: Intone Networks URL:   Title: Data Engineer Company: Tixr URL:</td><td>828</td></tr><tr><td>Data Engineer</td><td>#NAME?</td><td>Description: Join our winning team, recently honored as #67 on Forbes’ list of America’s Best Startup Employers for 2024! About The Helper Bees The Helper Bees’ mission is to help people stay home longer through data-driven services that transform both the payer and the care-recipient experience. At The Helper Bees, we are reshaping how care is delivered to aging individuals by leveraging innovative technology and insightful data solutions. We maintain multiple SaaS products and payment solutions through our web applications (internal and external facing), a mobile app, and reporting integrations. As part of our growing Data Engineering team, you’ll iterate quickly, have a high impact, and be challenged to design and implement cutting-edge solutions. At THB, we define our company culture through our Core Values: Quickly iterate through solutions: We move at a fast pace which requires quick iterations to find a path to a repeatable solution. Seek ways to create immediate impact: Be thoughtful and proactive in how you make an impact on your team. Actively look for ways to make a fast, positive impact. Bee the teammate you want to work with: We work as a team, help each other, and encourage each other. Ask questions, answer questions: You can't iterate through solutions if you don't ask the right questions, which is why there is an expectation that questions should be asked. When you know the answer, being a good teammate means chiming in to get others up to speed. Take the time to celebrate wins: It's so easy for a team that is heads down to forget about all the great things they've accomplished. That's why we make it a priority to remind ourselves to create space to celebrate wins, big or small. Job Summary We are seeking a motivated Data Engineer to join our team and help improve our tools, processes, and technical infrastructure. In this role, you will ensure the availability and quality of our data while contributing to the design, implementation, and maintenance of The Helper Bees’ products. You’ll collaborate across teams to create scalable and optimized software systems and play a key role in refining our development processes. This position offers a unique opportunity to learn and leverage cutting-edge AI development tools to enhance coding efficiency and develop advanced data tools and solutions. Supervisory Responsibilities: None Key Responsibilities Data Infrastructure: Design, implement, and maintain data pipelines, ensuring data availability, quality, and scalability. Product Development: Build and enhance products using Python, SQL, and modern technologies. AI Integration: Leverage cutting-edge AI tools, including Cursor, ChatGPT, and Claude to improve development processes, automate workflows, and create innovative data solutions. Collaboration: Communicate across departments to design, build, test, and implement new features and enhancements. Code Excellence: Produce quality, testable, and maintainable code while participating in code reviews. Problem Solving: Debug complex issues, interact with stakeholders, and design viable solutions with clear trade-offs. Process Optimization: Contribute to improving development processes, including deployment, on-call systems, and sprint planning. Team Growth: Collaborate within the development team to help each other grow and continuously learn. Stakeholder Engagement: Partner with analysts, scientists, and IT to ensure alignment and deliver data-driven solutions. Other duties as assigned/necessary Performance Metrics Code Quality: Maintain high coding standards through regular code reviews and adherence to best practices. Development Efficiency: Deliver high-quality features and fixes within efficient timeframes. Bug Resolution Time: Reduce the time taken to identify and resolve issues. System Scalability: Optimize system performance to handle increasing user demands. Collaboration: Foster a collaborative environment that encourages teamwork and knowledge sharing. Customer Satisfaction: Incorporate stakeholder feedback to improve solutions and enhance the customer experience. Continuous Learning: Pursue opportunities for skill development and share knowledge with the team. Requirements: Required Skills & Qualifications Technical Tools: Experience with in Python and/or SQL. Experience with Bash, Shell scripting, Big Query, Airflow, and is a plus. Programming: Cleaning data using code-based approach. AI Proficiency: Interest or experience in using AI tools for coding and development of data solutions. Soft Skills: Problem-solving, cross-team collaboration, data storytelling, and stakeholder engagement. Adaptability: Thrives in a fast-paced startup environment and embraces change. Proactivity: Self-directed, organized, and able to prioritize effectively. Collaboration: Ability to work effectively with cross-functional teams. Education & Experience: A bachelor’s degree is required, and a graduate degree is preferred. Relevant experience in data engineering, software development, STEM, or related fields. Strong experience with SQL and Python is highly desirable. Mindset: A passion for innovation, continuous improvement, and delivering high-quality results from messy data. Preferred Qualifications Familiarity with cloud-based solutions (e.g., Google Cloud Platform, Azure). Experience with ETL processes and tools. Experience building data visualization reports and dashboards Knowledge of modern data storage solutions and database management systems. Exposure to DevOps practices and tools for deployment and monitoring. Why Join Us? Work with a talented, collaborative team dedicated to making a difference. Gain exposure to innovative technologies and opportunities for growth. Learn and utilize cutting-edge AI tools to enhance your development skills and create impactful solutions. Be part of a company that values your contributions and encourages professional development. Join a rapidly expanding health-tech startup (~200 employees and growing) with a state-of-the-art technology office located in Hyde Park, offering a variety of exceptional benefits. Career Progression Timeline In 3 months: Gain a comprehensive understanding of our data infrastructure, technical stacks, and development cycles. Actively participate in team meetings and contribute to the development of new data pipelines. Begin leveraging AI tools, such as Cursor and ChatGPT, to enhance coding efficiency and workflow automation. In 6 months: Contribute to product enhancements and data reporting Collaborate effectively with cross-functional teams, providing insights and solutions for data-related challenges. Demonstrate proficiency in utilizing AI tools for coding and development, actively sharing knowledge with the team. In 12 months: Contribute to data engineering projects, ensuring scalability and performance optimization. Mentor non-technical internal partners to improve company-wide data literacy Contribute to the integration of advanced AI solutions into our development processes, contributing to the company's technological advancement. Physical Requirements: Ability to remain at your designated workstation for the duration of the workday Constantly operates a computer and other office productivity machinery, such as a phone and Voice over Internet Protocol (VoIP). The ability to communicate information and ideas so others will understand. Must be able to exchange accurate information in these situations. The ability to observe details at close range (typically on a computer screen) This position offers the flexibility of remote work at approved locations within the United States. Candidates must have a reliable internet connection and a designated work environment conducive to professional phone calls and sensitive data. Enjoy the convenience and comfort of working remotely while contributing to our team's success. Apply Today If you’re ready to take on challenging problems, contribute to impactful solutions, and grow as a data engineer, we’d love to hear from you. Join us at The Helper Bees and be part of a team that’s making a meaningful difference every day! The Helper Bees is committed to building a workplace where diversity, equity, and inclusion are valued and prioritized. We are an equal opportunity employer that welcomes all qualified applicants without discrimination based on race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or any non-merit based or legally protected grounds. The Helper Bees provides reasonable accommodations to qualified individuals with disabilities during the job application and interview process. To request accommodation, please let your recruiter know. As part of our standard hiring process, selected candidates may be required to undergo a background check and/or drug screen. The Helper Bees adheres to applicable federal, state, and local laws regarding these screenings, and the results will be considered in accordance with applicable regulations. The Helper Bees was recently made aware of a fraudulent entity posing as our organization and requesting personal information. Please be aware of and protect yourself from scams. Visit thehelperbees.com/careers to view all current job openings.</td><td>data</td><td>Description: Join our winning team, recently honored as #67 on Forbes’ list of America’s Best Startup Employers for 2024! About The Helper Bees The Helper Bees’ mission is to help people stay home longer through data-driven services that transform both the payer and the care-recipient experience. At The Helper Bees, we are reshaping how care is delivered to aging individuals by leveraging innovative technology and insightful data solutions. We maintain multiple SaaS products and payment solutions through our web applications (internal and external facing), a mobile app, and reporting integrations. As part of our growing Data Engineering team, you’ll iterate quickly, have a high impact, and be challenged to design and implement cutting-edge solutions. At THB, we define our company culture through our Core Values: Quickly iterate through solutions: We move at a fast pace which requires quick iterations to find a path to a repeatable solution. Seek ways to create immediate impact: Be thoughtful and proactive in how you make an impact on your team. Actively look for ways to make a fast, positive impact. Bee the teammate you want to work with: We work as a team, help each other, and encourage each other. Ask questions, answer questions: You can't iterate through solutions if you don't ask the right questions, which is why there is an expectation that questions should be asked. When you know the answer, being a good teammate means chiming in to get others up to speed. Take the time to celebrate wins: It's so easy for a team that is heads down to forget about all the great things they've accomplished. That's why we make it a priority to remind ourselves to create space to celebrate wins, big or small. Job Summary We are seeking a motivated Data Engineer to join our team and help improve our tools, processes, and technical infrastructure. In this role, you will ensure the availability and quality of our data while contributing to the design, implementation, and maintenance of The Helper Bees’ products. You’ll collaborate across teams to create scalable and optimized software systems and play a key role in refining our development processes. This position offers a unique opportunity to learn and leverage cutting-edge AI development tools to enhance coding efficiency and develop advanced data tools and solutions. Supervisory Responsibilities: None Key Responsibilities Data Infrastructure: Design, implement, and maintain data pipelines, ensuring data availability, quality, and scalability. Product Development: Build and enhance products using Python, SQL, and modern technologies. AI Integration: Leverage cutting-edge AI tools, including Cursor, ChatGPT, and Claude to improve development processes, automate workflows, and create innovative data solutions. Collaboration: Communicate across departments to design, build, test, and implement new features and enhancements. Code Excellence: Produce quality, testable, and maintainable code while participating in code reviews. Problem Solving: Debug complex issues, interact with stakeholders, and design viable solutions with clear trade-offs. Process Optimization: Contribute to improving development processes, including deployment, on-call systems, and sprint planning. Team Growth: Collaborate within the development team to help each other grow and continuously learn. Stakeholder Engagement: Partner with analysts, scientists, and IT to ensure alignment and deliver data-driven solutions. Other duties as assigned/necessary Performance Metrics Code Quality: Maintain high coding standards through regular code reviews and adherence to best practices. Development Efficiency: Deliver high-quality features and fixes within efficient timeframes. Bug Resolution Time: Reduce the time taken to identify and resolve issues. System Scalability: Optimize system performance to handle increasing user demands. Collaboration: Foster a collaborative environment that encourages teamwork and knowledge sharing. Customer Satisfaction: Incorporate stakeholder feedback to improve solutions and enhance the customer experience. Continuous Learning: Pursue opportunities for skill development and share knowledge with the team. Requirements: Required Skills & Qualifications Technical Tools: Experience with in Python and/or SQL. Experience with Bash, Shell scripting, Big Query, Airflow, and is a plus. Programming: Cleaning data using code-based approach. AI Proficiency: Interest or experience in using AI tools for coding and development of data solutions. Soft Skills: Problem-solving, cross-team collaboration, data storytelling, and stakeholder engagement. Adaptability: Thrives in a fast-paced startup environment and embraces change. Proactivity: Self-directed, organized, and able to prioritize effectively. Collaboration: Ability to work effectively with cross-functional teams. Education & Experience: A bachelor’s degree is required, and a graduate degree is preferred. Relevant experience in data engineering, software development, STEM, or related fields. Strong experience with SQL and Python is highly desirable. Mindset: A passion for innovation, continuous improvement, and delivering high-quality results from messy data. Preferred Qualifications Familiarity with cloud-based solutions (e.g., Google Cloud Platform, Azure). Experience with ETL processes and tools. Experience building data visualization reports and dashboards Knowledge of modern data storage solutions and database management systems. Exposure to DevOps practices and tools for deployment and monitoring. Why Join Us? Work with a talented, collaborative team dedicated to making a difference. Gain exposure to innovative technologies and opportunities for growth. Learn and utilize cutting-edge AI tools to enhance your development skills and create impactful solutions. Be part of a company that values your contributions and encourages professional development. Join a rapidly expanding health-tech startup (~200 employees and growing) with a state-of-the-art technology office located in Hyde Park, offering a variety of exceptional benefits. Career Progression Timeline In 3 months: Gain a comprehensive understanding of our data infrastructure, technical stacks, and development cycles. Actively participate in team meetings and contribute to the development of new data pipelines. Begin leveraging AI tools, such as Cursor and ChatGPT, to enhance coding efficiency and workflow automation. In 6 months: Contribute to product enhancements and data reporting Collaborate effectively with cross-functional teams, providing insights and solutions for data-related challenges. Demonstrate proficiency in utilizing AI tools for coding and development, actively sharing knowledge with the team. In 12 months: Contribute to data engineering projects, ensuring scalability and performance optimization. Mentor non-technical internal partners to improve company-wide data literacy Contribute to the integration of advanced AI solutions into our development processes, contributing to the company's technological advancement. Physical Requirements: Ability to remain at your designated workstation for the duration of the workday Constantly operates a computer and other office productivity machinery, such as a phone and Voice over Internet Protocol (VoIP). The ability to communicate information and ideas so others will understand. Must be able to exchange accurate information in these situations. The ability to observe details at close range (typically on a computer screen) This position offers the flexibility of remote work at approved locations within the United States. Candidates must have a reliable internet connection and a designated work environment conducive to professional phone calls and sensitive data. Enjoy the convenience and comfort of working remotely while contributing to our team's success. Apply Today If you’re ready to take on challenging problems, contribute to impactful solutions, and grow as a data engineer, we’d love to hear from you. Join us at The Helper Bees and be part of a team that’s making a meaningful difference every day! The Helper Bees is committed to building a workplace where diversity, equity, and inclusion are valued and prioritized. We are an equal opportunity employer that welcomes all qualified applicants without discrimination based on race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or any non-merit based or legally protected grounds. The Helper Bees provides reasonable accommodations to qualified individuals with disabilities during the job application and interview process. To request accommodation, please let your recruiter know. As part of our standard hiring process, selected candidates may be required to undergo a background check and/or drug screen. The Helper Bees adheres to applicable federal, state, and local laws regarding these screenings, and the results will be considered in accordance with applicable regulations. The Helper Bees was recently made aware of a fraudulent entity posing as our organization and requesting personal information. Please be aware of and protect yourself from scams. Visit thehelperbees.com/careers to view all current job openings.</td><td>Description: Join our winning team, recently honored as #67 on Forbes’ list of America’s Best Startup Employers for 2024! About The Helper Bees The Helper Bees’ mission is to help people stay home longer through data-driven services that transform both the payer and the care-recipient experience. At The Helper Bees, we are reshaping how care is delivered to aging individuals by leveraging innovative technology and insightful data solutions. We maintain multiple SaaS products and payment solutions through our web applications (internal and external facing), a mobile app, and reporting integrations. As part of our growing Data Engineering team, you’ll iterate quickly, have a high impact, and be challenged to design and implement cutting-edge solutions. At THB, we define our company culture through our Core Values: Quickly iterate through solutions: We move at a fast pace which requires quick iterations to find a path to a repeatable solution. Seek ways to create immediate impact: Be thoughtful and proactive in how you make an impact on your team. Actively look for ways to make a fast, positive impact. Bee the teammate you want to work with: We work as a team, help each other, and encourage each other. Ask questions, answer questions: You can't iterate through solutions if you don't ask the right questions, which is why there is an expectation that questions should be asked. When you know the answer, being a good teammate means chiming in to get others up to speed. Take the time to celebrate wins: It's so easy for a team that is heads down to forget about all the great things they've accomplished. That's why we make it a priority to remind ourselves to create space to celebrate wins, big or small. Job Summary We are seeking a motivated Data Engineer to join our team and help improve our tools, processes, and technical infrastructure. In this role, you will ensure the availability and quality of our data while contributing to the design, implementation, and maintenance of The Helper Bees’ products. You’ll collaborate across teams to create scalable and optimized software systems and play a key role in refining our development processes. This position offers a unique opportunity to learn and leverage cutting-edge AI development tools to enhance coding efficiency and develop advanced data tools and solutions. Supervisory Responsibilities: None Key Responsibilities Data Infrastructure: Design, implement, and maintain data pipelines, ensuring data availability, quality, and scalability. Product Development: Build and enhance products using Python, SQL, and modern technologies. AI Integration: Leverage cutting-edge AI tools, including Cursor, ChatGPT, and Claude to improve development processes, automate workflows, and create innovative data solutions. Collaboration: Communicate across departments to design, build, test, and implement new features and enhancements. Code Excellence: Produce quality, testable, and maintainable code while participating in code reviews. Problem Solving: Debug complex issues, interact with stakeholders, and design viable solutions with clear trade-offs. Process Optimization: Contribute to improving development processes, including deployment, on-call systems, and sprint planning. Team Growth: Collaborate within the development team to help each other grow and continuously learn. Stakeholder Engagement: Partner with analysts, scientists, and IT to ensure alignment and deliver data-driven solutions. Other duties as assigned/necessary Performance Metrics Code Quality: Maintain high coding standards through regular code reviews and adherence to best practices. Development Efficiency: Deliver high-quality features and fixes within efficient timeframes. Bug Resolution Time: Reduce the time taken to identify and resolve issues. System Scalability: Optimize system performance to handle increasing user demands. Collaboration: Foster a collaborative environment that encourages teamwork and knowledge sharing. Customer Satisfaction: Incorporate stakeholder feedback to improve solutions and enhance the customer experience. Continuous Learning: Pursue opportunities for skill development and share knowledge with the team. Requirements: Required Skills & Qualifications Technical Tools: Experience with in Python and/or SQL. Experience with Bash, Shell scripting, Big Query, Airflow, and is a plus. Programming: Cleaning data using code-based approach. AI Proficiency: Interest or experience in using AI tools for coding and development of data solutions. Soft Skills: Problem-solving, cross-team collaboration, data storytelling, and stakeholder engagement. Adaptability: Thrives in a fast-paced startup environment and embraces change. Proactivity: Self-directed, organized, and able to prioritize effectively. Collaboration: Ability to work effectively with cross-functional teams. Education & Experience: A bachelor’s degree is required, and a graduate degree is preferred. Relevant experience in data engineering, software development, STEM, or related fields. Strong experience with SQL and Python is highly desirable. Mindset: A passion for innovation, continuous improvement, and delivering high-quality results from messy data. Preferred Qualifications Familiarity with cloud-based solutions (e.g., Google Cloud Platform, Azure). Experience with ETL processes and tools. Experience building data visualization reports and dashboards Knowledge of modern data storage solutions and database management systems. Exposure to DevOps practices and tools for deployment and monitoring. Why Join Us? Work with a talented, collaborative team dedicated to making a difference. Gain exposure to innovative technologies and opportunities for growth. Learn and utilize cutting-edge AI tools to enhance your development skills and create impactful solutions. Be part of a company that values your contributions and encourages professional development. Join a rapidly expanding health-tech startup (~200 employees and growing) with a state-of-the-art technology office located in Hyde Park, offering a variety of exceptional benefits. Career Progression Timeline In 3 months: Gain a comprehensive understanding of our data infrastructure, technical stacks, and development cycles. Actively participate in team meetings and contribute to the development of new data pipelines. Begin leveraging AI tools, such as Cursor and ChatGPT, to enhance coding efficiency and workflow automation. In 6 months: Contribute to product enhancements and data reporting Collaborate effectively with cross-functional teams, providing insights and solutions for data-related challenges. Demonstrate proficiency in utilizing AI tools for coding and development, actively sharing knowledge with the team. In 12 months: Contribute to data engineering projects, ensuring scalability and performance optimization. Mentor non-technical internal partners to improve company-wide data literacy Contribute to the integration of advanced AI solutions into our development processes, contributing to the company's technological advancement. Physical Requirements: Ability to remain at your designated workstation for the duration of the workday Constantly operates a computer and other office productivity machinery, such as a phone and Voice over Internet Protocol (VoIP). The ability to communicate information and ideas so others will understand. Must be able to exchange accurate information in these situations. The ability to observe details at close range (typically on a computer screen) This position offers the flexibility of remote work at approved locations within the United States. Candidates must have a reliable internet connection and a designated work environment conducive to professional phone calls and sensitive data. Enjoy the convenience and comfort of working remotely while contributing to our team's success. Apply Today If you’re ready to take on challenging problems, contribute to impactful solutions, and grow as a data engineer, we’d love to hear from you. Join us at The Helper Bees and be part of a team that’s making a meaningful difference every day! The Helper Bees is committed to building a workplace where diversity, equity, and inclusion are valued and prioritized. We are an equal opportunity employer that welcomes all qualified applicants without discrimination based on race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or any non-merit based or legally protected grounds. The Helper Bees provides reasonable accommodations to qualified individuals with disabilities during the job application and interview process. To request accommodation, please let your recruiter know. As part of our standard hiring process, selected candidates may be required to undergo a background check and/or drug screen. The Helper Bees adheres to applicable federal, state, and local laws regarding these screenings, and the results will be considered in accordance with applicable regulations. The Helper Bees was recently made aware of a fraudulent entity posing as our organization and requesting personal information. Please be aware of and protect yourself from scams. Visit thehelperbees.com/careers to view all current job openings.</td><td>Technical Tools: Experience with in Python and/or SQL. Experience with Bash, Shell scripting, Big Query, Airflow, and is a plus. Programming: Cleaning data using code-based approach. AI Proficiency: Interest or experience in using AI tools for coding and development of data solutions. Soft Skills: Problem-solving, cross-team collaboration, data storytelling, and stakeholder engagement. Adaptability: Thrives in a fast-paced startup environment and embraces change. Proactivity: Self-directed, organized, and able to prioritize effectively. Collaboration: Ability to work effectively with cross-functional teams. Education & Experience: A bachelor’s degree is required, and a graduate degree is preferred. Relevant experience in data engineering, software development, STEM, or related fields. Strong experience with SQL and Python is highly desirable. Mindset: A passion for innovation, continuous improvement, and delivering high-quality results from messy data. Preferred Qualifications Familiarity with cloud-based solutions (e.g., Google Cloud Platform, Azure). Experience with ETL processes and tools. Experience building data visualization reports and dashboards Knowledge of modern data storage solutions and database management systems. Exposure to DevOps practices and tools for deployment and monitoring. Why Join Us? Work with a talented, collaborative team dedicated to making a difference. Gain exposure to innovative technologies and opportunities for growth. Learn and utilize cutting-edge AI tools to enhance your development skills and create impactful solutions. Be part of a company that values your contributions and encourages professional development. Join a rapidly expanding health-tech startup (~200 employees and growing) with a state-of-the-art technology office located in Hyde Park, offering a variety of exceptional benefits. Career Progression Timeline In 3 months: Gain a comprehensive understanding of our data infrastructure, technical stacks, and development cycles. Actively participate in team meetings and contribute to the development of new data pipelines. Begin leveraging AI tools, such as Cursor and ChatGPT, to enhance coding efficiency and workflow automation. In 6 months: Contribute to product enhancements and data reporting Collaborate effectively with cross-functional teams, providing insights and solutions for data-related challenges. Demonstrate proficiency in utilizing AI tools for coding and development, actively sharing knowledge with the team. In 12 months: Contribute to data engineering projects, ensuring scalability and performance optimization. Mentor non-technical internal partners to improve company-wide data literacy Contribute to the integration of advanced AI solutions into our development processes, contributing to the company's technological advancement. Physical Requirements: Ability to remain at your designated workstation for the duration of the workday Constantly operates a computer and other office productivity machinery, such as a phone and Voice over Internet Protocol (VoIP). The ability to communicate information and ideas so others will understand. Must be able to exchange accurate information in these situations. The ability to observe details at close range (typically on a computer screen) This position offers the flexibility of remote work at approved locations within the United States. Candidates must have a reliable internet connection and a designated work environment conducive to professional phone calls and sensitive data. Enjoy the convenience and comfort of working remotely while contributing to our team's success. Apply Today If you’re ready to take on challenging problems, contribute to impactful solutions, and grow as a data engineer, we’d love to hear from you. Join us at The Helper Bees and be part of a team that’s making a meaningful difference every day! The Helper Bees is committed to building a workplace where diversity, equity, and inclusion are valued and prioritized. We are an equal opportunity employer that welcomes all qualified applicants without discrimination based on race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or any non-merit based or legally protected grounds. The Helper Bees provides reasonable accommodations to qualified individuals with disabilities during the job application and interview process. To request accommodation, please let your recruiter know. As part of our standard hiring process, selected candidates may be required to undergo a background check and/or drug screen. The Helper Bees adheres to applicable federal, state, and local laws regarding these screenings, and the results will be considered in accordance with applicable regulations. The Helper Bees was recently made aware of a fraudulent entity posing as our organization and requesting personal information. Please be aware of and protect yourself from scams. Visit thehelperbees.com/careers to view all current job openings.</td><td>698</td></tr><tr><td>:</td><td>Curacao</td><td>Description: Join our winning team, recently honored as #67 on Forbes’ list of America’s Best Startup Employers for 2024! About The Helper Bees The Helper Bees’ mission is to help people stay home longer through data-driven services that transform both the payer and the care-recipient experience. At The Helper Bees, we are reshaping how care is delivered to aging individuals by leveraging innovative technology and insightful data solutions. We maintain multiple SaaS products and payment solutions through our web applications (internal and external facing), a mobile app, and reporting integrations. As part of our growing Data Engineering team, you’ll iterate quickly, have a high impact, and be challenged to design and implement cutting-edge solutions. At THB, we define our company culture through our Core Values: Quickly iterate through solutions: We move at a fast pace which requires quick iterations to find a path to a repeatable solution. Seek ways to create immediate impact: Be thoughtful and proactive in how you make an impact on your team. Actively look for ways to make a fast, positive impact. Bee the teammate you want to work with: We work as a team, help each other, and encourage each other. Ask questions, answer questions: You can't iterate through solutions if you don't ask the right questions, which is why there is an expectation that questions should be asked. When you know the answer, being a good teammate means chiming in to get others up to speed. Take the time to celebrate wins: It's so easy for a team that is heads down to forget about all the great things they've accomplished. That's why we make it a priority to remind ourselves to create space to celebrate wins, big or small. Job Summary We are seeking a motivated Data Engineer to join our team and help improve our tools, processes, and technical infrastructure. In this role, you will ensure the availability and quality of our data while contributing to the design, implementation, and maintenance of The Helper Bees’ products. You’ll collaborate across teams to create scalable and optimized software systems and play a key role in refining our development processes. This position offers a unique opportunity to learn and leverage cutting-edge AI development tools to enhance coding efficiency and develop advanced data tools and solutions. Supervisory Responsibilities: None Key Responsibilities Data Infrastructure: Design, implement, and maintain data pipelines, ensuring data availability, quality, and scalability. Product Development: Build and enhance products using Python, SQL, and modern technologies. AI Integration: Leverage cutting-edge AI tools, including Cursor, ChatGPT, and Claude to improve development processes, automate workflows, and create innovative data solutions. Collaboration: Communicate across departments to design, build, test, and implement new features and enhancements. Code Excellence: Produce quality, testable, and maintainable code while participating in code reviews. Problem Solving: Debug complex issues, interact with stakeholders, and design viable solutions with clear trade-offs. Process Optimization: Contribute to improving development processes, including deployment, on-call systems, and sprint planning. Team Growth: Collaborate within the development team to help each other grow and continuously learn. Stakeholder Engagement: Partner with analysts, scientists, and IT to ensure alignment and deliver data-driven solutions. Other duties as assigned/necessary Performance Metrics Code Quality: Maintain high coding standards through regular code reviews and adherence to best practices. Development Efficiency: Deliver high-quality features and fixes within efficient timeframes. Bug Resolution Time: Reduce the time taken to identify and resolve issues. System Scalability: Optimize system performance to handle increasing user demands. Collaboration: Foster a collaborative environment that encourages teamwork and knowledge sharing. Customer Satisfaction: Incorporate stakeholder feedback to improve solutions and enhance the customer experience. Continuous Learning: Pursue opportunities for skill development and share knowledge with the team. Requirements: Required Skills & Qualifications Technical Tools: Experience with in Python and/or SQL. Experience with Bash, Shell scripting, Big Query, Airflow, and is a plus. Programming: Cleaning data using code-based approach. AI Proficiency: Interest or experience in using AI tools for coding and development of data solutions. Soft Skills: Problem-solving, cross-team collaboration, data storytelling, and stakeholder engagement. Adaptability: Thrives in a fast-paced startup environment and embraces change. Proactivity: Self-directed, organized, and able to prioritize effectively. Collaboration: Ability to work effectively with cross-functional teams. Education & Experience: A bachelor’s degree is required, and a graduate degree is preferred. Relevant experience in data engineering, software development, STEM, or related fields. Strong experience with SQL and Python is highly desirable. Mindset: A passion for innovation, continuous improvement, and delivering high-quality results from messy data. Preferred Qualifications Familiarity with cloud-based solutions (e.g., Google Cloud Platform, Azure). Experience with ETL processes and tools. Experience building data visualization reports and dashboards Knowledge of modern data storage solutions and database management systems. Exposure to DevOps practices and tools for deployment and monitoring. Why Join Us? Work with a talented, collaborative team dedicated to making a difference. Gain exposure to innovative technologies and opportunities for growth. Learn and utilize cutting-edge AI tools to enhance your development skills and create impactful solutions. Be part of a company that values your contributions and encourages professional development. Join a rapidly expanding health-tech startup (~200 employees and growing) with a state-of-the-art technology office located in Hyde Park, offering a variety of exceptional benefits. Career Progression Timeline In 3 months: Gain a comprehensive understanding of our data infrastructure, technical stacks, and development cycles. Actively participate in team meetings and contribute to the development of new data pipelines. Begin leveraging AI tools, such as Cursor and ChatGPT, to enhance coding efficiency and workflow automation. In 6 months: Contribute to product enhancements and data reporting Collaborate effectively with cross-functional teams, providing insights and solutions for data-related challenges. Demonstrate proficiency in utilizing AI tools for coding and development, actively sharing knowledge with the team. In 12 months: Contribute to data engineering projects, ensuring scalability and performance optimization. Mentor non-technical internal partners to improve company-wide data literacy Contribute to the integration of advanced AI solutions into our development processes, contributing to the company's technological advancement. Physical Requirements: Ability to remain at your designated workstation for the duration of the workday Constantly operates a computer and other office productivity machinery, such as a phone and Voice over Internet Protocol (VoIP). The ability to communicate information and ideas so others will understand. Must be able to exchange accurate information in these situations. The ability to observe details at close range (typically on a computer screen) This position offers the flexibility of remote work at approved locations within the United States. Candidates must have a reliable internet connection and a designated work environment conducive to professional phone calls and sensitive data. Enjoy the convenience and comfort of working remotely while contributing to our team's success. Apply Today If you’re ready to take on challenging problems, contribute to impactful solutions, and grow as a data engineer, we’d love to hear from you. Join us at The Helper Bees and be part of a team that’s making a meaningful difference every day! The Helper Bees is committed to building a workplace where diversity, equity, and inclusion are valued and prioritized. We are an equal opportunity employer that welcomes all qualified applicants without discrimination based on race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or any non-merit based or legally protected grounds. The Helper Bees provides reasonable accommodations to qualified individuals with disabilities during the job application and interview process. To request accommodation, please let your recruiter know. As part of our standard hiring process, selected candidates may be required to undergo a background check and/or drug screen. The Helper Bees adheres to applicable federal, state, and local laws regarding these screenings, and the results will be considered in accordance with applicable regulations. The Helper Bees was recently made aware of a fraudulent entity posing as our organization and requesting personal information. Please be aware of and protect yourself from scams. Visit thehelperbees.com/careers to view all current job openings.</td><td>data</td><td>Description: Join our winning team, recently honored as #67 on Forbes’ list of America’s Best Startup Employers for 2024! About The Helper Bees The Helper Bees’ mission is to help people stay home longer through data-driven services that transform both the payer and the care-recipient experience. At The Helper Bees, we are reshaping how care is delivered to aging individuals by leveraging innovative technology and insightful data solutions. We maintain multiple SaaS products and payment solutions through our web applications (internal and external facing), a mobile app, and reporting integrations. As part of our growing Data Engineering team, you’ll iterate quickly, have a high impact, and be challenged to design and implement cutting-edge solutions. At THB, we define our company culture through our Core Values: Quickly iterate through solutions: We move at a fast pace which requires quick iterations to find a path to a repeatable solution. Seek ways to create immediate impact: Be thoughtful and proactive in how you make an impact on your team. Actively look for ways to make a fast, positive impact. Bee the teammate you want to work with: We work as a team, help each other, and encourage each other. Ask questions, answer questions: You can't iterate through solutions if you don't ask the right questions, which is why there is an expectation that questions should be asked. When you know the answer, being a good teammate means chiming in to get others up to speed. Take the time to celebrate wins: It's so easy for a team that is heads down to forget about all the great things they've accomplished. That's why we make it a priority to remind ourselves to create space to celebrate wins, big or small. Job Summary We are seeking a motivated Data Engineer to join our team and help improve our tools, processes, and technical infrastructure. In this role, you will ensure the availability and quality of our data while contributing to the design, implementation, and maintenance of The Helper Bees’ products. You’ll collaborate across teams to create scalable and optimized software systems and play a key role in refining our development processes. This position offers a unique opportunity to learn and leverage cutting-edge AI development tools to enhance coding efficiency and develop advanced data tools and solutions. Supervisory Responsibilities: None Key Responsibilities Data Infrastructure: Design, implement, and maintain data pipelines, ensuring data availability, quality, and scalability. Product Development: Build and enhance products using Python, SQL, and modern technologies. AI Integration: Leverage cutting-edge AI tools, including Cursor, ChatGPT, and Claude to improve development processes, automate workflows, and create innovative data solutions. Collaboration: Communicate across departments to design, build, test, and implement new features and enhancements. Code Excellence: Produce quality, testable, and maintainable code while participating in code reviews. Problem Solving: Debug complex issues, interact with stakeholders, and design viable solutions with clear trade-offs. Process Optimization: Contribute to improving development processes, including deployment, on-call systems, and sprint planning. Team Growth: Collaborate within the development team to help each other grow and continuously learn. Stakeholder Engagement: Partner with analysts, scientists, and IT to ensure alignment and deliver data-driven solutions. Other duties as assigned/necessary Performance Metrics Code Quality: Maintain high coding standards through regular code reviews and adherence to best practices. Development Efficiency: Deliver high-quality features and fixes within efficient timeframes. Bug Resolution Time: Reduce the time taken to identify and resolve issues. System Scalability: Optimize system performance to handle increasing user demands. Collaboration: Foster a collaborative environment that encourages teamwork and knowledge sharing. Customer Satisfaction: Incorporate stakeholder feedback to improve solutions and enhance the customer experience. Continuous Learning: Pursue opportunities for skill development and share knowledge with the team. Requirements: Required Skills & Qualifications Technical Tools: Experience with in Python and/or SQL. Experience with Bash, Shell scripting, Big Query, Airflow, and is a plus. Programming: Cleaning data using code-based approach. AI Proficiency: Interest or experience in using AI tools for coding and development of data solutions. Soft Skills: Problem-solving, cross-team collaboration, data storytelling, and stakeholder engagement. Adaptability: Thrives in a fast-paced startup environment and embraces change. Proactivity: Self-directed, organized, and able to prioritize effectively. Collaboration: Ability to work effectively with cross-functional teams. Education & Experience: A bachelor’s degree is required, and a graduate degree is preferred. Relevant experience in data engineering, software development, STEM, or related fields. Strong experience with SQL and Python is highly desirable. Mindset: A passion for innovation, continuous improvement, and delivering high-quality results from messy data. Preferred Qualifications Familiarity with cloud-based solutions (e.g., Google Cloud Platform, Azure). Experience with ETL processes and tools. Experience building data visualization reports and dashboards Knowledge of modern data storage solutions and database management systems. Exposure to DevOps practices and tools for deployment and monitoring. Why Join Us? Work with a talented, collaborative team dedicated to making a difference. Gain exposure to innovative technologies and opportunities for growth. Learn and utilize cutting-edge AI tools to enhance your development skills and create impactful solutions. Be part of a company that values your contributions and encourages professional development. Join a rapidly expanding health-tech startup (~200 employees and growing) with a state-of-the-art technology office located in Hyde Park, offering a variety of exceptional benefits. Career Progression Timeline In 3 months: Gain a comprehensive understanding of our data infrastructure, technical stacks, and development cycles. Actively participate in team meetings and contribute to the development of new data pipelines. Begin leveraging AI tools, such as Cursor and ChatGPT, to enhance coding efficiency and workflow automation. In 6 months: Contribute to product enhancements and data reporting Collaborate effectively with cross-functional teams, providing insights and solutions for data-related challenges. Demonstrate proficiency in utilizing AI tools for coding and development, actively sharing knowledge with the team. In 12 months: Contribute to data engineering projects, ensuring scalability and performance optimization. Mentor non-technical internal partners to improve company-wide data literacy Contribute to the integration of advanced AI solutions into our development processes, contributing to the company's technological advancement. Physical Requirements: Ability to remain at your designated workstation for the duration of the workday Constantly operates a computer and other office productivity machinery, such as a phone and Voice over Internet Protocol (VoIP). The ability to communicate information and ideas so others will understand. Must be able to exchange accurate information in these situations. The ability to observe details at close range (typically on a computer screen) This position offers the flexibility of remote work at approved locations within the United States. Candidates must have a reliable internet connection and a designated work environment conducive to professional phone calls and sensitive data. Enjoy the convenience and comfort of working remotely while contributing to our team's success. Apply Today If you’re ready to take on challenging problems, contribute to impactful solutions, and grow as a data engineer, we’d love to hear from you. Join us at The Helper Bees and be part of a team that’s making a meaningful difference every day! The Helper Bees is committed to building a workplace where diversity, equity, and inclusion are valued and prioritized. We are an equal opportunity employer that welcomes all qualified applicants without discrimination based on race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or any non-merit based or legally protected grounds. The Helper Bees provides reasonable accommodations to qualified individuals with disabilities during the job application and interview process. To request accommodation, please let your recruiter know. As part of our standard hiring process, selected candidates may be required to undergo a background check and/or drug screen. The Helper Bees adheres to applicable federal, state, and local laws regarding these screenings, and the results will be considered in accordance with applicable regulations. The Helper Bees was recently made aware of a fraudulent entity posing as our organization and requesting personal information. Please be aware of and protect yourself from scams. Visit thehelperbees.com/careers to view all current job openings.</td><td>Description: Join our winning team, recently honored as #67 on Forbes’ list of America’s Best Startup Employers for 2024! About The Helper Bees The Helper Bees’ mission is to help people stay home longer through data-driven services that transform both the payer and the care-recipient experience. At The Helper Bees, we are reshaping how care is delivered to aging individuals by leveraging innovative technology and insightful data solutions. We maintain multiple SaaS products and payment solutions through our web applications (internal and external facing), a mobile app, and reporting integrations. As part of our growing Data Engineering team, you’ll iterate quickly, have a high impact, and be challenged to design and implement cutting-edge solutions. At THB, we define our company culture through our Core Values: Quickly iterate through solutions: We move at a fast pace which requires quick iterations to find a path to a repeatable solution. Seek ways to create immediate impact: Be thoughtful and proactive in how you make an impact on your team. Actively look for ways to make a fast, positive impact. Bee the teammate you want to work with: We work as a team, help each other, and encourage each other. Ask questions, answer questions: You can't iterate through solutions if you don't ask the right questions, which is why there is an expectation that questions should be asked. When you know the answer, being a good teammate means chiming in to get others up to speed. Take the time to celebrate wins: It's so easy for a team that is heads down to forget about all the great things they've accomplished. That's why we make it a priority to remind ourselves to create space to celebrate wins, big or small. Job Summary We are seeking a motivated Data Engineer to join our team and help improve our tools, processes, and technical infrastructure. In this role, you will ensure the availability and quality of our data while contributing to the design, implementation, and maintenance of The Helper Bees’ products. You’ll collaborate across teams to create scalable and optimized software systems and play a key role in refining our development processes. This position offers a unique opportunity to learn and leverage cutting-edge AI development tools to enhance coding efficiency and develop advanced data tools and solutions. Supervisory Responsibilities: None Key Responsibilities Data Infrastructure: Design, implement, and maintain data pipelines, ensuring data availability, quality, and scalability. Product Development: Build and enhance products using Python, SQL, and modern technologies. AI Integration: Leverage cutting-edge AI tools, including Cursor, ChatGPT, and Claude to improve development processes, automate workflows, and create innovative data solutions. Collaboration: Communicate across departments to design, build, test, and implement new features and enhancements. Code Excellence: Produce quality, testable, and maintainable code while participating in code reviews. Problem Solving: Debug complex issues, interact with stakeholders, and design viable solutions with clear trade-offs. Process Optimization: Contribute to improving development processes, including deployment, on-call systems, and sprint planning. Team Growth: Collaborate within the development team to help each other grow and continuously learn. Stakeholder Engagement: Partner with analysts, scientists, and IT to ensure alignment and deliver data-driven solutions. Other duties as assigned/necessary Performance Metrics Code Quality: Maintain high coding standards through regular code reviews and adherence to best practices. Development Efficiency: Deliver high-quality features and fixes within efficient timeframes. Bug Resolution Time: Reduce the time taken to identify and resolve issues. System Scalability: Optimize system performance to handle increasing user demands. Collaboration: Foster a collaborative environment that encourages teamwork and knowledge sharing. Customer Satisfaction: Incorporate stakeholder feedback to improve solutions and enhance the customer experience. Continuous Learning: Pursue opportunities for skill development and share knowledge with the team. Requirements: Required Skills & Qualifications Technical Tools: Experience with in Python and/or SQL. Experience with Bash, Shell scripting, Big Query, Airflow, and is a plus. Programming: Cleaning data using code-based approach. AI Proficiency: Interest or experience in using AI tools for coding and development of data solutions. Soft Skills: Problem-solving, cross-team collaboration, data storytelling, and stakeholder engagement. Adaptability: Thrives in a fast-paced startup environment and embraces change. Proactivity: Self-directed, organized, and able to prioritize effectively. Collaboration: Ability to work effectively with cross-functional teams. Education & Experience: A bachelor’s degree is required, and a graduate degree is preferred. Relevant experience in data engineering, software development, STEM, or related fields. Strong experience with SQL and Python is highly desirable. Mindset: A passion for innovation, continuous improvement, and delivering high-quality results from messy data. Preferred Qualifications Familiarity with cloud-based solutions (e.g., Google Cloud Platform, Azure). Experience with ETL processes and tools. Experience building data visualization reports and dashboards Knowledge of modern data storage solutions and database management systems. Exposure to DevOps practices and tools for deployment and monitoring. Why Join Us? Work with a talented, collaborative team dedicated to making a difference. Gain exposure to innovative technologies and opportunities for growth. Learn and utilize cutting-edge AI tools to enhance your development skills and create impactful solutions. Be part of a company that values your contributions and encourages professional development. Join a rapidly expanding health-tech startup (~200 employees and growing) with a state-of-the-art technology office located in Hyde Park, offering a variety of exceptional benefits. Career Progression Timeline In 3 months: Gain a comprehensive understanding of our data infrastructure, technical stacks, and development cycles. Actively participate in team meetings and contribute to the development of new data pipelines. Begin leveraging AI tools, such as Cursor and ChatGPT, to enhance coding efficiency and workflow automation. In 6 months: Contribute to product enhancements and data reporting Collaborate effectively with cross-functional teams, providing insights and solutions for data-related challenges. Demonstrate proficiency in utilizing AI tools for coding and development, actively sharing knowledge with the team. In 12 months: Contribute to data engineering projects, ensuring scalability and performance optimization. Mentor non-technical internal partners to improve company-wide data literacy Contribute to the integration of advanced AI solutions into our development processes, contributing to the company's technological advancement. Physical Requirements: Ability to remain at your designated workstation for the duration of the workday Constantly operates a computer and other office productivity machinery, such as a phone and Voice over Internet Protocol (VoIP). The ability to communicate information and ideas so others will understand. Must be able to exchange accurate information in these situations. The ability to observe details at close range (typically on a computer screen) This position offers the flexibility of remote work at approved locations within the United States. Candidates must have a reliable internet connection and a designated work environment conducive to professional phone calls and sensitive data. Enjoy the convenience and comfort of working remotely while contributing to our team's success. Apply Today If you’re ready to take on challenging problems, contribute to impactful solutions, and grow as a data engineer, we’d love to hear from you. Join us at The Helper Bees and be part of a team that’s making a meaningful difference every day! The Helper Bees is committed to building a workplace where diversity, equity, and inclusion are valued and prioritized. We are an equal opportunity employer that welcomes all qualified applicants without discrimination based on race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or any non-merit based or legally protected grounds. The Helper Bees provides reasonable accommodations to qualified individuals with disabilities during the job application and interview process. To request accommodation, please let your recruiter know. As part of our standard hiring process, selected candidates may be required to undergo a background check and/or drug screen. The Helper Bees adheres to applicable federal, state, and local laws regarding these screenings, and the results will be considered in accordance with applicable regulations. The Helper Bees was recently made aware of a fraudulent entity posing as our organization and requesting personal information. Please be aware of and protect yourself from scams. Visit thehelperbees.com/careers to view all current job openings.</td><td>Technical Tools: Experience with in Python and/or SQL. Experience with Bash, Shell scripting, Big Query, Airflow, and is a plus. Programming: Cleaning data using code-based approach. AI Proficiency: Interest or experience in using AI tools for coding and development of data solutions. Soft Skills: Problem-solving, cross-team collaboration, data storytelling, and stakeholder engagement. Adaptability: Thrives in a fast-paced startup environment and embraces change. Proactivity: Self-directed, organized, and able to prioritize effectively. Collaboration: Ability to work effectively with cross-functional teams. Education & Experience: A bachelor’s degree is required, and a graduate degree is preferred. Relevant experience in data engineering, software development, STEM, or related fields. Strong experience with SQL and Python is highly desirable. Mindset: A passion for innovation, continuous improvement, and delivering high-quality results from messy data. Preferred Qualifications Familiarity with cloud-based solutions (e.g., Google Cloud Platform, Azure). Experience with ETL processes and tools. Experience building data visualization reports and dashboards Knowledge of modern data storage solutions and database management systems. Exposure to DevOps practices and tools for deployment and monitoring. Why Join Us? Work with a talented, collaborative team dedicated to making a difference. Gain exposure to innovative technologies and opportunities for growth. Learn and utilize cutting-edge AI tools to enhance your development skills and create impactful solutions. Be part of a company that values your contributions and encourages professional development. Join a rapidly expanding health-tech startup (~200 employees and growing) with a state-of-the-art technology office located in Hyde Park, offering a variety of exceptional benefits. Career Progression Timeline In 3 months: Gain a comprehensive understanding of our data infrastructure, technical stacks, and development cycles. Actively participate in team meetings and contribute to the development of new data pipelines. Begin leveraging AI tools, such as Cursor and ChatGPT, to enhance coding efficiency and workflow automation. In 6 months: Contribute to product enhancements and data reporting Collaborate effectively with cross-functional teams, providing insights and solutions for data-related challenges. Demonstrate proficiency in utilizing AI tools for coding and development, actively sharing knowledge with the team. In 12 months: Contribute to data engineering projects, ensuring scalability and performance optimization. Mentor non-technical internal partners to improve company-wide data literacy Contribute to the integration of advanced AI solutions into our development processes, contributing to the company's technological advancement. Physical Requirements: Ability to remain at your designated workstation for the duration of the workday Constantly operates a computer and other office productivity machinery, such as a phone and Voice over Internet Protocol (VoIP). The ability to communicate information and ideas so others will understand. Must be able to exchange accurate information in these situations. The ability to observe details at close range (typically on a computer screen) This position offers the flexibility of remote work at approved locations within the United States. Candidates must have a reliable internet connection and a designated work environment conducive to professional phone calls and sensitive data. Enjoy the convenience and comfort of working remotely while contributing to our team's success. Apply Today If you’re ready to take on challenging problems, contribute to impactful solutions, and grow as a data engineer, we’d love to hear from you. Join us at The Helper Bees and be part of a team that’s making a meaningful difference every day! The Helper Bees is committed to building a workplace where diversity, equity, and inclusion are valued and prioritized. We are an equal opportunity employer that welcomes all qualified applicants without discrimination based on race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or any non-merit based or legally protected grounds. The Helper Bees provides reasonable accommodations to qualified individuals with disabilities during the job application and interview process. To request accommodation, please let your recruiter know. As part of our standard hiring process, selected candidates may be required to undergo a background check and/or drug screen. The Helper Bees adheres to applicable federal, state, and local laws regarding these screenings, and the results will be considered in accordance with applicable regulations. The Helper Bees was recently made aware of a fraudulent entity posing as our organization and requesting personal information. Please be aware of and protect yourself from scams. Visit thehelperbees.com/careers to view all current job openings.</td><td>698</td></tr><tr><td>Data Engineer</td><td>Cella</td><td>Index Analytics, LLC, is a rapidly growing, Baltimore-based small business providing health-related consulting services to the federal government. At the center of our company culture is a commitment to instilling a dynamic and employee-friendly place to work. We place a priority on promoting a supportive and collegial team environment and enhancing staff experience through career development and educational opportunities. Position Overview The Data Engineer is responsible for designing, building, and maintaining data pipelines and architectures to support data analytics and reporting needs across the organization. This role involves working closely with data scientists, analysts, and other stakeholders to ensure that data is clean, accessible, and ready for analysis. The Data Engineer will optimize data systems, develop data integration solutions, and ensure data security and governance. Key responsibilities include creating ETL processes, managing databases, and improving data infrastructure performance. The ideal candidate has strong programming and database skills and experience with cloud-based data platforms. Responsibilities Leads design, implementation, and management of data pipelines Develops and executes ETL (extract, transform, load) or ELT code Supports design of robust Data Integration Architecture to support customers Helps monitor and administer the systems and ensures applications and systems are always functioning properly Analyzes the Data Integration and Engineering architecture to identify weaknesses and develops improvements such as enhancing business processes Identifies and analyzes business requirements, functional design, and translation of requirements to technical specifications Performs complex query design, developments, validation routine analysis, and streamlining processes Operates large data sets, delta data sets and querying efficiently Transforms, joins, and normalizes data in service of specific use cases. Employs AWS data pipeline solutions such as Glue, Data Pipeline, Step functions, MWAA to orchestrate data movement Work with DevSecOps engineer to deploy continuous integration and continuous deployment (CI/CD) data pipelines Understand the technical architecture to design, build, optimize, and maintain scalable data solutions in a Big Data environment Work with Product Owners and/or business stakeholders to gather business requirements and translate to detailed technical specifications US citizen or Authorized to Work and lived in the US for 3 of the last 5 years. Must be able to obtain a U.S. Federal government client badge and pass a government Public Trust. Bachelors degree or higher in IT or relevant discipline required 4+ years of IT experience Experience with setting up and operating data pipelines using Python or SQL Experience with Scala and PySpark 3+ years of experience working on AWS, GCP or Azure (AWS Preferred) cloud platforms Hands-on relational DB / NoSQL experience (PostgreSQL or similar) with specific implementation on cloud Experience working with data warehouses such as Redshift to open source and proprietary cloud data pipeline tools such as Airflow, Glue, Data Pipeline, Step functions Experience working with relational databases that handle structured and semi-structured (JSON) datasets Experience with data serialization languages such as JSON, XML, YAML Experience with code management tools (e.g. Git, SVN) and DevOps tools (e.g. Jenkins, Docker, AWS Code Pipeline) Strong analytical problem-solving ability Working experience with Transactional and Dimensional data modeling methodologies (Eg: Normalization, Star Schema, Snowflake Schema) Experience working with a distributed computing environment like AWS EMR or similar. Ability to obtain Public Trust level clearance Ability to demonstrate excellent written and oral communication required Prior experience with Center for Medicare Medicaid Services or other Govt agencies is a plus The salary range provided represents the estimated compensation for new hires in this position, applicable across all locations. Actual offers may vary based on factors such as the candidate's skills, qualifications, experience, and market conditions. Index complements its base salary offering with a competitive package that includes health and retirement benefits, discretionary bonuses, and reimbursement for professional development opportunities. Index Analytics provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training. Attention Candidates We're dedicated to ensuring a safe and transparent recruitment process for all candidates and have implemented robust measures to protect your personal information. Please be aware that all employment-related communications will originate from a secure portal ( NAME@msg.paycomonline.com ) or a corporate email address ( NAME@index-analytics.com ). If you have any concerns, please don't hesitate to reach out to us at recruiting@index-analytics.com</td><td>data</td><td>Index Analytics, LLC, is a rapidly growing, Baltimore-based small business providing health-related consulting services to the federal government. At the center of our company culture is a commitment to instilling a dynamic and employee-friendly place to work. We place a priority on promoting a supportive and collegial team environment and enhancing staff experience through career development and educational opportunities. Position Overview The Data Engineer is responsible for designing, building, and maintaining data pipelines and architectures to support data analytics and reporting needs across the organization. This role involves working closely with data scientists, analysts, and other stakeholders to ensure that data is clean, accessible, and ready for analysis. The Data Engineer will optimize data systems, develop data integration solutions, and ensure data security and governance. Key responsibilities include creating ETL processes, managing databases, and improving data infrastructure performance. The ideal candidate has strong programming and database skills and experience with cloud-based data platforms. Responsibilities Leads design, implementation, and management of data pipelines Develops and executes ETL (extract, transform, load) or ELT code Supports design of robust Data Integration Architecture to support customers Helps monitor and administer the systems and ensures applications and systems are always functioning properly Analyzes the Data Integration and Engineering architecture to identify weaknesses and develops improvements such as enhancing business processes Identifies and analyzes business requirements, functional design, and translation of requirements to technical specifications Performs complex query design, developments, validation routine analysis, and streamlining processes Operates large data sets, delta data sets and querying efficiently Transforms, joins, and normalizes data in service of specific use cases. Employs AWS data pipeline solutions such as Glue, Data Pipeline, Step functions, MWAA to orchestrate data movement Work with DevSecOps engineer to deploy continuous integration and continuous deployment (CI/CD) data pipelines Understand the technical architecture to design, build, optimize, and maintain scalable data solutions in a Big Data environment Work with Product Owners and/or business stakeholders to gather business requirements and translate to detailed technical specifications US citizen or Authorized to Work and lived in the US for 3 of the last 5 years. Must be able to obtain a U.S. Federal government client badge and pass a government Public Trust. Bachelors degree or higher in IT or relevant discipline required 4+ years of IT experience Experience with setting up and operating data pipelines using Python or SQL Experience with Scala and PySpark 3+ years of experience working on AWS, GCP or Azure (AWS Preferred) cloud platforms Hands-on relational DB / NoSQL experience (PostgreSQL or similar) with specific implementation on cloud Experience working with data warehouses such as Redshift to open source and proprietary cloud data pipeline tools such as Airflow, Glue, Data Pipeline, Step functions Experience working with relational databases that handle structured and semi-structured (JSON) datasets Experience with data serialization languages such as JSON, XML, YAML Experience with code management tools (e.g. Git, SVN) and DevOps tools (e.g. Jenkins, Docker, AWS Code Pipeline) Strong analytical problem-solving ability Working experience with Transactional and Dimensional data modeling methodologies (Eg: Normalization, Star Schema, Snowflake Schema) Experience working with a distributed computing environment like AWS EMR or similar. Ability to obtain Public Trust level clearance Ability to demonstrate excellent written and oral communication required Prior experience with Center for Medicare Medicaid Services or other Govt agencies is a plus The salary range provided represents the estimated compensation for new hires in this position, applicable across all locations. Actual offers may vary based on factors such as the candidate's skills, qualifications, experience, and market conditions. Index complements its base salary offering with a competitive package that includes health and retirement benefits, discretionary bonuses, and reimbursement for professional development opportunities. Index Analytics provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training. Attention Candidates We're dedicated to ensuring a safe and transparent recruitment process for all candidates and have implemented robust measures to protect your personal information. Please be aware that all employment-related communications will originate from a secure portal ( NAME@msg.paycomonline.com ) or a corporate email address ( NAME@index-analytics.com ). If you have any concerns, please don't hesitate to reach out to us at recruiting@index-analytics.com</td><td>Index Analytics, LLC, is a rapidly growing, Baltimore-based small business providing health-related consulting services to the federal government. At the center of our company culture is a commitment to instilling a dynamic and employee-friendly place to work. We place a priority on promoting a supportive and collegial team environment and enhancing staff experience through career development and educational opportunities. Position Overview The Data Engineer is responsible for designing, building, and maintaining data pipelines and architectures to support data analytics and reporting needs across the organization. This role involves working closely with data scientists, analysts, and other stakeholders to ensure that data is clean, accessible, and ready for analysis. The Data Engineer will optimize data systems, develop data integration solutions, and ensure data security and governance. Key responsibilities include creating ETL processes, managing databases, and improving data infrastructure performance. The ideal candidate has strong programming and database skills and experience with cloud-based data platforms. Responsibilities Leads design, implementation, and management of data pipelines Develops and executes ETL (extract, transform, load) or ELT code Supports design of robust Data Integration Architecture to support customers Helps monitor and administer the systems and ensures applications and systems are always functioning properly Analyzes the Data Integration and Engineering architecture to identify weaknesses and develops improvements such as enhancing business processes Identifies and analyzes business requirements, functional design, and translation of requirements to technical specifications Performs complex query design, developments, validation routine analysis, and streamlining processes Operates large data sets, delta data sets and querying efficiently Transforms, joins, and normalizes data in service of specific use cases. Employs AWS data pipeline solutions such as Glue, Data Pipeline, Step functions, MWAA to orchestrate data movement Work with DevSecOps engineer to deploy continuous integration and continuous deployment (CI/CD) data pipelines Understand the technical architecture to design, build, optimize, and maintain scalable data solutions in a Big Data environment Work with Product Owners and/or business stakeholders to gather business requirements and translate to detailed technical specifications US citizen or Authorized to Work and lived in the US for 3 of the last 5 years. Must be able to obtain a U.S. Federal government client badge and pass a government Public Trust. Bachelors degree or higher in IT or relevant discipline required 4+ years of IT experience Experience with setting up and operating data pipelines using Python or SQL Experience with Scala and PySpark 3+ years of experience working on AWS, GCP or Azure (AWS Preferred) cloud platforms Hands-on relational DB / NoSQL experience (PostgreSQL or similar) with specific implementation on cloud Experience working with data warehouses such as Redshift to open source and proprietary cloud data pipeline tools such as Airflow, Glue, Data Pipeline, Step functions Experience working with relational databases that handle structured and semi-structured (JSON) datasets Experience with data serialization languages such as JSON, XML, YAML Experience with code management tools (e.g. Git, SVN) and DevOps tools (e.g. Jenkins, Docker, AWS Code Pipeline) Strong analytical problem-solving ability Working experience with Transactional and Dimensional data modeling methodologies (Eg: Normalization, Star Schema, Snowflake Schema) Experience working with a distributed computing environment like AWS EMR or similar. Ability to obtain Public Trust level clearance Ability to demonstrate excellent written and oral communication required Prior experience with Center for Medicare Medicaid Services or other Govt agencies is a plus The salary range provided represents the estimated compensation for new hires in this position, applicable across all locations. Actual offers may vary based on factors such as the candidate's skills, qualifications, experience, and market conditions. Index complements its base salary offering with a competitive package that includes health and retirement benefits, discretionary bonuses, and reimbursement for professional development opportunities. Index Analytics provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training. Attention Candidates We're dedicated to ensuring a safe and transparent recruitment process for all candidates and have implemented robust measures to protect your personal information. Please be aware that all employment-related communications will originate from a secure portal ( NAME@msg.paycomonline.com ) or a corporate email address ( NAME@index-analytics.com ). If you have any concerns, please don't hesitate to reach out to us at recruiting@index-analytics.com</td><td>to technical specifications Performs complex query design, developments, validation routine analysis, and streamlining processes Operates large data sets, delta data sets and querying efficiently Transforms, joins, and normalizes data in service of specific use cases. Employs AWS data pipeline solutions such as Glue, Data Pipeline, Step functions, MWAA to orchestrate data movement Work with DevSecOps engineer to deploy continuous integration and continuous deployment (CI/CD) data pipelines Understand the technical architecture to design, build, optimize, and maintain scalable data solutions in a Big Data environment Work with Product Owners and/or business stakeholders to gather business requirements and translate to detailed technical specifications US citizen or Authorized to Work and lived in the US for 3 of the last 5 years. Must be able to obtain a U.S. Federal government client badge and pass a government Public Trust. Bachelors degree or higher in IT or relevant discipline required 4+ years of IT experience Experience with setting up and operating data pipelines using Python or SQL Experience with Scala and PySpark 3+ years of experience working on AWS, GCP or Azure (AWS Preferred) cloud platforms Hands-on relational DB / NoSQL experience (PostgreSQL or similar) with specific implementation on cloud Experience working with data warehouses such as Redshift to open source and proprietary cloud data pipeline tools such as Airflow, Glue, Data Pipeline, Step functions Experience working with relational databases that handle structured and semi-structured (JSON) datasets Experience with data serialization languages such as JSON, XML, YAML Experience with code management tools (e.g. Git, SVN) and DevOps tools (e.g. Jenkins, Docker, AWS Code Pipeline) Strong analytical problem-solving ability Working experience with Transactional and Dimensional data modeling methodologies (Eg: Normalization, Star Schema, Snowflake Schema) Experience working with a distributed computing environment like AWS EMR or similar. Ability to obtain Public Trust level clearance Ability to demonstrate excellent written and oral communication required Prior experience with Center for Medicare Medicaid Services or other Govt agencies is a plus The salary range provided represents the estimated compensation for new hires in this position, applicable across all locations. Actual offers may vary based on factors such as the candidate's skills, qualifications, experience, and market conditions. Index complements its base salary offering with a competitive package that includes health and retirement benefits, discretionary bonuses, and reimbursement for professional development opportunities. Index Analytics provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training. Attention Candidates We're dedicated to ensuring a safe and transparent recruitment process for all candidates and have implemented robust measures to protect your personal information. Please be aware that all employment-related communications will originate from a secure portal ( NAME@msg.paycomonline.com ) or a corporate email address ( NAME@index-analytics.com ). If you have any concerns, please don't hesitate to reach out to us at recruiting@index-analytics.com</td><td>524</td></tr><tr><td>Data Engineer</td><td>Intone Networks</td><td>About Tixr Tixr's on a mission to transform the ticket buying experience with a modern approach to a legacy business. Born from a fan-focused frame of mind, we empower large-scale events, music venues, and sports properties with modern, innovative solutions to their highly-complex ticketing and e-commerce needs. Our unified commerce platform is built for big, supporting all types of events, from festivals to global arena tours, and an almost limitless suite of commerce offerings beyond admission tickets. The Opportunity As our Data Engineer, you will play a crucial role in building and maintaining scalable, reliable, and secure data platforms to support our growing business. You'll work closely with data scientists, analysts, and engineers to design, develop, and optimize data pipelines and infrastructure. You will be joining a passionate team that continually pushes the boundaries of technology. Work-Life This role is 100% remote with an optional work environment at our Santa Monica office, located on the 3rd Street Promenade. Most teams run West Coast Hours with lots of autonomy. At this time we are only able to hire US Citizens or active US Green Card holders Skills & Qualifications Deep knowledge and experience with architectures for modern data infrastructure including data lakes, data warehouses, ETL pipelines, physical and logical data formats, data processing systems, data reliability, security, governance, and performance Work to improve and migrate existing code to improve performance, making deliberate and thoughtful tradeoffs where necessary. Extensive knowledge of different kinds of data stores (row-oriented, columnar, key/value, document, graph, etc.) and their use cases and tradeoffs Proficiency with various big data technologies including BigQuery, Redshift, Parquet, Spark, AWS Glue, Expertise in Java (Hibernate) Be independently responsible for the entire lifecycle of projects and systems, including design, development, and deployment High standards and expectations for software development, excellent written and verbal communication skills Strive to write elegant and maintainable code; comfortable picking up new technologies. You break down complex projects into simple systems that can be built and maintained by less experienced engineers You are proficient in working with distributed systems and have experience with different distributed processing frameworks that can handle data in batch and real-time Preferred Skills & Qualifications 5+ Years experience as a Software Engineer (Java preferred) with a focus on data 5+ Years experience working with distributed ingestion, processing, storage, and access of big data (bonus points for experience with AI/ML) 5+ Years experience with MySQL, Couchbase, Kafka, SageMaker 7+ Years experience leveraging tools and infrastructure provided by GCP and AWS The Perks Salary Range $130,000 - $180,000 + Bonus + Equity 100% Remote with Hybrid Optional Paid Health Benefits ($0 Premiums) Dental, Vision, Life plans Open Vacation 401k (50% match up to 3%) Paid Equipment Education Stipend Paid Holidays & Birthdays Off Parental Leave Team Offsites / Events Ticket hookups! Tixr is the largest, fastest-growing, privately-held primary ticketing and live event commerce marketplace in the world. We're a California born and bred company that's still founder owned and led to this day, and we support a global client base with staff throughout the US, Canada, and UK. We exclusively power 500 of the most respected live entertainment brands in 40 countries including LIV Golf, Wynn Nightlife, Riot Fest, Acura Grand Prix of Long Beach, Riot Games Arena, Luke Bryan’s Crash My Playa, Sturgis Buffalo Chip, Lightning in a Bottle, Portland Trail Blazers’ New G League Affiliate Rip City Remix, among many others. The pay range for this role is: 130,000 - 180,000 USD per year(Remote - United States) Title: Data Analytics Engineer Company: CardWorks URL: https://www.indeed.com/pagead/clk?mo=r&ad=-6NYlbfkN0BUbgFVVy_VKxKTM2USS09L-3kZv-F7kRpUqr0tB56vVP1i0xMkFj6KFckr2xoFpzjy4zfMSvjzthGntWDePJBN3xFIOUFM_Aoy8lY5wPHJc1SE7LWJshEMPhiobbMYtrxJzOsBUeWF8pdypcGyj4tc_97LJgH4X5Scy0Qpd8ThJnrYJOf9aFnVzfqj1sYm8-WGy_BxHzy0ja_6-B1p9BXqCST3QCLFqoUSNsgcOrg-u8QYnm3qZqNLPCQHA3hHsULSEOjx3XPO4U3YOZ49uBUTDRB8CyRW4Bjj1F_wbIHsQsUmd-vlrRBuHOpP9O3M64YAOyk7G3pgUFjRhX2myyeaGH54TybJ41The_fDTqYCRWkV-tltYwJ2AollXjkzguA0RxKe_2eWI5nX2Z27WXeXc9S1EV8kMD4f-5gRro3serTOAHTb11anERGDT4_2Jg6W15LoaA8wqbVs5iM0u9gMYMF9pwg0rIU7O8HqNBdIABTDb2Kfggyn1MfpaT76RIPIYYDb4BrZ4rD8bdg6JCiKutRMpe3MIpLHPjPxpFn7f9Br6bmGBi65bfHlCNXtwil1eIJk7P7afhZwo23v1UHgW72MhGh5ndqV9MSZCQ7NMmLz0rVbe0SM4W07-mAKYogvYYXeYLpS5Z0zeQeyCNZi&xkcb=SoAJ6_M33zDWevR-pR0LbzkdCdPP&camk=CPChkbYSGj-8rrWl1YViqg==&p=0&fvj=0&vjs=3  Title: Data Engineer Company: The Helper Bees URL: https://www.indeed.com/rc/clk?jk=6253474d1b58f413&bb=1TLRjqutBEYcit1OApAPtg6wY0fc5oBBCTyU7VwylasOUf6nQ8oTqOkXH0dnrnLZAaVB8nFtVNl5Z5kcRtJMk5SkC3U7H-JGc8jJqVcYLoUkDuSkTNrX8bAjfKZMI1yM&xkcb=SoBJ67M33zDWevR-pR0KbzkdCdPP&fccid=8ce618308adea162&vjs=3  Title: Data Analyst Company: Fix-It 24/7 URL: https://www.indeed.com/rc/clk?jk=06050d41e9f16407&bb=1TLRjqutBEYcit1OApAPto3A50Hg4Pzq5qFUF25sU891HTb0FMRKF-y31Tt72Rgj3vRHASDwe2nU2bKOyor677T1mfz6aMuuBmnum2LV6DDSRY1DGNuI6LNVrSB8DuSr&xkcb=SoDU67M33zDWevR-pR0JbzkdCdPP&fccid=61e4e7d2ce056d37&vjs=3  Title: Data Engineer I (R-17233) Company: Dun & Bradstreet URL: https://www.indeed.com/rc/clk?jk=f039623f105630f2&bb=1TLRjqutBEYcit1OApAPtg8D7eDBj8dWOPGrLLp5ZYiX2k5J48QjJ2VDYk8FyyDclWTFw3_uJx_lmIj2ONJMsJ2UUi5nujuLcodWuG6bPgGaBITZV5mfDBbvAF55qLOX&xkcb=SoBg67M33zDWevR-pR0IbzkdCdPP&fccid=fa0ca3b638673d62&vjs=3  Title: Data Analytics Engineer Company: Trolley Hospitality Companies URL: https://www.indeed.com/rc/clk?jk=2ed062ddf827d425&bb=1TLRjqutBEYcit1OApAPtqdISEDoy_d-IplDpybCSSMZpPo35r3cqU4mEJIYXYaDDVs9MrLJl-6gi6-5WFGx_E2KzO8CRErgNgARjPzv2CNuTu45b0AwJm3eCCk7YcVY&xkcb=SoDu67M33zDWevR-pR0PbzkdCdPP&fccid=d7db7b4b8d85f941&vjs=3  Title: Data Engineer Company: KesarWeb URL: https://www.indeed.com/rc/clk?jk=375bf3b4e704091b&bb=1TLRjqutBEYcit1OApAPtrcEczvcHO3wdOyX_7vPvKjueUN9MYpJsgZgF3qHa7uGyTbrxnq9JrcbPXGtFrlnc6K96XPZi_WmLBNMR-dU2giCyAECR-sdKTnVbuTCJ6Kd&xkcb=SoBa67M33zDWevR-pR0ObzkdCdPP&fccid=36a6953a97504177&cmp=KesarWeb&ti=Data+Engineer&vjs=3  Title: Data Analyst Company: TemperaturePro URL: https://www.indeed.com/rc/clk?jk=ce648987ee7515b1&bb=1TLRjqutBEYcit1OApAPtuY7ZI7s4dKP_loSJCdMjyEtPwhqz1EZ1Gv1WMK3EDBIZXPri1wso4SgFqKO0pamkIuqmPFovd77z5lF4obKC8yPJAQqUE0hF7tabRBUWj_z&xkcb=SoDH67M33zDWevR-pR0NbzkdCdPP&fccid=f67b5b2c8fb57889&vjs=3  Title: Data Scientist Company: Syntricate Technologies URL: https://www.indeed.com/rc/clk?jk=3d18d09ef73e17e3&bb=1TLRjqutBEYcit1OApAPtjJZHve0IREZcvimeUf98DreHFPkqvt2hoKQj7jltcOQMUfLQncq9bYhpa1IOZSu2ZOKrpNkE3JXFQl7HLR1kvew9FRZ-p5uYCmAYKypgrLe&xkcb=SoBz67M33zDWevR-pR0MbzkdCdPP&fccid=6a8862eed7fda9a3&cmp=Syntricate-Technologies&ti=Data+Scientist&vjs=3  Title: Data Scientist Company: ABOUT HEALTHCARE INC URL: https://www.indeed.com/rc/clk?jk=90ac2fadb29afe88&bb=1TLRjqutBEYcit1OApAPts7-O6E_jxzVoJOVxo_XYvb4FD_ctlKqGX5nL9lUGv3K0eAAvg-eH6qJq_emQfsWS6f-Wjw9iPsMS8Ybr0ijT61zmQk0UGii7V1s4hsi2x38&xkcb=SoCa67M33zDWevR-pR0DbzkdCdPP&fccid=c5bbd2c6370864bf&vjs=3  Title: Junior Data Engineer Company: American Veterinary Group URL: https://www.indeed.com/rc/clk?jk=b7ccd9fcd1afced7&bb=1TLRjqutBEYcit1OApAPtqrHYylbIkCH-hjMPAlsxl27fhhbmpR2ESoGFPzZ8_yAHfmXJJR-sxCiyJrJbrdNtoLq2VLDYGJB8eFEb_NompMj9I3HutPP1GvnnhForEvK&xkcb=SoAu67M33zDWevR-pR0CbzkdCdPP&fccid=4a4b722c7189c738&vjs=3  Title: Sr. Data Engineer Company: The Krusteaz Company URL: https://www.indeed.com/rc/clk?jk=ce1286f4f8d9c8f3&bb=1TLRjqutBEYcit1OApAPtg8D7eDBj8dWqCWgbfovlBMEYXXX_UJfze6KJ1Rk1HH29XymcqlzaGkV97O3N8iJ-QcsoD1GvtyjT96qcACImA-USRr2d9fMjXrM5az2uskT&xkcb=SoCz67M33zDWevR-pR0BbzkdCdPP&fccid=f5302c51750cf2bd&vjs=3  Title: Royalty Data Analyst - HarbourView Company: People Strata URL: https://www.indeed.com/rc/clk?jk=042c410f50c0faa6&bb=1TLRjqutBEYcit1OApAPtt6B4oNDQ9pvplvzh521n9octR12bdC8X0WPxpzUuEahEqtE5IkoxGLcfct2Fl3E3ERVE0CDNI3ufYlz_WxpqD2cHp3NqHNahE2fQxTMaZ59&xkcb=SoAH67M33zDWevR-pR0AbzkdCdPP&fccid=9e189ac6632e8eb3&vjs=3  Title: Data Engineer Company: Inizio Evoke URL: https://www.indeed.com/rc/clk?jk=9e40be84f9b83316&bb=1TLRjqutBEYcit1OApAPtiwFpIvslSGO7SJE2_6w2_yabPnRswbug_gQ3b7K53wZGRBcqAa66xMWWTgARyrcFowe-VfPsz2pyzNQu_d_4U1sucRRl3FlqEKL7xzWLpfM&xkcb=SoCJ67M33zDWevR-pR0HbzkdCdPP&fccid=9a61e67ffa915534&vjs=3  Title: Data Scientist Company: ENTERPRISE APPLICATIONS CONSULTING URL: https://www.indeed.com/rc/clk?jk=3887882c5612732e&bb=1TLRjqutBEYcit1OApAPtnomAnXe-PSxKGRzCB1zbhwQwhEyhzbWHNr_p7QvcZZj0wVF6Vw3tSd0HBb8Vm7gecKxVcnj_izsPiOGLXV5VBnBRZM8IPobYIIuWcT2KsXE&xkcb=SoA967M33zDWevR-pR0GbzkdCdPP&fccid=dd616958bd9ddc12&vjs=3  Title: Data Engineer II (Remote) Company: HirexHire URL: https://www.indeed.com/rc/clk?jk=4d6537997645be15&bb=1TLRjqutBEYcit1OApAPtsu8U9eiETJtKb46-YumxUjNFKa0IhH3KgXcjvuI5QjlLUeyjv-q0oPm8CDVODYtziLh0ZF2QcruNLh8cUnrQCpO9gqSUhjbq2HX5WTDgkfa&xkcb=SoCg67M33zDWevR-pR0FbzkdCdPP&fccid=97225ff5630ed4a6&vjs=3</td><td>data</td><td>About Tixr Tixr's on a mission to transform the ticket buying experience with a modern approach to a legacy business. Born from a fan-focused frame of mind, we empower large-scale events, music venues, and sports properties with modern, innovative solutions to their highly-complex ticketing and e-commerce needs. Our unified commerce platform is built for big, supporting all types of events, from festivals to global arena tours, and an almost limitless suite of commerce offerings beyond admission tickets. The Opportunity As our Data Engineer, you will play a crucial role in building and maintaining scalable, reliable, and secure data platforms to support our growing business. You'll work closely with data scientists, analysts, and engineers to design, develop, and optimize data pipelines and infrastructure. You will be joining a passionate team that continually pushes the boundaries of technology. Work-Life This role is 100% remote with an optional work environment at our Santa Monica office, located on the 3rd Street Promenade. Most teams run West Coast Hours with lots of autonomy. At this time we are only able to hire US Citizens or active US Green Card holders Skills & Qualifications Deep knowledge and experience with architectures for modern data infrastructure including data lakes, data warehouses, ETL pipelines, physical and logical data formats, data processing systems, data reliability, security, governance, and performance Work to improve and migrate existing code to improve performance, making deliberate and thoughtful tradeoffs where necessary. Extensive knowledge of different kinds of data stores (row-oriented, columnar, key/value, document, graph, etc.) and their use cases and tradeoffs Proficiency with various big data technologies including BigQuery, Redshift, Parquet, Spark, AWS Glue, Expertise in Java (Hibernate) Be independently responsible for the entire lifecycle of projects and systems, including design, development, and deployment High standards and expectations for software development, excellent written and verbal communication skills Strive to write elegant and maintainable code; comfortable picking up new technologies. You break down complex projects into simple systems that can be built and maintained by less experienced engineers You are proficient in working with distributed systems and have experience with different distributed processing frameworks that can handle data in batch and real-time Preferred Skills & Qualifications 5+ Years experience as a Software Engineer (Java preferred) with a focus on data 5+ Years experience working with distributed ingestion, processing, storage, and access of big data (bonus points for experience with AI/ML) 5+ Years experience with MySQL, Couchbase, Kafka, SageMaker 7+ Years experience leveraging tools and infrastructure provided by GCP and AWS The Perks Salary Range $130,000 - $180,000 + Bonus + Equity 100% Remote with Hybrid Optional Paid Health Benefits ($0 Premiums) Dental, Vision, Life plans Open Vacation 401k (50% match up to 3%) Paid Equipment Education Stipend Paid Holidays & Birthdays Off Parental Leave Team Offsites / Events Ticket hookups! Tixr is the largest, fastest-growing, privately-held primary ticketing and live event commerce marketplace in the world. We're a California born and bred company that's still founder owned and led to this day, and we support a global client base with staff throughout the US, Canada, and UK. We exclusively power 500 of the most respected live entertainment brands in 40 countries including LIV Golf, Wynn Nightlife, Riot Fest, Acura Grand Prix of Long Beach, Riot Games Arena, Luke Bryan’s Crash My Playa, Sturgis Buffalo Chip, Lightning in a Bottle, Portland Trail Blazers’ New G League Affiliate Rip City Remix, among many others. The pay range for this role is: 130,000 - 180,000 USD per year(Remote - United States) Title: Data Analytics Engineer Company: CardWorks URL:   Title: Data Engineer Company: The Helper Bees URL:   Title: Data Analyst Company: Fix-It 24/7 URL:   Title: Data Engineer I (R-17233) Company: Dun & Bradstreet URL:   Title: Data Analytics Engineer Company: Trolley Hospitality Companies URL:   Title: Data Engineer Company: KesarWeb URL:   Title: Data Analyst Company: TemperaturePro URL:   Title: Data Scientist Company: Syntricate Technologies URL:   Title: Data Scientist Company: ABOUT HEALTHCARE INC URL:   Title: Junior Data Engineer Company: American Veterinary Group URL:   Title: Sr. Data Engineer Company: The Krusteaz Company URL:   Title: Royalty Data Analyst - HarbourView Company: People Strata URL:   Title: Data Engineer Company: Inizio Evoke URL:   Title: Data Scientist Company: ENTERPRISE APPLICATIONS CONSULTING URL:   Title: Data Engineer II (Remote) Company: HirexHire URL: </td><td>About Tixr Tixr's on a mission to transform the ticket buying experience with a modern approach to a legacy business. Born from a fan-focused frame of mind, we empower large-scale events, music venues, and sports properties with modern, innovative solutions to their highly-complex ticketing and e-commerce needs. Our unified commerce platform is built for big, supporting all types of events, from festivals to global arena tours, and an almost limitless suite of commerce offerings beyond admission tickets. The Opportunity As our Data Engineer, you will play a crucial role in building and maintaining scalable, reliable, and secure data platforms to support our growing business. You'll work closely with data scientists, analysts, and engineers to design, develop, and optimize data pipelines and infrastructure. You will be joining a passionate team that continually pushes the boundaries of technology. Work-Life This role is 100% remote with an optional work environment at our Santa Monica office, located on the 3rd Street Promenade. Most teams run West Coast Hours with lots of autonomy. At this time we are only able to hire US Citizens or active US Green Card holders Skills & Qualifications Deep knowledge and experience with architectures for modern data infrastructure including data lakes, data warehouses, ETL pipelines, physical and logical data formats, data processing systems, data reliability, security, governance, and performance Work to improve and migrate existing code to improve performance, making deliberate and thoughtful tradeoffs where necessary. Extensive knowledge of different kinds of data stores (row-oriented, columnar, key/value, document, graph, etc.) and their use cases and tradeoffs Proficiency with various big data technologies including BigQuery, Redshift, Parquet, Spark, AWS Glue, Expertise in Java (Hibernate) Be independently responsible for the entire lifecycle of projects and systems, including design, development, and deployment High standards and expectations for software development, excellent written and verbal communication skills Strive to write elegant and maintainable code; comfortable picking up new technologies. You break down complex projects into simple systems that can be built and maintained by less experienced engineers You are proficient in working with distributed systems and have experience with different distributed processing frameworks that can handle data in batch and real-time Preferred Skills & Qualifications 5+ Years experience as a Software Engineer (Java preferred) with a focus on data 5+ Years experience working with distributed ingestion, processing, storage, and access of big data (bonus points for experience with AI/ML) 5+ Years experience with MySQL, Couchbase, Kafka, SageMaker 7+ Years experience leveraging tools and infrastructure provided by GCP and AWS The Perks Salary Range $130,000 - $180,000 + Bonus + Equity 100% Remote with Hybrid Optional Paid Health Benefits ($0 Premiums) Dental, Vision, Life plans Open Vacation 401k (50% match up to 3%) Paid Equipment Education Stipend Paid Holidays & Birthdays Off Parental Leave Team Offsites / Events Ticket hookups! Tixr is the largest, fastest-growing, privately-held primary ticketing and live event commerce marketplace in the world. We're a California born and bred company that's still founder owned and led to this day, and we support a global client base with staff throughout the US, Canada, and UK. We exclusively power 500 of the most respected live entertainment brands in 40 countries including LIV Golf, Wynn Nightlife, Riot Fest, Acura Grand Prix of Long Beach, Riot Games Arena, Luke Bryan’s Crash My Playa, Sturgis Buffalo Chip, Lightning in a Bottle, Portland Trail Blazers’ New G League Affiliate Rip City Remix, among many others. The pay range for this role is: 130,000 - 180,000 USD per year(Remote - United States) Title: Data Analytics Engineer Company: CardWorks URL:   Title: Data Engineer Company: The Helper Bees URL:   Title: Data Analyst Company: Fix-It 24/7 URL:   Title: Data Engineer I (R-17233) Company: Dun & Bradstreet URL:   Title: Data Analytics Engineer Company: Trolley Hospitality Companies URL:   Title: Data Engineer Company: KesarWeb URL:   Title: Data Analyst Company: TemperaturePro URL:   Title: Data Scientist Company: Syntricate Technologies URL:   Title: Data Scientist Company: ABOUT HEALTHCARE INC URL:   Title: Junior Data Engineer Company: American Veterinary Group URL:   Title: Sr. Data Engineer Company: The Krusteaz Company URL:   Title: Royalty Data Analyst - HarbourView Company: People Strata URL:   Title: Data Engineer Company: Inizio Evoke URL:   Title: Data Scientist Company: ENTERPRISE APPLICATIONS CONSULTING URL:   Title: Data Engineer II (Remote) Company: HirexHire URL:</td><td>Deep knowledge and experience with architectures for modern data infrastructure including data lakes, data warehouses, ETL pipelines, physical and logical data formats, data processing systems, data reliability, security, governance, and performance Work to improve and migrate existing code to improve performance, making deliberate and thoughtful tradeoffs where necessary. Extensive knowledge of different kinds of data stores (row-oriented, columnar, key/value, document, graph, etc.) and their use cases and tradeoffs Proficiency with various big data technologies including BigQuery, Redshift, Parquet, Spark, AWS Glue, Expertise in Java (Hibernate) Be independently responsible for the entire lifecycle of projects and systems, including design, development, and deployment High standards and expectations for software development, excellent written and verbal communication skills Strive to write elegant and maintainable code; comfortable picking up new technologies. You break down complex projects into simple systems that can be built and maintained by less experienced engineers You are proficient in working with distributed systems and have experience with different distributed processing frameworks that can handle data in batch and real-time Preferred Skills & Qualifications 5+ Years experience as a Software Engineer (Java preferred) with a focus on data 5+ Years experience working with distributed ingestion, processing, storage, and access of big data (bonus points for experience with AI/ML) 5+ Years experience with MySQL, Couchbase, Kafka, SageMaker 7+ Years experience leveraging tools and infrastructure provided by GCP and AWS The Perks Salary Range $130,000 - $180,000 + Bonus + Equity 100% Remote with Hybrid Optional Paid Health Benefits ($0 Premiums) Dental, Vision, Life plans Open Vacation 401k (50% match up to 3%) Paid Equipment Education Stipend Paid Holidays & Birthdays Off Parental Leave Team Offsites / Events Ticket hookups! Tixr is the largest, fastest-growing, privately-held primary ticketing and live event commerce marketplace in the world. We're a California born and bred company that's still founder owned and led to this day, and we support a global client base with staff throughout the US, Canada, and UK. We exclusively power 500 of the most respected live entertainment brands in 40 countries including LIV Golf, Wynn Nightlife, Riot Fest, Acura Grand Prix of Long Beach, Riot Games Arena, Luke Bryan’s Crash My Playa, Sturgis Buffalo Chip, Lightning in a Bottle, Portland Trail Blazers’ New G League Affiliate Rip City Remix, among many others. The pay range for this role is: 130,000 - 180,000 USD per year(Remote - United States) Title: Data Analytics Engineer Company: CardWorks URL:   Title: Data Engineer Company: The Helper Bees URL:   Title: Data Analyst Company: Fix-It 24/7 URL:   Title: Data Engineer I (R-17233) Company: Dun & Bradstreet URL:   Title: Data Analytics Engineer Company: Trolley Hospitality Companies URL:   Title: Data Engineer Company: KesarWeb URL:   Title: Data Analyst Company: TemperaturePro URL:   Title: Data Scientist Company: Syntricate Technologies URL:   Title: Data Scientist Company: ABOUT HEALTHCARE INC URL:   Title: Junior Data Engineer Company: American Veterinary Group URL:   Title: Sr. Data Engineer Company: The Krusteaz Company URL:   Title: Royalty Data Analyst - HarbourView Company: People Strata URL:   Title: Data Engineer Company: Inizio Evoke URL:   Title: Data Scientist Company: ENTERPRISE APPLICATIONS CONSULTING URL:   Title: Data Engineer II (Remote) Company: HirexHire URL:</td><td>513</td></tr><tr><td>Data Analyst</td><td>that values your contributions and encourages professional development.</td><td>Description: Join our winning team, recently honored as #67 on Forbes’ list of America’s Best Startup Employers for 2024! About The Helper Bees The Helper Bees’ mission is to help people stay home longer through data-driven services that transform both the payer and the care-recipient experience. At The Helper Bees, we are reshaping how care is delivered to aging individuals by leveraging innovative technology and insightful data solutions. We maintain multiple SaaS products and payment solutions through our web applications (internal and external facing), a mobile app, and reporting integrations. As part of our growing Data Engineering team, you’ll iterate quickly, have a high impact, and be challenged to design and implement cutting-edge solutions. At THB, we define our company culture through our Core Values: Quickly iterate through solutions: We move at a fast pace which requires quick iterations to find a path to a repeatable solution. Seek ways to create immediate impact: Be thoughtful and proactive in how you make an impact on your team. Actively look for ways to make a fast, positive impact. Bee the teammate you want to work with: We work as a team, help each other, and encourage each other. Ask questions, answer questions: You can't iterate through solutions if you don't ask the right questions, which is why there is an expectation that questions should be asked. When you know the answer, being a good teammate means chiming in to get others up to speed. Take the time to celebrate wins: It's so easy for a team that is heads down to forget about all the great things they've accomplished. That's why we make it a priority to remind ourselves to create space to celebrate wins, big or small. Job Summary We are seeking a motivated Data Engineer to join our team and help improve our tools, processes, and technical infrastructure. In this role, you will ensure the availability and quality of our data while contributing to the design, implementation, and maintenance of The Helper Bees’ products. You’ll collaborate across teams to create scalable and optimized software systems and play a key role in refining our development processes. This position offers a unique opportunity to learn and leverage cutting-edge AI development tools to enhance coding efficiency and develop advanced data tools and solutions. Supervisory Responsibilities: None Key Responsibilities Data Infrastructure: Design, implement, and maintain data pipelines, ensuring data availability, quality, and scalability. Product Development: Build and enhance products using Python, SQL, and modern technologies. AI Integration: Leverage cutting-edge AI tools, including Cursor, ChatGPT, and Claude to improve development processes, automate workflows, and create innovative data solutions. Collaboration: Communicate across departments to design, build, test, and implement new features and enhancements. Code Excellence: Produce quality, testable, and maintainable code while participating in code reviews. Problem Solving: Debug complex issues, interact with stakeholders, and design viable solutions with clear trade-offs. Process Optimization: Contribute to improving development processes, including deployment, on-call systems, and sprint planning. Team Growth: Collaborate within the development team to help each other grow and continuously learn. Stakeholder Engagement: Partner with analysts, scientists, and IT to ensure alignment and deliver data-driven solutions. Other duties as assigned/necessary Performance Metrics Code Quality: Maintain high coding standards through regular code reviews and adherence to best practices. Development Efficiency: Deliver high-quality features and fixes within efficient timeframes. Bug Resolution Time: Reduce the time taken to identify and resolve issues. System Scalability: Optimize system performance to handle increasing user demands. Collaboration: Foster a collaborative environment that encourages teamwork and knowledge sharing. Customer Satisfaction: Incorporate stakeholder feedback to improve solutions and enhance the customer experience. Continuous Learning: Pursue opportunities for skill development and share knowledge with the team. Requirements: Required Skills & Qualifications Technical Tools: Experience with in Python and/or SQL. Experience with Bash, Shell scripting, Big Query, Airflow, and is a plus. Programming: Cleaning data using code-based approach. AI Proficiency: Interest or experience in using AI tools for coding and development of data solutions. Soft Skills: Problem-solving, cross-team collaboration, data storytelling, and stakeholder engagement. Adaptability: Thrives in a fast-paced startup environment and embraces change. Proactivity: Self-directed, organized, and able to prioritize effectively. Collaboration: Ability to work effectively with cross-functional teams. Education & Experience: A bachelor’s degree is required, and a graduate degree is preferred. Relevant experience in data engineering, software development, STEM, or related fields. Strong experience with SQL and Python is highly desirable. Mindset: A passion for innovation, continuous improvement, and delivering high-quality results from messy data. Preferred Qualifications Familiarity with cloud-based solutions (e.g., Google Cloud Platform, Azure). Experience with ETL processes and tools. Experience building data visualization reports and dashboards Knowledge of modern data storage solutions and database management systems. Exposure to DevOps practices and tools for deployment and monitoring. Why Join Us? Work with a talented, collaborative team dedicated to making a difference. Gain exposure to innovative technologies and opportunities for growth. Learn and utilize cutting-edge AI tools to enhance your development skills and create impactful solutions. Be part of a company that values your contributions and encourages professional development. Join a rapidly expanding health-tech startup (~200 employees and growing) with a state-of-the-art technology office located in Hyde Park, offering a variety of exceptional benefits. Career Progression Timeline In 3 months: Gain a comprehensive understanding of our data infrastructure, technical stacks, and development cycles. Actively participate in team meetings and contribute to the development of new data pipelines. Begin leveraging AI tools, such as Cursor and ChatGPT, to enhance coding efficiency and workflow automation. In 6 months: Contribute to product enhancements and data reporting Collaborate effectively with cross-functional teams, providing insights and solutions for data-related challenges. Demonstrate proficiency in utilizing AI tools for coding and development, actively sharing knowledge with the team. In 12 months: Contribute to data engineering projects, ensuring scalability and performance optimization. Mentor non-technical internal partners to improve company-wide data literacy Contribute to the integration of advanced AI solutions into our development processes, contributing to the company's technological advancement. Physical Requirements: Ability to remain at your designated workstation for the duration of the workday Constantly operates a computer and other office productivity machinery, such as a phone and Voice over Internet Protocol (VoIP). The ability to communicate information and ideas so others will understand. Must be able to exchange accurate information in these situations. The ability to observe details at close range (typically on a computer screen) This position offers the flexibility of remote work at approved locations within the United States. Candidates must have a reliable internet connection and a designated work environment conducive to professional phone calls and sensitive data. Enjoy the convenience and comfort of working remotely while contributing to our team's success. Apply Today If you’re ready to take on challenging problems, contribute to impactful solutions, and grow as a data engineer, we’d love to hear from you. Join us at The Helper Bees and be part of a team that’s making a meaningful difference every day! The Helper Bees is committed to building a workplace where diversity, equity, and inclusion are valued and prioritized. We are an equal opportunity employer that welcomes all qualified applicants without discrimination based on race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or any non-merit based or legally protected grounds. The Helper Bees provides reasonable accommodations to qualified individuals with disabilities during the job application and interview process. To request accommodation, please let your recruiter know. As part of our standard hiring process, selected candidates may be required to undergo a background check and/or drug screen. The Helper Bees adheres to applicable federal, state, and local laws regarding these screenings, and the results will be considered in accordance with applicable regulations. The Helper Bees was recently made aware of a fraudulent entity posing as our organization and requesting personal information. Please be aware of and protect yourself from scams. Visit thehelperbees.com/careers to view all current job openings.</td><td>data</td><td>Description: Join our winning team, recently honored as #67 on Forbes’ list of America’s Best Startup Employers for 2024! About The Helper Bees The Helper Bees’ mission is to help people stay home longer through data-driven services that transform both the payer and the care-recipient experience. At The Helper Bees, we are reshaping how care is delivered to aging individuals by leveraging innovative technology and insightful data solutions. We maintain multiple SaaS products and payment solutions through our web applications (internal and external facing), a mobile app, and reporting integrations. As part of our growing Data Engineering team, you’ll iterate quickly, have a high impact, and be challenged to design and implement cutting-edge solutions. At THB, we define our company culture through our Core Values: Quickly iterate through solutions: We move at a fast pace which requires quick iterations to find a path to a repeatable solution. Seek ways to create immediate impact: Be thoughtful and proactive in how you make an impact on your team. Actively look for ways to make a fast, positive impact. Bee the teammate you want to work with: We work as a team, help each other, and encourage each other. Ask questions, answer questions: You can't iterate through solutions if you don't ask the right questions, which is why there is an expectation that questions should be asked. When you know the answer, being a good teammate means chiming in to get others up to speed. Take the time to celebrate wins: It's so easy for a team that is heads down to forget about all the great things they've accomplished. That's why we make it a priority to remind ourselves to create space to celebrate wins, big or small. Job Summary We are seeking a motivated Data Engineer to join our team and help improve our tools, processes, and technical infrastructure. In this role, you will ensure the availability and quality of our data while contributing to the design, implementation, and maintenance of The Helper Bees’ products. You’ll collaborate across teams to create scalable and optimized software systems and play a key role in refining our development processes. This position offers a unique opportunity to learn and leverage cutting-edge AI development tools to enhance coding efficiency and develop advanced data tools and solutions. Supervisory Responsibilities: None Key Responsibilities Data Infrastructure: Design, implement, and maintain data pipelines, ensuring data availability, quality, and scalability. Product Development: Build and enhance products using Python, SQL, and modern technologies. AI Integration: Leverage cutting-edge AI tools, including Cursor, ChatGPT, and Claude to improve development processes, automate workflows, and create innovative data solutions. Collaboration: Communicate across departments to design, build, test, and implement new features and enhancements. Code Excellence: Produce quality, testable, and maintainable code while participating in code reviews. Problem Solving: Debug complex issues, interact with stakeholders, and design viable solutions with clear trade-offs. Process Optimization: Contribute to improving development processes, including deployment, on-call systems, and sprint planning. Team Growth: Collaborate within the development team to help each other grow and continuously learn. Stakeholder Engagement: Partner with analysts, scientists, and IT to ensure alignment and deliver data-driven solutions. Other duties as assigned/necessary Performance Metrics Code Quality: Maintain high coding standards through regular code reviews and adherence to best practices. Development Efficiency: Deliver high-quality features and fixes within efficient timeframes. Bug Resolution Time: Reduce the time taken to identify and resolve issues. System Scalability: Optimize system performance to handle increasing user demands. Collaboration: Foster a collaborative environment that encourages teamwork and knowledge sharing. Customer Satisfaction: Incorporate stakeholder feedback to improve solutions and enhance the customer experience. Continuous Learning: Pursue opportunities for skill development and share knowledge with the team. Requirements: Required Skills & Qualifications Technical Tools: Experience with in Python and/or SQL. Experience with Bash, Shell scripting, Big Query, Airflow, and is a plus. Programming: Cleaning data using code-based approach. AI Proficiency: Interest or experience in using AI tools for coding and development of data solutions. Soft Skills: Problem-solving, cross-team collaboration, data storytelling, and stakeholder engagement. Adaptability: Thrives in a fast-paced startup environment and embraces change. Proactivity: Self-directed, organized, and able to prioritize effectively. Collaboration: Ability to work effectively with cross-functional teams. Education & Experience: A bachelor’s degree is required, and a graduate degree is preferred. Relevant experience in data engineering, software development, STEM, or related fields. Strong experience with SQL and Python is highly desirable. Mindset: A passion for innovation, continuous improvement, and delivering high-quality results from messy data. Preferred Qualifications Familiarity with cloud-based solutions (e.g., Google Cloud Platform, Azure). Experience with ETL processes and tools. Experience building data visualization reports and dashboards Knowledge of modern data storage solutions and database management systems. Exposure to DevOps practices and tools for deployment and monitoring. Why Join Us? Work with a talented, collaborative team dedicated to making a difference. Gain exposure to innovative technologies and opportunities for growth. Learn and utilize cutting-edge AI tools to enhance your development skills and create impactful solutions. Be part of a company that values your contributions and encourages professional development. Join a rapidly expanding health-tech startup (~200 employees and growing) with a state-of-the-art technology office located in Hyde Park, offering a variety of exceptional benefits. Career Progression Timeline In 3 months: Gain a comprehensive understanding of our data infrastructure, technical stacks, and development cycles. Actively participate in team meetings and contribute to the development of new data pipelines. Begin leveraging AI tools, such as Cursor and ChatGPT, to enhance coding efficiency and workflow automation. In 6 months: Contribute to product enhancements and data reporting Collaborate effectively with cross-functional teams, providing insights and solutions for data-related challenges. Demonstrate proficiency in utilizing AI tools for coding and development, actively sharing knowledge with the team. In 12 months: Contribute to data engineering projects, ensuring scalability and performance optimization. Mentor non-technical internal partners to improve company-wide data literacy Contribute to the integration of advanced AI solutions into our development processes, contributing to the company's technological advancement. Physical Requirements: Ability to remain at your designated workstation for the duration of the workday Constantly operates a computer and other office productivity machinery, such as a phone and Voice over Internet Protocol (VoIP). The ability to communicate information and ideas so others will understand. Must be able to exchange accurate information in these situations. The ability to observe details at close range (typically on a computer screen) This position offers the flexibility of remote work at approved locations within the United States. Candidates must have a reliable internet connection and a designated work environment conducive to professional phone calls and sensitive data. Enjoy the convenience and comfort of working remotely while contributing to our team's success. Apply Today If you’re ready to take on challenging problems, contribute to impactful solutions, and grow as a data engineer, we’d love to hear from you. Join us at The Helper Bees and be part of a team that’s making a meaningful difference every day! The Helper Bees is committed to building a workplace where diversity, equity, and inclusion are valued and prioritized. We are an equal opportunity employer that welcomes all qualified applicants without discrimination based on race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or any non-merit based or legally protected grounds. The Helper Bees provides reasonable accommodations to qualified individuals with disabilities during the job application and interview process. To request accommodation, please let your recruiter know. As part of our standard hiring process, selected candidates may be required to undergo a background check and/or drug screen. The Helper Bees adheres to applicable federal, state, and local laws regarding these screenings, and the results will be considered in accordance with applicable regulations. The Helper Bees was recently made aware of a fraudulent entity posing as our organization and requesting personal information. Please be aware of and protect yourself from scams. Visit thehelperbees.com/careers to view all current job openings.</td><td>Description: Join our winning team, recently honored as #67 on Forbes’ list of America’s Best Startup Employers for 2024! About The Helper Bees The Helper Bees’ mission is to help people stay home longer through data-driven services that transform both the payer and the care-recipient experience. At The Helper Bees, we are reshaping how care is delivered to aging individuals by leveraging innovative technology and insightful data solutions. We maintain multiple SaaS products and payment solutions through our web applications (internal and external facing), a mobile app, and reporting integrations. As part of our growing Data Engineering team, you’ll iterate quickly, have a high impact, and be challenged to design and implement cutting-edge solutions. At THB, we define our company culture through our Core Values: Quickly iterate through solutions: We move at a fast pace which requires quick iterations to find a path to a repeatable solution. Seek ways to create immediate impact: Be thoughtful and proactive in how you make an impact on your team. Actively look for ways to make a fast, positive impact. Bee the teammate you want to work with: We work as a team, help each other, and encourage each other. Ask questions, answer questions: You can't iterate through solutions if you don't ask the right questions, which is why there is an expectation that questions should be asked. When you know the answer, being a good teammate means chiming in to get others up to speed. Take the time to celebrate wins: It's so easy for a team that is heads down to forget about all the great things they've accomplished. That's why we make it a priority to remind ourselves to create space to celebrate wins, big or small. Job Summary We are seeking a motivated Data Engineer to join our team and help improve our tools, processes, and technical infrastructure. In this role, you will ensure the availability and quality of our data while contributing to the design, implementation, and maintenance of The Helper Bees’ products. You’ll collaborate across teams to create scalable and optimized software systems and play a key role in refining our development processes. This position offers a unique opportunity to learn and leverage cutting-edge AI development tools to enhance coding efficiency and develop advanced data tools and solutions. Supervisory Responsibilities: None Key Responsibilities Data Infrastructure: Design, implement, and maintain data pipelines, ensuring data availability, quality, and scalability. Product Development: Build and enhance products using Python, SQL, and modern technologies. AI Integration: Leverage cutting-edge AI tools, including Cursor, ChatGPT, and Claude to improve development processes, automate workflows, and create innovative data solutions. Collaboration: Communicate across departments to design, build, test, and implement new features and enhancements. Code Excellence: Produce quality, testable, and maintainable code while participating in code reviews. Problem Solving: Debug complex issues, interact with stakeholders, and design viable solutions with clear trade-offs. Process Optimization: Contribute to improving development processes, including deployment, on-call systems, and sprint planning. Team Growth: Collaborate within the development team to help each other grow and continuously learn. Stakeholder Engagement: Partner with analysts, scientists, and IT to ensure alignment and deliver data-driven solutions. Other duties as assigned/necessary Performance Metrics Code Quality: Maintain high coding standards through regular code reviews and adherence to best practices. Development Efficiency: Deliver high-quality features and fixes within efficient timeframes. Bug Resolution Time: Reduce the time taken to identify and resolve issues. System Scalability: Optimize system performance to handle increasing user demands. Collaboration: Foster a collaborative environment that encourages teamwork and knowledge sharing. Customer Satisfaction: Incorporate stakeholder feedback to improve solutions and enhance the customer experience. Continuous Learning: Pursue opportunities for skill development and share knowledge with the team. Requirements: Required Skills & Qualifications Technical Tools: Experience with in Python and/or SQL. Experience with Bash, Shell scripting, Big Query, Airflow, and is a plus. Programming: Cleaning data using code-based approach. AI Proficiency: Interest or experience in using AI tools for coding and development of data solutions. Soft Skills: Problem-solving, cross-team collaboration, data storytelling, and stakeholder engagement. Adaptability: Thrives in a fast-paced startup environment and embraces change. Proactivity: Self-directed, organized, and able to prioritize effectively. Collaboration: Ability to work effectively with cross-functional teams. Education & Experience: A bachelor’s degree is required, and a graduate degree is preferred. Relevant experience in data engineering, software development, STEM, or related fields. Strong experience with SQL and Python is highly desirable. Mindset: A passion for innovation, continuous improvement, and delivering high-quality results from messy data. Preferred Qualifications Familiarity with cloud-based solutions (e.g., Google Cloud Platform, Azure). Experience with ETL processes and tools. Experience building data visualization reports and dashboards Knowledge of modern data storage solutions and database management systems. Exposure to DevOps practices and tools for deployment and monitoring. Why Join Us? Work with a talented, collaborative team dedicated to making a difference. Gain exposure to innovative technologies and opportunities for growth. Learn and utilize cutting-edge AI tools to enhance your development skills and create impactful solutions. Be part of a company that values your contributions and encourages professional development. Join a rapidly expanding health-tech startup (~200 employees and growing) with a state-of-the-art technology office located in Hyde Park, offering a variety of exceptional benefits. Career Progression Timeline In 3 months: Gain a comprehensive understanding of our data infrastructure, technical stacks, and development cycles. Actively participate in team meetings and contribute to the development of new data pipelines. Begin leveraging AI tools, such as Cursor and ChatGPT, to enhance coding efficiency and workflow automation. In 6 months: Contribute to product enhancements and data reporting Collaborate effectively with cross-functional teams, providing insights and solutions for data-related challenges. Demonstrate proficiency in utilizing AI tools for coding and development, actively sharing knowledge with the team. In 12 months: Contribute to data engineering projects, ensuring scalability and performance optimization. Mentor non-technical internal partners to improve company-wide data literacy Contribute to the integration of advanced AI solutions into our development processes, contributing to the company's technological advancement. Physical Requirements: Ability to remain at your designated workstation for the duration of the workday Constantly operates a computer and other office productivity machinery, such as a phone and Voice over Internet Protocol (VoIP). The ability to communicate information and ideas so others will understand. Must be able to exchange accurate information in these situations. The ability to observe details at close range (typically on a computer screen) This position offers the flexibility of remote work at approved locations within the United States. Candidates must have a reliable internet connection and a designated work environment conducive to professional phone calls and sensitive data. Enjoy the convenience and comfort of working remotely while contributing to our team's success. Apply Today If you’re ready to take on challenging problems, contribute to impactful solutions, and grow as a data engineer, we’d love to hear from you. Join us at The Helper Bees and be part of a team that’s making a meaningful difference every day! The Helper Bees is committed to building a workplace where diversity, equity, and inclusion are valued and prioritized. We are an equal opportunity employer that welcomes all qualified applicants without discrimination based on race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or any non-merit based or legally protected grounds. The Helper Bees provides reasonable accommodations to qualified individuals with disabilities during the job application and interview process. To request accommodation, please let your recruiter know. As part of our standard hiring process, selected candidates may be required to undergo a background check and/or drug screen. The Helper Bees adheres to applicable federal, state, and local laws regarding these screenings, and the results will be considered in accordance with applicable regulations. The Helper Bees was recently made aware of a fraudulent entity posing as our organization and requesting personal information. Please be aware of and protect yourself from scams. Visit thehelperbees.com/careers to view all current job openings.</td><td>Technical Tools: Experience with in Python and/or SQL. Experience with Bash, Shell scripting, Big Query, Airflow, and is a plus. Programming: Cleaning data using code-based approach. AI Proficiency: Interest or experience in using AI tools for coding and development of data solutions. Soft Skills: Problem-solving, cross-team collaboration, data storytelling, and stakeholder engagement. Adaptability: Thrives in a fast-paced startup environment and embraces change. Proactivity: Self-directed, organized, and able to prioritize effectively. Collaboration: Ability to work effectively with cross-functional teams. Education & Experience: A bachelor’s degree is required, and a graduate degree is preferred. Relevant experience in data engineering, software development, STEM, or related fields. Strong experience with SQL and Python is highly desirable. Mindset: A passion for innovation, continuous improvement, and delivering high-quality results from messy data. Preferred Qualifications Familiarity with cloud-based solutions (e.g., Google Cloud Platform, Azure). Experience with ETL processes and tools. Experience building data visualization reports and dashboards Knowledge of modern data storage solutions and database management systems. Exposure to DevOps practices and tools for deployment and monitoring. Why Join Us? Work with a talented, collaborative team dedicated to making a difference. Gain exposure to innovative technologies and opportunities for growth. Learn and utilize cutting-edge AI tools to enhance your development skills and create impactful solutions. Be part of a company that values your contributions and encourages professional development. Join a rapidly expanding health-tech startup (~200 employees and growing) with a state-of-the-art technology office located in Hyde Park, offering a variety of exceptional benefits. Career Progression Timeline In 3 months: Gain a comprehensive understanding of our data infrastructure, technical stacks, and development cycles. Actively participate in team meetings and contribute to the development of new data pipelines. Begin leveraging AI tools, such as Cursor and ChatGPT, to enhance coding efficiency and workflow automation. In 6 months: Contribute to product enhancements and data reporting Collaborate effectively with cross-functional teams, providing insights and solutions for data-related challenges. Demonstrate proficiency in utilizing AI tools for coding and development, actively sharing knowledge with the team. In 12 months: Contribute to data engineering projects, ensuring scalability and performance optimization. Mentor non-technical internal partners to improve company-wide data literacy Contribute to the integration of advanced AI solutions into our development processes, contributing to the company's technological advancement. Physical Requirements: Ability to remain at your designated workstation for the duration of the workday Constantly operates a computer and other office productivity machinery, such as a phone and Voice over Internet Protocol (VoIP). The ability to communicate information and ideas so others will understand. Must be able to exchange accurate information in these situations. The ability to observe details at close range (typically on a computer screen) This position offers the flexibility of remote work at approved locations within the United States. Candidates must have a reliable internet connection and a designated work environment conducive to professional phone calls and sensitive data. Enjoy the convenience and comfort of working remotely while contributing to our team's success. Apply Today If you’re ready to take on challenging problems, contribute to impactful solutions, and grow as a data engineer, we’d love to hear from you. Join us at The Helper Bees and be part of a team that’s making a meaningful difference every day! The Helper Bees is committed to building a workplace where diversity, equity, and inclusion are valued and prioritized. We are an equal opportunity employer that welcomes all qualified applicants without discrimination based on race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or any non-merit based or legally protected grounds. The Helper Bees provides reasonable accommodations to qualified individuals with disabilities during the job application and interview process. To request accommodation, please let your recruiter know. As part of our standard hiring process, selected candidates may be required to undergo a background check and/or drug screen. The Helper Bees adheres to applicable federal, state, and local laws regarding these screenings, and the results will be considered in accordance with applicable regulations. The Helper Bees was recently made aware of a fraudulent entity posing as our organization and requesting personal information. Please be aware of and protect yourself from scams. Visit thehelperbees.com/careers to view all current job openings.</td><td>698</td></tr><tr><td>Data Scientist</td><td>'s technological advancement.</td><td>Description: Join our winning team, recently honored as #67 on Forbes’ list of America’s Best Startup Employers for 2024! About The Helper Bees The Helper Bees’ mission is to help people stay home longer through data-driven services that transform both the payer and the care-recipient experience. At The Helper Bees, we are reshaping how care is delivered to aging individuals by leveraging innovative technology and insightful data solutions. We maintain multiple SaaS products and payment solutions through our web applications (internal and external facing), a mobile app, and reporting integrations. As part of our growing Data Engineering team, you’ll iterate quickly, have a high impact, and be challenged to design and implement cutting-edge solutions. At THB, we define our company culture through our Core Values: Quickly iterate through solutions: We move at a fast pace which requires quick iterations to find a path to a repeatable solution. Seek ways to create immediate impact: Be thoughtful and proactive in how you make an impact on your team. Actively look for ways to make a fast, positive impact. Bee the teammate you want to work with: We work as a team, help each other, and encourage each other. Ask questions, answer questions: You can't iterate through solutions if you don't ask the right questions, which is why there is an expectation that questions should be asked. When you know the answer, being a good teammate means chiming in to get others up to speed. Take the time to celebrate wins: It's so easy for a team that is heads down to forget about all the great things they've accomplished. That's why we make it a priority to remind ourselves to create space to celebrate wins, big or small. Job Summary We are seeking a motivated Data Engineer to join our team and help improve our tools, processes, and technical infrastructure. In this role, you will ensure the availability and quality of our data while contributing to the design, implementation, and maintenance of The Helper Bees’ products. You’ll collaborate across teams to create scalable and optimized software systems and play a key role in refining our development processes. This position offers a unique opportunity to learn and leverage cutting-edge AI development tools to enhance coding efficiency and develop advanced data tools and solutions. Supervisory Responsibilities: None Key Responsibilities Data Infrastructure: Design, implement, and maintain data pipelines, ensuring data availability, quality, and scalability. Product Development: Build and enhance products using Python, SQL, and modern technologies. AI Integration: Leverage cutting-edge AI tools, including Cursor, ChatGPT, and Claude to improve development processes, automate workflows, and create innovative data solutions. Collaboration: Communicate across departments to design, build, test, and implement new features and enhancements. Code Excellence: Produce quality, testable, and maintainable code while participating in code reviews. Problem Solving: Debug complex issues, interact with stakeholders, and design viable solutions with clear trade-offs. Process Optimization: Contribute to improving development processes, including deployment, on-call systems, and sprint planning. Team Growth: Collaborate within the development team to help each other grow and continuously learn. Stakeholder Engagement: Partner with analysts, scientists, and IT to ensure alignment and deliver data-driven solutions. Other duties as assigned/necessary Performance Metrics Code Quality: Maintain high coding standards through regular code reviews and adherence to best practices. Development Efficiency: Deliver high-quality features and fixes within efficient timeframes. Bug Resolution Time: Reduce the time taken to identify and resolve issues. System Scalability: Optimize system performance to handle increasing user demands. Collaboration: Foster a collaborative environment that encourages teamwork and knowledge sharing. Customer Satisfaction: Incorporate stakeholder feedback to improve solutions and enhance the customer experience. Continuous Learning: Pursue opportunities for skill development and share knowledge with the team. Requirements: Required Skills & Qualifications Technical Tools: Experience with in Python and/or SQL. Experience with Bash, Shell scripting, Big Query, Airflow, and is a plus. Programming: Cleaning data using code-based approach. AI Proficiency: Interest or experience in using AI tools for coding and development of data solutions. Soft Skills: Problem-solving, cross-team collaboration, data storytelling, and stakeholder engagement. Adaptability: Thrives in a fast-paced startup environment and embraces change. Proactivity: Self-directed, organized, and able to prioritize effectively. Collaboration: Ability to work effectively with cross-functional teams. Education & Experience: A bachelor’s degree is required, and a graduate degree is preferred. Relevant experience in data engineering, software development, STEM, or related fields. Strong experience with SQL and Python is highly desirable. Mindset: A passion for innovation, continuous improvement, and delivering high-quality results from messy data. Preferred Qualifications Familiarity with cloud-based solutions (e.g., Google Cloud Platform, Azure). Experience with ETL processes and tools. Experience building data visualization reports and dashboards Knowledge of modern data storage solutions and database management systems. Exposure to DevOps practices and tools for deployment and monitoring. Why Join Us? Work with a talented, collaborative team dedicated to making a difference. Gain exposure to innovative technologies and opportunities for growth. Learn and utilize cutting-edge AI tools to enhance your development skills and create impactful solutions. Be part of a company that values your contributions and encourages professional development. Join a rapidly expanding health-tech startup (~200 employees and growing) with a state-of-the-art technology office located in Hyde Park, offering a variety of exceptional benefits. Career Progression Timeline In 3 months: Gain a comprehensive understanding of our data infrastructure, technical stacks, and development cycles. Actively participate in team meetings and contribute to the development of new data pipelines. Begin leveraging AI tools, such as Cursor and ChatGPT, to enhance coding efficiency and workflow automation. In 6 months: Contribute to product enhancements and data reporting Collaborate effectively with cross-functional teams, providing insights and solutions for data-related challenges. Demonstrate proficiency in utilizing AI tools for coding and development, actively sharing knowledge with the team. In 12 months: Contribute to data engineering projects, ensuring scalability and performance optimization. Mentor non-technical internal partners to improve company-wide data literacy Contribute to the integration of advanced AI solutions into our development processes, contributing to the company's technological advancement. Physical Requirements: Ability to remain at your designated workstation for the duration of the workday Constantly operates a computer and other office productivity machinery, such as a phone and Voice over Internet Protocol (VoIP). The ability to communicate information and ideas so others will understand. Must be able to exchange accurate information in these situations. The ability to observe details at close range (typically on a computer screen) This position offers the flexibility of remote work at approved locations within the United States. Candidates must have a reliable internet connection and a designated work environment conducive to professional phone calls and sensitive data. Enjoy the convenience and comfort of working remotely while contributing to our team's success. Apply Today If you’re ready to take on challenging problems, contribute to impactful solutions, and grow as a data engineer, we’d love to hear from you. Join us at The Helper Bees and be part of a team that’s making a meaningful difference every day! The Helper Bees is committed to building a workplace where diversity, equity, and inclusion are valued and prioritized. We are an equal opportunity employer that welcomes all qualified applicants without discrimination based on race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or any non-merit based or legally protected grounds. The Helper Bees provides reasonable accommodations to qualified individuals with disabilities during the job application and interview process. To request accommodation, please let your recruiter know. As part of our standard hiring process, selected candidates may be required to undergo a background check and/or drug screen. The Helper Bees adheres to applicable federal, state, and local laws regarding these screenings, and the results will be considered in accordance with applicable regulations. The Helper Bees was recently made aware of a fraudulent entity posing as our organization and requesting personal information. Please be aware of and protect yourself from scams. Visit thehelperbees.com/careers to view all current job openings.</td><td>data</td><td>Description: Join our winning team, recently honored as #67 on Forbes’ list of America’s Best Startup Employers for 2024! About The Helper Bees The Helper Bees’ mission is to help people stay home longer through data-driven services that transform both the payer and the care-recipient experience. At The Helper Bees, we are reshaping how care is delivered to aging individuals by leveraging innovative technology and insightful data solutions. We maintain multiple SaaS products and payment solutions through our web applications (internal and external facing), a mobile app, and reporting integrations. As part of our growing Data Engineering team, you’ll iterate quickly, have a high impact, and be challenged to design and implement cutting-edge solutions. At THB, we define our company culture through our Core Values: Quickly iterate through solutions: We move at a fast pace which requires quick iterations to find a path to a repeatable solution. Seek ways to create immediate impact: Be thoughtful and proactive in how you make an impact on your team. Actively look for ways to make a fast, positive impact. Bee the teammate you want to work with: We work as a team, help each other, and encourage each other. Ask questions, answer questions: You can't iterate through solutions if you don't ask the right questions, which is why there is an expectation that questions should be asked. When you know the answer, being a good teammate means chiming in to get others up to speed. Take the time to celebrate wins: It's so easy for a team that is heads down to forget about all the great things they've accomplished. That's why we make it a priority to remind ourselves to create space to celebrate wins, big or small. Job Summary We are seeking a motivated Data Engineer to join our team and help improve our tools, processes, and technical infrastructure. In this role, you will ensure the availability and quality of our data while contributing to the design, implementation, and maintenance of The Helper Bees’ products. You’ll collaborate across teams to create scalable and optimized software systems and play a key role in refining our development processes. This position offers a unique opportunity to learn and leverage cutting-edge AI development tools to enhance coding efficiency and develop advanced data tools and solutions. Supervisory Responsibilities: None Key Responsibilities Data Infrastructure: Design, implement, and maintain data pipelines, ensuring data availability, quality, and scalability. Product Development: Build and enhance products using Python, SQL, and modern technologies. AI Integration: Leverage cutting-edge AI tools, including Cursor, ChatGPT, and Claude to improve development processes, automate workflows, and create innovative data solutions. Collaboration: Communicate across departments to design, build, test, and implement new features and enhancements. Code Excellence: Produce quality, testable, and maintainable code while participating in code reviews. Problem Solving: Debug complex issues, interact with stakeholders, and design viable solutions with clear trade-offs. Process Optimization: Contribute to improving development processes, including deployment, on-call systems, and sprint planning. Team Growth: Collaborate within the development team to help each other grow and continuously learn. Stakeholder Engagement: Partner with analysts, scientists, and IT to ensure alignment and deliver data-driven solutions. Other duties as assigned/necessary Performance Metrics Code Quality: Maintain high coding standards through regular code reviews and adherence to best practices. Development Efficiency: Deliver high-quality features and fixes within efficient timeframes. Bug Resolution Time: Reduce the time taken to identify and resolve issues. System Scalability: Optimize system performance to handle increasing user demands. Collaboration: Foster a collaborative environment that encourages teamwork and knowledge sharing. Customer Satisfaction: Incorporate stakeholder feedback to improve solutions and enhance the customer experience. Continuous Learning: Pursue opportunities for skill development and share knowledge with the team. Requirements: Required Skills & Qualifications Technical Tools: Experience with in Python and/or SQL. Experience with Bash, Shell scripting, Big Query, Airflow, and is a plus. Programming: Cleaning data using code-based approach. AI Proficiency: Interest or experience in using AI tools for coding and development of data solutions. Soft Skills: Problem-solving, cross-team collaboration, data storytelling, and stakeholder engagement. Adaptability: Thrives in a fast-paced startup environment and embraces change. Proactivity: Self-directed, organized, and able to prioritize effectively. Collaboration: Ability to work effectively with cross-functional teams. Education & Experience: A bachelor’s degree is required, and a graduate degree is preferred. Relevant experience in data engineering, software development, STEM, or related fields. Strong experience with SQL and Python is highly desirable. Mindset: A passion for innovation, continuous improvement, and delivering high-quality results from messy data. Preferred Qualifications Familiarity with cloud-based solutions (e.g., Google Cloud Platform, Azure). Experience with ETL processes and tools. Experience building data visualization reports and dashboards Knowledge of modern data storage solutions and database management systems. Exposure to DevOps practices and tools for deployment and monitoring. Why Join Us? Work with a talented, collaborative team dedicated to making a difference. Gain exposure to innovative technologies and opportunities for growth. Learn and utilize cutting-edge AI tools to enhance your development skills and create impactful solutions. Be part of a company that values your contributions and encourages professional development. Join a rapidly expanding health-tech startup (~200 employees and growing) with a state-of-the-art technology office located in Hyde Park, offering a variety of exceptional benefits. Career Progression Timeline In 3 months: Gain a comprehensive understanding of our data infrastructure, technical stacks, and development cycles. Actively participate in team meetings and contribute to the development of new data pipelines. Begin leveraging AI tools, such as Cursor and ChatGPT, to enhance coding efficiency and workflow automation. In 6 months: Contribute to product enhancements and data reporting Collaborate effectively with cross-functional teams, providing insights and solutions for data-related challenges. Demonstrate proficiency in utilizing AI tools for coding and development, actively sharing knowledge with the team. In 12 months: Contribute to data engineering projects, ensuring scalability and performance optimization. Mentor non-technical internal partners to improve company-wide data literacy Contribute to the integration of advanced AI solutions into our development processes, contributing to the company's technological advancement. Physical Requirements: Ability to remain at your designated workstation for the duration of the workday Constantly operates a computer and other office productivity machinery, such as a phone and Voice over Internet Protocol (VoIP). The ability to communicate information and ideas so others will understand. Must be able to exchange accurate information in these situations. The ability to observe details at close range (typically on a computer screen) This position offers the flexibility of remote work at approved locations within the United States. Candidates must have a reliable internet connection and a designated work environment conducive to professional phone calls and sensitive data. Enjoy the convenience and comfort of working remotely while contributing to our team's success. Apply Today If you’re ready to take on challenging problems, contribute to impactful solutions, and grow as a data engineer, we’d love to hear from you. Join us at The Helper Bees and be part of a team that’s making a meaningful difference every day! The Helper Bees is committed to building a workplace where diversity, equity, and inclusion are valued and prioritized. We are an equal opportunity employer that welcomes all qualified applicants without discrimination based on race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or any non-merit based or legally protected grounds. The Helper Bees provides reasonable accommodations to qualified individuals with disabilities during the job application and interview process. To request accommodation, please let your recruiter know. As part of our standard hiring process, selected candidates may be required to undergo a background check and/or drug screen. The Helper Bees adheres to applicable federal, state, and local laws regarding these screenings, and the results will be considered in accordance with applicable regulations. The Helper Bees was recently made aware of a fraudulent entity posing as our organization and requesting personal information. Please be aware of and protect yourself from scams. Visit thehelperbees.com/careers to view all current job openings.</td><td>Description: Join our winning team, recently honored as #67 on Forbes’ list of America’s Best Startup Employers for 2024! About The Helper Bees The Helper Bees’ mission is to help people stay home longer through data-driven services that transform both the payer and the care-recipient experience. At The Helper Bees, we are reshaping how care is delivered to aging individuals by leveraging innovative technology and insightful data solutions. We maintain multiple SaaS products and payment solutions through our web applications (internal and external facing), a mobile app, and reporting integrations. As part of our growing Data Engineering team, you’ll iterate quickly, have a high impact, and be challenged to design and implement cutting-edge solutions. At THB, we define our company culture through our Core Values: Quickly iterate through solutions: We move at a fast pace which requires quick iterations to find a path to a repeatable solution. Seek ways to create immediate impact: Be thoughtful and proactive in how you make an impact on your team. Actively look for ways to make a fast, positive impact. Bee the teammate you want to work with: We work as a team, help each other, and encourage each other. Ask questions, answer questions: You can't iterate through solutions if you don't ask the right questions, which is why there is an expectation that questions should be asked. When you know the answer, being a good teammate means chiming in to get others up to speed. Take the time to celebrate wins: It's so easy for a team that is heads down to forget about all the great things they've accomplished. That's why we make it a priority to remind ourselves to create space to celebrate wins, big or small. Job Summary We are seeking a motivated Data Engineer to join our team and help improve our tools, processes, and technical infrastructure. In this role, you will ensure the availability and quality of our data while contributing to the design, implementation, and maintenance of The Helper Bees’ products. You’ll collaborate across teams to create scalable and optimized software systems and play a key role in refining our development processes. This position offers a unique opportunity to learn and leverage cutting-edge AI development tools to enhance coding efficiency and develop advanced data tools and solutions. Supervisory Responsibilities: None Key Responsibilities Data Infrastructure: Design, implement, and maintain data pipelines, ensuring data availability, quality, and scalability. Product Development: Build and enhance products using Python, SQL, and modern technologies. AI Integration: Leverage cutting-edge AI tools, including Cursor, ChatGPT, and Claude to improve development processes, automate workflows, and create innovative data solutions. Collaboration: Communicate across departments to design, build, test, and implement new features and enhancements. Code Excellence: Produce quality, testable, and maintainable code while participating in code reviews. Problem Solving: Debug complex issues, interact with stakeholders, and design viable solutions with clear trade-offs. Process Optimization: Contribute to improving development processes, including deployment, on-call systems, and sprint planning. Team Growth: Collaborate within the development team to help each other grow and continuously learn. Stakeholder Engagement: Partner with analysts, scientists, and IT to ensure alignment and deliver data-driven solutions. Other duties as assigned/necessary Performance Metrics Code Quality: Maintain high coding standards through regular code reviews and adherence to best practices. Development Efficiency: Deliver high-quality features and fixes within efficient timeframes. Bug Resolution Time: Reduce the time taken to identify and resolve issues. System Scalability: Optimize system performance to handle increasing user demands. Collaboration: Foster a collaborative environment that encourages teamwork and knowledge sharing. Customer Satisfaction: Incorporate stakeholder feedback to improve solutions and enhance the customer experience. Continuous Learning: Pursue opportunities for skill development and share knowledge with the team. Requirements: Required Skills & Qualifications Technical Tools: Experience with in Python and/or SQL. Experience with Bash, Shell scripting, Big Query, Airflow, and is a plus. Programming: Cleaning data using code-based approach. AI Proficiency: Interest or experience in using AI tools for coding and development of data solutions. Soft Skills: Problem-solving, cross-team collaboration, data storytelling, and stakeholder engagement. Adaptability: Thrives in a fast-paced startup environment and embraces change. Proactivity: Self-directed, organized, and able to prioritize effectively. Collaboration: Ability to work effectively with cross-functional teams. Education & Experience: A bachelor’s degree is required, and a graduate degree is preferred. Relevant experience in data engineering, software development, STEM, or related fields. Strong experience with SQL and Python is highly desirable. Mindset: A passion for innovation, continuous improvement, and delivering high-quality results from messy data. Preferred Qualifications Familiarity with cloud-based solutions (e.g., Google Cloud Platform, Azure). Experience with ETL processes and tools. Experience building data visualization reports and dashboards Knowledge of modern data storage solutions and database management systems. Exposure to DevOps practices and tools for deployment and monitoring. Why Join Us? Work with a talented, collaborative team dedicated to making a difference. Gain exposure to innovative technologies and opportunities for growth. Learn and utilize cutting-edge AI tools to enhance your development skills and create impactful solutions. Be part of a company that values your contributions and encourages professional development. Join a rapidly expanding health-tech startup (~200 employees and growing) with a state-of-the-art technology office located in Hyde Park, offering a variety of exceptional benefits. Career Progression Timeline In 3 months: Gain a comprehensive understanding of our data infrastructure, technical stacks, and development cycles. Actively participate in team meetings and contribute to the development of new data pipelines. Begin leveraging AI tools, such as Cursor and ChatGPT, to enhance coding efficiency and workflow automation. In 6 months: Contribute to product enhancements and data reporting Collaborate effectively with cross-functional teams, providing insights and solutions for data-related challenges. Demonstrate proficiency in utilizing AI tools for coding and development, actively sharing knowledge with the team. In 12 months: Contribute to data engineering projects, ensuring scalability and performance optimization. Mentor non-technical internal partners to improve company-wide data literacy Contribute to the integration of advanced AI solutions into our development processes, contributing to the company's technological advancement. Physical Requirements: Ability to remain at your designated workstation for the duration of the workday Constantly operates a computer and other office productivity machinery, such as a phone and Voice over Internet Protocol (VoIP). The ability to communicate information and ideas so others will understand. Must be able to exchange accurate information in these situations. The ability to observe details at close range (typically on a computer screen) This position offers the flexibility of remote work at approved locations within the United States. Candidates must have a reliable internet connection and a designated work environment conducive to professional phone calls and sensitive data. Enjoy the convenience and comfort of working remotely while contributing to our team's success. Apply Today If you’re ready to take on challenging problems, contribute to impactful solutions, and grow as a data engineer, we’d love to hear from you. Join us at The Helper Bees and be part of a team that’s making a meaningful difference every day! The Helper Bees is committed to building a workplace where diversity, equity, and inclusion are valued and prioritized. We are an equal opportunity employer that welcomes all qualified applicants without discrimination based on race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or any non-merit based or legally protected grounds. The Helper Bees provides reasonable accommodations to qualified individuals with disabilities during the job application and interview process. To request accommodation, please let your recruiter know. As part of our standard hiring process, selected candidates may be required to undergo a background check and/or drug screen. The Helper Bees adheres to applicable federal, state, and local laws regarding these screenings, and the results will be considered in accordance with applicable regulations. The Helper Bees was recently made aware of a fraudulent entity posing as our organization and requesting personal information. Please be aware of and protect yourself from scams. Visit thehelperbees.com/careers to view all current job openings.</td><td>Technical Tools: Experience with in Python and/or SQL. Experience with Bash, Shell scripting, Big Query, Airflow, and is a plus. Programming: Cleaning data using code-based approach. AI Proficiency: Interest or experience in using AI tools for coding and development of data solutions. Soft Skills: Problem-solving, cross-team collaboration, data storytelling, and stakeholder engagement. Adaptability: Thrives in a fast-paced startup environment and embraces change. Proactivity: Self-directed, organized, and able to prioritize effectively. Collaboration: Ability to work effectively with cross-functional teams. Education & Experience: A bachelor’s degree is required, and a graduate degree is preferred. Relevant experience in data engineering, software development, STEM, or related fields. Strong experience with SQL and Python is highly desirable. Mindset: A passion for innovation, continuous improvement, and delivering high-quality results from messy data. Preferred Qualifications Familiarity with cloud-based solutions (e.g., Google Cloud Platform, Azure). Experience with ETL processes and tools. Experience building data visualization reports and dashboards Knowledge of modern data storage solutions and database management systems. Exposure to DevOps practices and tools for deployment and monitoring. Why Join Us? Work with a talented, collaborative team dedicated to making a difference. Gain exposure to innovative technologies and opportunities for growth. Learn and utilize cutting-edge AI tools to enhance your development skills and create impactful solutions. Be part of a company that values your contributions and encourages professional development. Join a rapidly expanding health-tech startup (~200 employees and growing) with a state-of-the-art technology office located in Hyde Park, offering a variety of exceptional benefits. Career Progression Timeline In 3 months: Gain a comprehensive understanding of our data infrastructure, technical stacks, and development cycles. Actively participate in team meetings and contribute to the development of new data pipelines. Begin leveraging AI tools, such as Cursor and ChatGPT, to enhance coding efficiency and workflow automation. In 6 months: Contribute to product enhancements and data reporting Collaborate effectively with cross-functional teams, providing insights and solutions for data-related challenges. Demonstrate proficiency in utilizing AI tools for coding and development, actively sharing knowledge with the team. In 12 months: Contribute to data engineering projects, ensuring scalability and performance optimization. Mentor non-technical internal partners to improve company-wide data literacy Contribute to the integration of advanced AI solutions into our development processes, contributing to the company's technological advancement. Physical Requirements: Ability to remain at your designated workstation for the duration of the workday Constantly operates a computer and other office productivity machinery, such as a phone and Voice over Internet Protocol (VoIP). The ability to communicate information and ideas so others will understand. Must be able to exchange accurate information in these situations. The ability to observe details at close range (typically on a computer screen) This position offers the flexibility of remote work at approved locations within the United States. Candidates must have a reliable internet connection and a designated work environment conducive to professional phone calls and sensitive data. Enjoy the convenience and comfort of working remotely while contributing to our team's success. Apply Today If you’re ready to take on challenging problems, contribute to impactful solutions, and grow as a data engineer, we’d love to hear from you. Join us at The Helper Bees and be part of a team that’s making a meaningful difference every day! The Helper Bees is committed to building a workplace where diversity, equity, and inclusion are valued and prioritized. We are an equal opportunity employer that welcomes all qualified applicants without discrimination based on race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or any non-merit based or legally protected grounds. The Helper Bees provides reasonable accommodations to qualified individuals with disabilities during the job application and interview process. To request accommodation, please let your recruiter know. As part of our standard hiring process, selected candidates may be required to undergo a background check and/or drug screen. The Helper Bees adheres to applicable federal, state, and local laws regarding these screenings, and the results will be considered in accordance with applicable regulations. The Helper Bees was recently made aware of a fraudulent entity posing as our organization and requesting personal information. Please be aware of and protect yourself from scams. Visit thehelperbees.com/careers to view all current job openings.</td><td>698</td></tr><tr><td>Data Engineer II (Remote)</td><td>, we welcome people of all abilities and want to ensure that our hiring and interview process meets the needs of all applicants. If you require a reasonable accommodation to make your application or interview experience a great one, please contact HRsupport@randstadusa.com.</td><td>Index Analytics, LLC, is a rapidly growing, Baltimore-based small business providing health-related consulting services to the federal government. At the center of our company culture is a commitment to instilling a dynamic and employee-friendly place to work. We place a priority on promoting a supportive and collegial team environment and enhancing staff experience through career development and educational opportunities. Position Overview The Data Engineer is responsible for designing, building, and maintaining data pipelines and architectures to support data analytics and reporting needs across the organization. This role involves working closely with data scientists, analysts, and other stakeholders to ensure that data is clean, accessible, and ready for analysis. The Data Engineer will optimize data systems, develop data integration solutions, and ensure data security and governance. Key responsibilities include creating ETL processes, managing databases, and improving data infrastructure performance. The ideal candidate has strong programming and database skills and experience with cloud-based data platforms. Responsibilities Leads design, implementation, and management of data pipelines Develops and executes ETL (extract, transform, load) or ELT code Supports design of robust Data Integration Architecture to support customers Helps monitor and administer the systems and ensures applications and systems are always functioning properly Analyzes the Data Integration and Engineering architecture to identify weaknesses and develops improvements such as enhancing business processes Identifies and analyzes business requirements, functional design, and translation of requirements to technical specifications Performs complex query design, developments, validation routine analysis, and streamlining processes Operates large data sets, delta data sets and querying efficiently Transforms, joins, and normalizes data in service of specific use cases. Employs AWS data pipeline solutions such as Glue, Data Pipeline, Step functions, MWAA to orchestrate data movement Work with DevSecOps engineer to deploy continuous integration and continuous deployment (CI/CD) data pipelines Understand the technical architecture to design, build, optimize, and maintain scalable data solutions in a Big Data environment Work with Product Owners and/or business stakeholders to gather business requirements and translate to detailed technical specifications US citizen or Authorized to Work and lived in the US for 3 of the last 5 years. Must be able to obtain a U.S. Federal government client badge and pass a government Public Trust. Bachelors degree or higher in IT or relevant discipline required 4+ years of IT experience Experience with setting up and operating data pipelines using Python or SQL Experience with Scala and PySpark 3+ years of experience working on AWS, GCP or Azure (AWS Preferred) cloud platforms Hands-on relational DB / NoSQL experience (PostgreSQL or similar) with specific implementation on cloud Experience working with data warehouses such as Redshift to open source and proprietary cloud data pipeline tools such as Airflow, Glue, Data Pipeline, Step functions Experience working with relational databases that handle structured and semi-structured (JSON) datasets Experience with data serialization languages such as JSON, XML, YAML Experience with code management tools (e.g. Git, SVN) and DevOps tools (e.g. Jenkins, Docker, AWS Code Pipeline) Strong analytical problem-solving ability Working experience with Transactional and Dimensional data modeling methodologies (Eg: Normalization, Star Schema, Snowflake Schema) Experience working with a distributed computing environment like AWS EMR or similar. Ability to obtain Public Trust level clearance Ability to demonstrate excellent written and oral communication required Prior experience with Center for Medicare Medicaid Services or other Govt agencies is a plus The salary range provided represents the estimated compensation for new hires in this position, applicable across all locations. Actual offers may vary based on factors such as the candidate's skills, qualifications, experience, and market conditions. Index complements its base salary offering with a competitive package that includes health and retirement benefits, discretionary bonuses, and reimbursement for professional development opportunities. Index Analytics provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training. Attention Candidates We're dedicated to ensuring a safe and transparent recruitment process for all candidates and have implemented robust measures to protect your personal information. Please be aware that all employment-related communications will originate from a secure portal ( NAME@msg.paycomonline.com ) or a corporate email address ( NAME@index-analytics.com ). If you have any concerns, please don't hesitate to reach out to us at recruiting@index-analytics.com</td><td>data</td><td>Index Analytics, LLC, is a rapidly growing, Baltimore-based small business providing health-related consulting services to the federal government. At the center of our company culture is a commitment to instilling a dynamic and employee-friendly place to work. We place a priority on promoting a supportive and collegial team environment and enhancing staff experience through career development and educational opportunities. Position Overview The Data Engineer is responsible for designing, building, and maintaining data pipelines and architectures to support data analytics and reporting needs across the organization. This role involves working closely with data scientists, analysts, and other stakeholders to ensure that data is clean, accessible, and ready for analysis. The Data Engineer will optimize data systems, develop data integration solutions, and ensure data security and governance. Key responsibilities include creating ETL processes, managing databases, and improving data infrastructure performance. The ideal candidate has strong programming and database skills and experience with cloud-based data platforms. Responsibilities Leads design, implementation, and management of data pipelines Develops and executes ETL (extract, transform, load) or ELT code Supports design of robust Data Integration Architecture to support customers Helps monitor and administer the systems and ensures applications and systems are always functioning properly Analyzes the Data Integration and Engineering architecture to identify weaknesses and develops improvements such as enhancing business processes Identifies and analyzes business requirements, functional design, and translation of requirements to technical specifications Performs complex query design, developments, validation routine analysis, and streamlining processes Operates large data sets, delta data sets and querying efficiently Transforms, joins, and normalizes data in service of specific use cases. Employs AWS data pipeline solutions such as Glue, Data Pipeline, Step functions, MWAA to orchestrate data movement Work with DevSecOps engineer to deploy continuous integration and continuous deployment (CI/CD) data pipelines Understand the technical architecture to design, build, optimize, and maintain scalable data solutions in a Big Data environment Work with Product Owners and/or business stakeholders to gather business requirements and translate to detailed technical specifications US citizen or Authorized to Work and lived in the US for 3 of the last 5 years. Must be able to obtain a U.S. Federal government client badge and pass a government Public Trust. Bachelors degree or higher in IT or relevant discipline required 4+ years of IT experience Experience with setting up and operating data pipelines using Python or SQL Experience with Scala and PySpark 3+ years of experience working on AWS, GCP or Azure (AWS Preferred) cloud platforms Hands-on relational DB / NoSQL experience (PostgreSQL or similar) with specific implementation on cloud Experience working with data warehouses such as Redshift to open source and proprietary cloud data pipeline tools such as Airflow, Glue, Data Pipeline, Step functions Experience working with relational databases that handle structured and semi-structured (JSON) datasets Experience with data serialization languages such as JSON, XML, YAML Experience with code management tools (e.g. Git, SVN) and DevOps tools (e.g. Jenkins, Docker, AWS Code Pipeline) Strong analytical problem-solving ability Working experience with Transactional and Dimensional data modeling methodologies (Eg: Normalization, Star Schema, Snowflake Schema) Experience working with a distributed computing environment like AWS EMR or similar. Ability to obtain Public Trust level clearance Ability to demonstrate excellent written and oral communication required Prior experience with Center for Medicare Medicaid Services or other Govt agencies is a plus The salary range provided represents the estimated compensation for new hires in this position, applicable across all locations. Actual offers may vary based on factors such as the candidate's skills, qualifications, experience, and market conditions. Index complements its base salary offering with a competitive package that includes health and retirement benefits, discretionary bonuses, and reimbursement for professional development opportunities. Index Analytics provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training. Attention Candidates We're dedicated to ensuring a safe and transparent recruitment process for all candidates and have implemented robust measures to protect your personal information. Please be aware that all employment-related communications will originate from a secure portal ( NAME@msg.paycomonline.com ) or a corporate email address ( NAME@index-analytics.com ). If you have any concerns, please don't hesitate to reach out to us at recruiting@index-analytics.com</td><td>Index Analytics, LLC, is a rapidly growing, Baltimore-based small business providing health-related consulting services to the federal government. At the center of our company culture is a commitment to instilling a dynamic and employee-friendly place to work. We place a priority on promoting a supportive and collegial team environment and enhancing staff experience through career development and educational opportunities. Position Overview The Data Engineer is responsible for designing, building, and maintaining data pipelines and architectures to support data analytics and reporting needs across the organization. This role involves working closely with data scientists, analysts, and other stakeholders to ensure that data is clean, accessible, and ready for analysis. The Data Engineer will optimize data systems, develop data integration solutions, and ensure data security and governance. Key responsibilities include creating ETL processes, managing databases, and improving data infrastructure performance. The ideal candidate has strong programming and database skills and experience with cloud-based data platforms. Responsibilities Leads design, implementation, and management of data pipelines Develops and executes ETL (extract, transform, load) or ELT code Supports design of robust Data Integration Architecture to support customers Helps monitor and administer the systems and ensures applications and systems are always functioning properly Analyzes the Data Integration and Engineering architecture to identify weaknesses and develops improvements such as enhancing business processes Identifies and analyzes business requirements, functional design, and translation of requirements to technical specifications Performs complex query design, developments, validation routine analysis, and streamlining processes Operates large data sets, delta data sets and querying efficiently Transforms, joins, and normalizes data in service of specific use cases. Employs AWS data pipeline solutions such as Glue, Data Pipeline, Step functions, MWAA to orchestrate data movement Work with DevSecOps engineer to deploy continuous integration and continuous deployment (CI/CD) data pipelines Understand the technical architecture to design, build, optimize, and maintain scalable data solutions in a Big Data environment Work with Product Owners and/or business stakeholders to gather business requirements and translate to detailed technical specifications US citizen or Authorized to Work and lived in the US for 3 of the last 5 years. Must be able to obtain a U.S. Federal government client badge and pass a government Public Trust. Bachelors degree or higher in IT or relevant discipline required 4+ years of IT experience Experience with setting up and operating data pipelines using Python or SQL Experience with Scala and PySpark 3+ years of experience working on AWS, GCP or Azure (AWS Preferred) cloud platforms Hands-on relational DB / NoSQL experience (PostgreSQL or similar) with specific implementation on cloud Experience working with data warehouses such as Redshift to open source and proprietary cloud data pipeline tools such as Airflow, Glue, Data Pipeline, Step functions Experience working with relational databases that handle structured and semi-structured (JSON) datasets Experience with data serialization languages such as JSON, XML, YAML Experience with code management tools (e.g. Git, SVN) and DevOps tools (e.g. Jenkins, Docker, AWS Code Pipeline) Strong analytical problem-solving ability Working experience with Transactional and Dimensional data modeling methodologies (Eg: Normalization, Star Schema, Snowflake Schema) Experience working with a distributed computing environment like AWS EMR or similar. Ability to obtain Public Trust level clearance Ability to demonstrate excellent written and oral communication required Prior experience with Center for Medicare Medicaid Services or other Govt agencies is a plus The salary range provided represents the estimated compensation for new hires in this position, applicable across all locations. Actual offers may vary based on factors such as the candidate's skills, qualifications, experience, and market conditions. Index complements its base salary offering with a competitive package that includes health and retirement benefits, discretionary bonuses, and reimbursement for professional development opportunities. Index Analytics provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training. Attention Candidates We're dedicated to ensuring a safe and transparent recruitment process for all candidates and have implemented robust measures to protect your personal information. Please be aware that all employment-related communications will originate from a secure portal ( NAME@msg.paycomonline.com ) or a corporate email address ( NAME@index-analytics.com ). If you have any concerns, please don't hesitate to reach out to us at recruiting@index-analytics.com</td><td>to technical specifications Performs complex query design, developments, validation routine analysis, and streamlining processes Operates large data sets, delta data sets and querying efficiently Transforms, joins, and normalizes data in service of specific use cases. Employs AWS data pipeline solutions such as Glue, Data Pipeline, Step functions, MWAA to orchestrate data movement Work with DevSecOps engineer to deploy continuous integration and continuous deployment (CI/CD) data pipelines Understand the technical architecture to design, build, optimize, and maintain scalable data solutions in a Big Data environment Work with Product Owners and/or business stakeholders to gather business requirements and translate to detailed technical specifications US citizen or Authorized to Work and lived in the US for 3 of the last 5 years. Must be able to obtain a U.S. Federal government client badge and pass a government Public Trust. Bachelors degree or higher in IT or relevant discipline required 4+ years of IT experience Experience with setting up and operating data pipelines using Python or SQL Experience with Scala and PySpark 3+ years of experience working on AWS, GCP or Azure (AWS Preferred) cloud platforms Hands-on relational DB / NoSQL experience (PostgreSQL or similar) with specific implementation on cloud Experience working with data warehouses such as Redshift to open source and proprietary cloud data pipeline tools such as Airflow, Glue, Data Pipeline, Step functions Experience working with relational databases that handle structured and semi-structured (JSON) datasets Experience with data serialization languages such as JSON, XML, YAML Experience with code management tools (e.g. Git, SVN) and DevOps tools (e.g. Jenkins, Docker, AWS Code Pipeline) Strong analytical problem-solving ability Working experience with Transactional and Dimensional data modeling methodologies (Eg: Normalization, Star Schema, Snowflake Schema) Experience working with a distributed computing environment like AWS EMR or similar. Ability to obtain Public Trust level clearance Ability to demonstrate excellent written and oral communication required Prior experience with Center for Medicare Medicaid Services or other Govt agencies is a plus The salary range provided represents the estimated compensation for new hires in this position, applicable across all locations. Actual offers may vary based on factors such as the candidate's skills, qualifications, experience, and market conditions. Index complements its base salary offering with a competitive package that includes health and retirement benefits, discretionary bonuses, and reimbursement for professional development opportunities. Index Analytics provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training. Attention Candidates We're dedicated to ensuring a safe and transparent recruitment process for all candidates and have implemented robust measures to protect your personal information. Please be aware that all employment-related communications will originate from a secure portal ( NAME@msg.paycomonline.com ) or a corporate email address ( NAME@index-analytics.com ). If you have any concerns, please don't hesitate to reach out to us at recruiting@index-analytics.com</td><td>524</td></tr><tr><td>null</td><td>The Helper Bees</td><td>Description: Join our winning team, recently honored as #67 on Forbes’ list of America’s Best Startup Employers for 2024! About The Helper Bees The Helper Bees’ mission is to help people stay home longer through data-driven services that transform both the payer and the care-recipient experience. At The Helper Bees, we are reshaping how care is delivered to aging individuals by leveraging innovative technology and insightful data solutions. We maintain multiple SaaS products and payment solutions through our web applications (internal and external facing), a mobile app, and reporting integrations. As part of our growing Data Engineering team, you’ll iterate quickly, have a high impact, and be challenged to design and implement cutting-edge solutions. At THB, we define our company culture through our Core Values: Quickly iterate through solutions: We move at a fast pace which requires quick iterations to find a path to a repeatable solution. Seek ways to create immediate impact: Be thoughtful and proactive in how you make an impact on your team. Actively look for ways to make a fast, positive impact. Bee the teammate you want to work with: We work as a team, help each other, and encourage each other. Ask questions, answer questions: You can't iterate through solutions if you don't ask the right questions, which is why there is an expectation that questions should be asked. When you know the answer, being a good teammate means chiming in to get others up to speed. Take the time to celebrate wins: It's so easy for a team that is heads down to forget about all the great things they've accomplished. That's why we make it a priority to remind ourselves to create space to celebrate wins, big or small. Job Summary We are seeking a motivated Data Engineer to join our team and help improve our tools, processes, and technical infrastructure. In this role, you will ensure the availability and quality of our data while contributing to the design, implementation, and maintenance of The Helper Bees’ products. You’ll collaborate across teams to create scalable and optimized software systems and play a key role in refining our development processes. This position offers a unique opportunity to learn and leverage cutting-edge AI development tools to enhance coding efficiency and develop advanced data tools and solutions. Supervisory Responsibilities: None Key Responsibilities Data Infrastructure: Design, implement, and maintain data pipelines, ensuring data availability, quality, and scalability. Product Development: Build and enhance products using Python, SQL, and modern technologies. AI Integration: Leverage cutting-edge AI tools, including Cursor, ChatGPT, and Claude to improve development processes, automate workflows, and create innovative data solutions. Collaboration: Communicate across departments to design, build, test, and implement new features and enhancements. Code Excellence: Produce quality, testable, and maintainable code while participating in code reviews. Problem Solving: Debug complex issues, interact with stakeholders, and design viable solutions with clear trade-offs. Process Optimization: Contribute to improving development processes, including deployment, on-call systems, and sprint planning. Team Growth: Collaborate within the development team to help each other grow and continuously learn. Stakeholder Engagement: Partner with analysts, scientists, and IT to ensure alignment and deliver data-driven solutions. Other duties as assigned/necessary Performance Metrics Code Quality: Maintain high coding standards through regular code reviews and adherence to best practices. Development Efficiency: Deliver high-quality features and fixes within efficient timeframes. Bug Resolution Time: Reduce the time taken to identify and resolve issues. System Scalability: Optimize system performance to handle increasing user demands. Collaboration: Foster a collaborative environment that encourages teamwork and knowledge sharing. Customer Satisfaction: Incorporate stakeholder feedback to improve solutions and enhance the customer experience. Continuous Learning: Pursue opportunities for skill development and share knowledge with the team. Requirements: Required Skills & Qualifications Technical Tools: Experience with in Python and/or SQL. Experience with Bash, Shell scripting, Big Query, Airflow, and is a plus. Programming: Cleaning data using code-based approach. AI Proficiency: Interest or experience in using AI tools for coding and development of data solutions. Soft Skills: Problem-solving, cross-team collaboration, data storytelling, and stakeholder engagement. Adaptability: Thrives in a fast-paced startup environment and embraces change. Proactivity: Self-directed, organized, and able to prioritize effectively. Collaboration: Ability to work effectively with cross-functional teams. Education & Experience: A bachelor’s degree is required, and a graduate degree is preferred. Relevant experience in data engineering, software development, STEM, or related fields. Strong experience with SQL and Python is highly desirable. Mindset: A passion for innovation, continuous improvement, and delivering high-quality results from messy data. Preferred Qualifications Familiarity with cloud-based solutions (e.g., Google Cloud Platform, Azure). Experience with ETL processes and tools. Experience building data visualization reports and dashboards Knowledge of modern data storage solutions and database management systems. Exposure to DevOps practices and tools for deployment and monitoring. Why Join Us? Work with a talented, collaborative team dedicated to making a difference. Gain exposure to innovative technologies and opportunities for growth. Learn and utilize cutting-edge AI tools to enhance your development skills and create impactful solutions. Be part of a company that values your contributions and encourages professional development. Join a rapidly expanding health-tech startup (~200 employees and growing) with a state-of-the-art technology office located in Hyde Park, offering a variety of exceptional benefits. Career Progression Timeline In 3 months: Gain a comprehensive understanding of our data infrastructure, technical stacks, and development cycles. Actively participate in team meetings and contribute to the development of new data pipelines. Begin leveraging AI tools, such as Cursor and ChatGPT, to enhance coding efficiency and workflow automation. In 6 months: Contribute to product enhancements and data reporting Collaborate effectively with cross-functional teams, providing insights and solutions for data-related challenges. Demonstrate proficiency in utilizing AI tools for coding and development, actively sharing knowledge with the team. In 12 months: Contribute to data engineering projects, ensuring scalability and performance optimization. Mentor non-technical internal partners to improve company-wide data literacy Contribute to the integration of advanced AI solutions into our development processes, contributing to the company's technological advancement. Physical Requirements: Ability to remain at your designated workstation for the duration of the workday Constantly operates a computer and other office productivity machinery, such as a phone and Voice over Internet Protocol (VoIP). The ability to communicate information and ideas so others will understand. Must be able to exchange accurate information in these situations. The ability to observe details at close range (typically on a computer screen) This position offers the flexibility of remote work at approved locations within the United States. Candidates must have a reliable internet connection and a designated work environment conducive to professional phone calls and sensitive data. Enjoy the convenience and comfort of working remotely while contributing to our team's success. Apply Today If you’re ready to take on challenging problems, contribute to impactful solutions, and grow as a data engineer, we’d love to hear from you. Join us at The Helper Bees and be part of a team that’s making a meaningful difference every day! The Helper Bees is committed to building a workplace where diversity, equity, and inclusion are valued and prioritized. We are an equal opportunity employer that welcomes all qualified applicants without discrimination based on race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or any non-merit based or legally protected grounds. The Helper Bees provides reasonable accommodations to qualified individuals with disabilities during the job application and interview process. To request accommodation, please let your recruiter know. As part of our standard hiring process, selected candidates may be required to undergo a background check and/or drug screen. The Helper Bees adheres to applicable federal, state, and local laws regarding these screenings, and the results will be considered in accordance with applicable regulations. The Helper Bees was recently made aware of a fraudulent entity posing as our organization and requesting personal information. Please be aware of and protect yourself from scams. Visit thehelperbees.com/careers to view all current job openings. Opened URL: https://www.indeed.com/rc/clk?jk=06050d41e9f16407&bb=1TLRjqutBEYcit1OApAPto3A50Hg4Pzq5qFUF25sU891HTb0FMRKF-y31Tt72Rgj3vRHASDwe2nU2bKOyor677T1mfz6aMuuBmnum2LV6DDSRY1DGNuI6LNVrSB8DuSr&xkcb=SoDU67M33zDWevR-pR0JbzkdCdPP&fccid=61e4e7d2ce056d37&vjs=3</td><td>data</td><td>Description: Join our winning team, recently honored as #67 on Forbes’ list of America’s Best Startup Employers for 2024! About The Helper Bees The Helper Bees’ mission is to help people stay home longer through data-driven services that transform both the payer and the care-recipient experience. At The Helper Bees, we are reshaping how care is delivered to aging individuals by leveraging innovative technology and insightful data solutions. We maintain multiple SaaS products and payment solutions through our web applications (internal and external facing), a mobile app, and reporting integrations. As part of our growing Data Engineering team, you’ll iterate quickly, have a high impact, and be challenged to design and implement cutting-edge solutions. At THB, we define our company culture through our Core Values: Quickly iterate through solutions: We move at a fast pace which requires quick iterations to find a path to a repeatable solution. Seek ways to create immediate impact: Be thoughtful and proactive in how you make an impact on your team. Actively look for ways to make a fast, positive impact. Bee the teammate you want to work with: We work as a team, help each other, and encourage each other. Ask questions, answer questions: You can't iterate through solutions if you don't ask the right questions, which is why there is an expectation that questions should be asked. When you know the answer, being a good teammate means chiming in to get others up to speed. Take the time to celebrate wins: It's so easy for a team that is heads down to forget about all the great things they've accomplished. That's why we make it a priority to remind ourselves to create space to celebrate wins, big or small. Job Summary We are seeking a motivated Data Engineer to join our team and help improve our tools, processes, and technical infrastructure. In this role, you will ensure the availability and quality of our data while contributing to the design, implementation, and maintenance of The Helper Bees’ products. You’ll collaborate across teams to create scalable and optimized software systems and play a key role in refining our development processes. This position offers a unique opportunity to learn and leverage cutting-edge AI development tools to enhance coding efficiency and develop advanced data tools and solutions. Supervisory Responsibilities: None Key Responsibilities Data Infrastructure: Design, implement, and maintain data pipelines, ensuring data availability, quality, and scalability. Product Development: Build and enhance products using Python, SQL, and modern technologies. AI Integration: Leverage cutting-edge AI tools, including Cursor, ChatGPT, and Claude to improve development processes, automate workflows, and create innovative data solutions. Collaboration: Communicate across departments to design, build, test, and implement new features and enhancements. Code Excellence: Produce quality, testable, and maintainable code while participating in code reviews. Problem Solving: Debug complex issues, interact with stakeholders, and design viable solutions with clear trade-offs. Process Optimization: Contribute to improving development processes, including deployment, on-call systems, and sprint planning. Team Growth: Collaborate within the development team to help each other grow and continuously learn. Stakeholder Engagement: Partner with analysts, scientists, and IT to ensure alignment and deliver data-driven solutions. Other duties as assigned/necessary Performance Metrics Code Quality: Maintain high coding standards through regular code reviews and adherence to best practices. Development Efficiency: Deliver high-quality features and fixes within efficient timeframes. Bug Resolution Time: Reduce the time taken to identify and resolve issues. System Scalability: Optimize system performance to handle increasing user demands. Collaboration: Foster a collaborative environment that encourages teamwork and knowledge sharing. Customer Satisfaction: Incorporate stakeholder feedback to improve solutions and enhance the customer experience. Continuous Learning: Pursue opportunities for skill development and share knowledge with the team. Requirements: Required Skills & Qualifications Technical Tools: Experience with in Python and/or SQL. Experience with Bash, Shell scripting, Big Query, Airflow, and is a plus. Programming: Cleaning data using code-based approach. AI Proficiency: Interest or experience in using AI tools for coding and development of data solutions. Soft Skills: Problem-solving, cross-team collaboration, data storytelling, and stakeholder engagement. Adaptability: Thrives in a fast-paced startup environment and embraces change. Proactivity: Self-directed, organized, and able to prioritize effectively. Collaboration: Ability to work effectively with cross-functional teams. Education & Experience: A bachelor’s degree is required, and a graduate degree is preferred. Relevant experience in data engineering, software development, STEM, or related fields. Strong experience with SQL and Python is highly desirable. Mindset: A passion for innovation, continuous improvement, and delivering high-quality results from messy data. Preferred Qualifications Familiarity with cloud-based solutions (e.g., Google Cloud Platform, Azure). Experience with ETL processes and tools. Experience building data visualization reports and dashboards Knowledge of modern data storage solutions and database management systems. Exposure to DevOps practices and tools for deployment and monitoring. Why Join Us? Work with a talented, collaborative team dedicated to making a difference. Gain exposure to innovative technologies and opportunities for growth. Learn and utilize cutting-edge AI tools to enhance your development skills and create impactful solutions. Be part of a company that values your contributions and encourages professional development. Join a rapidly expanding health-tech startup (~200 employees and growing) with a state-of-the-art technology office located in Hyde Park, offering a variety of exceptional benefits. Career Progression Timeline In 3 months: Gain a comprehensive understanding of our data infrastructure, technical stacks, and development cycles. Actively participate in team meetings and contribute to the development of new data pipelines. Begin leveraging AI tools, such as Cursor and ChatGPT, to enhance coding efficiency and workflow automation. In 6 months: Contribute to product enhancements and data reporting Collaborate effectively with cross-functional teams, providing insights and solutions for data-related challenges. Demonstrate proficiency in utilizing AI tools for coding and development, actively sharing knowledge with the team. In 12 months: Contribute to data engineering projects, ensuring scalability and performance optimization. Mentor non-technical internal partners to improve company-wide data literacy Contribute to the integration of advanced AI solutions into our development processes, contributing to the company's technological advancement. Physical Requirements: Ability to remain at your designated workstation for the duration of the workday Constantly operates a computer and other office productivity machinery, such as a phone and Voice over Internet Protocol (VoIP). The ability to communicate information and ideas so others will understand. Must be able to exchange accurate information in these situations. The ability to observe details at close range (typically on a computer screen) This position offers the flexibility of remote work at approved locations within the United States. Candidates must have a reliable internet connection and a designated work environment conducive to professional phone calls and sensitive data. Enjoy the convenience and comfort of working remotely while contributing to our team's success. Apply Today If you’re ready to take on challenging problems, contribute to impactful solutions, and grow as a data engineer, we’d love to hear from you. Join us at The Helper Bees and be part of a team that’s making a meaningful difference every day! The Helper Bees is committed to building a workplace where diversity, equity, and inclusion are valued and prioritized. We are an equal opportunity employer that welcomes all qualified applicants without discrimination based on race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or any non-merit based or legally protected grounds. The Helper Bees provides reasonable accommodations to qualified individuals with disabilities during the job application and interview process. To request accommodation, please let your recruiter know. As part of our standard hiring process, selected candidates may be required to undergo a background check and/or drug screen. The Helper Bees adheres to applicable federal, state, and local laws regarding these screenings, and the results will be considered in accordance with applicable regulations. The Helper Bees was recently made aware of a fraudulent entity posing as our organization and requesting personal information. Please be aware of and protect yourself from scams. Visit thehelperbees.com/careers to view all current job openings.</td><td>Description: Join our winning team, recently honored as #67 on Forbes’ list of America’s Best Startup Employers for 2024! About The Helper Bees The Helper Bees’ mission is to help people stay home longer through data-driven services that transform both the payer and the care-recipient experience. At The Helper Bees, we are reshaping how care is delivered to aging individuals by leveraging innovative technology and insightful data solutions. We maintain multiple SaaS products and payment solutions through our web applications (internal and external facing), a mobile app, and reporting integrations. As part of our growing Data Engineering team, you’ll iterate quickly, have a high impact, and be challenged to design and implement cutting-edge solutions. At THB, we define our company culture through our Core Values: Quickly iterate through solutions: We move at a fast pace which requires quick iterations to find a path to a repeatable solution. Seek ways to create immediate impact: Be thoughtful and proactive in how you make an impact on your team. Actively look for ways to make a fast, positive impact. Bee the teammate you want to work with: We work as a team, help each other, and encourage each other. Ask questions, answer questions: You can't iterate through solutions if you don't ask the right questions, which is why there is an expectation that questions should be asked. When you know the answer, being a good teammate means chiming in to get others up to speed. Take the time to celebrate wins: It's so easy for a team that is heads down to forget about all the great things they've accomplished. That's why we make it a priority to remind ourselves to create space to celebrate wins, big or small. Job Summary We are seeking a motivated Data Engineer to join our team and help improve our tools, processes, and technical infrastructure. In this role, you will ensure the availability and quality of our data while contributing to the design, implementation, and maintenance of The Helper Bees’ products. You’ll collaborate across teams to create scalable and optimized software systems and play a key role in refining our development processes. This position offers a unique opportunity to learn and leverage cutting-edge AI development tools to enhance coding efficiency and develop advanced data tools and solutions. Supervisory Responsibilities: None Key Responsibilities Data Infrastructure: Design, implement, and maintain data pipelines, ensuring data availability, quality, and scalability. Product Development: Build and enhance products using Python, SQL, and modern technologies. AI Integration: Leverage cutting-edge AI tools, including Cursor, ChatGPT, and Claude to improve development processes, automate workflows, and create innovative data solutions. Collaboration: Communicate across departments to design, build, test, and implement new features and enhancements. Code Excellence: Produce quality, testable, and maintainable code while participating in code reviews. Problem Solving: Debug complex issues, interact with stakeholders, and design viable solutions with clear trade-offs. Process Optimization: Contribute to improving development processes, including deployment, on-call systems, and sprint planning. Team Growth: Collaborate within the development team to help each other grow and continuously learn. Stakeholder Engagement: Partner with analysts, scientists, and IT to ensure alignment and deliver data-driven solutions. Other duties as assigned/necessary Performance Metrics Code Quality: Maintain high coding standards through regular code reviews and adherence to best practices. Development Efficiency: Deliver high-quality features and fixes within efficient timeframes. Bug Resolution Time: Reduce the time taken to identify and resolve issues. System Scalability: Optimize system performance to handle increasing user demands. Collaboration: Foster a collaborative environment that encourages teamwork and knowledge sharing. Customer Satisfaction: Incorporate stakeholder feedback to improve solutions and enhance the customer experience. Continuous Learning: Pursue opportunities for skill development and share knowledge with the team. Requirements: Required Skills & Qualifications Technical Tools: Experience with in Python and/or SQL. Experience with Bash, Shell scripting, Big Query, Airflow, and is a plus. Programming: Cleaning data using code-based approach. AI Proficiency: Interest or experience in using AI tools for coding and development of data solutions. Soft Skills: Problem-solving, cross-team collaboration, data storytelling, and stakeholder engagement. Adaptability: Thrives in a fast-paced startup environment and embraces change. Proactivity: Self-directed, organized, and able to prioritize effectively. Collaboration: Ability to work effectively with cross-functional teams. Education & Experience: A bachelor’s degree is required, and a graduate degree is preferred. Relevant experience in data engineering, software development, STEM, or related fields. Strong experience with SQL and Python is highly desirable. Mindset: A passion for innovation, continuous improvement, and delivering high-quality results from messy data. Preferred Qualifications Familiarity with cloud-based solutions (e.g., Google Cloud Platform, Azure). Experience with ETL processes and tools. Experience building data visualization reports and dashboards Knowledge of modern data storage solutions and database management systems. Exposure to DevOps practices and tools for deployment and monitoring. Why Join Us? Work with a talented, collaborative team dedicated to making a difference. Gain exposure to innovative technologies and opportunities for growth. Learn and utilize cutting-edge AI tools to enhance your development skills and create impactful solutions. Be part of a company that values your contributions and encourages professional development. Join a rapidly expanding health-tech startup (~200 employees and growing) with a state-of-the-art technology office located in Hyde Park, offering a variety of exceptional benefits. Career Progression Timeline In 3 months: Gain a comprehensive understanding of our data infrastructure, technical stacks, and development cycles. Actively participate in team meetings and contribute to the development of new data pipelines. Begin leveraging AI tools, such as Cursor and ChatGPT, to enhance coding efficiency and workflow automation. In 6 months: Contribute to product enhancements and data reporting Collaborate effectively with cross-functional teams, providing insights and solutions for data-related challenges. Demonstrate proficiency in utilizing AI tools for coding and development, actively sharing knowledge with the team. In 12 months: Contribute to data engineering projects, ensuring scalability and performance optimization. Mentor non-technical internal partners to improve company-wide data literacy Contribute to the integration of advanced AI solutions into our development processes, contributing to the company's technological advancement. Physical Requirements: Ability to remain at your designated workstation for the duration of the workday Constantly operates a computer and other office productivity machinery, such as a phone and Voice over Internet Protocol (VoIP). The ability to communicate information and ideas so others will understand. Must be able to exchange accurate information in these situations. The ability to observe details at close range (typically on a computer screen) This position offers the flexibility of remote work at approved locations within the United States. Candidates must have a reliable internet connection and a designated work environment conducive to professional phone calls and sensitive data. Enjoy the convenience and comfort of working remotely while contributing to our team's success. Apply Today If you’re ready to take on challenging problems, contribute to impactful solutions, and grow as a data engineer, we’d love to hear from you. Join us at The Helper Bees and be part of a team that’s making a meaningful difference every day! The Helper Bees is committed to building a workplace where diversity, equity, and inclusion are valued and prioritized. We are an equal opportunity employer that welcomes all qualified applicants without discrimination based on race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or any non-merit based or legally protected grounds. The Helper Bees provides reasonable accommodations to qualified individuals with disabilities during the job application and interview process. To request accommodation, please let your recruiter know. As part of our standard hiring process, selected candidates may be required to undergo a background check and/or drug screen. The Helper Bees adheres to applicable federal, state, and local laws regarding these screenings, and the results will be considered in accordance with applicable regulations. The Helper Bees was recently made aware of a fraudulent entity posing as our organization and requesting personal information. Please be aware of and protect yourself from scams. Visit thehelperbees.com/careers to view all current job openings.</td><td>Technical Tools: Experience with in Python and/or SQL. Experience with Bash, Shell scripting, Big Query, Airflow, and is a plus. Programming: Cleaning data using code-based approach. AI Proficiency: Interest or experience in using AI tools for coding and development of data solutions. Soft Skills: Problem-solving, cross-team collaboration, data storytelling, and stakeholder engagement. Adaptability: Thrives in a fast-paced startup environment and embraces change. Proactivity: Self-directed, organized, and able to prioritize effectively. Collaboration: Ability to work effectively with cross-functional teams. Education & Experience: A bachelor’s degree is required, and a graduate degree is preferred. Relevant experience in data engineering, software development, STEM, or related fields. Strong experience with SQL and Python is highly desirable. Mindset: A passion for innovation, continuous improvement, and delivering high-quality results from messy data. Preferred Qualifications Familiarity with cloud-based solutions (e.g., Google Cloud Platform, Azure). Experience with ETL processes and tools. Experience building data visualization reports and dashboards Knowledge of modern data storage solutions and database management systems. Exposure to DevOps practices and tools for deployment and monitoring. Why Join Us? Work with a talented, collaborative team dedicated to making a difference. Gain exposure to innovative technologies and opportunities for growth. Learn and utilize cutting-edge AI tools to enhance your development skills and create impactful solutions. Be part of a company that values your contributions and encourages professional development. Join a rapidly expanding health-tech startup (~200 employees and growing) with a state-of-the-art technology office located in Hyde Park, offering a variety of exceptional benefits. Career Progression Timeline In 3 months: Gain a comprehensive understanding of our data infrastructure, technical stacks, and development cycles. Actively participate in team meetings and contribute to the development of new data pipelines. Begin leveraging AI tools, such as Cursor and ChatGPT, to enhance coding efficiency and workflow automation. In 6 months: Contribute to product enhancements and data reporting Collaborate effectively with cross-functional teams, providing insights and solutions for data-related challenges. Demonstrate proficiency in utilizing AI tools for coding and development, actively sharing knowledge with the team. In 12 months: Contribute to data engineering projects, ensuring scalability and performance optimization. Mentor non-technical internal partners to improve company-wide data literacy Contribute to the integration of advanced AI solutions into our development processes, contributing to the company's technological advancement. Physical Requirements: Ability to remain at your designated workstation for the duration of the workday Constantly operates a computer and other office productivity machinery, such as a phone and Voice over Internet Protocol (VoIP). The ability to communicate information and ideas so others will understand. Must be able to exchange accurate information in these situations. The ability to observe details at close range (typically on a computer screen) This position offers the flexibility of remote work at approved locations within the United States. Candidates must have a reliable internet connection and a designated work environment conducive to professional phone calls and sensitive data. Enjoy the convenience and comfort of working remotely while contributing to our team's success. Apply Today If you’re ready to take on challenging problems, contribute to impactful solutions, and grow as a data engineer, we’d love to hear from you. Join us at The Helper Bees and be part of a team that’s making a meaningful difference every day! The Helper Bees is committed to building a workplace where diversity, equity, and inclusion are valued and prioritized. We are an equal opportunity employer that welcomes all qualified applicants without discrimination based on race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or any non-merit based or legally protected grounds. The Helper Bees provides reasonable accommodations to qualified individuals with disabilities during the job application and interview process. To request accommodation, please let your recruiter know. As part of our standard hiring process, selected candidates may be required to undergo a background check and/or drug screen. The Helper Bees adheres to applicable federal, state, and local laws regarding these screenings, and the results will be considered in accordance with applicable regulations. The Helper Bees was recently made aware of a fraudulent entity posing as our organization and requesting personal information. Please be aware of and protect yourself from scams. Visit thehelperbees.com/careers to view all current job openings.</td><td>698</td></tr><tr><td>null</td><td>ABOUT HEALTHCARE INC</td><td>SUMMARY: ABOUT Healthcare is seeking a skilled and innovative Data Scientist to help expand our predictive analytics capabilities and advance our mission to revolutionize hospital operations. This role will work at the intersection of AI/ML, healthcare, and operations to develop and scale machine learning models that deliver actionable insights to hospitals. ESSENTIAL FUNCTIONS : This class specification lists the major duties and requirements of the job and is not all-inclusive. Incumbent(s) may be expected to perform job-related duties other than those contained in this document and may be required to have specific job-related knowledge and skills. Predictive Analytics Development : Build and refine machine learning models for hourly discharge forecasting, aggregate hospital admission/discharge predictions, and patient-level progress tracking. Data Exploration : Analyze complex healthcare datasets to identify trends, challenges, and actionable opportunities. Model Deployment : Collaborate with engineers to deploy AI/ML solutions into production, ensuring reliability and scalability. Collaboration : Partner with product managers, operations teams, and customers to define and implement data-driven features and metrics. Feature Engineering : Work with AWS infrastructure (S3, Glue, Athena, Timestream, Bedrock, Nova, SageMaker) to standardize data pipelines and enrich machine learning models. Continuous Improvement : Optimize model accuracy and efficiency through testing, monitoring, and iteration. Documentation and Communication : Present technical findings and recommendations to stakeholders in an easily understandable way. LLMs: Demonstrate experience and depth in building products through applying LLMs or other AI domains like NLP, ML or deep learning. Full Stack: Capable as a full-stack engineer, seeing LLM implementations from concept to production. Perform other duties as assigned. QUALIFICATIONS: To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The requirements listed below are representative of the knowledge, skill, and/or ability required. Need to Have: Bachelor’s in data science, Computer Science, Statistics, or related field (or equivalent experience). 1+ years of experience developing and deploying machine learning models in production. Proficiency in Python (or R), SQL, and common ML libraries (e.g., Scikit-learn, TensorFlow, PyTorch). Experience working with cloud technologies, particularly AWS (e.g., S3, Glue, Timestream, Bedrock, Nova, sageMaker). Strong analytical skills and ability to interpret complex datasets. Knowledge of ETL processes, feature engineering, and real-time forecasting methods. Excellent communication skills with the ability to present technical concepts to non-technical stakeholders. Nice to Have: Experience in healthcare data analytics or hospital operations. Familiarity with EHR/EMR data or healthcare interoperability standards. Knowledge of time-series modeling and ensemble methods. Exposure to data visualization tools (e.g., Tableau, Power BI). Understanding of Agile methodologies and collaborative software development. Required Knowledge and Skills Required Knowledge: Correct business English, including spelling, grammar and punctuation. Medical Terminology Health system operating and working models Business planning and development Required Skills: Using initiative and independent judgment within established department guidelines. Contributing effectively to the accomplishment of team or work unit goals, objectives and activities. Establishing and maintaining effective working relationships with a variety of individuals. PHYSICAL/MENTAL REQUIREMENTS: The physical demands described herein are representative of those that must be met by an employee to successfully perform the essential functions of the job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions. Mobility to work in an office setting, use standard office equipment and stamina to sit for extended periods of time; strength to lift and carry up to 10 pounds; vision to read printed materials and computer screens; and hearing and speech to communicate in person or over the telephone. Travel as needed to support company and customer initiatives. Work on Site at our St Paul office may be required and ABOUT reserves the right to change the location of the role at any time. This role may involve work on federal government contracts that require additional federal background investigations, training, and federal badging. As such, you may be required to submit personal information to the government and be fingerprinted and photographed at your local Department of Veteran Affairs Medical Center. ABOUT is also an Equal Employment Opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, age, national origin, protected veteran status, disability status, sexual orientation, gender identity or expression, marital status, genetic information, or any other characteristic protected by law. ABOUT offers a flexible, purpose-built solution that empowers hospitals and health systems to operate as one connected network of care. We enable easy access for clinicians to move patients into and out of the acute care setting - getting them to the next, best care setting faster and easier. Complemented by our clinical experts and best practices, we provide health systems the necessary controls and insights to grow with resilience, drive clinician effectiveness, and improve patient outcomes. __________________________________________________________________________________________________________________________________ Opened URL: https://www.indeed.com/rc/clk?jk=b7ccd9fcd1afced7&bb=1TLRjqutBEYcit1OApAPtqrHYylbIkCH-hjMPAlsxl27fhhbmpR2ESoGFPzZ8_yAHfmXJJR-sxCiyJrJbrdNtoLq2VLDYGJB8eFEb_NompMj9I3HutPP1GvnnhForEvK&xkcb=SoAu67M33zDWevR-pR0CbzkdCdPP&fccid=4a4b722c7189c738&vjs=3</td><td>data</td><td>SUMMARY: ABOUT Healthcare is seeking a skilled and innovative Data Scientist to help expand our predictive analytics capabilities and advance our mission to revolutionize hospital operations. This role will work at the intersection of AI/ML, healthcare, and operations to develop and scale machine learning models that deliver actionable insights to hospitals. ESSENTIAL FUNCTIONS : This class specification lists the major duties and requirements of the job and is not all-inclusive. Incumbent(s) may be expected to perform job-related duties other than those contained in this document and may be required to have specific job-related knowledge and skills. Predictive Analytics Development : Build and refine machine learning models for hourly discharge forecasting, aggregate hospital admission/discharge predictions, and patient-level progress tracking. Data Exploration : Analyze complex healthcare datasets to identify trends, challenges, and actionable opportunities. Model Deployment : Collaborate with engineers to deploy AI/ML solutions into production, ensuring reliability and scalability. Collaboration : Partner with product managers, operations teams, and customers to define and implement data-driven features and metrics. Feature Engineering : Work with AWS infrastructure (S3, Glue, Athena, Timestream, Bedrock, Nova, SageMaker) to standardize data pipelines and enrich machine learning models. Continuous Improvement : Optimize model accuracy and efficiency through testing, monitoring, and iteration. Documentation and Communication : Present technical findings and recommendations to stakeholders in an easily understandable way. LLMs: Demonstrate experience and depth in building products through applying LLMs or other AI domains like NLP, ML or deep learning. Full Stack: Capable as a full-stack engineer, seeing LLM implementations from concept to production. Perform other duties as assigned. QUALIFICATIONS: To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The requirements listed below are representative of the knowledge, skill, and/or ability required. Need to Have: Bachelor’s in data science, Computer Science, Statistics, or related field (or equivalent experience). 1+ years of experience developing and deploying machine learning models in production. Proficiency in Python (or R), SQL, and common ML libraries (e.g., Scikit-learn, TensorFlow, PyTorch). Experience working with cloud technologies, particularly AWS (e.g., S3, Glue, Timestream, Bedrock, Nova, sageMaker). Strong analytical skills and ability to interpret complex datasets. Knowledge of ETL processes, feature engineering, and real-time forecasting methods. Excellent communication skills with the ability to present technical concepts to non-technical stakeholders. Nice to Have: Experience in healthcare data analytics or hospital operations. Familiarity with EHR/EMR data or healthcare interoperability standards. Knowledge of time-series modeling and ensemble methods. Exposure to data visualization tools (e.g., Tableau, Power BI). Understanding of Agile methodologies and collaborative software development. Required Knowledge and Skills Required Knowledge: Correct business English, including spelling, grammar and punctuation. Medical Terminology Health system operating and working models Business planning and development Required Skills: Using initiative and independent judgment within established department guidelines. Contributing effectively to the accomplishment of team or work unit goals, objectives and activities. Establishing and maintaining effective working relationships with a variety of individuals. PHYSICAL/MENTAL REQUIREMENTS: The physical demands described herein are representative of those that must be met by an employee to successfully perform the essential functions of the job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions. Mobility to work in an office setting, use standard office equipment and stamina to sit for extended periods of time; strength to lift and carry up to 10 pounds; vision to read printed materials and computer screens; and hearing and speech to communicate in person or over the telephone. Travel as needed to support company and customer initiatives. Work on Site at our St Paul office may be required and ABOUT reserves the right to change the location of the role at any time. This role may involve work on federal government contracts that require additional federal background investigations, training, and federal badging. As such, you may be required to submit personal information to the government and be fingerprinted and photographed at your local Department of Veteran Affairs Medical Center. ABOUT is also an Equal Employment Opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, age, national origin, protected veteran status, disability status, sexual orientation, gender identity or expression, marital status, genetic information, or any other characteristic protected by law. ABOUT offers a flexible, purpose-built solution that empowers hospitals and health systems to operate as one connected network of care. We enable easy access for clinicians to move patients into and out of the acute care setting - getting them to the next, best care setting faster and easier. Complemented by our clinical experts and best practices, we provide health systems the necessary controls and insights to grow with resilience, drive clinician effectiveness, and improve patient outcomes. __________________________________________________________________________________________________________________________________</td><td>SUMMARY: ABOUT Healthcare is seeking a skilled and innovative Data Scientist to help expand our predictive analytics capabilities and advance our mission to revolutionize hospital operations. This role will work at the intersection of AI/ML, healthcare, and operations to develop and scale machine learning models that deliver actionable insights to hospitals. ESSENTIAL FUNCTIONS : This class specification lists the major duties and requirements of the job and is not all-inclusive. Incumbent(s) may be expected to perform job-related duties other than those contained in this document and may be required to have specific job-related knowledge and skills. Predictive Analytics Development : Build and refine machine learning models for hourly discharge forecasting, aggregate hospital admission/discharge predictions, and patient-level progress tracking. Data Exploration : Analyze complex healthcare datasets to identify trends, challenges, and actionable opportunities. Model Deployment : Collaborate with engineers to deploy AI/ML solutions into production, ensuring reliability and scalability. Collaboration : Partner with product managers, operations teams, and customers to define and implement data-driven features and metrics. Feature Engineering : Work with AWS infrastructure (S3, Glue, Athena, Timestream, Bedrock, Nova, SageMaker) to standardize data pipelines and enrich machine learning models. Continuous Improvement : Optimize model accuracy and efficiency through testing, monitoring, and iteration. Documentation and Communication : Present technical findings and recommendations to stakeholders in an easily understandable way. LLMs: Demonstrate experience and depth in building products through applying LLMs or other AI domains like NLP, ML or deep learning. Full Stack: Capable as a full-stack engineer, seeing LLM implementations from concept to production. Perform other duties as assigned. QUALIFICATIONS: To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The requirements listed below are representative of the knowledge, skill, and/or ability required. Need to Have: Bachelor’s in data science, Computer Science, Statistics, or related field (or equivalent experience). 1+ years of experience developing and deploying machine learning models in production. Proficiency in Python (or R), SQL, and common ML libraries (e.g., Scikit-learn, TensorFlow, PyTorch). Experience working with cloud technologies, particularly AWS (e.g., S3, Glue, Timestream, Bedrock, Nova, sageMaker). Strong analytical skills and ability to interpret complex datasets. Knowledge of ETL processes, feature engineering, and real-time forecasting methods. Excellent communication skills with the ability to present technical concepts to non-technical stakeholders. Nice to Have: Experience in healthcare data analytics or hospital operations. Familiarity with EHR/EMR data or healthcare interoperability standards. Knowledge of time-series modeling and ensemble methods. Exposure to data visualization tools (e.g., Tableau, Power BI). Understanding of Agile methodologies and collaborative software development. Required Knowledge and Skills Required Knowledge: Correct business English, including spelling, grammar and punctuation. Medical Terminology Health system operating and working models Business planning and development Required Skills: Using initiative and independent judgment within established department guidelines. Contributing effectively to the accomplishment of team or work unit goals, objectives and activities. Establishing and maintaining effective working relationships with a variety of individuals. PHYSICAL/MENTAL REQUIREMENTS: The physical demands described herein are representative of those that must be met by an employee to successfully perform the essential functions of the job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions. Mobility to work in an office setting, use standard office equipment and stamina to sit for extended periods of time; strength to lift and carry up to 10 pounds; vision to read printed materials and computer screens; and hearing and speech to communicate in person or over the telephone. Travel as needed to support company and customer initiatives. Work on Site at our St Paul office may be required and ABOUT reserves the right to change the location of the role at any time. This role may involve work on federal government contracts that require additional federal background investigations, training, and federal badging. As such, you may be required to submit personal information to the government and be fingerprinted and photographed at your local Department of Veteran Affairs Medical Center. ABOUT is also an Equal Employment Opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, age, national origin, protected veteran status, disability status, sexual orientation, gender identity or expression, marital status, genetic information, or any other characteristic protected by law. ABOUT offers a flexible, purpose-built solution that empowers hospitals and health systems to operate as one connected network of care. We enable easy access for clinicians to move patients into and out of the acute care setting - getting them to the next, best care setting faster and easier. Complemented by our clinical experts and best practices, we provide health systems the necessary controls and insights to grow with resilience, drive clinician effectiveness, and improve patient outcomes. __________________________________________________________________________________________________________________________________</td><td>To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The requirements listed below are representative of the knowledge, skill, and/or ability required. Need to Have: Bachelor’s in data science, Computer Science, Statistics, or related field (or equivalent experience). 1+ years of experience developing and deploying machine learning models in production. Proficiency in Python (or R), SQL, and common ML libraries (e.g., Scikit-learn, TensorFlow, PyTorch). Experience working with cloud technologies, particularly AWS (e.g., S3, Glue, Timestream, Bedrock, Nova, sageMaker). Strong analytical skills and ability to interpret complex datasets. Knowledge of ETL processes, feature engineering, and real-time forecasting methods. Excellent communication skills with the ability to present technical concepts to non-technical stakeholders. Nice to Have: Experience in healthcare data analytics or hospital operations. Familiarity with EHR/EMR data or healthcare interoperability standards. Knowledge of time-series modeling and ensemble methods. Exposure to data visualization tools (e.g., Tableau, Power BI). Understanding of Agile methodologies and collaborative software development. Required Knowledge and Skills Required Knowledge: Correct business English, including spelling, grammar and punctuation. Medical Terminology Health system operating and working models Business planning and development Required Skills: Using initiative and independent judgment within established department guidelines. Contributing effectively to the accomplishment of team or work unit goals, objectives and activities. Establishing and maintaining effective working relationships with a variety of individuals. PHYSICAL/MENTAL REQUIREMENTS: The physical demands described herein are representative of those that must be met by an employee to successfully perform the essential functions of the job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions. Mobility to work in an office setting, use standard office equipment and stamina to sit for extended periods of time; strength to lift and carry up to 10 pounds; vision to read printed materials and computer screens; and hearing and speech to communicate in person or over the telephone. Travel as needed to support company and customer initiatives. Work on Site at our St Paul office may be required and ABOUT reserves the right to change the location of the role at any time. This role may involve work on federal government contracts that require additional federal background investigations, training, and federal badging. As such, you may be required to submit personal information to the government and be fingerprinted and photographed at your local Department of Veteran Affairs Medical Center. ABOUT is also an Equal Employment Opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, age, national origin, protected veteran status, disability status, sexual orientation, gender identity or expression, marital status, genetic information, or any other characteristic protected by law. ABOUT offers a flexible, purpose-built solution that empowers hospitals and health systems to operate as one connected network of care. We enable easy access for clinicians to move patients into and out of the acute care setting - getting them to the next, best care setting faster and easier. Complemented by our clinical experts and best practices, we provide health systems the necessary controls and insights to grow with resilience, drive clinician effectiveness, and improve patient outcomes. __________________________________________________________________________________________________________________________________</td><td>521</td></tr><tr><td>null</td><td>The Krusteaz Company</td><td>The Krusteaz Company is seeking a Senior Data Engineer to lead the architecture and development of our enterprise data strategy. Reporting to the Director of Enterprise Applications and Data Management, this role will play a key role in design, delivery, and management of our enterprise data strategy and solution(s). As a key contributor to our digital transformation, this role will take the lead in designing data structure, design, and ingestion, reporting processes and standards for the organization working across both the IT development, infrastructure, and analyst teams. As a senior member of the IT team, this role will be instrumental in promoting agility, scalability, and operational excellence. This role will also be a key contributor in our business transformation, working closely with our IT Business Analysts to understand the challenges facing our business partners and developing scalable and repeatable data solutions to meet their needs. This role will be a trusted partner to your peers within the IT team, demonstrating the ability to provide both conceptual and technical mentorship. Essential Functions : Other duties, responsibilities, and activities may change or be assigned at any time. Maintain and build on our data warehouse and analytics environment. Design, implement, test, deploy, and maintain stable, secure, and scalable data engineering solutions and pipelines. Build reports and data visualizations, using data from the data warehouse and other sources. Produce scalable, replicable code and engineering solutions that help automate repetitive data management tasks. Implement and monitor best in class security measures in our data warehouse and analytics environment. Provide direct input on the IT technology roadmap, helping ensure we make appropriate investments in build vs. buy decisions. Define and document best practices and strategies. Keep apprised of trends, identifies best-in class capabilities, opportunities and technology that may benefit The Krusteaz Company. Provide guidance, thought leadership, and mentorship to development and infrastructure teams to build EDW and development competencies. Position Requirements To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The requirements listed below are representative of the knowledge, skill, and/or ability required. Reasonable accommodations may be made to enable individuals qualified with disabilities to perform the essential functions. Proven success in developing technical solutions with a ‘cloud first’ mindset. Deep understanding of cloud data warehousing and ETL best practices, including system reliability and scalability. Ensuring data quality and consistency across various sources. Ability to function effectively as a change agent and problem solver within your team and across IT and the business. Excellent written, verbal, communication, and presentation skills with the ability to think critically, problem solve, and articulate new ideas and concepts to technical and non-technical audiences. Education and/or Experience: Bachelor’s degree in computer science, information technology, mathematics, or progressive relevant work experience. 8+ years of development experience required. 5+ years’ experience working with public cloud providers (Azure, Oracle Cloud, etc.). 5+ years’ experience in data pipeline development, including languages such as Python and R, and tools such as Airflow and SSIS. 5+ years Data Warehousing and ETL experience, preferably with large transactional datasets. Familiarity working in both Windows and Linux environments. Direct experience working with both traditional and agile methodologies required. Experience within the manufacturing industry, including knowledge in supply chain, procurement, and logistics is preferred but not required. Physical Demands and Work Environment: While performing the duties of this job, the employee is regularly required to stand, sit, talk, hear, and use hands and fingers to operate a computer and telephone along with reaching. Specific vision abilities include close vision requirements due to computer work. Moderate noise, ability to work in a confined area, and ability to sit at a computer for an extended period of time are also included. The policy of The Krusteaz Company is to hire, train, and promote all persons in all job groups in accordance with law, without regard to race, color, religion, sex, sexual orientation, age, marital or military status, national origin, gender identity, the presence of any sensory, mental or physical disability, genetic information, or any other status or characteristic protected by local, state, or federal law. Get to know us: A people-focused company that cares: We're a 90-year-old company with the entrepreneurial spirit of a startup and a focused eye on the future. As a midsized, privately held company with a portfolio of beloved food and beverage brands, our people are the most important ingredient in our success. A valued and supported workforce : We place tremendous value in our employees and provide competitive pay and comprehensive benefits to ensure our employees can create the best life for themselves. Benefits include a top tier health insurance plan with lower-than-average employee cost share, generous PTO, 401(k) match, and more. An engaged and energized culture: At The Krusteaz Company, collaboration and ingenuity drive our fierce commitment to creating extraordinary product experiences that people love. A place to grow and make a difference: An entrepreneurial spirit has been at the core of our company since the beginning, attracting self-starters who are curious and love to learn and to share ideas. Hybrid Work Model: At The Krusteaz Company, we have in-office \"core days\" of Tuesdays and Wednesdays where all corporate employees are expected to be onsite. Mondays, Thursdays, and Fridays are flexible remote days to allow for work/life balance. You may be asked to come in outside of a core day from time to time, based on business needs. We have found aligning our scheduled in-office days provides opportunity for employees to build connections and collaborate together. Benefits: We are proud to offer generous benefits including comprehensive medical, dental, and vision insurance (starting at $50/month for employee only coverage on the PPO Plan or starting at $25/month for employee only coverage on the HDHP), 401(K) matching, 3 weeks of paid vacation, 10 paid holidays, company provided life insurance and disability insurance, flexible spending account, healthcare saving account, voluntary accident insurance, voluntary critical illness insurance, and tuition reimbursement. Salary Information: An employee in this position can expect a salary range between $126,101 and $208,055. We typically pay out between $142,000 and $180,000. The actual salary offered will carefully consider a wide range of factors, including internal equity, experience, education, certification, training, and location. All positions are eligible for additional incentives based on business performance. We hope you'll take the time to get to know us! The Krusteaz Company is not sponsoring new applicant employment authorization at this time and please, no third-party recruiters. Opened URL: https://www.indeed.com/rc/clk?jk=042c410f50c0faa6&bb=1TLRjqutBEYcit1OApAPtt6B4oNDQ9pvplvzh521n9octR12bdC8X0WPxpzUuEahEqtE5IkoxGLcfct2Fl3E3ERVE0CDNI3ufYlz_WxpqD2cHp3NqHNahE2fQxTMaZ59&xkcb=SoAH67M33zDWevR-pR0AbzkdCdPP&fccid=9e189ac6632e8eb3&vjs=3</td><td>data</td><td>The Krusteaz Company is seeking a Senior Data Engineer to lead the architecture and development of our enterprise data strategy. Reporting to the Director of Enterprise Applications and Data Management, this role will play a key role in design, delivery, and management of our enterprise data strategy and solution(s). As a key contributor to our digital transformation, this role will take the lead in designing data structure, design, and ingestion, reporting processes and standards for the organization working across both the IT development, infrastructure, and analyst teams. As a senior member of the IT team, this role will be instrumental in promoting agility, scalability, and operational excellence. This role will also be a key contributor in our business transformation, working closely with our IT Business Analysts to understand the challenges facing our business partners and developing scalable and repeatable data solutions to meet their needs. This role will be a trusted partner to your peers within the IT team, demonstrating the ability to provide both conceptual and technical mentorship. Essential Functions : Other duties, responsibilities, and activities may change or be assigned at any time. Maintain and build on our data warehouse and analytics environment. Design, implement, test, deploy, and maintain stable, secure, and scalable data engineering solutions and pipelines. Build reports and data visualizations, using data from the data warehouse and other sources. Produce scalable, replicable code and engineering solutions that help automate repetitive data management tasks. Implement and monitor best in class security measures in our data warehouse and analytics environment. Provide direct input on the IT technology roadmap, helping ensure we make appropriate investments in build vs. buy decisions. Define and document best practices and strategies. Keep apprised of trends, identifies best-in class capabilities, opportunities and technology that may benefit The Krusteaz Company. Provide guidance, thought leadership, and mentorship to development and infrastructure teams to build EDW and development competencies. Position Requirements To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The requirements listed below are representative of the knowledge, skill, and/or ability required. Reasonable accommodations may be made to enable individuals qualified with disabilities to perform the essential functions. Proven success in developing technical solutions with a ‘cloud first’ mindset. Deep understanding of cloud data warehousing and ETL best practices, including system reliability and scalability. Ensuring data quality and consistency across various sources. Ability to function effectively as a change agent and problem solver within your team and across IT and the business. Excellent written, verbal, communication, and presentation skills with the ability to think critically, problem solve, and articulate new ideas and concepts to technical and non-technical audiences. Education and/or Experience: Bachelor’s degree in computer science, information technology, mathematics, or progressive relevant work experience. 8+ years of development experience required. 5+ years’ experience working with public cloud providers (Azure, Oracle Cloud, etc.). 5+ years’ experience in data pipeline development, including languages such as Python and R, and tools such as Airflow and SSIS. 5+ years Data Warehousing and ETL experience, preferably with large transactional datasets. Familiarity working in both Windows and Linux environments. Direct experience working with both traditional and agile methodologies required. Experience within the manufacturing industry, including knowledge in supply chain, procurement, and logistics is preferred but not required. Physical Demands and Work Environment: While performing the duties of this job, the employee is regularly required to stand, sit, talk, hear, and use hands and fingers to operate a computer and telephone along with reaching. Specific vision abilities include close vision requirements due to computer work. Moderate noise, ability to work in a confined area, and ability to sit at a computer for an extended period of time are also included. The policy of The Krusteaz Company is to hire, train, and promote all persons in all job groups in accordance with law, without regard to race, color, religion, sex, sexual orientation, age, marital or military status, national origin, gender identity, the presence of any sensory, mental or physical disability, genetic information, or any other status or characteristic protected by local, state, or federal law. Get to know us: A people-focused company that cares: We're a 90-year-old company with the entrepreneurial spirit of a startup and a focused eye on the future. As a midsized, privately held company with a portfolio of beloved food and beverage brands, our people are the most important ingredient in our success. A valued and supported workforce : We place tremendous value in our employees and provide competitive pay and comprehensive benefits to ensure our employees can create the best life for themselves. Benefits include a top tier health insurance plan with lower-than-average employee cost share, generous PTO, 401(k) match, and more. An engaged and energized culture: At The Krusteaz Company, collaboration and ingenuity drive our fierce commitment to creating extraordinary product experiences that people love. A place to grow and make a difference: An entrepreneurial spirit has been at the core of our company since the beginning, attracting self-starters who are curious and love to learn and to share ideas. Hybrid Work Model: At The Krusteaz Company, we have in-office \"core days\" of Tuesdays and Wednesdays where all corporate employees are expected to be onsite. Mondays, Thursdays, and Fridays are flexible remote days to allow for work/life balance. You may be asked to come in outside of a core day from time to time, based on business needs. We have found aligning our scheduled in-office days provides opportunity for employees to build connections and collaborate together. Benefits: We are proud to offer generous benefits including comprehensive medical, dental, and vision insurance (starting at $50/month for employee only coverage on the PPO Plan or starting at $25/month for employee only coverage on the HDHP), 401(K) matching, 3 weeks of paid vacation, 10 paid holidays, company provided life insurance and disability insurance, flexible spending account, healthcare saving account, voluntary accident insurance, voluntary critical illness insurance, and tuition reimbursement. Salary Information: An employee in this position can expect a salary range between $126,101 and $208,055. We typically pay out between $142,000 and $180,000. The actual salary offered will carefully consider a wide range of factors, including internal equity, experience, education, certification, training, and location. All positions are eligible for additional incentives based on business performance. We hope you'll take the time to get to know us! The Krusteaz Company is not sponsoring new applicant employment authorization at this time and please, no third-party recruiters.</td><td>The Krusteaz Company is seeking a Senior Data Engineer to lead the architecture and development of our enterprise data strategy. Reporting to the Director of Enterprise Applications and Data Management, this role will play a key role in design, delivery, and management of our enterprise data strategy and solution(s). As a key contributor to our digital transformation, this role will take the lead in designing data structure, design, and ingestion, reporting processes and standards for the organization working across both the IT development, infrastructure, and analyst teams. As a senior member of the IT team, this role will be instrumental in promoting agility, scalability, and operational excellence. This role will also be a key contributor in our business transformation, working closely with our IT Business Analysts to understand the challenges facing our business partners and developing scalable and repeatable data solutions to meet their needs. This role will be a trusted partner to your peers within the IT team, demonstrating the ability to provide both conceptual and technical mentorship. Essential Functions : Other duties, responsibilities, and activities may change or be assigned at any time. Maintain and build on our data warehouse and analytics environment. Design, implement, test, deploy, and maintain stable, secure, and scalable data engineering solutions and pipelines. Build reports and data visualizations, using data from the data warehouse and other sources. Produce scalable, replicable code and engineering solutions that help automate repetitive data management tasks. Implement and monitor best in class security measures in our data warehouse and analytics environment. Provide direct input on the IT technology roadmap, helping ensure we make appropriate investments in build vs. buy decisions. Define and document best practices and strategies. Keep apprised of trends, identifies best-in class capabilities, opportunities and technology that may benefit The Krusteaz Company. Provide guidance, thought leadership, and mentorship to development and infrastructure teams to build EDW and development competencies. Position Requirements To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The requirements listed below are representative of the knowledge, skill, and/or ability required. Reasonable accommodations may be made to enable individuals qualified with disabilities to perform the essential functions. Proven success in developing technical solutions with a ‘cloud first’ mindset. Deep understanding of cloud data warehousing and ETL best practices, including system reliability and scalability. Ensuring data quality and consistency across various sources. Ability to function effectively as a change agent and problem solver within your team and across IT and the business. Excellent written, verbal, communication, and presentation skills with the ability to think critically, problem solve, and articulate new ideas and concepts to technical and non-technical audiences. Education and/or Experience: Bachelor’s degree in computer science, information technology, mathematics, or progressive relevant work experience. 8+ years of development experience required. 5+ years’ experience working with public cloud providers (Azure, Oracle Cloud, etc.). 5+ years’ experience in data pipeline development, including languages such as Python and R, and tools such as Airflow and SSIS. 5+ years Data Warehousing and ETL experience, preferably with large transactional datasets. Familiarity working in both Windows and Linux environments. Direct experience working with both traditional and agile methodologies required. Experience within the manufacturing industry, including knowledge in supply chain, procurement, and logistics is preferred but not required. Physical Demands and Work Environment: While performing the duties of this job, the employee is regularly required to stand, sit, talk, hear, and use hands and fingers to operate a computer and telephone along with reaching. Specific vision abilities include close vision requirements due to computer work. Moderate noise, ability to work in a confined area, and ability to sit at a computer for an extended period of time are also included. The policy of The Krusteaz Company is to hire, train, and promote all persons in all job groups in accordance with law, without regard to race, color, religion, sex, sexual orientation, age, marital or military status, national origin, gender identity, the presence of any sensory, mental or physical disability, genetic information, or any other status or characteristic protected by local, state, or federal law. Get to know us: A people-focused company that cares: We're a 90-year-old company with the entrepreneurial spirit of a startup and a focused eye on the future. As a midsized, privately held company with a portfolio of beloved food and beverage brands, our people are the most important ingredient in our success. A valued and supported workforce : We place tremendous value in our employees and provide competitive pay and comprehensive benefits to ensure our employees can create the best life for themselves. Benefits include a top tier health insurance plan with lower-than-average employee cost share, generous PTO, 401(k) match, and more. An engaged and energized culture: At The Krusteaz Company, collaboration and ingenuity drive our fierce commitment to creating extraordinary product experiences that people love. A place to grow and make a difference: An entrepreneurial spirit has been at the core of our company since the beginning, attracting self-starters who are curious and love to learn and to share ideas. Hybrid Work Model: At The Krusteaz Company, we have in-office \"core days\" of Tuesdays and Wednesdays where all corporate employees are expected to be onsite. Mondays, Thursdays, and Fridays are flexible remote days to allow for work/life balance. You may be asked to come in outside of a core day from time to time, based on business needs. We have found aligning our scheduled in-office days provides opportunity for employees to build connections and collaborate together. Benefits: We are proud to offer generous benefits including comprehensive medical, dental, and vision insurance (starting at $50/month for employee only coverage on the PPO Plan or starting at $25/month for employee only coverage on the HDHP), 401(K) matching, 3 weeks of paid vacation, 10 paid holidays, company provided life insurance and disability insurance, flexible spending account, healthcare saving account, voluntary accident insurance, voluntary critical illness insurance, and tuition reimbursement. Salary Information: An employee in this position can expect a salary range between $126,101 and $208,055. We typically pay out between $142,000 and $180,000. The actual salary offered will carefully consider a wide range of factors, including internal equity, experience, education, certification, training, and location. All positions are eligible for additional incentives based on business performance. We hope you'll take the time to get to know us! The Krusteaz Company is not sponsoring new applicant employment authorization at this time and please, no third-party recruiters.</td><td>To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The requirements listed below are representative of the knowledge, skill, and/or ability required. Reasonable accommodations may be made to enable individuals qualified with disabilities to perform the essential functions. Proven success in developing technical solutions with a ‘cloud first’ mindset. Deep understanding of cloud data warehousing and ETL best practices, including system reliability and scalability. Ensuring data quality and consistency across various sources. Ability to function effectively as a change agent and problem solver within your team and across IT and the business. Excellent written, verbal, communication, and presentation skills with the ability to think critically, problem solve, and articulate new ideas and concepts to technical and non-technical audiences. Education and/or Experience: Bachelor’s degree in computer science, information technology, mathematics, or progressive relevant work experience. 8+ years of development experience required. 5+ years’ experience working with public cloud providers (Azure, Oracle Cloud, etc.). 5+ years’ experience in data pipeline development, including languages such as Python and R, and tools such as Airflow and SSIS. 5+ years Data Warehousing and ETL experience, preferably with large transactional datasets. Familiarity working in both Windows and Linux environments. Direct experience working with both traditional and agile methodologies required. Experience within the manufacturing industry, including knowledge in supply chain, procurement, and logistics is preferred but not required. Physical Demands and Work Environment: While performing the duties of this job, the employee is regularly required to stand, sit, talk, hear, and use hands and fingers to operate a computer and telephone along with reaching. Specific vision abilities include close vision requirements due to computer work. Moderate noise, ability to work in a confined area, and ability to sit at a computer for an extended period of time are also included. The policy of The Krusteaz Company is to hire, train, and promote all persons in all job groups in accordance with law, without regard to race, color, religion, sex, sexual orientation, age, marital or military status, national origin, gender identity, the presence of any sensory, mental or physical disability, genetic information, or any other status or characteristic protected by local, state, or federal law. Get to know us: A people-focused company that cares: We're a 90-year-old company with the entrepreneurial spirit of a startup and a focused eye on the future. As a midsized, privately held company with a portfolio of beloved food and beverage brands, our people are the most important ingredient in our success. A valued and supported workforce : We place tremendous value in our employees and provide competitive pay and comprehensive benefits to ensure our employees can create the best life for themselves. Benefits include a top tier health insurance plan with lower-than-average employee cost share, generous PTO, 401(k) match, and more. An engaged and energized culture: At The Krusteaz Company, collaboration and ingenuity drive our fierce commitment to creating extraordinary product experiences that people love. A place to grow and make a difference: An entrepreneurial spirit has been at the core of our company since the beginning, attracting self-starters who are curious and love to learn and to share ideas. Hybrid Work Model: At The Krusteaz Company, we have in-office \"core days\" of Tuesdays and Wednesdays where all corporate employees are expected to be onsite. Mondays, Thursdays, and Fridays are flexible remote days to allow for work/life balance. You may be asked to come in outside of a core day from time to time, based on business needs. We have found aligning our scheduled in-office days provides opportunity for employees to build connections and collaborate together. Benefits: We are proud to offer generous benefits including comprehensive medical, dental, and vision insurance (starting at $50/month for employee only coverage on the PPO Plan or starting at $25/month for employee only coverage on the HDHP), 401(K) matching, 3 weeks of paid vacation, 10 paid holidays, company provided life insurance and disability insurance, flexible spending account, healthcare saving account, voluntary accident insurance, voluntary critical illness insurance, and tuition reimbursement. Salary Information: An employee in this position can expect a salary range between $126,101 and $208,055. We typically pay out between $142,000 and $180,000. The actual salary offered will carefully consider a wide range of factors, including internal equity, experience, education, certification, training, and location. All positions are eligible for additional incentives based on business performance. We hope you'll take the time to get to know us! The Krusteaz Company is not sponsoring new applicant employment authorization at this time and please, no third-party recruiters.</td><td>756</td></tr><tr><td>null</td><td>#NAME?</td><td>Description: Join our winning team, recently honored as #67 on Forbes’ list of America’s Best Startup Employers for 2024! About The Helper Bees The Helper Bees’ mission is to help people stay home longer through data-driven services that transform both the payer and the care-recipient experience. At The Helper Bees, we are reshaping how care is delivered to aging individuals by leveraging innovative technology and insightful data solutions. We maintain multiple SaaS products and payment solutions through our web applications (internal and external facing), a mobile app, and reporting integrations. As part of our growing Data Engineering team, you’ll iterate quickly, have a high impact, and be challenged to design and implement cutting-edge solutions. At THB, we define our company culture through our Core Values: Quickly iterate through solutions: We move at a fast pace which requires quick iterations to find a path to a repeatable solution. Seek ways to create immediate impact: Be thoughtful and proactive in how you make an impact on your team. Actively look for ways to make a fast, positive impact. Bee the teammate you want to work with: We work as a team, help each other, and encourage each other. Ask questions, answer questions: You can't iterate through solutions if you don't ask the right questions, which is why there is an expectation that questions should be asked. When you know the answer, being a good teammate means chiming in to get others up to speed. Take the time to celebrate wins: It's so easy for a team that is heads down to forget about all the great things they've accomplished. That's why we make it a priority to remind ourselves to create space to celebrate wins, big or small. Job Summary We are seeking a motivated Data Engineer to join our team and help improve our tools, processes, and technical infrastructure. In this role, you will ensure the availability and quality of our data while contributing to the design, implementation, and maintenance of The Helper Bees’ products. You’ll collaborate across teams to create scalable and optimized software systems and play a key role in refining our development processes. This position offers a unique opportunity to learn and leverage cutting-edge AI development tools to enhance coding efficiency and develop advanced data tools and solutions. Supervisory Responsibilities: None Key Responsibilities Data Infrastructure: Design, implement, and maintain data pipelines, ensuring data availability, quality, and scalability. Product Development: Build and enhance products using Python, SQL, and modern technologies. AI Integration: Leverage cutting-edge AI tools, including Cursor, ChatGPT, and Claude to improve development processes, automate workflows, and create innovative data solutions. Collaboration: Communicate across departments to design, build, test, and implement new features and enhancements. Code Excellence: Produce quality, testable, and maintainable code while participating in code reviews. Problem Solving: Debug complex issues, interact with stakeholders, and design viable solutions with clear trade-offs. Process Optimization: Contribute to improving development processes, including deployment, on-call systems, and sprint planning. Team Growth: Collaborate within the development team to help each other grow and continuously learn. Stakeholder Engagement: Partner with analysts, scientists, and IT to ensure alignment and deliver data-driven solutions. Other duties as assigned/necessary Performance Metrics Code Quality: Maintain high coding standards through regular code reviews and adherence to best practices. Development Efficiency: Deliver high-quality features and fixes within efficient timeframes. Bug Resolution Time: Reduce the time taken to identify and resolve issues. System Scalability: Optimize system performance to handle increasing user demands. Collaboration: Foster a collaborative environment that encourages teamwork and knowledge sharing. Customer Satisfaction: Incorporate stakeholder feedback to improve solutions and enhance the customer experience. Continuous Learning: Pursue opportunities for skill development and share knowledge with the team. Requirements: Required Skills & Qualifications Technical Tools: Experience with in Python and/or SQL. Experience with Bash, Shell scripting, Big Query, Airflow, and is a plus. Programming: Cleaning data using code-based approach. AI Proficiency: Interest or experience in using AI tools for coding and development of data solutions. Soft Skills: Problem-solving, cross-team collaboration, data storytelling, and stakeholder engagement. Adaptability: Thrives in a fast-paced startup environment and embraces change. Proactivity: Self-directed, organized, and able to prioritize effectively. Collaboration: Ability to work effectively with cross-functional teams. Education & Experience: A bachelor’s degree is required, and a graduate degree is preferred. Relevant experience in data engineering, software development, STEM, or related fields. Strong experience with SQL and Python is highly desirable. Mindset: A passion for innovation, continuous improvement, and delivering high-quality results from messy data. Preferred Qualifications Familiarity with cloud-based solutions (e.g., Google Cloud Platform, Azure). Experience with ETL processes and tools. Experience building data visualization reports and dashboards Knowledge of modern data storage solutions and database management systems. Exposure to DevOps practices and tools for deployment and monitoring. Why Join Us? Work with a talented, collaborative team dedicated to making a difference. Gain exposure to innovative technologies and opportunities for growth. Learn and utilize cutting-edge AI tools to enhance your development skills and create impactful solutions. Be part of a company that values your contributions and encourages professional development. Join a rapidly expanding health-tech startup (~200 employees and growing) with a state-of-the-art technology office located in Hyde Park, offering a variety of exceptional benefits. Career Progression Timeline In 3 months: Gain a comprehensive understanding of our data infrastructure, technical stacks, and development cycles. Actively participate in team meetings and contribute to the development of new data pipelines. Begin leveraging AI tools, such as Cursor and ChatGPT, to enhance coding efficiency and workflow automation. In 6 months: Contribute to product enhancements and data reporting Collaborate effectively with cross-functional teams, providing insights and solutions for data-related challenges. Demonstrate proficiency in utilizing AI tools for coding and development, actively sharing knowledge with the team. In 12 months: Contribute to data engineering projects, ensuring scalability and performance optimization. Mentor non-technical internal partners to improve company-wide data literacy Contribute to the integration of advanced AI solutions into our development processes, contributing to the company's technological advancement. Physical Requirements: Ability to remain at your designated workstation for the duration of the workday Constantly operates a computer and other office productivity machinery, such as a phone and Voice over Internet Protocol (VoIP). The ability to communicate information and ideas so others will understand. Must be able to exchange accurate information in these situations. The ability to observe details at close range (typically on a computer screen) This position offers the flexibility of remote work at approved locations within the United States. Candidates must have a reliable internet connection and a designated work environment conducive to professional phone calls and sensitive data. Enjoy the convenience and comfort of working remotely while contributing to our team's success. Apply Today If you’re ready to take on challenging problems, contribute to impactful solutions, and grow as a data engineer, we’d love to hear from you. Join us at The Helper Bees and be part of a team that’s making a meaningful difference every day! The Helper Bees is committed to building a workplace where diversity, equity, and inclusion are valued and prioritized. We are an equal opportunity employer that welcomes all qualified applicants without discrimination based on race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or any non-merit based or legally protected grounds. The Helper Bees provides reasonable accommodations to qualified individuals with disabilities during the job application and interview process. To request accommodation, please let your recruiter know. As part of our standard hiring process, selected candidates may be required to undergo a background check and/or drug screen. The Helper Bees adheres to applicable federal, state, and local laws regarding these screenings, and the results will be considered in accordance with applicable regulations. The Helper Bees was recently made aware of a fraudulent entity posing as our organization and requesting personal information. Please be aware of and protect yourself from scams. Visit thehelperbees.com/careers to view all current job openings.</td><td>data</td><td>Description: Join our winning team, recently honored as #67 on Forbes’ list of America’s Best Startup Employers for 2024! About The Helper Bees The Helper Bees’ mission is to help people stay home longer through data-driven services that transform both the payer and the care-recipient experience. At The Helper Bees, we are reshaping how care is delivered to aging individuals by leveraging innovative technology and insightful data solutions. We maintain multiple SaaS products and payment solutions through our web applications (internal and external facing), a mobile app, and reporting integrations. As part of our growing Data Engineering team, you’ll iterate quickly, have a high impact, and be challenged to design and implement cutting-edge solutions. At THB, we define our company culture through our Core Values: Quickly iterate through solutions: We move at a fast pace which requires quick iterations to find a path to a repeatable solution. Seek ways to create immediate impact: Be thoughtful and proactive in how you make an impact on your team. Actively look for ways to make a fast, positive impact. Bee the teammate you want to work with: We work as a team, help each other, and encourage each other. Ask questions, answer questions: You can't iterate through solutions if you don't ask the right questions, which is why there is an expectation that questions should be asked. When you know the answer, being a good teammate means chiming in to get others up to speed. Take the time to celebrate wins: It's so easy for a team that is heads down to forget about all the great things they've accomplished. That's why we make it a priority to remind ourselves to create space to celebrate wins, big or small. Job Summary We are seeking a motivated Data Engineer to join our team and help improve our tools, processes, and technical infrastructure. In this role, you will ensure the availability and quality of our data while contributing to the design, implementation, and maintenance of The Helper Bees’ products. You’ll collaborate across teams to create scalable and optimized software systems and play a key role in refining our development processes. This position offers a unique opportunity to learn and leverage cutting-edge AI development tools to enhance coding efficiency and develop advanced data tools and solutions. Supervisory Responsibilities: None Key Responsibilities Data Infrastructure: Design, implement, and maintain data pipelines, ensuring data availability, quality, and scalability. Product Development: Build and enhance products using Python, SQL, and modern technologies. AI Integration: Leverage cutting-edge AI tools, including Cursor, ChatGPT, and Claude to improve development processes, automate workflows, and create innovative data solutions. Collaboration: Communicate across departments to design, build, test, and implement new features and enhancements. Code Excellence: Produce quality, testable, and maintainable code while participating in code reviews. Problem Solving: Debug complex issues, interact with stakeholders, and design viable solutions with clear trade-offs. Process Optimization: Contribute to improving development processes, including deployment, on-call systems, and sprint planning. Team Growth: Collaborate within the development team to help each other grow and continuously learn. Stakeholder Engagement: Partner with analysts, scientists, and IT to ensure alignment and deliver data-driven solutions. Other duties as assigned/necessary Performance Metrics Code Quality: Maintain high coding standards through regular code reviews and adherence to best practices. Development Efficiency: Deliver high-quality features and fixes within efficient timeframes. Bug Resolution Time: Reduce the time taken to identify and resolve issues. System Scalability: Optimize system performance to handle increasing user demands. Collaboration: Foster a collaborative environment that encourages teamwork and knowledge sharing. Customer Satisfaction: Incorporate stakeholder feedback to improve solutions and enhance the customer experience. Continuous Learning: Pursue opportunities for skill development and share knowledge with the team. Requirements: Required Skills & Qualifications Technical Tools: Experience with in Python and/or SQL. Experience with Bash, Shell scripting, Big Query, Airflow, and is a plus. Programming: Cleaning data using code-based approach. AI Proficiency: Interest or experience in using AI tools for coding and development of data solutions. Soft Skills: Problem-solving, cross-team collaboration, data storytelling, and stakeholder engagement. Adaptability: Thrives in a fast-paced startup environment and embraces change. Proactivity: Self-directed, organized, and able to prioritize effectively. Collaboration: Ability to work effectively with cross-functional teams. Education & Experience: A bachelor’s degree is required, and a graduate degree is preferred. Relevant experience in data engineering, software development, STEM, or related fields. Strong experience with SQL and Python is highly desirable. Mindset: A passion for innovation, continuous improvement, and delivering high-quality results from messy data. Preferred Qualifications Familiarity with cloud-based solutions (e.g., Google Cloud Platform, Azure). Experience with ETL processes and tools. Experience building data visualization reports and dashboards Knowledge of modern data storage solutions and database management systems. Exposure to DevOps practices and tools for deployment and monitoring. Why Join Us? Work with a talented, collaborative team dedicated to making a difference. Gain exposure to innovative technologies and opportunities for growth. Learn and utilize cutting-edge AI tools to enhance your development skills and create impactful solutions. Be part of a company that values your contributions and encourages professional development. Join a rapidly expanding health-tech startup (~200 employees and growing) with a state-of-the-art technology office located in Hyde Park, offering a variety of exceptional benefits. Career Progression Timeline In 3 months: Gain a comprehensive understanding of our data infrastructure, technical stacks, and development cycles. Actively participate in team meetings and contribute to the development of new data pipelines. Begin leveraging AI tools, such as Cursor and ChatGPT, to enhance coding efficiency and workflow automation. In 6 months: Contribute to product enhancements and data reporting Collaborate effectively with cross-functional teams, providing insights and solutions for data-related challenges. Demonstrate proficiency in utilizing AI tools for coding and development, actively sharing knowledge with the team. In 12 months: Contribute to data engineering projects, ensuring scalability and performance optimization. Mentor non-technical internal partners to improve company-wide data literacy Contribute to the integration of advanced AI solutions into our development processes, contributing to the company's technological advancement. Physical Requirements: Ability to remain at your designated workstation for the duration of the workday Constantly operates a computer and other office productivity machinery, such as a phone and Voice over Internet Protocol (VoIP). The ability to communicate information and ideas so others will understand. Must be able to exchange accurate information in these situations. The ability to observe details at close range (typically on a computer screen) This position offers the flexibility of remote work at approved locations within the United States. Candidates must have a reliable internet connection and a designated work environment conducive to professional phone calls and sensitive data. Enjoy the convenience and comfort of working remotely while contributing to our team's success. Apply Today If you’re ready to take on challenging problems, contribute to impactful solutions, and grow as a data engineer, we’d love to hear from you. Join us at The Helper Bees and be part of a team that’s making a meaningful difference every day! The Helper Bees is committed to building a workplace where diversity, equity, and inclusion are valued and prioritized. We are an equal opportunity employer that welcomes all qualified applicants without discrimination based on race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or any non-merit based or legally protected grounds. The Helper Bees provides reasonable accommodations to qualified individuals with disabilities during the job application and interview process. To request accommodation, please let your recruiter know. As part of our standard hiring process, selected candidates may be required to undergo a background check and/or drug screen. The Helper Bees adheres to applicable federal, state, and local laws regarding these screenings, and the results will be considered in accordance with applicable regulations. The Helper Bees was recently made aware of a fraudulent entity posing as our organization and requesting personal information. Please be aware of and protect yourself from scams. Visit thehelperbees.com/careers to view all current job openings.</td><td>Description: Join our winning team, recently honored as #67 on Forbes’ list of America’s Best Startup Employers for 2024! About The Helper Bees The Helper Bees’ mission is to help people stay home longer through data-driven services that transform both the payer and the care-recipient experience. At The Helper Bees, we are reshaping how care is delivered to aging individuals by leveraging innovative technology and insightful data solutions. We maintain multiple SaaS products and payment solutions through our web applications (internal and external facing), a mobile app, and reporting integrations. As part of our growing Data Engineering team, you’ll iterate quickly, have a high impact, and be challenged to design and implement cutting-edge solutions. At THB, we define our company culture through our Core Values: Quickly iterate through solutions: We move at a fast pace which requires quick iterations to find a path to a repeatable solution. Seek ways to create immediate impact: Be thoughtful and proactive in how you make an impact on your team. Actively look for ways to make a fast, positive impact. Bee the teammate you want to work with: We work as a team, help each other, and encourage each other. Ask questions, answer questions: You can't iterate through solutions if you don't ask the right questions, which is why there is an expectation that questions should be asked. When you know the answer, being a good teammate means chiming in to get others up to speed. Take the time to celebrate wins: It's so easy for a team that is heads down to forget about all the great things they've accomplished. That's why we make it a priority to remind ourselves to create space to celebrate wins, big or small. Job Summary We are seeking a motivated Data Engineer to join our team and help improve our tools, processes, and technical infrastructure. In this role, you will ensure the availability and quality of our data while contributing to the design, implementation, and maintenance of The Helper Bees’ products. You’ll collaborate across teams to create scalable and optimized software systems and play a key role in refining our development processes. This position offers a unique opportunity to learn and leverage cutting-edge AI development tools to enhance coding efficiency and develop advanced data tools and solutions. Supervisory Responsibilities: None Key Responsibilities Data Infrastructure: Design, implement, and maintain data pipelines, ensuring data availability, quality, and scalability. Product Development: Build and enhance products using Python, SQL, and modern technologies. AI Integration: Leverage cutting-edge AI tools, including Cursor, ChatGPT, and Claude to improve development processes, automate workflows, and create innovative data solutions. Collaboration: Communicate across departments to design, build, test, and implement new features and enhancements. Code Excellence: Produce quality, testable, and maintainable code while participating in code reviews. Problem Solving: Debug complex issues, interact with stakeholders, and design viable solutions with clear trade-offs. Process Optimization: Contribute to improving development processes, including deployment, on-call systems, and sprint planning. Team Growth: Collaborate within the development team to help each other grow and continuously learn. Stakeholder Engagement: Partner with analysts, scientists, and IT to ensure alignment and deliver data-driven solutions. Other duties as assigned/necessary Performance Metrics Code Quality: Maintain high coding standards through regular code reviews and adherence to best practices. Development Efficiency: Deliver high-quality features and fixes within efficient timeframes. Bug Resolution Time: Reduce the time taken to identify and resolve issues. System Scalability: Optimize system performance to handle increasing user demands. Collaboration: Foster a collaborative environment that encourages teamwork and knowledge sharing. Customer Satisfaction: Incorporate stakeholder feedback to improve solutions and enhance the customer experience. Continuous Learning: Pursue opportunities for skill development and share knowledge with the team. Requirements: Required Skills & Qualifications Technical Tools: Experience with in Python and/or SQL. Experience with Bash, Shell scripting, Big Query, Airflow, and is a plus. Programming: Cleaning data using code-based approach. AI Proficiency: Interest or experience in using AI tools for coding and development of data solutions. Soft Skills: Problem-solving, cross-team collaboration, data storytelling, and stakeholder engagement. Adaptability: Thrives in a fast-paced startup environment and embraces change. Proactivity: Self-directed, organized, and able to prioritize effectively. Collaboration: Ability to work effectively with cross-functional teams. Education & Experience: A bachelor’s degree is required, and a graduate degree is preferred. Relevant experience in data engineering, software development, STEM, or related fields. Strong experience with SQL and Python is highly desirable. Mindset: A passion for innovation, continuous improvement, and delivering high-quality results from messy data. Preferred Qualifications Familiarity with cloud-based solutions (e.g., Google Cloud Platform, Azure). Experience with ETL processes and tools. Experience building data visualization reports and dashboards Knowledge of modern data storage solutions and database management systems. Exposure to DevOps practices and tools for deployment and monitoring. Why Join Us? Work with a talented, collaborative team dedicated to making a difference. Gain exposure to innovative technologies and opportunities for growth. Learn and utilize cutting-edge AI tools to enhance your development skills and create impactful solutions. Be part of a company that values your contributions and encourages professional development. Join a rapidly expanding health-tech startup (~200 employees and growing) with a state-of-the-art technology office located in Hyde Park, offering a variety of exceptional benefits. Career Progression Timeline In 3 months: Gain a comprehensive understanding of our data infrastructure, technical stacks, and development cycles. Actively participate in team meetings and contribute to the development of new data pipelines. Begin leveraging AI tools, such as Cursor and ChatGPT, to enhance coding efficiency and workflow automation. In 6 months: Contribute to product enhancements and data reporting Collaborate effectively with cross-functional teams, providing insights and solutions for data-related challenges. Demonstrate proficiency in utilizing AI tools for coding and development, actively sharing knowledge with the team. In 12 months: Contribute to data engineering projects, ensuring scalability and performance optimization. Mentor non-technical internal partners to improve company-wide data literacy Contribute to the integration of advanced AI solutions into our development processes, contributing to the company's technological advancement. Physical Requirements: Ability to remain at your designated workstation for the duration of the workday Constantly operates a computer and other office productivity machinery, such as a phone and Voice over Internet Protocol (VoIP). The ability to communicate information and ideas so others will understand. Must be able to exchange accurate information in these situations. The ability to observe details at close range (typically on a computer screen) This position offers the flexibility of remote work at approved locations within the United States. Candidates must have a reliable internet connection and a designated work environment conducive to professional phone calls and sensitive data. Enjoy the convenience and comfort of working remotely while contributing to our team's success. Apply Today If you’re ready to take on challenging problems, contribute to impactful solutions, and grow as a data engineer, we’d love to hear from you. Join us at The Helper Bees and be part of a team that’s making a meaningful difference every day! The Helper Bees is committed to building a workplace where diversity, equity, and inclusion are valued and prioritized. We are an equal opportunity employer that welcomes all qualified applicants without discrimination based on race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or any non-merit based or legally protected grounds. The Helper Bees provides reasonable accommodations to qualified individuals with disabilities during the job application and interview process. To request accommodation, please let your recruiter know. As part of our standard hiring process, selected candidates may be required to undergo a background check and/or drug screen. The Helper Bees adheres to applicable federal, state, and local laws regarding these screenings, and the results will be considered in accordance with applicable regulations. The Helper Bees was recently made aware of a fraudulent entity posing as our organization and requesting personal information. Please be aware of and protect yourself from scams. Visit thehelperbees.com/careers to view all current job openings.</td><td>Technical Tools: Experience with in Python and/or SQL. Experience with Bash, Shell scripting, Big Query, Airflow, and is a plus. Programming: Cleaning data using code-based approach. AI Proficiency: Interest or experience in using AI tools for coding and development of data solutions. Soft Skills: Problem-solving, cross-team collaboration, data storytelling, and stakeholder engagement. Adaptability: Thrives in a fast-paced startup environment and embraces change. Proactivity: Self-directed, organized, and able to prioritize effectively. Collaboration: Ability to work effectively with cross-functional teams. Education & Experience: A bachelor’s degree is required, and a graduate degree is preferred. Relevant experience in data engineering, software development, STEM, or related fields. Strong experience with SQL and Python is highly desirable. Mindset: A passion for innovation, continuous improvement, and delivering high-quality results from messy data. Preferred Qualifications Familiarity with cloud-based solutions (e.g., Google Cloud Platform, Azure). Experience with ETL processes and tools. Experience building data visualization reports and dashboards Knowledge of modern data storage solutions and database management systems. Exposure to DevOps practices and tools for deployment and monitoring. Why Join Us? Work with a talented, collaborative team dedicated to making a difference. Gain exposure to innovative technologies and opportunities for growth. Learn and utilize cutting-edge AI tools to enhance your development skills and create impactful solutions. Be part of a company that values your contributions and encourages professional development. Join a rapidly expanding health-tech startup (~200 employees and growing) with a state-of-the-art technology office located in Hyde Park, offering a variety of exceptional benefits. Career Progression Timeline In 3 months: Gain a comprehensive understanding of our data infrastructure, technical stacks, and development cycles. Actively participate in team meetings and contribute to the development of new data pipelines. Begin leveraging AI tools, such as Cursor and ChatGPT, to enhance coding efficiency and workflow automation. In 6 months: Contribute to product enhancements and data reporting Collaborate effectively with cross-functional teams, providing insights and solutions for data-related challenges. Demonstrate proficiency in utilizing AI tools for coding and development, actively sharing knowledge with the team. In 12 months: Contribute to data engineering projects, ensuring scalability and performance optimization. Mentor non-technical internal partners to improve company-wide data literacy Contribute to the integration of advanced AI solutions into our development processes, contributing to the company's technological advancement. Physical Requirements: Ability to remain at your designated workstation for the duration of the workday Constantly operates a computer and other office productivity machinery, such as a phone and Voice over Internet Protocol (VoIP). The ability to communicate information and ideas so others will understand. Must be able to exchange accurate information in these situations. The ability to observe details at close range (typically on a computer screen) This position offers the flexibility of remote work at approved locations within the United States. Candidates must have a reliable internet connection and a designated work environment conducive to professional phone calls and sensitive data. Enjoy the convenience and comfort of working remotely while contributing to our team's success. Apply Today If you’re ready to take on challenging problems, contribute to impactful solutions, and grow as a data engineer, we’d love to hear from you. Join us at The Helper Bees and be part of a team that’s making a meaningful difference every day! The Helper Bees is committed to building a workplace where diversity, equity, and inclusion are valued and prioritized. We are an equal opportunity employer that welcomes all qualified applicants without discrimination based on race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or any non-merit based or legally protected grounds. The Helper Bees provides reasonable accommodations to qualified individuals with disabilities during the job application and interview process. To request accommodation, please let your recruiter know. As part of our standard hiring process, selected candidates may be required to undergo a background check and/or drug screen. The Helper Bees adheres to applicable federal, state, and local laws regarding these screenings, and the results will be considered in accordance with applicable regulations. The Helper Bees was recently made aware of a fraudulent entity posing as our organization and requesting personal information. Please be aware of and protect yourself from scams. Visit thehelperbees.com/careers to view all current job openings.</td><td>698</td></tr><tr><td>null</td><td>culture through our Core Values:</td><td>Description: Join our winning team, recently honored as #67 on Forbes’ list of America’s Best Startup Employers for 2024! About The Helper Bees The Helper Bees’ mission is to help people stay home longer through data-driven services that transform both the payer and the care-recipient experience. At The Helper Bees, we are reshaping how care is delivered to aging individuals by leveraging innovative technology and insightful data solutions. We maintain multiple SaaS products and payment solutions through our web applications (internal and external facing), a mobile app, and reporting integrations. As part of our growing Data Engineering team, you’ll iterate quickly, have a high impact, and be challenged to design and implement cutting-edge solutions. At THB, we define our company culture through our Core Values: Quickly iterate through solutions: We move at a fast pace which requires quick iterations to find a path to a repeatable solution. Seek ways to create immediate impact: Be thoughtful and proactive in how you make an impact on your team. Actively look for ways to make a fast, positive impact. Bee the teammate you want to work with: We work as a team, help each other, and encourage each other. Ask questions, answer questions: You can't iterate through solutions if you don't ask the right questions, which is why there is an expectation that questions should be asked. When you know the answer, being a good teammate means chiming in to get others up to speed. Take the time to celebrate wins: It's so easy for a team that is heads down to forget about all the great things they've accomplished. That's why we make it a priority to remind ourselves to create space to celebrate wins, big or small. Job Summary We are seeking a motivated Data Engineer to join our team and help improve our tools, processes, and technical infrastructure. In this role, you will ensure the availability and quality of our data while contributing to the design, implementation, and maintenance of The Helper Bees’ products. You’ll collaborate across teams to create scalable and optimized software systems and play a key role in refining our development processes. This position offers a unique opportunity to learn and leverage cutting-edge AI development tools to enhance coding efficiency and develop advanced data tools and solutions. Supervisory Responsibilities: None Key Responsibilities Data Infrastructure: Design, implement, and maintain data pipelines, ensuring data availability, quality, and scalability. Product Development: Build and enhance products using Python, SQL, and modern technologies. AI Integration: Leverage cutting-edge AI tools, including Cursor, ChatGPT, and Claude to improve development processes, automate workflows, and create innovative data solutions. Collaboration: Communicate across departments to design, build, test, and implement new features and enhancements. Code Excellence: Produce quality, testable, and maintainable code while participating in code reviews. Problem Solving: Debug complex issues, interact with stakeholders, and design viable solutions with clear trade-offs. Process Optimization: Contribute to improving development processes, including deployment, on-call systems, and sprint planning. Team Growth: Collaborate within the development team to help each other grow and continuously learn. Stakeholder Engagement: Partner with analysts, scientists, and IT to ensure alignment and deliver data-driven solutions. Other duties as assigned/necessary Performance Metrics Code Quality: Maintain high coding standards through regular code reviews and adherence to best practices. Development Efficiency: Deliver high-quality features and fixes within efficient timeframes. Bug Resolution Time: Reduce the time taken to identify and resolve issues. System Scalability: Optimize system performance to handle increasing user demands. Collaboration: Foster a collaborative environment that encourages teamwork and knowledge sharing. Customer Satisfaction: Incorporate stakeholder feedback to improve solutions and enhance the customer experience. Continuous Learning: Pursue opportunities for skill development and share knowledge with the team. Requirements: Required Skills & Qualifications Technical Tools: Experience with in Python and/or SQL. Experience with Bash, Shell scripting, Big Query, Airflow, and is a plus. Programming: Cleaning data using code-based approach. AI Proficiency: Interest or experience in using AI tools for coding and development of data solutions. Soft Skills: Problem-solving, cross-team collaboration, data storytelling, and stakeholder engagement. Adaptability: Thrives in a fast-paced startup environment and embraces change. Proactivity: Self-directed, organized, and able to prioritize effectively. Collaboration: Ability to work effectively with cross-functional teams. Education & Experience: A bachelor’s degree is required, and a graduate degree is preferred. Relevant experience in data engineering, software development, STEM, or related fields. Strong experience with SQL and Python is highly desirable. Mindset: A passion for innovation, continuous improvement, and delivering high-quality results from messy data. Preferred Qualifications Familiarity with cloud-based solutions (e.g., Google Cloud Platform, Azure). Experience with ETL processes and tools. Experience building data visualization reports and dashboards Knowledge of modern data storage solutions and database management systems. Exposure to DevOps practices and tools for deployment and monitoring. Why Join Us? Work with a talented, collaborative team dedicated to making a difference. Gain exposure to innovative technologies and opportunities for growth. Learn and utilize cutting-edge AI tools to enhance your development skills and create impactful solutions. Be part of a company that values your contributions and encourages professional development. Join a rapidly expanding health-tech startup (~200 employees and growing) with a state-of-the-art technology office located in Hyde Park, offering a variety of exceptional benefits. Career Progression Timeline In 3 months: Gain a comprehensive understanding of our data infrastructure, technical stacks, and development cycles. Actively participate in team meetings and contribute to the development of new data pipelines. Begin leveraging AI tools, such as Cursor and ChatGPT, to enhance coding efficiency and workflow automation. In 6 months: Contribute to product enhancements and data reporting Collaborate effectively with cross-functional teams, providing insights and solutions for data-related challenges. Demonstrate proficiency in utilizing AI tools for coding and development, actively sharing knowledge with the team. In 12 months: Contribute to data engineering projects, ensuring scalability and performance optimization. Mentor non-technical internal partners to improve company-wide data literacy Contribute to the integration of advanced AI solutions into our development processes, contributing to the company's technological advancement. Physical Requirements: Ability to remain at your designated workstation for the duration of the workday Constantly operates a computer and other office productivity machinery, such as a phone and Voice over Internet Protocol (VoIP). The ability to communicate information and ideas so others will understand. Must be able to exchange accurate information in these situations. The ability to observe details at close range (typically on a computer screen) This position offers the flexibility of remote work at approved locations within the United States. Candidates must have a reliable internet connection and a designated work environment conducive to professional phone calls and sensitive data. Enjoy the convenience and comfort of working remotely while contributing to our team's success. Apply Today If you’re ready to take on challenging problems, contribute to impactful solutions, and grow as a data engineer, we’d love to hear from you. Join us at The Helper Bees and be part of a team that’s making a meaningful difference every day! The Helper Bees is committed to building a workplace where diversity, equity, and inclusion are valued and prioritized. We are an equal opportunity employer that welcomes all qualified applicants without discrimination based on race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or any non-merit based or legally protected grounds. The Helper Bees provides reasonable accommodations to qualified individuals with disabilities during the job application and interview process. To request accommodation, please let your recruiter know. As part of our standard hiring process, selected candidates may be required to undergo a background check and/or drug screen. The Helper Bees adheres to applicable federal, state, and local laws regarding these screenings, and the results will be considered in accordance with applicable regulations. The Helper Bees was recently made aware of a fraudulent entity posing as our organization and requesting personal information. Please be aware of and protect yourself from scams. Visit thehelperbees.com/careers to view all current job openings.</td><td>data</td><td>Description: Join our winning team, recently honored as #67 on Forbes’ list of America’s Best Startup Employers for 2024! About The Helper Bees The Helper Bees’ mission is to help people stay home longer through data-driven services that transform both the payer and the care-recipient experience. At The Helper Bees, we are reshaping how care is delivered to aging individuals by leveraging innovative technology and insightful data solutions. We maintain multiple SaaS products and payment solutions through our web applications (internal and external facing), a mobile app, and reporting integrations. As part of our growing Data Engineering team, you’ll iterate quickly, have a high impact, and be challenged to design and implement cutting-edge solutions. At THB, we define our company culture through our Core Values: Quickly iterate through solutions: We move at a fast pace which requires quick iterations to find a path to a repeatable solution. Seek ways to create immediate impact: Be thoughtful and proactive in how you make an impact on your team. Actively look for ways to make a fast, positive impact. Bee the teammate you want to work with: We work as a team, help each other, and encourage each other. Ask questions, answer questions: You can't iterate through solutions if you don't ask the right questions, which is why there is an expectation that questions should be asked. When you know the answer, being a good teammate means chiming in to get others up to speed. Take the time to celebrate wins: It's so easy for a team that is heads down to forget about all the great things they've accomplished. That's why we make it a priority to remind ourselves to create space to celebrate wins, big or small. Job Summary We are seeking a motivated Data Engineer to join our team and help improve our tools, processes, and technical infrastructure. In this role, you will ensure the availability and quality of our data while contributing to the design, implementation, and maintenance of The Helper Bees’ products. You’ll collaborate across teams to create scalable and optimized software systems and play a key role in refining our development processes. This position offers a unique opportunity to learn and leverage cutting-edge AI development tools to enhance coding efficiency and develop advanced data tools and solutions. Supervisory Responsibilities: None Key Responsibilities Data Infrastructure: Design, implement, and maintain data pipelines, ensuring data availability, quality, and scalability. Product Development: Build and enhance products using Python, SQL, and modern technologies. AI Integration: Leverage cutting-edge AI tools, including Cursor, ChatGPT, and Claude to improve development processes, automate workflows, and create innovative data solutions. Collaboration: Communicate across departments to design, build, test, and implement new features and enhancements. Code Excellence: Produce quality, testable, and maintainable code while participating in code reviews. Problem Solving: Debug complex issues, interact with stakeholders, and design viable solutions with clear trade-offs. Process Optimization: Contribute to improving development processes, including deployment, on-call systems, and sprint planning. Team Growth: Collaborate within the development team to help each other grow and continuously learn. Stakeholder Engagement: Partner with analysts, scientists, and IT to ensure alignment and deliver data-driven solutions. Other duties as assigned/necessary Performance Metrics Code Quality: Maintain high coding standards through regular code reviews and adherence to best practices. Development Efficiency: Deliver high-quality features and fixes within efficient timeframes. Bug Resolution Time: Reduce the time taken to identify and resolve issues. System Scalability: Optimize system performance to handle increasing user demands. Collaboration: Foster a collaborative environment that encourages teamwork and knowledge sharing. Customer Satisfaction: Incorporate stakeholder feedback to improve solutions and enhance the customer experience. Continuous Learning: Pursue opportunities for skill development and share knowledge with the team. Requirements: Required Skills & Qualifications Technical Tools: Experience with in Python and/or SQL. Experience with Bash, Shell scripting, Big Query, Airflow, and is a plus. Programming: Cleaning data using code-based approach. AI Proficiency: Interest or experience in using AI tools for coding and development of data solutions. Soft Skills: Problem-solving, cross-team collaboration, data storytelling, and stakeholder engagement. Adaptability: Thrives in a fast-paced startup environment and embraces change. Proactivity: Self-directed, organized, and able to prioritize effectively. Collaboration: Ability to work effectively with cross-functional teams. Education & Experience: A bachelor’s degree is required, and a graduate degree is preferred. Relevant experience in data engineering, software development, STEM, or related fields. Strong experience with SQL and Python is highly desirable. Mindset: A passion for innovation, continuous improvement, and delivering high-quality results from messy data. Preferred Qualifications Familiarity with cloud-based solutions (e.g., Google Cloud Platform, Azure). Experience with ETL processes and tools. Experience building data visualization reports and dashboards Knowledge of modern data storage solutions and database management systems. Exposure to DevOps practices and tools for deployment and monitoring. Why Join Us? Work with a talented, collaborative team dedicated to making a difference. Gain exposure to innovative technologies and opportunities for growth. Learn and utilize cutting-edge AI tools to enhance your development skills and create impactful solutions. Be part of a company that values your contributions and encourages professional development. Join a rapidly expanding health-tech startup (~200 employees and growing) with a state-of-the-art technology office located in Hyde Park, offering a variety of exceptional benefits. Career Progression Timeline In 3 months: Gain a comprehensive understanding of our data infrastructure, technical stacks, and development cycles. Actively participate in team meetings and contribute to the development of new data pipelines. Begin leveraging AI tools, such as Cursor and ChatGPT, to enhance coding efficiency and workflow automation. In 6 months: Contribute to product enhancements and data reporting Collaborate effectively with cross-functional teams, providing insights and solutions for data-related challenges. Demonstrate proficiency in utilizing AI tools for coding and development, actively sharing knowledge with the team. In 12 months: Contribute to data engineering projects, ensuring scalability and performance optimization. Mentor non-technical internal partners to improve company-wide data literacy Contribute to the integration of advanced AI solutions into our development processes, contributing to the company's technological advancement. Physical Requirements: Ability to remain at your designated workstation for the duration of the workday Constantly operates a computer and other office productivity machinery, such as a phone and Voice over Internet Protocol (VoIP). The ability to communicate information and ideas so others will understand. Must be able to exchange accurate information in these situations. The ability to observe details at close range (typically on a computer screen) This position offers the flexibility of remote work at approved locations within the United States. Candidates must have a reliable internet connection and a designated work environment conducive to professional phone calls and sensitive data. Enjoy the convenience and comfort of working remotely while contributing to our team's success. Apply Today If you’re ready to take on challenging problems, contribute to impactful solutions, and grow as a data engineer, we’d love to hear from you. Join us at The Helper Bees and be part of a team that’s making a meaningful difference every day! The Helper Bees is committed to building a workplace where diversity, equity, and inclusion are valued and prioritized. We are an equal opportunity employer that welcomes all qualified applicants without discrimination based on race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or any non-merit based or legally protected grounds. The Helper Bees provides reasonable accommodations to qualified individuals with disabilities during the job application and interview process. To request accommodation, please let your recruiter know. As part of our standard hiring process, selected candidates may be required to undergo a background check and/or drug screen. The Helper Bees adheres to applicable federal, state, and local laws regarding these screenings, and the results will be considered in accordance with applicable regulations. The Helper Bees was recently made aware of a fraudulent entity posing as our organization and requesting personal information. Please be aware of and protect yourself from scams. Visit thehelperbees.com/careers to view all current job openings.</td><td>Description: Join our winning team, recently honored as #67 on Forbes’ list of America’s Best Startup Employers for 2024! About The Helper Bees The Helper Bees’ mission is to help people stay home longer through data-driven services that transform both the payer and the care-recipient experience. At The Helper Bees, we are reshaping how care is delivered to aging individuals by leveraging innovative technology and insightful data solutions. We maintain multiple SaaS products and payment solutions through our web applications (internal and external facing), a mobile app, and reporting integrations. As part of our growing Data Engineering team, you’ll iterate quickly, have a high impact, and be challenged to design and implement cutting-edge solutions. At THB, we define our company culture through our Core Values: Quickly iterate through solutions: We move at a fast pace which requires quick iterations to find a path to a repeatable solution. Seek ways to create immediate impact: Be thoughtful and proactive in how you make an impact on your team. Actively look for ways to make a fast, positive impact. Bee the teammate you want to work with: We work as a team, help each other, and encourage each other. Ask questions, answer questions: You can't iterate through solutions if you don't ask the right questions, which is why there is an expectation that questions should be asked. When you know the answer, being a good teammate means chiming in to get others up to speed. Take the time to celebrate wins: It's so easy for a team that is heads down to forget about all the great things they've accomplished. That's why we make it a priority to remind ourselves to create space to celebrate wins, big or small. Job Summary We are seeking a motivated Data Engineer to join our team and help improve our tools, processes, and technical infrastructure. In this role, you will ensure the availability and quality of our data while contributing to the design, implementation, and maintenance of The Helper Bees’ products. You’ll collaborate across teams to create scalable and optimized software systems and play a key role in refining our development processes. This position offers a unique opportunity to learn and leverage cutting-edge AI development tools to enhance coding efficiency and develop advanced data tools and solutions. Supervisory Responsibilities: None Key Responsibilities Data Infrastructure: Design, implement, and maintain data pipelines, ensuring data availability, quality, and scalability. Product Development: Build and enhance products using Python, SQL, and modern technologies. AI Integration: Leverage cutting-edge AI tools, including Cursor, ChatGPT, and Claude to improve development processes, automate workflows, and create innovative data solutions. Collaboration: Communicate across departments to design, build, test, and implement new features and enhancements. Code Excellence: Produce quality, testable, and maintainable code while participating in code reviews. Problem Solving: Debug complex issues, interact with stakeholders, and design viable solutions with clear trade-offs. Process Optimization: Contribute to improving development processes, including deployment, on-call systems, and sprint planning. Team Growth: Collaborate within the development team to help each other grow and continuously learn. Stakeholder Engagement: Partner with analysts, scientists, and IT to ensure alignment and deliver data-driven solutions. Other duties as assigned/necessary Performance Metrics Code Quality: Maintain high coding standards through regular code reviews and adherence to best practices. Development Efficiency: Deliver high-quality features and fixes within efficient timeframes. Bug Resolution Time: Reduce the time taken to identify and resolve issues. System Scalability: Optimize system performance to handle increasing user demands. Collaboration: Foster a collaborative environment that encourages teamwork and knowledge sharing. Customer Satisfaction: Incorporate stakeholder feedback to improve solutions and enhance the customer experience. Continuous Learning: Pursue opportunities for skill development and share knowledge with the team. Requirements: Required Skills & Qualifications Technical Tools: Experience with in Python and/or SQL. Experience with Bash, Shell scripting, Big Query, Airflow, and is a plus. Programming: Cleaning data using code-based approach. AI Proficiency: Interest or experience in using AI tools for coding and development of data solutions. Soft Skills: Problem-solving, cross-team collaboration, data storytelling, and stakeholder engagement. Adaptability: Thrives in a fast-paced startup environment and embraces change. Proactivity: Self-directed, organized, and able to prioritize effectively. Collaboration: Ability to work effectively with cross-functional teams. Education & Experience: A bachelor’s degree is required, and a graduate degree is preferred. Relevant experience in data engineering, software development, STEM, or related fields. Strong experience with SQL and Python is highly desirable. Mindset: A passion for innovation, continuous improvement, and delivering high-quality results from messy data. Preferred Qualifications Familiarity with cloud-based solutions (e.g., Google Cloud Platform, Azure). Experience with ETL processes and tools. Experience building data visualization reports and dashboards Knowledge of modern data storage solutions and database management systems. Exposure to DevOps practices and tools for deployment and monitoring. Why Join Us? Work with a talented, collaborative team dedicated to making a difference. Gain exposure to innovative technologies and opportunities for growth. Learn and utilize cutting-edge AI tools to enhance your development skills and create impactful solutions. Be part of a company that values your contributions and encourages professional development. Join a rapidly expanding health-tech startup (~200 employees and growing) with a state-of-the-art technology office located in Hyde Park, offering a variety of exceptional benefits. Career Progression Timeline In 3 months: Gain a comprehensive understanding of our data infrastructure, technical stacks, and development cycles. Actively participate in team meetings and contribute to the development of new data pipelines. Begin leveraging AI tools, such as Cursor and ChatGPT, to enhance coding efficiency and workflow automation. In 6 months: Contribute to product enhancements and data reporting Collaborate effectively with cross-functional teams, providing insights and solutions for data-related challenges. Demonstrate proficiency in utilizing AI tools for coding and development, actively sharing knowledge with the team. In 12 months: Contribute to data engineering projects, ensuring scalability and performance optimization. Mentor non-technical internal partners to improve company-wide data literacy Contribute to the integration of advanced AI solutions into our development processes, contributing to the company's technological advancement. Physical Requirements: Ability to remain at your designated workstation for the duration of the workday Constantly operates a computer and other office productivity machinery, such as a phone and Voice over Internet Protocol (VoIP). The ability to communicate information and ideas so others will understand. Must be able to exchange accurate information in these situations. The ability to observe details at close range (typically on a computer screen) This position offers the flexibility of remote work at approved locations within the United States. Candidates must have a reliable internet connection and a designated work environment conducive to professional phone calls and sensitive data. Enjoy the convenience and comfort of working remotely while contributing to our team's success. Apply Today If you’re ready to take on challenging problems, contribute to impactful solutions, and grow as a data engineer, we’d love to hear from you. Join us at The Helper Bees and be part of a team that’s making a meaningful difference every day! The Helper Bees is committed to building a workplace where diversity, equity, and inclusion are valued and prioritized. We are an equal opportunity employer that welcomes all qualified applicants without discrimination based on race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or any non-merit based or legally protected grounds. The Helper Bees provides reasonable accommodations to qualified individuals with disabilities during the job application and interview process. To request accommodation, please let your recruiter know. As part of our standard hiring process, selected candidates may be required to undergo a background check and/or drug screen. The Helper Bees adheres to applicable federal, state, and local laws regarding these screenings, and the results will be considered in accordance with applicable regulations. The Helper Bees was recently made aware of a fraudulent entity posing as our organization and requesting personal information. Please be aware of and protect yourself from scams. Visit thehelperbees.com/careers to view all current job openings.</td><td>Technical Tools: Experience with in Python and/or SQL. Experience with Bash, Shell scripting, Big Query, Airflow, and is a plus. Programming: Cleaning data using code-based approach. AI Proficiency: Interest or experience in using AI tools for coding and development of data solutions. Soft Skills: Problem-solving, cross-team collaboration, data storytelling, and stakeholder engagement. Adaptability: Thrives in a fast-paced startup environment and embraces change. Proactivity: Self-directed, organized, and able to prioritize effectively. Collaboration: Ability to work effectively with cross-functional teams. Education & Experience: A bachelor’s degree is required, and a graduate degree is preferred. Relevant experience in data engineering, software development, STEM, or related fields. Strong experience with SQL and Python is highly desirable. Mindset: A passion for innovation, continuous improvement, and delivering high-quality results from messy data. Preferred Qualifications Familiarity with cloud-based solutions (e.g., Google Cloud Platform, Azure). Experience with ETL processes and tools. Experience building data visualization reports and dashboards Knowledge of modern data storage solutions and database management systems. Exposure to DevOps practices and tools for deployment and monitoring. Why Join Us? Work with a talented, collaborative team dedicated to making a difference. Gain exposure to innovative technologies and opportunities for growth. Learn and utilize cutting-edge AI tools to enhance your development skills and create impactful solutions. Be part of a company that values your contributions and encourages professional development. Join a rapidly expanding health-tech startup (~200 employees and growing) with a state-of-the-art technology office located in Hyde Park, offering a variety of exceptional benefits. Career Progression Timeline In 3 months: Gain a comprehensive understanding of our data infrastructure, technical stacks, and development cycles. Actively participate in team meetings and contribute to the development of new data pipelines. Begin leveraging AI tools, such as Cursor and ChatGPT, to enhance coding efficiency and workflow automation. In 6 months: Contribute to product enhancements and data reporting Collaborate effectively with cross-functional teams, providing insights and solutions for data-related challenges. Demonstrate proficiency in utilizing AI tools for coding and development, actively sharing knowledge with the team. In 12 months: Contribute to data engineering projects, ensuring scalability and performance optimization. Mentor non-technical internal partners to improve company-wide data literacy Contribute to the integration of advanced AI solutions into our development processes, contributing to the company's technological advancement. Physical Requirements: Ability to remain at your designated workstation for the duration of the workday Constantly operates a computer and other office productivity machinery, such as a phone and Voice over Internet Protocol (VoIP). The ability to communicate information and ideas so others will understand. Must be able to exchange accurate information in these situations. The ability to observe details at close range (typically on a computer screen) This position offers the flexibility of remote work at approved locations within the United States. Candidates must have a reliable internet connection and a designated work environment conducive to professional phone calls and sensitive data. Enjoy the convenience and comfort of working remotely while contributing to our team's success. Apply Today If you’re ready to take on challenging problems, contribute to impactful solutions, and grow as a data engineer, we’d love to hear from you. Join us at The Helper Bees and be part of a team that’s making a meaningful difference every day! The Helper Bees is committed to building a workplace where diversity, equity, and inclusion are valued and prioritized. We are an equal opportunity employer that welcomes all qualified applicants without discrimination based on race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or any non-merit based or legally protected grounds. The Helper Bees provides reasonable accommodations to qualified individuals with disabilities during the job application and interview process. To request accommodation, please let your recruiter know. As part of our standard hiring process, selected candidates may be required to undergo a background check and/or drug screen. The Helper Bees adheres to applicable federal, state, and local laws regarding these screenings, and the results will be considered in accordance with applicable regulations. The Helper Bees was recently made aware of a fraudulent entity posing as our organization and requesting personal information. Please be aware of and protect yourself from scams. Visit thehelperbees.com/careers to view all current job openings.</td><td>698</td></tr><tr><td>null</td><td>culture is a commitment to instilling a dynamic and employee-friendly place to work. We place a priority on promoting a supportive and collegial team environment and enhancing staff experience through career development and educational opportunities.</td><td>Index Analytics, LLC, is a rapidly growing, Baltimore-based small business providing health-related consulting services to the federal government. At the center of our company culture is a commitment to instilling a dynamic and employee-friendly place to work. We place a priority on promoting a supportive and collegial team environment and enhancing staff experience through career development and educational opportunities. Position Overview The Data Engineer is responsible for designing, building, and maintaining data pipelines and architectures to support data analytics and reporting needs across the organization. This role involves working closely with data scientists, analysts, and other stakeholders to ensure that data is clean, accessible, and ready for analysis. The Data Engineer will optimize data systems, develop data integration solutions, and ensure data security and governance. Key responsibilities include creating ETL processes, managing databases, and improving data infrastructure performance. The ideal candidate has strong programming and database skills and experience with cloud-based data platforms. Responsibilities Leads design, implementation, and management of data pipelines Develops and executes ETL (extract, transform, load) or ELT code Supports design of robust Data Integration Architecture to support customers Helps monitor and administer the systems and ensures applications and systems are always functioning properly Analyzes the Data Integration and Engineering architecture to identify weaknesses and develops improvements such as enhancing business processes Identifies and analyzes business requirements, functional design, and translation of requirements to technical specifications Performs complex query design, developments, validation routine analysis, and streamlining processes Operates large data sets, delta data sets and querying efficiently Transforms, joins, and normalizes data in service of specific use cases. Employs AWS data pipeline solutions such as Glue, Data Pipeline, Step functions, MWAA to orchestrate data movement Work with DevSecOps engineer to deploy continuous integration and continuous deployment (CI/CD) data pipelines Understand the technical architecture to design, build, optimize, and maintain scalable data solutions in a Big Data environment Work with Product Owners and/or business stakeholders to gather business requirements and translate to detailed technical specifications US citizen or Authorized to Work and lived in the US for 3 of the last 5 years. Must be able to obtain a U.S. Federal government client badge and pass a government Public Trust. Bachelors degree or higher in IT or relevant discipline required 4+ years of IT experience Experience with setting up and operating data pipelines using Python or SQL Experience with Scala and PySpark 3+ years of experience working on AWS, GCP or Azure (AWS Preferred) cloud platforms Hands-on relational DB / NoSQL experience (PostgreSQL or similar) with specific implementation on cloud Experience working with data warehouses such as Redshift to open source and proprietary cloud data pipeline tools such as Airflow, Glue, Data Pipeline, Step functions Experience working with relational databases that handle structured and semi-structured (JSON) datasets Experience with data serialization languages such as JSON, XML, YAML Experience with code management tools (e.g. Git, SVN) and DevOps tools (e.g. Jenkins, Docker, AWS Code Pipeline) Strong analytical problem-solving ability Working experience with Transactional and Dimensional data modeling methodologies (Eg: Normalization, Star Schema, Snowflake Schema) Experience working with a distributed computing environment like AWS EMR or similar. Ability to obtain Public Trust level clearance Ability to demonstrate excellent written and oral communication required Prior experience with Center for Medicare Medicaid Services or other Govt agencies is a plus The salary range provided represents the estimated compensation for new hires in this position, applicable across all locations. Actual offers may vary based on factors such as the candidate's skills, qualifications, experience, and market conditions. Index complements its base salary offering with a competitive package that includes health and retirement benefits, discretionary bonuses, and reimbursement for professional development opportunities. Index Analytics provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training. Attention Candidates We're dedicated to ensuring a safe and transparent recruitment process for all candidates and have implemented robust measures to protect your personal information. Please be aware that all employment-related communications will originate from a secure portal ( NAME@msg.paycomonline.com ) or a corporate email address ( NAME@index-analytics.com ). If you have any concerns, please don't hesitate to reach out to us at recruiting@index-analytics.com</td><td>data</td><td>Index Analytics, LLC, is a rapidly growing, Baltimore-based small business providing health-related consulting services to the federal government. At the center of our company culture is a commitment to instilling a dynamic and employee-friendly place to work. We place a priority on promoting a supportive and collegial team environment and enhancing staff experience through career development and educational opportunities. Position Overview The Data Engineer is responsible for designing, building, and maintaining data pipelines and architectures to support data analytics and reporting needs across the organization. This role involves working closely with data scientists, analysts, and other stakeholders to ensure that data is clean, accessible, and ready for analysis. The Data Engineer will optimize data systems, develop data integration solutions, and ensure data security and governance. Key responsibilities include creating ETL processes, managing databases, and improving data infrastructure performance. The ideal candidate has strong programming and database skills and experience with cloud-based data platforms. Responsibilities Leads design, implementation, and management of data pipelines Develops and executes ETL (extract, transform, load) or ELT code Supports design of robust Data Integration Architecture to support customers Helps monitor and administer the systems and ensures applications and systems are always functioning properly Analyzes the Data Integration and Engineering architecture to identify weaknesses and develops improvements such as enhancing business processes Identifies and analyzes business requirements, functional design, and translation of requirements to technical specifications Performs complex query design, developments, validation routine analysis, and streamlining processes Operates large data sets, delta data sets and querying efficiently Transforms, joins, and normalizes data in service of specific use cases. Employs AWS data pipeline solutions such as Glue, Data Pipeline, Step functions, MWAA to orchestrate data movement Work with DevSecOps engineer to deploy continuous integration and continuous deployment (CI/CD) data pipelines Understand the technical architecture to design, build, optimize, and maintain scalable data solutions in a Big Data environment Work with Product Owners and/or business stakeholders to gather business requirements and translate to detailed technical specifications US citizen or Authorized to Work and lived in the US for 3 of the last 5 years. Must be able to obtain a U.S. Federal government client badge and pass a government Public Trust. Bachelors degree or higher in IT or relevant discipline required 4+ years of IT experience Experience with setting up and operating data pipelines using Python or SQL Experience with Scala and PySpark 3+ years of experience working on AWS, GCP or Azure (AWS Preferred) cloud platforms Hands-on relational DB / NoSQL experience (PostgreSQL or similar) with specific implementation on cloud Experience working with data warehouses such as Redshift to open source and proprietary cloud data pipeline tools such as Airflow, Glue, Data Pipeline, Step functions Experience working with relational databases that handle structured and semi-structured (JSON) datasets Experience with data serialization languages such as JSON, XML, YAML Experience with code management tools (e.g. Git, SVN) and DevOps tools (e.g. Jenkins, Docker, AWS Code Pipeline) Strong analytical problem-solving ability Working experience with Transactional and Dimensional data modeling methodologies (Eg: Normalization, Star Schema, Snowflake Schema) Experience working with a distributed computing environment like AWS EMR or similar. Ability to obtain Public Trust level clearance Ability to demonstrate excellent written and oral communication required Prior experience with Center for Medicare Medicaid Services or other Govt agencies is a plus The salary range provided represents the estimated compensation for new hires in this position, applicable across all locations. Actual offers may vary based on factors such as the candidate's skills, qualifications, experience, and market conditions. Index complements its base salary offering with a competitive package that includes health and retirement benefits, discretionary bonuses, and reimbursement for professional development opportunities. Index Analytics provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training. Attention Candidates We're dedicated to ensuring a safe and transparent recruitment process for all candidates and have implemented robust measures to protect your personal information. Please be aware that all employment-related communications will originate from a secure portal ( NAME@msg.paycomonline.com ) or a corporate email address ( NAME@index-analytics.com ). If you have any concerns, please don't hesitate to reach out to us at recruiting@index-analytics.com</td><td>Index Analytics, LLC, is a rapidly growing, Baltimore-based small business providing health-related consulting services to the federal government. At the center of our company culture is a commitment to instilling a dynamic and employee-friendly place to work. We place a priority on promoting a supportive and collegial team environment and enhancing staff experience through career development and educational opportunities. Position Overview The Data Engineer is responsible for designing, building, and maintaining data pipelines and architectures to support data analytics and reporting needs across the organization. This role involves working closely with data scientists, analysts, and other stakeholders to ensure that data is clean, accessible, and ready for analysis. The Data Engineer will optimize data systems, develop data integration solutions, and ensure data security and governance. Key responsibilities include creating ETL processes, managing databases, and improving data infrastructure performance. The ideal candidate has strong programming and database skills and experience with cloud-based data platforms. Responsibilities Leads design, implementation, and management of data pipelines Develops and executes ETL (extract, transform, load) or ELT code Supports design of robust Data Integration Architecture to support customers Helps monitor and administer the systems and ensures applications and systems are always functioning properly Analyzes the Data Integration and Engineering architecture to identify weaknesses and develops improvements such as enhancing business processes Identifies and analyzes business requirements, functional design, and translation of requirements to technical specifications Performs complex query design, developments, validation routine analysis, and streamlining processes Operates large data sets, delta data sets and querying efficiently Transforms, joins, and normalizes data in service of specific use cases. Employs AWS data pipeline solutions such as Glue, Data Pipeline, Step functions, MWAA to orchestrate data movement Work with DevSecOps engineer to deploy continuous integration and continuous deployment (CI/CD) data pipelines Understand the technical architecture to design, build, optimize, and maintain scalable data solutions in a Big Data environment Work with Product Owners and/or business stakeholders to gather business requirements and translate to detailed technical specifications US citizen or Authorized to Work and lived in the US for 3 of the last 5 years. Must be able to obtain a U.S. Federal government client badge and pass a government Public Trust. Bachelors degree or higher in IT or relevant discipline required 4+ years of IT experience Experience with setting up and operating data pipelines using Python or SQL Experience with Scala and PySpark 3+ years of experience working on AWS, GCP or Azure (AWS Preferred) cloud platforms Hands-on relational DB / NoSQL experience (PostgreSQL or similar) with specific implementation on cloud Experience working with data warehouses such as Redshift to open source and proprietary cloud data pipeline tools such as Airflow, Glue, Data Pipeline, Step functions Experience working with relational databases that handle structured and semi-structured (JSON) datasets Experience with data serialization languages such as JSON, XML, YAML Experience with code management tools (e.g. Git, SVN) and DevOps tools (e.g. Jenkins, Docker, AWS Code Pipeline) Strong analytical problem-solving ability Working experience with Transactional and Dimensional data modeling methodologies (Eg: Normalization, Star Schema, Snowflake Schema) Experience working with a distributed computing environment like AWS EMR or similar. Ability to obtain Public Trust level clearance Ability to demonstrate excellent written and oral communication required Prior experience with Center for Medicare Medicaid Services or other Govt agencies is a plus The salary range provided represents the estimated compensation for new hires in this position, applicable across all locations. Actual offers may vary based on factors such as the candidate's skills, qualifications, experience, and market conditions. Index complements its base salary offering with a competitive package that includes health and retirement benefits, discretionary bonuses, and reimbursement for professional development opportunities. Index Analytics provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training. Attention Candidates We're dedicated to ensuring a safe and transparent recruitment process for all candidates and have implemented robust measures to protect your personal information. Please be aware that all employment-related communications will originate from a secure portal ( NAME@msg.paycomonline.com ) or a corporate email address ( NAME@index-analytics.com ). If you have any concerns, please don't hesitate to reach out to us at recruiting@index-analytics.com</td><td>to technical specifications Performs complex query design, developments, validation routine analysis, and streamlining processes Operates large data sets, delta data sets and querying efficiently Transforms, joins, and normalizes data in service of specific use cases. Employs AWS data pipeline solutions such as Glue, Data Pipeline, Step functions, MWAA to orchestrate data movement Work with DevSecOps engineer to deploy continuous integration and continuous deployment (CI/CD) data pipelines Understand the technical architecture to design, build, optimize, and maintain scalable data solutions in a Big Data environment Work with Product Owners and/or business stakeholders to gather business requirements and translate to detailed technical specifications US citizen or Authorized to Work and lived in the US for 3 of the last 5 years. Must be able to obtain a U.S. Federal government client badge and pass a government Public Trust. Bachelors degree or higher in IT or relevant discipline required 4+ years of IT experience Experience with setting up and operating data pipelines using Python or SQL Experience with Scala and PySpark 3+ years of experience working on AWS, GCP or Azure (AWS Preferred) cloud platforms Hands-on relational DB / NoSQL experience (PostgreSQL or similar) with specific implementation on cloud Experience working with data warehouses such as Redshift to open source and proprietary cloud data pipeline tools such as Airflow, Glue, Data Pipeline, Step functions Experience working with relational databases that handle structured and semi-structured (JSON) datasets Experience with data serialization languages such as JSON, XML, YAML Experience with code management tools (e.g. Git, SVN) and DevOps tools (e.g. Jenkins, Docker, AWS Code Pipeline) Strong analytical problem-solving ability Working experience with Transactional and Dimensional data modeling methodologies (Eg: Normalization, Star Schema, Snowflake Schema) Experience working with a distributed computing environment like AWS EMR or similar. Ability to obtain Public Trust level clearance Ability to demonstrate excellent written and oral communication required Prior experience with Center for Medicare Medicaid Services or other Govt agencies is a plus The salary range provided represents the estimated compensation for new hires in this position, applicable across all locations. Actual offers may vary based on factors such as the candidate's skills, qualifications, experience, and market conditions. Index complements its base salary offering with a competitive package that includes health and retirement benefits, discretionary bonuses, and reimbursement for professional development opportunities. Index Analytics provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training. Attention Candidates We're dedicated to ensuring a safe and transparent recruitment process for all candidates and have implemented robust measures to protect your personal information. Please be aware that all employment-related communications will originate from a secure portal ( NAME@msg.paycomonline.com ) or a corporate email address ( NAME@index-analytics.com ). If you have any concerns, please don't hesitate to reach out to us at recruiting@index-analytics.com</td><td>524</td></tr><tr><td>null</td><td>#NAME?</td><td>Description: Join our winning team, recently honored as #67 on Forbes’ list of America’s Best Startup Employers for 2024! About The Helper Bees The Helper Bees’ mission is to help people stay home longer through data-driven services that transform both the payer and the care-recipient experience. At The Helper Bees, we are reshaping how care is delivered to aging individuals by leveraging innovative technology and insightful data solutions. We maintain multiple SaaS products and payment solutions through our web applications (internal and external facing), a mobile app, and reporting integrations. As part of our growing Data Engineering team, you’ll iterate quickly, have a high impact, and be challenged to design and implement cutting-edge solutions. At THB, we define our company culture through our Core Values: Quickly iterate through solutions: We move at a fast pace which requires quick iterations to find a path to a repeatable solution. Seek ways to create immediate impact: Be thoughtful and proactive in how you make an impact on your team. Actively look for ways to make a fast, positive impact. Bee the teammate you want to work with: We work as a team, help each other, and encourage each other. Ask questions, answer questions: You can't iterate through solutions if you don't ask the right questions, which is why there is an expectation that questions should be asked. When you know the answer, being a good teammate means chiming in to get others up to speed. Take the time to celebrate wins: It's so easy for a team that is heads down to forget about all the great things they've accomplished. That's why we make it a priority to remind ourselves to create space to celebrate wins, big or small. Job Summary We are seeking a motivated Data Engineer to join our team and help improve our tools, processes, and technical infrastructure. In this role, you will ensure the availability and quality of our data while contributing to the design, implementation, and maintenance of The Helper Bees’ products. You’ll collaborate across teams to create scalable and optimized software systems and play a key role in refining our development processes. This position offers a unique opportunity to learn and leverage cutting-edge AI development tools to enhance coding efficiency and develop advanced data tools and solutions. Supervisory Responsibilities: None Key Responsibilities Data Infrastructure: Design, implement, and maintain data pipelines, ensuring data availability, quality, and scalability. Product Development: Build and enhance products using Python, SQL, and modern technologies. AI Integration: Leverage cutting-edge AI tools, including Cursor, ChatGPT, and Claude to improve development processes, automate workflows, and create innovative data solutions. Collaboration: Communicate across departments to design, build, test, and implement new features and enhancements. Code Excellence: Produce quality, testable, and maintainable code while participating in code reviews. Problem Solving: Debug complex issues, interact with stakeholders, and design viable solutions with clear trade-offs. Process Optimization: Contribute to improving development processes, including deployment, on-call systems, and sprint planning. Team Growth: Collaborate within the development team to help each other grow and continuously learn. Stakeholder Engagement: Partner with analysts, scientists, and IT to ensure alignment and deliver data-driven solutions. Other duties as assigned/necessary Performance Metrics Code Quality: Maintain high coding standards through regular code reviews and adherence to best practices. Development Efficiency: Deliver high-quality features and fixes within efficient timeframes. Bug Resolution Time: Reduce the time taken to identify and resolve issues. System Scalability: Optimize system performance to handle increasing user demands. Collaboration: Foster a collaborative environment that encourages teamwork and knowledge sharing. Customer Satisfaction: Incorporate stakeholder feedback to improve solutions and enhance the customer experience. Continuous Learning: Pursue opportunities for skill development and share knowledge with the team. Requirements: Required Skills & Qualifications Technical Tools: Experience with in Python and/or SQL. Experience with Bash, Shell scripting, Big Query, Airflow, and is a plus. Programming: Cleaning data using code-based approach. AI Proficiency: Interest or experience in using AI tools for coding and development of data solutions. Soft Skills: Problem-solving, cross-team collaboration, data storytelling, and stakeholder engagement. Adaptability: Thrives in a fast-paced startup environment and embraces change. Proactivity: Self-directed, organized, and able to prioritize effectively. Collaboration: Ability to work effectively with cross-functional teams. Education & Experience: A bachelor’s degree is required, and a graduate degree is preferred. Relevant experience in data engineering, software development, STEM, or related fields. Strong experience with SQL and Python is highly desirable. Mindset: A passion for innovation, continuous improvement, and delivering high-quality results from messy data. Preferred Qualifications Familiarity with cloud-based solutions (e.g., Google Cloud Platform, Azure). Experience with ETL processes and tools. Experience building data visualization reports and dashboards Knowledge of modern data storage solutions and database management systems. Exposure to DevOps practices and tools for deployment and monitoring. Why Join Us? Work with a talented, collaborative team dedicated to making a difference. Gain exposure to innovative technologies and opportunities for growth. Learn and utilize cutting-edge AI tools to enhance your development skills and create impactful solutions. Be part of a company that values your contributions and encourages professional development. Join a rapidly expanding health-tech startup (~200 employees and growing) with a state-of-the-art technology office located in Hyde Park, offering a variety of exceptional benefits. Career Progression Timeline In 3 months: Gain a comprehensive understanding of our data infrastructure, technical stacks, and development cycles. Actively participate in team meetings and contribute to the development of new data pipelines. Begin leveraging AI tools, such as Cursor and ChatGPT, to enhance coding efficiency and workflow automation. In 6 months: Contribute to product enhancements and data reporting Collaborate effectively with cross-functional teams, providing insights and solutions for data-related challenges. Demonstrate proficiency in utilizing AI tools for coding and development, actively sharing knowledge with the team. In 12 months: Contribute to data engineering projects, ensuring scalability and performance optimization. Mentor non-technical internal partners to improve company-wide data literacy Contribute to the integration of advanced AI solutions into our development processes, contributing to the company's technological advancement. Physical Requirements: Ability to remain at your designated workstation for the duration of the workday Constantly operates a computer and other office productivity machinery, such as a phone and Voice over Internet Protocol (VoIP). The ability to communicate information and ideas so others will understand. Must be able to exchange accurate information in these situations. The ability to observe details at close range (typically on a computer screen) This position offers the flexibility of remote work at approved locations within the United States. Candidates must have a reliable internet connection and a designated work environment conducive to professional phone calls and sensitive data. Enjoy the convenience and comfort of working remotely while contributing to our team's success. Apply Today If you’re ready to take on challenging problems, contribute to impactful solutions, and grow as a data engineer, we’d love to hear from you. Join us at The Helper Bees and be part of a team that’s making a meaningful difference every day! The Helper Bees is committed to building a workplace where diversity, equity, and inclusion are valued and prioritized. We are an equal opportunity employer that welcomes all qualified applicants without discrimination based on race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or any non-merit based or legally protected grounds. The Helper Bees provides reasonable accommodations to qualified individuals with disabilities during the job application and interview process. To request accommodation, please let your recruiter know. As part of our standard hiring process, selected candidates may be required to undergo a background check and/or drug screen. The Helper Bees adheres to applicable federal, state, and local laws regarding these screenings, and the results will be considered in accordance with applicable regulations. The Helper Bees was recently made aware of a fraudulent entity posing as our organization and requesting personal information. Please be aware of and protect yourself from scams. Visit thehelperbees.com/careers to view all current job openings. Opened URL: https://www.indeed.com/rc/clk?jk=06050d41e9f16407&bb=1TLRjqutBEYcit1OApAPto3A50Hg4Pzq5qFUF25sU891HTb0FMRKF-y31Tt72Rgj3vRHASDwe2nU2bKOyor677T1mfz6aMuuBmnum2LV6DDSRY1DGNuI6LNVrSB8DuSr&xkcb=SoDU67M33zDWevR-pR0JbzkdCdPP&fccid=61e4e7d2ce056d37&vjs=3</td><td>data</td><td>Description: Join our winning team, recently honored as #67 on Forbes’ list of America’s Best Startup Employers for 2024! About The Helper Bees The Helper Bees’ mission is to help people stay home longer through data-driven services that transform both the payer and the care-recipient experience. At The Helper Bees, we are reshaping how care is delivered to aging individuals by leveraging innovative technology and insightful data solutions. We maintain multiple SaaS products and payment solutions through our web applications (internal and external facing), a mobile app, and reporting integrations. As part of our growing Data Engineering team, you’ll iterate quickly, have a high impact, and be challenged to design and implement cutting-edge solutions. At THB, we define our company culture through our Core Values: Quickly iterate through solutions: We move at a fast pace which requires quick iterations to find a path to a repeatable solution. Seek ways to create immediate impact: Be thoughtful and proactive in how you make an impact on your team. Actively look for ways to make a fast, positive impact. Bee the teammate you want to work with: We work as a team, help each other, and encourage each other. Ask questions, answer questions: You can't iterate through solutions if you don't ask the right questions, which is why there is an expectation that questions should be asked. When you know the answer, being a good teammate means chiming in to get others up to speed. Take the time to celebrate wins: It's so easy for a team that is heads down to forget about all the great things they've accomplished. That's why we make it a priority to remind ourselves to create space to celebrate wins, big or small. Job Summary We are seeking a motivated Data Engineer to join our team and help improve our tools, processes, and technical infrastructure. In this role, you will ensure the availability and quality of our data while contributing to the design, implementation, and maintenance of The Helper Bees’ products. You’ll collaborate across teams to create scalable and optimized software systems and play a key role in refining our development processes. This position offers a unique opportunity to learn and leverage cutting-edge AI development tools to enhance coding efficiency and develop advanced data tools and solutions. Supervisory Responsibilities: None Key Responsibilities Data Infrastructure: Design, implement, and maintain data pipelines, ensuring data availability, quality, and scalability. Product Development: Build and enhance products using Python, SQL, and modern technologies. AI Integration: Leverage cutting-edge AI tools, including Cursor, ChatGPT, and Claude to improve development processes, automate workflows, and create innovative data solutions. Collaboration: Communicate across departments to design, build, test, and implement new features and enhancements. Code Excellence: Produce quality, testable, and maintainable code while participating in code reviews. Problem Solving: Debug complex issues, interact with stakeholders, and design viable solutions with clear trade-offs. Process Optimization: Contribute to improving development processes, including deployment, on-call systems, and sprint planning. Team Growth: Collaborate within the development team to help each other grow and continuously learn. Stakeholder Engagement: Partner with analysts, scientists, and IT to ensure alignment and deliver data-driven solutions. Other duties as assigned/necessary Performance Metrics Code Quality: Maintain high coding standards through regular code reviews and adherence to best practices. Development Efficiency: Deliver high-quality features and fixes within efficient timeframes. Bug Resolution Time: Reduce the time taken to identify and resolve issues. System Scalability: Optimize system performance to handle increasing user demands. Collaboration: Foster a collaborative environment that encourages teamwork and knowledge sharing. Customer Satisfaction: Incorporate stakeholder feedback to improve solutions and enhance the customer experience. Continuous Learning: Pursue opportunities for skill development and share knowledge with the team. Requirements: Required Skills & Qualifications Technical Tools: Experience with in Python and/or SQL. Experience with Bash, Shell scripting, Big Query, Airflow, and is a plus. Programming: Cleaning data using code-based approach. AI Proficiency: Interest or experience in using AI tools for coding and development of data solutions. Soft Skills: Problem-solving, cross-team collaboration, data storytelling, and stakeholder engagement. Adaptability: Thrives in a fast-paced startup environment and embraces change. Proactivity: Self-directed, organized, and able to prioritize effectively. Collaboration: Ability to work effectively with cross-functional teams. Education & Experience: A bachelor’s degree is required, and a graduate degree is preferred. Relevant experience in data engineering, software development, STEM, or related fields. Strong experience with SQL and Python is highly desirable. Mindset: A passion for innovation, continuous improvement, and delivering high-quality results from messy data. Preferred Qualifications Familiarity with cloud-based solutions (e.g., Google Cloud Platform, Azure). Experience with ETL processes and tools. Experience building data visualization reports and dashboards Knowledge of modern data storage solutions and database management systems. Exposure to DevOps practices and tools for deployment and monitoring. Why Join Us? Work with a talented, collaborative team dedicated to making a difference. Gain exposure to innovative technologies and opportunities for growth. Learn and utilize cutting-edge AI tools to enhance your development skills and create impactful solutions. Be part of a company that values your contributions and encourages professional development. Join a rapidly expanding health-tech startup (~200 employees and growing) with a state-of-the-art technology office located in Hyde Park, offering a variety of exceptional benefits. Career Progression Timeline In 3 months: Gain a comprehensive understanding of our data infrastructure, technical stacks, and development cycles. Actively participate in team meetings and contribute to the development of new data pipelines. Begin leveraging AI tools, such as Cursor and ChatGPT, to enhance coding efficiency and workflow automation. In 6 months: Contribute to product enhancements and data reporting Collaborate effectively with cross-functional teams, providing insights and solutions for data-related challenges. Demonstrate proficiency in utilizing AI tools for coding and development, actively sharing knowledge with the team. In 12 months: Contribute to data engineering projects, ensuring scalability and performance optimization. Mentor non-technical internal partners to improve company-wide data literacy Contribute to the integration of advanced AI solutions into our development processes, contributing to the company's technological advancement. Physical Requirements: Ability to remain at your designated workstation for the duration of the workday Constantly operates a computer and other office productivity machinery, such as a phone and Voice over Internet Protocol (VoIP). The ability to communicate information and ideas so others will understand. Must be able to exchange accurate information in these situations. The ability to observe details at close range (typically on a computer screen) This position offers the flexibility of remote work at approved locations within the United States. Candidates must have a reliable internet connection and a designated work environment conducive to professional phone calls and sensitive data. Enjoy the convenience and comfort of working remotely while contributing to our team's success. Apply Today If you’re ready to take on challenging problems, contribute to impactful solutions, and grow as a data engineer, we’d love to hear from you. Join us at The Helper Bees and be part of a team that’s making a meaningful difference every day! The Helper Bees is committed to building a workplace where diversity, equity, and inclusion are valued and prioritized. We are an equal opportunity employer that welcomes all qualified applicants without discrimination based on race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or any non-merit based or legally protected grounds. The Helper Bees provides reasonable accommodations to qualified individuals with disabilities during the job application and interview process. To request accommodation, please let your recruiter know. As part of our standard hiring process, selected candidates may be required to undergo a background check and/or drug screen. The Helper Bees adheres to applicable federal, state, and local laws regarding these screenings, and the results will be considered in accordance with applicable regulations. The Helper Bees was recently made aware of a fraudulent entity posing as our organization and requesting personal information. Please be aware of and protect yourself from scams. Visit thehelperbees.com/careers to view all current job openings.</td><td>Description: Join our winning team, recently honored as #67 on Forbes’ list of America’s Best Startup Employers for 2024! About The Helper Bees The Helper Bees’ mission is to help people stay home longer through data-driven services that transform both the payer and the care-recipient experience. At The Helper Bees, we are reshaping how care is delivered to aging individuals by leveraging innovative technology and insightful data solutions. We maintain multiple SaaS products and payment solutions through our web applications (internal and external facing), a mobile app, and reporting integrations. As part of our growing Data Engineering team, you’ll iterate quickly, have a high impact, and be challenged to design and implement cutting-edge solutions. At THB, we define our company culture through our Core Values: Quickly iterate through solutions: We move at a fast pace which requires quick iterations to find a path to a repeatable solution. Seek ways to create immediate impact: Be thoughtful and proactive in how you make an impact on your team. Actively look for ways to make a fast, positive impact. Bee the teammate you want to work with: We work as a team, help each other, and encourage each other. Ask questions, answer questions: You can't iterate through solutions if you don't ask the right questions, which is why there is an expectation that questions should be asked. When you know the answer, being a good teammate means chiming in to get others up to speed. Take the time to celebrate wins: It's so easy for a team that is heads down to forget about all the great things they've accomplished. That's why we make it a priority to remind ourselves to create space to celebrate wins, big or small. Job Summary We are seeking a motivated Data Engineer to join our team and help improve our tools, processes, and technical infrastructure. In this role, you will ensure the availability and quality of our data while contributing to the design, implementation, and maintenance of The Helper Bees’ products. You’ll collaborate across teams to create scalable and optimized software systems and play a key role in refining our development processes. This position offers a unique opportunity to learn and leverage cutting-edge AI development tools to enhance coding efficiency and develop advanced data tools and solutions. Supervisory Responsibilities: None Key Responsibilities Data Infrastructure: Design, implement, and maintain data pipelines, ensuring data availability, quality, and scalability. Product Development: Build and enhance products using Python, SQL, and modern technologies. AI Integration: Leverage cutting-edge AI tools, including Cursor, ChatGPT, and Claude to improve development processes, automate workflows, and create innovative data solutions. Collaboration: Communicate across departments to design, build, test, and implement new features and enhancements. Code Excellence: Produce quality, testable, and maintainable code while participating in code reviews. Problem Solving: Debug complex issues, interact with stakeholders, and design viable solutions with clear trade-offs. Process Optimization: Contribute to improving development processes, including deployment, on-call systems, and sprint planning. Team Growth: Collaborate within the development team to help each other grow and continuously learn. Stakeholder Engagement: Partner with analysts, scientists, and IT to ensure alignment and deliver data-driven solutions. Other duties as assigned/necessary Performance Metrics Code Quality: Maintain high coding standards through regular code reviews and adherence to best practices. Development Efficiency: Deliver high-quality features and fixes within efficient timeframes. Bug Resolution Time: Reduce the time taken to identify and resolve issues. System Scalability: Optimize system performance to handle increasing user demands. Collaboration: Foster a collaborative environment that encourages teamwork and knowledge sharing. Customer Satisfaction: Incorporate stakeholder feedback to improve solutions and enhance the customer experience. Continuous Learning: Pursue opportunities for skill development and share knowledge with the team. Requirements: Required Skills & Qualifications Technical Tools: Experience with in Python and/or SQL. Experience with Bash, Shell scripting, Big Query, Airflow, and is a plus. Programming: Cleaning data using code-based approach. AI Proficiency: Interest or experience in using AI tools for coding and development of data solutions. Soft Skills: Problem-solving, cross-team collaboration, data storytelling, and stakeholder engagement. Adaptability: Thrives in a fast-paced startup environment and embraces change. Proactivity: Self-directed, organized, and able to prioritize effectively. Collaboration: Ability to work effectively with cross-functional teams. Education & Experience: A bachelor’s degree is required, and a graduate degree is preferred. Relevant experience in data engineering, software development, STEM, or related fields. Strong experience with SQL and Python is highly desirable. Mindset: A passion for innovation, continuous improvement, and delivering high-quality results from messy data. Preferred Qualifications Familiarity with cloud-based solutions (e.g., Google Cloud Platform, Azure). Experience with ETL processes and tools. Experience building data visualization reports and dashboards Knowledge of modern data storage solutions and database management systems. Exposure to DevOps practices and tools for deployment and monitoring. Why Join Us? Work with a talented, collaborative team dedicated to making a difference. Gain exposure to innovative technologies and opportunities for growth. Learn and utilize cutting-edge AI tools to enhance your development skills and create impactful solutions. Be part of a company that values your contributions and encourages professional development. Join a rapidly expanding health-tech startup (~200 employees and growing) with a state-of-the-art technology office located in Hyde Park, offering a variety of exceptional benefits. Career Progression Timeline In 3 months: Gain a comprehensive understanding of our data infrastructure, technical stacks, and development cycles. Actively participate in team meetings and contribute to the development of new data pipelines. Begin leveraging AI tools, such as Cursor and ChatGPT, to enhance coding efficiency and workflow automation. In 6 months: Contribute to product enhancements and data reporting Collaborate effectively with cross-functional teams, providing insights and solutions for data-related challenges. Demonstrate proficiency in utilizing AI tools for coding and development, actively sharing knowledge with the team. In 12 months: Contribute to data engineering projects, ensuring scalability and performance optimization. Mentor non-technical internal partners to improve company-wide data literacy Contribute to the integration of advanced AI solutions into our development processes, contributing to the company's technological advancement. Physical Requirements: Ability to remain at your designated workstation for the duration of the workday Constantly operates a computer and other office productivity machinery, such as a phone and Voice over Internet Protocol (VoIP). The ability to communicate information and ideas so others will understand. Must be able to exchange accurate information in these situations. The ability to observe details at close range (typically on a computer screen) This position offers the flexibility of remote work at approved locations within the United States. Candidates must have a reliable internet connection and a designated work environment conducive to professional phone calls and sensitive data. Enjoy the convenience and comfort of working remotely while contributing to our team's success. Apply Today If you’re ready to take on challenging problems, contribute to impactful solutions, and grow as a data engineer, we’d love to hear from you. Join us at The Helper Bees and be part of a team that’s making a meaningful difference every day! The Helper Bees is committed to building a workplace where diversity, equity, and inclusion are valued and prioritized. We are an equal opportunity employer that welcomes all qualified applicants without discrimination based on race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or any non-merit based or legally protected grounds. The Helper Bees provides reasonable accommodations to qualified individuals with disabilities during the job application and interview process. To request accommodation, please let your recruiter know. As part of our standard hiring process, selected candidates may be required to undergo a background check and/or drug screen. The Helper Bees adheres to applicable federal, state, and local laws regarding these screenings, and the results will be considered in accordance with applicable regulations. The Helper Bees was recently made aware of a fraudulent entity posing as our organization and requesting personal information. Please be aware of and protect yourself from scams. Visit thehelperbees.com/careers to view all current job openings.</td><td>Technical Tools: Experience with in Python and/or SQL. Experience with Bash, Shell scripting, Big Query, Airflow, and is a plus. Programming: Cleaning data using code-based approach. AI Proficiency: Interest or experience in using AI tools for coding and development of data solutions. Soft Skills: Problem-solving, cross-team collaboration, data storytelling, and stakeholder engagement. Adaptability: Thrives in a fast-paced startup environment and embraces change. Proactivity: Self-directed, organized, and able to prioritize effectively. Collaboration: Ability to work effectively with cross-functional teams. Education & Experience: A bachelor’s degree is required, and a graduate degree is preferred. Relevant experience in data engineering, software development, STEM, or related fields. Strong experience with SQL and Python is highly desirable. Mindset: A passion for innovation, continuous improvement, and delivering high-quality results from messy data. Preferred Qualifications Familiarity with cloud-based solutions (e.g., Google Cloud Platform, Azure). Experience with ETL processes and tools. Experience building data visualization reports and dashboards Knowledge of modern data storage solutions and database management systems. Exposure to DevOps practices and tools for deployment and monitoring. Why Join Us? Work with a talented, collaborative team dedicated to making a difference. Gain exposure to innovative technologies and opportunities for growth. Learn and utilize cutting-edge AI tools to enhance your development skills and create impactful solutions. Be part of a company that values your contributions and encourages professional development. Join a rapidly expanding health-tech startup (~200 employees and growing) with a state-of-the-art technology office located in Hyde Park, offering a variety of exceptional benefits. Career Progression Timeline In 3 months: Gain a comprehensive understanding of our data infrastructure, technical stacks, and development cycles. Actively participate in team meetings and contribute to the development of new data pipelines. Begin leveraging AI tools, such as Cursor and ChatGPT, to enhance coding efficiency and workflow automation. In 6 months: Contribute to product enhancements and data reporting Collaborate effectively with cross-functional teams, providing insights and solutions for data-related challenges. Demonstrate proficiency in utilizing AI tools for coding and development, actively sharing knowledge with the team. In 12 months: Contribute to data engineering projects, ensuring scalability and performance optimization. Mentor non-technical internal partners to improve company-wide data literacy Contribute to the integration of advanced AI solutions into our development processes, contributing to the company's technological advancement. Physical Requirements: Ability to remain at your designated workstation for the duration of the workday Constantly operates a computer and other office productivity machinery, such as a phone and Voice over Internet Protocol (VoIP). The ability to communicate information and ideas so others will understand. Must be able to exchange accurate information in these situations. The ability to observe details at close range (typically on a computer screen) This position offers the flexibility of remote work at approved locations within the United States. Candidates must have a reliable internet connection and a designated work environment conducive to professional phone calls and sensitive data. Enjoy the convenience and comfort of working remotely while contributing to our team's success. Apply Today If you’re ready to take on challenging problems, contribute to impactful solutions, and grow as a data engineer, we’d love to hear from you. Join us at The Helper Bees and be part of a team that’s making a meaningful difference every day! The Helper Bees is committed to building a workplace where diversity, equity, and inclusion are valued and prioritized. We are an equal opportunity employer that welcomes all qualified applicants without discrimination based on race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or any non-merit based or legally protected grounds. The Helper Bees provides reasonable accommodations to qualified individuals with disabilities during the job application and interview process. To request accommodation, please let your recruiter know. As part of our standard hiring process, selected candidates may be required to undergo a background check and/or drug screen. The Helper Bees adheres to applicable federal, state, and local laws regarding these screenings, and the results will be considered in accordance with applicable regulations. The Helper Bees was recently made aware of a fraudulent entity posing as our organization and requesting personal information. Please be aware of and protect yourself from scams. Visit thehelperbees.com/careers to view all current job openings.</td><td>698</td></tr><tr><td>null</td><td>experience</td><td>SUMMARY: ABOUT Healthcare is seeking a skilled and innovative Data Scientist to help expand our predictive analytics capabilities and advance our mission to revolutionize hospital operations. This role will work at the intersection of AI/ML, healthcare, and operations to develop and scale machine learning models that deliver actionable insights to hospitals. ESSENTIAL FUNCTIONS : This class specification lists the major duties and requirements of the job and is not all-inclusive. Incumbent(s) may be expected to perform job-related duties other than those contained in this document and may be required to have specific job-related knowledge and skills. Predictive Analytics Development : Build and refine machine learning models for hourly discharge forecasting, aggregate hospital admission/discharge predictions, and patient-level progress tracking. Data Exploration : Analyze complex healthcare datasets to identify trends, challenges, and actionable opportunities. Model Deployment : Collaborate with engineers to deploy AI/ML solutions into production, ensuring reliability and scalability. Collaboration : Partner with product managers, operations teams, and customers to define and implement data-driven features and metrics. Feature Engineering : Work with AWS infrastructure (S3, Glue, Athena, Timestream, Bedrock, Nova, SageMaker) to standardize data pipelines and enrich machine learning models. Continuous Improvement : Optimize model accuracy and efficiency through testing, monitoring, and iteration. Documentation and Communication : Present technical findings and recommendations to stakeholders in an easily understandable way. LLMs: Demonstrate experience and depth in building products through applying LLMs or other AI domains like NLP, ML or deep learning. Full Stack: Capable as a full-stack engineer, seeing LLM implementations from concept to production. Perform other duties as assigned. QUALIFICATIONS: To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The requirements listed below are representative of the knowledge, skill, and/or ability required. Need to Have: Bachelor’s in data science, Computer Science, Statistics, or related field (or equivalent experience). 1+ years of experience developing and deploying machine learning models in production. Proficiency in Python (or R), SQL, and common ML libraries (e.g., Scikit-learn, TensorFlow, PyTorch). Experience working with cloud technologies, particularly AWS (e.g., S3, Glue, Timestream, Bedrock, Nova, sageMaker). Strong analytical skills and ability to interpret complex datasets. Knowledge of ETL processes, feature engineering, and real-time forecasting methods. Excellent communication skills with the ability to present technical concepts to non-technical stakeholders. Nice to Have: Experience in healthcare data analytics or hospital operations. Familiarity with EHR/EMR data or healthcare interoperability standards. Knowledge of time-series modeling and ensemble methods. Exposure to data visualization tools (e.g., Tableau, Power BI). Understanding of Agile methodologies and collaborative software development. Required Knowledge and Skills Required Knowledge: Correct business English, including spelling, grammar and punctuation. Medical Terminology Health system operating and working models Business planning and development Required Skills: Using initiative and independent judgment within established department guidelines. Contributing effectively to the accomplishment of team or work unit goals, objectives and activities. Establishing and maintaining effective working relationships with a variety of individuals. PHYSICAL/MENTAL REQUIREMENTS: The physical demands described herein are representative of those that must be met by an employee to successfully perform the essential functions of the job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions. Mobility to work in an office setting, use standard office equipment and stamina to sit for extended periods of time; strength to lift and carry up to 10 pounds; vision to read printed materials and computer screens; and hearing and speech to communicate in person or over the telephone. Travel as needed to support company and customer initiatives. Work on Site at our St Paul office may be required and ABOUT reserves the right to change the location of the role at any time. This role may involve work on federal government contracts that require additional federal background investigations, training, and federal badging. As such, you may be required to submit personal information to the government and be fingerprinted and photographed at your local Department of Veteran Affairs Medical Center. ABOUT is also an Equal Employment Opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, age, national origin, protected veteran status, disability status, sexual orientation, gender identity or expression, marital status, genetic information, or any other characteristic protected by law. ABOUT offers a flexible, purpose-built solution that empowers hospitals and health systems to operate as one connected network of care. We enable easy access for clinicians to move patients into and out of the acute care setting - getting them to the next, best care setting faster and easier. Complemented by our clinical experts and best practices, we provide health systems the necessary controls and insights to grow with resilience, drive clinician effectiveness, and improve patient outcomes. __________________________________________________________________________________________________________________________________ Opened URL: https://www.indeed.com/rc/clk?jk=b7ccd9fcd1afced7&bb=1TLRjqutBEYcit1OApAPtqrHYylbIkCH-hjMPAlsxl27fhhbmpR2ESoGFPzZ8_yAHfmXJJR-sxCiyJrJbrdNtoLq2VLDYGJB8eFEb_NompMj9I3HutPP1GvnnhForEvK&xkcb=SoAu67M33zDWevR-pR0CbzkdCdPP&fccid=4a4b722c7189c738&vjs=3</td><td>data</td><td>SUMMARY: ABOUT Healthcare is seeking a skilled and innovative Data Scientist to help expand our predictive analytics capabilities and advance our mission to revolutionize hospital operations. This role will work at the intersection of AI/ML, healthcare, and operations to develop and scale machine learning models that deliver actionable insights to hospitals. ESSENTIAL FUNCTIONS : This class specification lists the major duties and requirements of the job and is not all-inclusive. Incumbent(s) may be expected to perform job-related duties other than those contained in this document and may be required to have specific job-related knowledge and skills. Predictive Analytics Development : Build and refine machine learning models for hourly discharge forecasting, aggregate hospital admission/discharge predictions, and patient-level progress tracking. Data Exploration : Analyze complex healthcare datasets to identify trends, challenges, and actionable opportunities. Model Deployment : Collaborate with engineers to deploy AI/ML solutions into production, ensuring reliability and scalability. Collaboration : Partner with product managers, operations teams, and customers to define and implement data-driven features and metrics. Feature Engineering : Work with AWS infrastructure (S3, Glue, Athena, Timestream, Bedrock, Nova, SageMaker) to standardize data pipelines and enrich machine learning models. Continuous Improvement : Optimize model accuracy and efficiency through testing, monitoring, and iteration. Documentation and Communication : Present technical findings and recommendations to stakeholders in an easily understandable way. LLMs: Demonstrate experience and depth in building products through applying LLMs or other AI domains like NLP, ML or deep learning. Full Stack: Capable as a full-stack engineer, seeing LLM implementations from concept to production. Perform other duties as assigned. QUALIFICATIONS: To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The requirements listed below are representative of the knowledge, skill, and/or ability required. Need to Have: Bachelor’s in data science, Computer Science, Statistics, or related field (or equivalent experience). 1+ years of experience developing and deploying machine learning models in production. Proficiency in Python (or R), SQL, and common ML libraries (e.g., Scikit-learn, TensorFlow, PyTorch). Experience working with cloud technologies, particularly AWS (e.g., S3, Glue, Timestream, Bedrock, Nova, sageMaker). Strong analytical skills and ability to interpret complex datasets. Knowledge of ETL processes, feature engineering, and real-time forecasting methods. Excellent communication skills with the ability to present technical concepts to non-technical stakeholders. Nice to Have: Experience in healthcare data analytics or hospital operations. Familiarity with EHR/EMR data or healthcare interoperability standards. Knowledge of time-series modeling and ensemble methods. Exposure to data visualization tools (e.g., Tableau, Power BI). Understanding of Agile methodologies and collaborative software development. Required Knowledge and Skills Required Knowledge: Correct business English, including spelling, grammar and punctuation. Medical Terminology Health system operating and working models Business planning and development Required Skills: Using initiative and independent judgment within established department guidelines. Contributing effectively to the accomplishment of team or work unit goals, objectives and activities. Establishing and maintaining effective working relationships with a variety of individuals. PHYSICAL/MENTAL REQUIREMENTS: The physical demands described herein are representative of those that must be met by an employee to successfully perform the essential functions of the job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions. Mobility to work in an office setting, use standard office equipment and stamina to sit for extended periods of time; strength to lift and carry up to 10 pounds; vision to read printed materials and computer screens; and hearing and speech to communicate in person or over the telephone. Travel as needed to support company and customer initiatives. Work on Site at our St Paul office may be required and ABOUT reserves the right to change the location of the role at any time. This role may involve work on federal government contracts that require additional federal background investigations, training, and federal badging. As such, you may be required to submit personal information to the government and be fingerprinted and photographed at your local Department of Veteran Affairs Medical Center. ABOUT is also an Equal Employment Opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, age, national origin, protected veteran status, disability status, sexual orientation, gender identity or expression, marital status, genetic information, or any other characteristic protected by law. ABOUT offers a flexible, purpose-built solution that empowers hospitals and health systems to operate as one connected network of care. We enable easy access for clinicians to move patients into and out of the acute care setting - getting them to the next, best care setting faster and easier. Complemented by our clinical experts and best practices, we provide health systems the necessary controls and insights to grow with resilience, drive clinician effectiveness, and improve patient outcomes. __________________________________________________________________________________________________________________________________</td><td>SUMMARY: ABOUT Healthcare is seeking a skilled and innovative Data Scientist to help expand our predictive analytics capabilities and advance our mission to revolutionize hospital operations. This role will work at the intersection of AI/ML, healthcare, and operations to develop and scale machine learning models that deliver actionable insights to hospitals. ESSENTIAL FUNCTIONS : This class specification lists the major duties and requirements of the job and is not all-inclusive. Incumbent(s) may be expected to perform job-related duties other than those contained in this document and may be required to have specific job-related knowledge and skills. Predictive Analytics Development : Build and refine machine learning models for hourly discharge forecasting, aggregate hospital admission/discharge predictions, and patient-level progress tracking. Data Exploration : Analyze complex healthcare datasets to identify trends, challenges, and actionable opportunities. Model Deployment : Collaborate with engineers to deploy AI/ML solutions into production, ensuring reliability and scalability. Collaboration : Partner with product managers, operations teams, and customers to define and implement data-driven features and metrics. Feature Engineering : Work with AWS infrastructure (S3, Glue, Athena, Timestream, Bedrock, Nova, SageMaker) to standardize data pipelines and enrich machine learning models. Continuous Improvement : Optimize model accuracy and efficiency through testing, monitoring, and iteration. Documentation and Communication : Present technical findings and recommendations to stakeholders in an easily understandable way. LLMs: Demonstrate experience and depth in building products through applying LLMs or other AI domains like NLP, ML or deep learning. Full Stack: Capable as a full-stack engineer, seeing LLM implementations from concept to production. Perform other duties as assigned. QUALIFICATIONS: To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The requirements listed below are representative of the knowledge, skill, and/or ability required. Need to Have: Bachelor’s in data science, Computer Science, Statistics, or related field (or equivalent experience). 1+ years of experience developing and deploying machine learning models in production. Proficiency in Python (or R), SQL, and common ML libraries (e.g., Scikit-learn, TensorFlow, PyTorch). Experience working with cloud technologies, particularly AWS (e.g., S3, Glue, Timestream, Bedrock, Nova, sageMaker). Strong analytical skills and ability to interpret complex datasets. Knowledge of ETL processes, feature engineering, and real-time forecasting methods. Excellent communication skills with the ability to present technical concepts to non-technical stakeholders. Nice to Have: Experience in healthcare data analytics or hospital operations. Familiarity with EHR/EMR data or healthcare interoperability standards. Knowledge of time-series modeling and ensemble methods. Exposure to data visualization tools (e.g., Tableau, Power BI). Understanding of Agile methodologies and collaborative software development. Required Knowledge and Skills Required Knowledge: Correct business English, including spelling, grammar and punctuation. Medical Terminology Health system operating and working models Business planning and development Required Skills: Using initiative and independent judgment within established department guidelines. Contributing effectively to the accomplishment of team or work unit goals, objectives and activities. Establishing and maintaining effective working relationships with a variety of individuals. PHYSICAL/MENTAL REQUIREMENTS: The physical demands described herein are representative of those that must be met by an employee to successfully perform the essential functions of the job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions. Mobility to work in an office setting, use standard office equipment and stamina to sit for extended periods of time; strength to lift and carry up to 10 pounds; vision to read printed materials and computer screens; and hearing and speech to communicate in person or over the telephone. Travel as needed to support company and customer initiatives. Work on Site at our St Paul office may be required and ABOUT reserves the right to change the location of the role at any time. This role may involve work on federal government contracts that require additional federal background investigations, training, and federal badging. As such, you may be required to submit personal information to the government and be fingerprinted and photographed at your local Department of Veteran Affairs Medical Center. ABOUT is also an Equal Employment Opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, age, national origin, protected veteran status, disability status, sexual orientation, gender identity or expression, marital status, genetic information, or any other characteristic protected by law. ABOUT offers a flexible, purpose-built solution that empowers hospitals and health systems to operate as one connected network of care. We enable easy access for clinicians to move patients into and out of the acute care setting - getting them to the next, best care setting faster and easier. Complemented by our clinical experts and best practices, we provide health systems the necessary controls and insights to grow with resilience, drive clinician effectiveness, and improve patient outcomes. __________________________________________________________________________________________________________________________________</td><td>To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The requirements listed below are representative of the knowledge, skill, and/or ability required. Need to Have: Bachelor’s in data science, Computer Science, Statistics, or related field (or equivalent experience). 1+ years of experience developing and deploying machine learning models in production. Proficiency in Python (or R), SQL, and common ML libraries (e.g., Scikit-learn, TensorFlow, PyTorch). Experience working with cloud technologies, particularly AWS (e.g., S3, Glue, Timestream, Bedrock, Nova, sageMaker). Strong analytical skills and ability to interpret complex datasets. Knowledge of ETL processes, feature engineering, and real-time forecasting methods. Excellent communication skills with the ability to present technical concepts to non-technical stakeholders. Nice to Have: Experience in healthcare data analytics or hospital operations. Familiarity with EHR/EMR data or healthcare interoperability standards. Knowledge of time-series modeling and ensemble methods. Exposure to data visualization tools (e.g., Tableau, Power BI). Understanding of Agile methodologies and collaborative software development. Required Knowledge and Skills Required Knowledge: Correct business English, including spelling, grammar and punctuation. Medical Terminology Health system operating and working models Business planning and development Required Skills: Using initiative and independent judgment within established department guidelines. Contributing effectively to the accomplishment of team or work unit goals, objectives and activities. Establishing and maintaining effective working relationships with a variety of individuals. PHYSICAL/MENTAL REQUIREMENTS: The physical demands described herein are representative of those that must be met by an employee to successfully perform the essential functions of the job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions. Mobility to work in an office setting, use standard office equipment and stamina to sit for extended periods of time; strength to lift and carry up to 10 pounds; vision to read printed materials and computer screens; and hearing and speech to communicate in person or over the telephone. Travel as needed to support company and customer initiatives. Work on Site at our St Paul office may be required and ABOUT reserves the right to change the location of the role at any time. This role may involve work on federal government contracts that require additional federal background investigations, training, and federal badging. As such, you may be required to submit personal information to the government and be fingerprinted and photographed at your local Department of Veteran Affairs Medical Center. ABOUT is also an Equal Employment Opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, age, national origin, protected veteran status, disability status, sexual orientation, gender identity or expression, marital status, genetic information, or any other characteristic protected by law. ABOUT offers a flexible, purpose-built solution that empowers hospitals and health systems to operate as one connected network of care. We enable easy access for clinicians to move patients into and out of the acute care setting - getting them to the next, best care setting faster and easier. Complemented by our clinical experts and best practices, we provide health systems the necessary controls and insights to grow with resilience, drive clinician effectiveness, and improve patient outcomes. __________________________________________________________________________________________________________________________________</td><td>521</td></tr><tr><td>null</td><td>.</td><td>The Krusteaz Company is seeking a Senior Data Engineer to lead the architecture and development of our enterprise data strategy. Reporting to the Director of Enterprise Applications and Data Management, this role will play a key role in design, delivery, and management of our enterprise data strategy and solution(s). As a key contributor to our digital transformation, this role will take the lead in designing data structure, design, and ingestion, reporting processes and standards for the organization working across both the IT development, infrastructure, and analyst teams. As a senior member of the IT team, this role will be instrumental in promoting agility, scalability, and operational excellence. This role will also be a key contributor in our business transformation, working closely with our IT Business Analysts to understand the challenges facing our business partners and developing scalable and repeatable data solutions to meet their needs. This role will be a trusted partner to your peers within the IT team, demonstrating the ability to provide both conceptual and technical mentorship. Essential Functions : Other duties, responsibilities, and activities may change or be assigned at any time. Maintain and build on our data warehouse and analytics environment. Design, implement, test, deploy, and maintain stable, secure, and scalable data engineering solutions and pipelines. Build reports and data visualizations, using data from the data warehouse and other sources. Produce scalable, replicable code and engineering solutions that help automate repetitive data management tasks. Implement and monitor best in class security measures in our data warehouse and analytics environment. Provide direct input on the IT technology roadmap, helping ensure we make appropriate investments in build vs. buy decisions. Define and document best practices and strategies. Keep apprised of trends, identifies best-in class capabilities, opportunities and technology that may benefit The Krusteaz Company. Provide guidance, thought leadership, and mentorship to development and infrastructure teams to build EDW and development competencies. Position Requirements To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The requirements listed below are representative of the knowledge, skill, and/or ability required. Reasonable accommodations may be made to enable individuals qualified with disabilities to perform the essential functions. Proven success in developing technical solutions with a ‘cloud first’ mindset. Deep understanding of cloud data warehousing and ETL best practices, including system reliability and scalability. Ensuring data quality and consistency across various sources. Ability to function effectively as a change agent and problem solver within your team and across IT and the business. Excellent written, verbal, communication, and presentation skills with the ability to think critically, problem solve, and articulate new ideas and concepts to technical and non-technical audiences. Education and/or Experience: Bachelor’s degree in computer science, information technology, mathematics, or progressive relevant work experience. 8+ years of development experience required. 5+ years’ experience working with public cloud providers (Azure, Oracle Cloud, etc.). 5+ years’ experience in data pipeline development, including languages such as Python and R, and tools such as Airflow and SSIS. 5+ years Data Warehousing and ETL experience, preferably with large transactional datasets. Familiarity working in both Windows and Linux environments. Direct experience working with both traditional and agile methodologies required. Experience within the manufacturing industry, including knowledge in supply chain, procurement, and logistics is preferred but not required. Physical Demands and Work Environment: While performing the duties of this job, the employee is regularly required to stand, sit, talk, hear, and use hands and fingers to operate a computer and telephone along with reaching. Specific vision abilities include close vision requirements due to computer work. Moderate noise, ability to work in a confined area, and ability to sit at a computer for an extended period of time are also included. The policy of The Krusteaz Company is to hire, train, and promote all persons in all job groups in accordance with law, without regard to race, color, religion, sex, sexual orientation, age, marital or military status, national origin, gender identity, the presence of any sensory, mental or physical disability, genetic information, or any other status or characteristic protected by local, state, or federal law. Get to know us: A people-focused company that cares: We're a 90-year-old company with the entrepreneurial spirit of a startup and a focused eye on the future. As a midsized, privately held company with a portfolio of beloved food and beverage brands, our people are the most important ingredient in our success. A valued and supported workforce : We place tremendous value in our employees and provide competitive pay and comprehensive benefits to ensure our employees can create the best life for themselves. Benefits include a top tier health insurance plan with lower-than-average employee cost share, generous PTO, 401(k) match, and more. An engaged and energized culture: At The Krusteaz Company, collaboration and ingenuity drive our fierce commitment to creating extraordinary product experiences that people love. A place to grow and make a difference: An entrepreneurial spirit has been at the core of our company since the beginning, attracting self-starters who are curious and love to learn and to share ideas. Hybrid Work Model: At The Krusteaz Company, we have in-office \"core days\" of Tuesdays and Wednesdays where all corporate employees are expected to be onsite. Mondays, Thursdays, and Fridays are flexible remote days to allow for work/life balance. You may be asked to come in outside of a core day from time to time, based on business needs. We have found aligning our scheduled in-office days provides opportunity for employees to build connections and collaborate together. Benefits: We are proud to offer generous benefits including comprehensive medical, dental, and vision insurance (starting at $50/month for employee only coverage on the PPO Plan or starting at $25/month for employee only coverage on the HDHP), 401(K) matching, 3 weeks of paid vacation, 10 paid holidays, company provided life insurance and disability insurance, flexible spending account, healthcare saving account, voluntary accident insurance, voluntary critical illness insurance, and tuition reimbursement. Salary Information: An employee in this position can expect a salary range between $126,101 and $208,055. We typically pay out between $142,000 and $180,000. The actual salary offered will carefully consider a wide range of factors, including internal equity, experience, education, certification, training, and location. All positions are eligible for additional incentives based on business performance. We hope you'll take the time to get to know us! The Krusteaz Company is not sponsoring new applicant employment authorization at this time and please, no third-party recruiters. Opened URL: https://www.indeed.com/rc/clk?jk=042c410f50c0faa6&bb=1TLRjqutBEYcit1OApAPtt6B4oNDQ9pvplvzh521n9octR12bdC8X0WPxpzUuEahEqtE5IkoxGLcfct2Fl3E3ERVE0CDNI3ufYlz_WxpqD2cHp3NqHNahE2fQxTMaZ59&xkcb=SoAH67M33zDWevR-pR0AbzkdCdPP&fccid=9e189ac6632e8eb3&vjs=3</td><td>data</td><td>The Krusteaz Company is seeking a Senior Data Engineer to lead the architecture and development of our enterprise data strategy. Reporting to the Director of Enterprise Applications and Data Management, this role will play a key role in design, delivery, and management of our enterprise data strategy and solution(s). As a key contributor to our digital transformation, this role will take the lead in designing data structure, design, and ingestion, reporting processes and standards for the organization working across both the IT development, infrastructure, and analyst teams. As a senior member of the IT team, this role will be instrumental in promoting agility, scalability, and operational excellence. This role will also be a key contributor in our business transformation, working closely with our IT Business Analysts to understand the challenges facing our business partners and developing scalable and repeatable data solutions to meet their needs. This role will be a trusted partner to your peers within the IT team, demonstrating the ability to provide both conceptual and technical mentorship. Essential Functions : Other duties, responsibilities, and activities may change or be assigned at any time. Maintain and build on our data warehouse and analytics environment. Design, implement, test, deploy, and maintain stable, secure, and scalable data engineering solutions and pipelines. Build reports and data visualizations, using data from the data warehouse and other sources. Produce scalable, replicable code and engineering solutions that help automate repetitive data management tasks. Implement and monitor best in class security measures in our data warehouse and analytics environment. Provide direct input on the IT technology roadmap, helping ensure we make appropriate investments in build vs. buy decisions. Define and document best practices and strategies. Keep apprised of trends, identifies best-in class capabilities, opportunities and technology that may benefit The Krusteaz Company. Provide guidance, thought leadership, and mentorship to development and infrastructure teams to build EDW and development competencies. Position Requirements To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The requirements listed below are representative of the knowledge, skill, and/or ability required. Reasonable accommodations may be made to enable individuals qualified with disabilities to perform the essential functions. Proven success in developing technical solutions with a ‘cloud first’ mindset. Deep understanding of cloud data warehousing and ETL best practices, including system reliability and scalability. Ensuring data quality and consistency across various sources. Ability to function effectively as a change agent and problem solver within your team and across IT and the business. Excellent written, verbal, communication, and presentation skills with the ability to think critically, problem solve, and articulate new ideas and concepts to technical and non-technical audiences. Education and/or Experience: Bachelor’s degree in computer science, information technology, mathematics, or progressive relevant work experience. 8+ years of development experience required. 5+ years’ experience working with public cloud providers (Azure, Oracle Cloud, etc.). 5+ years’ experience in data pipeline development, including languages such as Python and R, and tools such as Airflow and SSIS. 5+ years Data Warehousing and ETL experience, preferably with large transactional datasets. Familiarity working in both Windows and Linux environments. Direct experience working with both traditional and agile methodologies required. Experience within the manufacturing industry, including knowledge in supply chain, procurement, and logistics is preferred but not required. Physical Demands and Work Environment: While performing the duties of this job, the employee is regularly required to stand, sit, talk, hear, and use hands and fingers to operate a computer and telephone along with reaching. Specific vision abilities include close vision requirements due to computer work. Moderate noise, ability to work in a confined area, and ability to sit at a computer for an extended period of time are also included. The policy of The Krusteaz Company is to hire, train, and promote all persons in all job groups in accordance with law, without regard to race, color, religion, sex, sexual orientation, age, marital or military status, national origin, gender identity, the presence of any sensory, mental or physical disability, genetic information, or any other status or characteristic protected by local, state, or federal law. Get to know us: A people-focused company that cares: We're a 90-year-old company with the entrepreneurial spirit of a startup and a focused eye on the future. As a midsized, privately held company with a portfolio of beloved food and beverage brands, our people are the most important ingredient in our success. A valued and supported workforce : We place tremendous value in our employees and provide competitive pay and comprehensive benefits to ensure our employees can create the best life for themselves. Benefits include a top tier health insurance plan with lower-than-average employee cost share, generous PTO, 401(k) match, and more. An engaged and energized culture: At The Krusteaz Company, collaboration and ingenuity drive our fierce commitment to creating extraordinary product experiences that people love. A place to grow and make a difference: An entrepreneurial spirit has been at the core of our company since the beginning, attracting self-starters who are curious and love to learn and to share ideas. Hybrid Work Model: At The Krusteaz Company, we have in-office \"core days\" of Tuesdays and Wednesdays where all corporate employees are expected to be onsite. Mondays, Thursdays, and Fridays are flexible remote days to allow for work/life balance. You may be asked to come in outside of a core day from time to time, based on business needs. We have found aligning our scheduled in-office days provides opportunity for employees to build connections and collaborate together. Benefits: We are proud to offer generous benefits including comprehensive medical, dental, and vision insurance (starting at $50/month for employee only coverage on the PPO Plan or starting at $25/month for employee only coverage on the HDHP), 401(K) matching, 3 weeks of paid vacation, 10 paid holidays, company provided life insurance and disability insurance, flexible spending account, healthcare saving account, voluntary accident insurance, voluntary critical illness insurance, and tuition reimbursement. Salary Information: An employee in this position can expect a salary range between $126,101 and $208,055. We typically pay out between $142,000 and $180,000. The actual salary offered will carefully consider a wide range of factors, including internal equity, experience, education, certification, training, and location. All positions are eligible for additional incentives based on business performance. We hope you'll take the time to get to know us! The Krusteaz Company is not sponsoring new applicant employment authorization at this time and please, no third-party recruiters.</td><td>The Krusteaz Company is seeking a Senior Data Engineer to lead the architecture and development of our enterprise data strategy. Reporting to the Director of Enterprise Applications and Data Management, this role will play a key role in design, delivery, and management of our enterprise data strategy and solution(s). As a key contributor to our digital transformation, this role will take the lead in designing data structure, design, and ingestion, reporting processes and standards for the organization working across both the IT development, infrastructure, and analyst teams. As a senior member of the IT team, this role will be instrumental in promoting agility, scalability, and operational excellence. This role will also be a key contributor in our business transformation, working closely with our IT Business Analysts to understand the challenges facing our business partners and developing scalable and repeatable data solutions to meet their needs. This role will be a trusted partner to your peers within the IT team, demonstrating the ability to provide both conceptual and technical mentorship. Essential Functions : Other duties, responsibilities, and activities may change or be assigned at any time. Maintain and build on our data warehouse and analytics environment. Design, implement, test, deploy, and maintain stable, secure, and scalable data engineering solutions and pipelines. Build reports and data visualizations, using data from the data warehouse and other sources. Produce scalable, replicable code and engineering solutions that help automate repetitive data management tasks. Implement and monitor best in class security measures in our data warehouse and analytics environment. Provide direct input on the IT technology roadmap, helping ensure we make appropriate investments in build vs. buy decisions. Define and document best practices and strategies. Keep apprised of trends, identifies best-in class capabilities, opportunities and technology that may benefit The Krusteaz Company. Provide guidance, thought leadership, and mentorship to development and infrastructure teams to build EDW and development competencies. Position Requirements To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The requirements listed below are representative of the knowledge, skill, and/or ability required. Reasonable accommodations may be made to enable individuals qualified with disabilities to perform the essential functions. Proven success in developing technical solutions with a ‘cloud first’ mindset. Deep understanding of cloud data warehousing and ETL best practices, including system reliability and scalability. Ensuring data quality and consistency across various sources. Ability to function effectively as a change agent and problem solver within your team and across IT and the business. Excellent written, verbal, communication, and presentation skills with the ability to think critically, problem solve, and articulate new ideas and concepts to technical and non-technical audiences. Education and/or Experience: Bachelor’s degree in computer science, information technology, mathematics, or progressive relevant work experience. 8+ years of development experience required. 5+ years’ experience working with public cloud providers (Azure, Oracle Cloud, etc.). 5+ years’ experience in data pipeline development, including languages such as Python and R, and tools such as Airflow and SSIS. 5+ years Data Warehousing and ETL experience, preferably with large transactional datasets. Familiarity working in both Windows and Linux environments. Direct experience working with both traditional and agile methodologies required. Experience within the manufacturing industry, including knowledge in supply chain, procurement, and logistics is preferred but not required. Physical Demands and Work Environment: While performing the duties of this job, the employee is regularly required to stand, sit, talk, hear, and use hands and fingers to operate a computer and telephone along with reaching. Specific vision abilities include close vision requirements due to computer work. Moderate noise, ability to work in a confined area, and ability to sit at a computer for an extended period of time are also included. The policy of The Krusteaz Company is to hire, train, and promote all persons in all job groups in accordance with law, without regard to race, color, religion, sex, sexual orientation, age, marital or military status, national origin, gender identity, the presence of any sensory, mental or physical disability, genetic information, or any other status or characteristic protected by local, state, or federal law. Get to know us: A people-focused company that cares: We're a 90-year-old company with the entrepreneurial spirit of a startup and a focused eye on the future. As a midsized, privately held company with a portfolio of beloved food and beverage brands, our people are the most important ingredient in our success. A valued and supported workforce : We place tremendous value in our employees and provide competitive pay and comprehensive benefits to ensure our employees can create the best life for themselves. Benefits include a top tier health insurance plan with lower-than-average employee cost share, generous PTO, 401(k) match, and more. An engaged and energized culture: At The Krusteaz Company, collaboration and ingenuity drive our fierce commitment to creating extraordinary product experiences that people love. A place to grow and make a difference: An entrepreneurial spirit has been at the core of our company since the beginning, attracting self-starters who are curious and love to learn and to share ideas. Hybrid Work Model: At The Krusteaz Company, we have in-office \"core days\" of Tuesdays and Wednesdays where all corporate employees are expected to be onsite. Mondays, Thursdays, and Fridays are flexible remote days to allow for work/life balance. You may be asked to come in outside of a core day from time to time, based on business needs. We have found aligning our scheduled in-office days provides opportunity for employees to build connections and collaborate together. Benefits: We are proud to offer generous benefits including comprehensive medical, dental, and vision insurance (starting at $50/month for employee only coverage on the PPO Plan or starting at $25/month for employee only coverage on the HDHP), 401(K) matching, 3 weeks of paid vacation, 10 paid holidays, company provided life insurance and disability insurance, flexible spending account, healthcare saving account, voluntary accident insurance, voluntary critical illness insurance, and tuition reimbursement. Salary Information: An employee in this position can expect a salary range between $126,101 and $208,055. We typically pay out between $142,000 and $180,000. The actual salary offered will carefully consider a wide range of factors, including internal equity, experience, education, certification, training, and location. All positions are eligible for additional incentives based on business performance. We hope you'll take the time to get to know us! The Krusteaz Company is not sponsoring new applicant employment authorization at this time and please, no third-party recruiters.</td><td>To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The requirements listed below are representative of the knowledge, skill, and/or ability required. Reasonable accommodations may be made to enable individuals qualified with disabilities to perform the essential functions. Proven success in developing technical solutions with a ‘cloud first’ mindset. Deep understanding of cloud data warehousing and ETL best practices, including system reliability and scalability. Ensuring data quality and consistency across various sources. Ability to function effectively as a change agent and problem solver within your team and across IT and the business. Excellent written, verbal, communication, and presentation skills with the ability to think critically, problem solve, and articulate new ideas and concepts to technical and non-technical audiences. Education and/or Experience: Bachelor’s degree in computer science, information technology, mathematics, or progressive relevant work experience. 8+ years of development experience required. 5+ years’ experience working with public cloud providers (Azure, Oracle Cloud, etc.). 5+ years’ experience in data pipeline development, including languages such as Python and R, and tools such as Airflow and SSIS. 5+ years Data Warehousing and ETL experience, preferably with large transactional datasets. Familiarity working in both Windows and Linux environments. Direct experience working with both traditional and agile methodologies required. Experience within the manufacturing industry, including knowledge in supply chain, procurement, and logistics is preferred but not required. Physical Demands and Work Environment: While performing the duties of this job, the employee is regularly required to stand, sit, talk, hear, and use hands and fingers to operate a computer and telephone along with reaching. Specific vision abilities include close vision requirements due to computer work. Moderate noise, ability to work in a confined area, and ability to sit at a computer for an extended period of time are also included. The policy of The Krusteaz Company is to hire, train, and promote all persons in all job groups in accordance with law, without regard to race, color, religion, sex, sexual orientation, age, marital or military status, national origin, gender identity, the presence of any sensory, mental or physical disability, genetic information, or any other status or characteristic protected by local, state, or federal law. Get to know us: A people-focused company that cares: We're a 90-year-old company with the entrepreneurial spirit of a startup and a focused eye on the future. As a midsized, privately held company with a portfolio of beloved food and beverage brands, our people are the most important ingredient in our success. A valued and supported workforce : We place tremendous value in our employees and provide competitive pay and comprehensive benefits to ensure our employees can create the best life for themselves. Benefits include a top tier health insurance plan with lower-than-average employee cost share, generous PTO, 401(k) match, and more. An engaged and energized culture: At The Krusteaz Company, collaboration and ingenuity drive our fierce commitment to creating extraordinary product experiences that people love. A place to grow and make a difference: An entrepreneurial spirit has been at the core of our company since the beginning, attracting self-starters who are curious and love to learn and to share ideas. Hybrid Work Model: At The Krusteaz Company, we have in-office \"core days\" of Tuesdays and Wednesdays where all corporate employees are expected to be onsite. Mondays, Thursdays, and Fridays are flexible remote days to allow for work/life balance. You may be asked to come in outside of a core day from time to time, based on business needs. We have found aligning our scheduled in-office days provides opportunity for employees to build connections and collaborate together. Benefits: We are proud to offer generous benefits including comprehensive medical, dental, and vision insurance (starting at $50/month for employee only coverage on the PPO Plan or starting at $25/month for employee only coverage on the HDHP), 401(K) matching, 3 weeks of paid vacation, 10 paid holidays, company provided life insurance and disability insurance, flexible spending account, healthcare saving account, voluntary accident insurance, voluntary critical illness insurance, and tuition reimbursement. Salary Information: An employee in this position can expect a salary range between $126,101 and $208,055. We typically pay out between $142,000 and $180,000. The actual salary offered will carefully consider a wide range of factors, including internal equity, experience, education, certification, training, and location. All positions are eligible for additional incentives based on business performance. We hope you'll take the time to get to know us! The Krusteaz Company is not sponsoring new applicant employment authorization at this time and please, no third-party recruiters.</td><td>756</td></tr><tr><td>null</td><td>provided life insurance and disability insurance, flexible spending account, healthcare saving account, voluntary accident insurance, voluntary critical illness insurance, and tuition reimbursement.</td><td>Description: Join our winning team, recently honored as #67 on Forbes’ list of America’s Best Startup Employers for 2024! About The Helper Bees The Helper Bees’ mission is to help people stay home longer through data-driven services that transform both the payer and the care-recipient experience. At The Helper Bees, we are reshaping how care is delivered to aging individuals by leveraging innovative technology and insightful data solutions. We maintain multiple SaaS products and payment solutions through our web applications (internal and external facing), a mobile app, and reporting integrations. As part of our growing Data Engineering team, you’ll iterate quickly, have a high impact, and be challenged to design and implement cutting-edge solutions. At THB, we define our company culture through our Core Values: Quickly iterate through solutions: We move at a fast pace which requires quick iterations to find a path to a repeatable solution. Seek ways to create immediate impact: Be thoughtful and proactive in how you make an impact on your team. Actively look for ways to make a fast, positive impact. Bee the teammate you want to work with: We work as a team, help each other, and encourage each other. Ask questions, answer questions: You can't iterate through solutions if you don't ask the right questions, which is why there is an expectation that questions should be asked. When you know the answer, being a good teammate means chiming in to get others up to speed. Take the time to celebrate wins: It's so easy for a team that is heads down to forget about all the great things they've accomplished. That's why we make it a priority to remind ourselves to create space to celebrate wins, big or small. Job Summary We are seeking a motivated Data Engineer to join our team and help improve our tools, processes, and technical infrastructure. In this role, you will ensure the availability and quality of our data while contributing to the design, implementation, and maintenance of The Helper Bees’ products. You’ll collaborate across teams to create scalable and optimized software systems and play a key role in refining our development processes. This position offers a unique opportunity to learn and leverage cutting-edge AI development tools to enhance coding efficiency and develop advanced data tools and solutions. Supervisory Responsibilities: None Key Responsibilities Data Infrastructure: Design, implement, and maintain data pipelines, ensuring data availability, quality, and scalability. Product Development: Build and enhance products using Python, SQL, and modern technologies. AI Integration: Leverage cutting-edge AI tools, including Cursor, ChatGPT, and Claude to improve development processes, automate workflows, and create innovative data solutions. Collaboration: Communicate across departments to design, build, test, and implement new features and enhancements. Code Excellence: Produce quality, testable, and maintainable code while participating in code reviews. Problem Solving: Debug complex issues, interact with stakeholders, and design viable solutions with clear trade-offs. Process Optimization: Contribute to improving development processes, including deployment, on-call systems, and sprint planning. Team Growth: Collaborate within the development team to help each other grow and continuously learn. Stakeholder Engagement: Partner with analysts, scientists, and IT to ensure alignment and deliver data-driven solutions. Other duties as assigned/necessary Performance Metrics Code Quality: Maintain high coding standards through regular code reviews and adherence to best practices. Development Efficiency: Deliver high-quality features and fixes within efficient timeframes. Bug Resolution Time: Reduce the time taken to identify and resolve issues. System Scalability: Optimize system performance to handle increasing user demands. Collaboration: Foster a collaborative environment that encourages teamwork and knowledge sharing. Customer Satisfaction: Incorporate stakeholder feedback to improve solutions and enhance the customer experience. Continuous Learning: Pursue opportunities for skill development and share knowledge with the team. Requirements: Required Skills & Qualifications Technical Tools: Experience with in Python and/or SQL. Experience with Bash, Shell scripting, Big Query, Airflow, and is a plus. Programming: Cleaning data using code-based approach. AI Proficiency: Interest or experience in using AI tools for coding and development of data solutions. Soft Skills: Problem-solving, cross-team collaboration, data storytelling, and stakeholder engagement. Adaptability: Thrives in a fast-paced startup environment and embraces change. Proactivity: Self-directed, organized, and able to prioritize effectively. Collaboration: Ability to work effectively with cross-functional teams. Education & Experience: A bachelor’s degree is required, and a graduate degree is preferred. Relevant experience in data engineering, software development, STEM, or related fields. Strong experience with SQL and Python is highly desirable. Mindset: A passion for innovation, continuous improvement, and delivering high-quality results from messy data. Preferred Qualifications Familiarity with cloud-based solutions (e.g., Google Cloud Platform, Azure). Experience with ETL processes and tools. Experience building data visualization reports and dashboards Knowledge of modern data storage solutions and database management systems. Exposure to DevOps practices and tools for deployment and monitoring. Why Join Us? Work with a talented, collaborative team dedicated to making a difference. Gain exposure to innovative technologies and opportunities for growth. Learn and utilize cutting-edge AI tools to enhance your development skills and create impactful solutions. Be part of a company that values your contributions and encourages professional development. Join a rapidly expanding health-tech startup (~200 employees and growing) with a state-of-the-art technology office located in Hyde Park, offering a variety of exceptional benefits. Career Progression Timeline In 3 months: Gain a comprehensive understanding of our data infrastructure, technical stacks, and development cycles. Actively participate in team meetings and contribute to the development of new data pipelines. Begin leveraging AI tools, such as Cursor and ChatGPT, to enhance coding efficiency and workflow automation. In 6 months: Contribute to product enhancements and data reporting Collaborate effectively with cross-functional teams, providing insights and solutions for data-related challenges. Demonstrate proficiency in utilizing AI tools for coding and development, actively sharing knowledge with the team. In 12 months: Contribute to data engineering projects, ensuring scalability and performance optimization. Mentor non-technical internal partners to improve company-wide data literacy Contribute to the integration of advanced AI solutions into our development processes, contributing to the company's technological advancement. Physical Requirements: Ability to remain at your designated workstation for the duration of the workday Constantly operates a computer and other office productivity machinery, such as a phone and Voice over Internet Protocol (VoIP). The ability to communicate information and ideas so others will understand. Must be able to exchange accurate information in these situations. The ability to observe details at close range (typically on a computer screen) This position offers the flexibility of remote work at approved locations within the United States. Candidates must have a reliable internet connection and a designated work environment conducive to professional phone calls and sensitive data. Enjoy the convenience and comfort of working remotely while contributing to our team's success. Apply Today If you’re ready to take on challenging problems, contribute to impactful solutions, and grow as a data engineer, we’d love to hear from you. Join us at The Helper Bees and be part of a team that’s making a meaningful difference every day! The Helper Bees is committed to building a workplace where diversity, equity, and inclusion are valued and prioritized. We are an equal opportunity employer that welcomes all qualified applicants without discrimination based on race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or any non-merit based or legally protected grounds. The Helper Bees provides reasonable accommodations to qualified individuals with disabilities during the job application and interview process. To request accommodation, please let your recruiter know. As part of our standard hiring process, selected candidates may be required to undergo a background check and/or drug screen. The Helper Bees adheres to applicable federal, state, and local laws regarding these screenings, and the results will be considered in accordance with applicable regulations. The Helper Bees was recently made aware of a fraudulent entity posing as our organization and requesting personal information. Please be aware of and protect yourself from scams. Visit thehelperbees.com/careers to view all current job openings. Opened URL: https://www.indeed.com/rc/clk?jk=06050d41e9f16407&bb=nVjcBhNqHzp8_NHgm7Pt9q7Srq7WJc3laX3t3bfzY84KBRoVLSzYwQg5Id0CB1on-KM_yMleDsx7wPr33UW8XbqBO4oQrHGnF3Ow3KdqYHbSXJt-uTwunph9tFWLP-yb&xkcb=SoDC67M33zEiEHSkNJ0IbzkdCdPP&fccid=61e4e7d2ce056d37&vjs=3</td><td>data</td><td>Description: Join our winning team, recently honored as #67 on Forbes’ list of America’s Best Startup Employers for 2024! About The Helper Bees The Helper Bees’ mission is to help people stay home longer through data-driven services that transform both the payer and the care-recipient experience. At The Helper Bees, we are reshaping how care is delivered to aging individuals by leveraging innovative technology and insightful data solutions. We maintain multiple SaaS products and payment solutions through our web applications (internal and external facing), a mobile app, and reporting integrations. As part of our growing Data Engineering team, you’ll iterate quickly, have a high impact, and be challenged to design and implement cutting-edge solutions. At THB, we define our company culture through our Core Values: Quickly iterate through solutions: We move at a fast pace which requires quick iterations to find a path to a repeatable solution. Seek ways to create immediate impact: Be thoughtful and proactive in how you make an impact on your team. Actively look for ways to make a fast, positive impact. Bee the teammate you want to work with: We work as a team, help each other, and encourage each other. Ask questions, answer questions: You can't iterate through solutions if you don't ask the right questions, which is why there is an expectation that questions should be asked. When you know the answer, being a good teammate means chiming in to get others up to speed. Take the time to celebrate wins: It's so easy for a team that is heads down to forget about all the great things they've accomplished. That's why we make it a priority to remind ourselves to create space to celebrate wins, big or small. Job Summary We are seeking a motivated Data Engineer to join our team and help improve our tools, processes, and technical infrastructure. In this role, you will ensure the availability and quality of our data while contributing to the design, implementation, and maintenance of The Helper Bees’ products. You’ll collaborate across teams to create scalable and optimized software systems and play a key role in refining our development processes. This position offers a unique opportunity to learn and leverage cutting-edge AI development tools to enhance coding efficiency and develop advanced data tools and solutions. Supervisory Responsibilities: None Key Responsibilities Data Infrastructure: Design, implement, and maintain data pipelines, ensuring data availability, quality, and scalability. Product Development: Build and enhance products using Python, SQL, and modern technologies. AI Integration: Leverage cutting-edge AI tools, including Cursor, ChatGPT, and Claude to improve development processes, automate workflows, and create innovative data solutions. Collaboration: Communicate across departments to design, build, test, and implement new features and enhancements. Code Excellence: Produce quality, testable, and maintainable code while participating in code reviews. Problem Solving: Debug complex issues, interact with stakeholders, and design viable solutions with clear trade-offs. Process Optimization: Contribute to improving development processes, including deployment, on-call systems, and sprint planning. Team Growth: Collaborate within the development team to help each other grow and continuously learn. Stakeholder Engagement: Partner with analysts, scientists, and IT to ensure alignment and deliver data-driven solutions. Other duties as assigned/necessary Performance Metrics Code Quality: Maintain high coding standards through regular code reviews and adherence to best practices. Development Efficiency: Deliver high-quality features and fixes within efficient timeframes. Bug Resolution Time: Reduce the time taken to identify and resolve issues. System Scalability: Optimize system performance to handle increasing user demands. Collaboration: Foster a collaborative environment that encourages teamwork and knowledge sharing. Customer Satisfaction: Incorporate stakeholder feedback to improve solutions and enhance the customer experience. Continuous Learning: Pursue opportunities for skill development and share knowledge with the team. Requirements: Required Skills & Qualifications Technical Tools: Experience with in Python and/or SQL. Experience with Bash, Shell scripting, Big Query, Airflow, and is a plus. Programming: Cleaning data using code-based approach. AI Proficiency: Interest or experience in using AI tools for coding and development of data solutions. Soft Skills: Problem-solving, cross-team collaboration, data storytelling, and stakeholder engagement. Adaptability: Thrives in a fast-paced startup environment and embraces change. Proactivity: Self-directed, organized, and able to prioritize effectively. Collaboration: Ability to work effectively with cross-functional teams. Education & Experience: A bachelor’s degree is required, and a graduate degree is preferred. Relevant experience in data engineering, software development, STEM, or related fields. Strong experience with SQL and Python is highly desirable. Mindset: A passion for innovation, continuous improvement, and delivering high-quality results from messy data. Preferred Qualifications Familiarity with cloud-based solutions (e.g., Google Cloud Platform, Azure). Experience with ETL processes and tools. Experience building data visualization reports and dashboards Knowledge of modern data storage solutions and database management systems. Exposure to DevOps practices and tools for deployment and monitoring. Why Join Us? Work with a talented, collaborative team dedicated to making a difference. Gain exposure to innovative technologies and opportunities for growth. Learn and utilize cutting-edge AI tools to enhance your development skills and create impactful solutions. Be part of a company that values your contributions and encourages professional development. Join a rapidly expanding health-tech startup (~200 employees and growing) with a state-of-the-art technology office located in Hyde Park, offering a variety of exceptional benefits. Career Progression Timeline In 3 months: Gain a comprehensive understanding of our data infrastructure, technical stacks, and development cycles. Actively participate in team meetings and contribute to the development of new data pipelines. Begin leveraging AI tools, such as Cursor and ChatGPT, to enhance coding efficiency and workflow automation. In 6 months: Contribute to product enhancements and data reporting Collaborate effectively with cross-functional teams, providing insights and solutions for data-related challenges. Demonstrate proficiency in utilizing AI tools for coding and development, actively sharing knowledge with the team. In 12 months: Contribute to data engineering projects, ensuring scalability and performance optimization. Mentor non-technical internal partners to improve company-wide data literacy Contribute to the integration of advanced AI solutions into our development processes, contributing to the company's technological advancement. Physical Requirements: Ability to remain at your designated workstation for the duration of the workday Constantly operates a computer and other office productivity machinery, such as a phone and Voice over Internet Protocol (VoIP). The ability to communicate information and ideas so others will understand. Must be able to exchange accurate information in these situations. The ability to observe details at close range (typically on a computer screen) This position offers the flexibility of remote work at approved locations within the United States. Candidates must have a reliable internet connection and a designated work environment conducive to professional phone calls and sensitive data. Enjoy the convenience and comfort of working remotely while contributing to our team's success. Apply Today If you’re ready to take on challenging problems, contribute to impactful solutions, and grow as a data engineer, we’d love to hear from you. Join us at The Helper Bees and be part of a team that’s making a meaningful difference every day! The Helper Bees is committed to building a workplace where diversity, equity, and inclusion are valued and prioritized. We are an equal opportunity employer that welcomes all qualified applicants without discrimination based on race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or any non-merit based or legally protected grounds. The Helper Bees provides reasonable accommodations to qualified individuals with disabilities during the job application and interview process. To request accommodation, please let your recruiter know. As part of our standard hiring process, selected candidates may be required to undergo a background check and/or drug screen. The Helper Bees adheres to applicable federal, state, and local laws regarding these screenings, and the results will be considered in accordance with applicable regulations. The Helper Bees was recently made aware of a fraudulent entity posing as our organization and requesting personal information. Please be aware of and protect yourself from scams. Visit thehelperbees.com/careers to view all current job openings.</td><td>Description: Join our winning team, recently honored as #67 on Forbes’ list of America’s Best Startup Employers for 2024! About The Helper Bees The Helper Bees’ mission is to help people stay home longer through data-driven services that transform both the payer and the care-recipient experience. At The Helper Bees, we are reshaping how care is delivered to aging individuals by leveraging innovative technology and insightful data solutions. We maintain multiple SaaS products and payment solutions through our web applications (internal and external facing), a mobile app, and reporting integrations. As part of our growing Data Engineering team, you’ll iterate quickly, have a high impact, and be challenged to design and implement cutting-edge solutions. At THB, we define our company culture through our Core Values: Quickly iterate through solutions: We move at a fast pace which requires quick iterations to find a path to a repeatable solution. Seek ways to create immediate impact: Be thoughtful and proactive in how you make an impact on your team. Actively look for ways to make a fast, positive impact. Bee the teammate you want to work with: We work as a team, help each other, and encourage each other. Ask questions, answer questions: You can't iterate through solutions if you don't ask the right questions, which is why there is an expectation that questions should be asked. When you know the answer, being a good teammate means chiming in to get others up to speed. Take the time to celebrate wins: It's so easy for a team that is heads down to forget about all the great things they've accomplished. That's why we make it a priority to remind ourselves to create space to celebrate wins, big or small. Job Summary We are seeking a motivated Data Engineer to join our team and help improve our tools, processes, and technical infrastructure. In this role, you will ensure the availability and quality of our data while contributing to the design, implementation, and maintenance of The Helper Bees’ products. You’ll collaborate across teams to create scalable and optimized software systems and play a key role in refining our development processes. This position offers a unique opportunity to learn and leverage cutting-edge AI development tools to enhance coding efficiency and develop advanced data tools and solutions. Supervisory Responsibilities: None Key Responsibilities Data Infrastructure: Design, implement, and maintain data pipelines, ensuring data availability, quality, and scalability. Product Development: Build and enhance products using Python, SQL, and modern technologies. AI Integration: Leverage cutting-edge AI tools, including Cursor, ChatGPT, and Claude to improve development processes, automate workflows, and create innovative data solutions. Collaboration: Communicate across departments to design, build, test, and implement new features and enhancements. Code Excellence: Produce quality, testable, and maintainable code while participating in code reviews. Problem Solving: Debug complex issues, interact with stakeholders, and design viable solutions with clear trade-offs. Process Optimization: Contribute to improving development processes, including deployment, on-call systems, and sprint planning. Team Growth: Collaborate within the development team to help each other grow and continuously learn. Stakeholder Engagement: Partner with analysts, scientists, and IT to ensure alignment and deliver data-driven solutions. Other duties as assigned/necessary Performance Metrics Code Quality: Maintain high coding standards through regular code reviews and adherence to best practices. Development Efficiency: Deliver high-quality features and fixes within efficient timeframes. Bug Resolution Time: Reduce the time taken to identify and resolve issues. System Scalability: Optimize system performance to handle increasing user demands. Collaboration: Foster a collaborative environment that encourages teamwork and knowledge sharing. Customer Satisfaction: Incorporate stakeholder feedback to improve solutions and enhance the customer experience. Continuous Learning: Pursue opportunities for skill development and share knowledge with the team. Requirements: Required Skills & Qualifications Technical Tools: Experience with in Python and/or SQL. Experience with Bash, Shell scripting, Big Query, Airflow, and is a plus. Programming: Cleaning data using code-based approach. AI Proficiency: Interest or experience in using AI tools for coding and development of data solutions. Soft Skills: Problem-solving, cross-team collaboration, data storytelling, and stakeholder engagement. Adaptability: Thrives in a fast-paced startup environment and embraces change. Proactivity: Self-directed, organized, and able to prioritize effectively. Collaboration: Ability to work effectively with cross-functional teams. Education & Experience: A bachelor’s degree is required, and a graduate degree is preferred. Relevant experience in data engineering, software development, STEM, or related fields. Strong experience with SQL and Python is highly desirable. Mindset: A passion for innovation, continuous improvement, and delivering high-quality results from messy data. Preferred Qualifications Familiarity with cloud-based solutions (e.g., Google Cloud Platform, Azure). Experience with ETL processes and tools. Experience building data visualization reports and dashboards Knowledge of modern data storage solutions and database management systems. Exposure to DevOps practices and tools for deployment and monitoring. Why Join Us? Work with a talented, collaborative team dedicated to making a difference. Gain exposure to innovative technologies and opportunities for growth. Learn and utilize cutting-edge AI tools to enhance your development skills and create impactful solutions. Be part of a company that values your contributions and encourages professional development. Join a rapidly expanding health-tech startup (~200 employees and growing) with a state-of-the-art technology office located in Hyde Park, offering a variety of exceptional benefits. Career Progression Timeline In 3 months: Gain a comprehensive understanding of our data infrastructure, technical stacks, and development cycles. Actively participate in team meetings and contribute to the development of new data pipelines. Begin leveraging AI tools, such as Cursor and ChatGPT, to enhance coding efficiency and workflow automation. In 6 months: Contribute to product enhancements and data reporting Collaborate effectively with cross-functional teams, providing insights and solutions for data-related challenges. Demonstrate proficiency in utilizing AI tools for coding and development, actively sharing knowledge with the team. In 12 months: Contribute to data engineering projects, ensuring scalability and performance optimization. Mentor non-technical internal partners to improve company-wide data literacy Contribute to the integration of advanced AI solutions into our development processes, contributing to the company's technological advancement. Physical Requirements: Ability to remain at your designated workstation for the duration of the workday Constantly operates a computer and other office productivity machinery, such as a phone and Voice over Internet Protocol (VoIP). The ability to communicate information and ideas so others will understand. Must be able to exchange accurate information in these situations. The ability to observe details at close range (typically on a computer screen) This position offers the flexibility of remote work at approved locations within the United States. Candidates must have a reliable internet connection and a designated work environment conducive to professional phone calls and sensitive data. Enjoy the convenience and comfort of working remotely while contributing to our team's success. Apply Today If you’re ready to take on challenging problems, contribute to impactful solutions, and grow as a data engineer, we’d love to hear from you. Join us at The Helper Bees and be part of a team that’s making a meaningful difference every day! The Helper Bees is committed to building a workplace where diversity, equity, and inclusion are valued and prioritized. We are an equal opportunity employer that welcomes all qualified applicants without discrimination based on race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or any non-merit based or legally protected grounds. The Helper Bees provides reasonable accommodations to qualified individuals with disabilities during the job application and interview process. To request accommodation, please let your recruiter know. As part of our standard hiring process, selected candidates may be required to undergo a background check and/or drug screen. The Helper Bees adheres to applicable federal, state, and local laws regarding these screenings, and the results will be considered in accordance with applicable regulations. The Helper Bees was recently made aware of a fraudulent entity posing as our organization and requesting personal information. Please be aware of and protect yourself from scams. Visit thehelperbees.com/careers to view all current job openings.</td><td>Technical Tools: Experience with in Python and/or SQL. Experience with Bash, Shell scripting, Big Query, Airflow, and is a plus. Programming: Cleaning data using code-based approach. AI Proficiency: Interest or experience in using AI tools for coding and development of data solutions. Soft Skills: Problem-solving, cross-team collaboration, data storytelling, and stakeholder engagement. Adaptability: Thrives in a fast-paced startup environment and embraces change. Proactivity: Self-directed, organized, and able to prioritize effectively. Collaboration: Ability to work effectively with cross-functional teams. Education & Experience: A bachelor’s degree is required, and a graduate degree is preferred. Relevant experience in data engineering, software development, STEM, or related fields. Strong experience with SQL and Python is highly desirable. Mindset: A passion for innovation, continuous improvement, and delivering high-quality results from messy data. Preferred Qualifications Familiarity with cloud-based solutions (e.g., Google Cloud Platform, Azure). Experience with ETL processes and tools. Experience building data visualization reports and dashboards Knowledge of modern data storage solutions and database management systems. Exposure to DevOps practices and tools for deployment and monitoring. Why Join Us? Work with a talented, collaborative team dedicated to making a difference. Gain exposure to innovative technologies and opportunities for growth. Learn and utilize cutting-edge AI tools to enhance your development skills and create impactful solutions. Be part of a company that values your contributions and encourages professional development. Join a rapidly expanding health-tech startup (~200 employees and growing) with a state-of-the-art technology office located in Hyde Park, offering a variety of exceptional benefits. Career Progression Timeline In 3 months: Gain a comprehensive understanding of our data infrastructure, technical stacks, and development cycles. Actively participate in team meetings and contribute to the development of new data pipelines. Begin leveraging AI tools, such as Cursor and ChatGPT, to enhance coding efficiency and workflow automation. In 6 months: Contribute to product enhancements and data reporting Collaborate effectively with cross-functional teams, providing insights and solutions for data-related challenges. Demonstrate proficiency in utilizing AI tools for coding and development, actively sharing knowledge with the team. In 12 months: Contribute to data engineering projects, ensuring scalability and performance optimization. Mentor non-technical internal partners to improve company-wide data literacy Contribute to the integration of advanced AI solutions into our development processes, contributing to the company's technological advancement. Physical Requirements: Ability to remain at your designated workstation for the duration of the workday Constantly operates a computer and other office productivity machinery, such as a phone and Voice over Internet Protocol (VoIP). The ability to communicate information and ideas so others will understand. Must be able to exchange accurate information in these situations. The ability to observe details at close range (typically on a computer screen) This position offers the flexibility of remote work at approved locations within the United States. Candidates must have a reliable internet connection and a designated work environment conducive to professional phone calls and sensitive data. Enjoy the convenience and comfort of working remotely while contributing to our team's success. Apply Today If you’re ready to take on challenging problems, contribute to impactful solutions, and grow as a data engineer, we’d love to hear from you. Join us at The Helper Bees and be part of a team that’s making a meaningful difference every day! The Helper Bees is committed to building a workplace where diversity, equity, and inclusion are valued and prioritized. We are an equal opportunity employer that welcomes all qualified applicants without discrimination based on race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or any non-merit based or legally protected grounds. The Helper Bees provides reasonable accommodations to qualified individuals with disabilities during the job application and interview process. To request accommodation, please let your recruiter know. As part of our standard hiring process, selected candidates may be required to undergo a background check and/or drug screen. The Helper Bees adheres to applicable federal, state, and local laws regarding these screenings, and the results will be considered in accordance with applicable regulations. The Helper Bees was recently made aware of a fraudulent entity posing as our organization and requesting personal information. Please be aware of and protect yourself from scams. Visit thehelperbees.com/careers to view all current job openings.</td><td>698</td></tr><tr><td>Instructional Designer, Content Developer</td><td>Boston Scientific Corporation</td><td>Work mode: Hybrid Onsite Location(s): Maple Grove, MN, US, 55311 Additional Location(s): US-MN-Maple Grove Diversity - Innovation - Caring - Global Collaboration - Winning Spirit - High Performance At Boston Scientific, we’ll give you the opportunity to harness all that’s within you by working in teams of diverse and high-performing employees, tackling some of the most important health industry challenges. With access to the latest tools, information and training, we’ll help you in advancing your skills and career. Here, you’ll be supported in progressing – whatever your ambitions. The Instructional Designer Content Developer (Cardiology Training) works closely with business partners, subject matter experts (SMEs), and other key stakeholders to plan and develop high-quality learning experiences to support business goals. This individual is responsible for the development of content, which may include interactive, multimedia, instructor led. This position reports to the Cardiology Training Operations Manager. Candidates will provide work portfolio as part of the application process. The interview will include a portfolio review and discussion. Your responsibilities will include: Partnering with subject matter experts and other stakeholders to analyze the learning needs. Planning, organizing, and developing learning solutions using a variety of modalities. Synthesizing and translating technical information into clear, effective, and engaging learning. Ensuring a consistent approach to the learning experience. Being proficient with a wide variety of learning tools, including but not limited to Storyline, RISE, game-based learning, videos, InDesign. Managing multiple projects with frequent priority shifts, working with high attention to accuracy and detail, and delivering within expected timelines. Being familiar with Learning Management Systems, as it relates to ensuring content works appropriately. Managing and organizing content in a centralized repository to ensure accuracy of material. Minimum Qualifications: Bachelor’s degree and/or equivalent of industry experience Four years of Instructional Design and content creation Innovative, curious mindset and ability to work independently to meet deadlines Excellent written and verbal communication skills Experience editing content for clarity and accuracy Experience using Microsoft 365 tools Experience using Articulate 360 software Experience using video editing software Experience using software to create animated characters Experience using Adobe InDesign Preferred Qualifications: Experience working within an FDA regulated environment Experience using Sales and Learning Enablement Platforms, (such as Showpad, Allego, SmartWinnr, etc) Requisition ID: 598020 Minimum Salary: $ 99100 Maximum Salary: $ 188300 Compensation for non-exempt (hourly), non-sales roles may also include variable compensation from time to time (e.g., any overtime and shift differential) and annual bonus target (subject to plan eligibility and other requirements). Compensation for exempt, non-sales roles may also include variable compensation, i.e., annual bonus target and long-term incentives (subject to plan eligibility and other requirements. For MA positions: It is unlawful to require or administer a lie detector test for employment. Violators are subject to criminal penalties and civil liability. As a leader in medical science for more than 40 years, we are committed to solving the challenges that matter most – united by a deep caring for human life. Our mission to advance science for life is about transforming lives through innovative medical solutions that improve patient lives, create value for our customers, and support our employees and the communities in which we operate. Now more than ever, we have a responsibility to apply those values to everything we do – as a global business and as a global corporate citizen. So, choosing a career with Boston Scientific (NYSE: BSX) isn’t just business, it’s personal. And if you’re a natural problem-solver with the imagination, determination, and spirit to make a meaningful difference to people worldwide, we encourage you to apply and look forward to connecting with you! At Boston Scientific, we recognize that nurturing a diverse and inclusive workplace helps us be more innovative and it is important in our work of advancing science for life and improving patient health. That is why we stand for inclusion, equality, and opportunity for all. By embracing the richness of our unique backgrounds and perspectives, we create a better, more rewarding place for our employees to work and reflect the patients, customers, and communities we serve. Boston Scientific Corporation has been and will continue to be an equal opportunity employer. To ensure full implementation of its equal employment policy, the Company will continue to take steps to assure that recruitment, hiring, assignment, promotion, compensation, and all other personnel decisions are made and administered without regard to race, religion, color, national origin, citizenship, sex, sexual orientation, gender identify, gender expression, veteran status, age, mental or physical disability, genetic information or any other protected class. Please be advised that certain US based positions, including without limitation field sales and service positions that call on hospitals and/or health care centers, require acceptable proof of COVID-19 vaccination status. Candidates will be notified during the interview and selection process if the role(s) for which they have applied require proof of vaccination as a condition of employment. Boston Scientific continues to evaluate its policies and protocols regarding the COVID-19 vaccine and will comply with all applicable state and federal law and healthcare credentialing requirements. As employees of the Company, you will be expected to meet the ongoing requirements for your roles, including any new requirements, should the Company’s policies or protocols change with regard to COVID-19 vaccination. Nearest Major Market: Minneapolis Job Segment: Learning, Testing, Developer, Programmer, Information Technology, Human Resources, Technology Title: Software Engineer Company: Specialty Capital URL: https://www.indeed.com/pagead/clk?mo=r&ad=-6NYlbfkN0DzX7PQAKaiJCZnVFs2Ov8U9Q9S3K6neGnvbuf6n2zC9_Pkj_sXND7Qk4-xgBEMNM9-p4oZMWw5vmAUGkwUkI9i3Ndwit9RWbFDI0MuTROa2LZyH6BjeGUt6QkYQYyZ8HsEoA330tU-H53xVOdfKCqwBoM5_UZDYqq1CxoJHxdDaOZie-n2VGzRKb_eCti_lL9JVg2C1G-CfGJR2cl7RKHDse4BDFvttFpqWGZ8aUq_6_OKvwXw2Ze6Cc1O43BHduYrcEvYRgzw6bTD9sVNVQQ_eomhM1YQp-dOZU8bveYJanIRmabafxJKZE9P6fWJWDrIB61yygA7A38kNlO7xt5eOOgZN5bTYctOMLBsk3QBr0RyODVF4AzvhkVs8p5pi33aqy71uyL3awFy5c56HCxs-uORyqrUU5i_CsBNa0CuJlrOtXV6sCJYldh2kqBTHgVHr5fBDF6LpwdO4N4-ONAkNY7OHwPrrJ9r-Pyola0xAFcCFbduFrlQh-obJ4eLHqhlmciGaVffzsiEkHW6y-D0ueZfR82sxCA3N-Z7Xez2gzWZZ9NeHh_AxWvT5x4_yKcSortfOhNv4PjrIne_L3DdeEFsqYbakOorH7_pJOK67ChBMizMRoOGTqApz9qFfMk=&xkcb=SoCB6_M331x-WqyLNB0NbzkdCdPP&camk=ethIe0s0hefEWJEBjQdxdQ==&p=0&fvj=0&vjs=3  Title: Software Safety Engineer Company: Entegee URL: https://www.indeed.com/pagead/clk?mo=r&ad=-6NYlbfkN0D6OzZjpD_hbicRkMZwNNvvxSeL23iIfvaC4EytleQ8zJPuRiz-GFjENB8tAhgtYfTeju-esYvHP6v3vTW71M2A9oDC-Rz_h3qInRx1oYz3a_7E2sB53Poa4HuP1onGqi-iFt9RtQ9x3FWdLUgr0ghWui8odQO5a_Vl_2K4vZF7404wVXbKwnYB5G9OOSBVRoOmF48k5GxxSO8PvnaFd-vPFWIPZ_yWWAjzz5hLdVJ7o3FvnsE4CHtoP0BHCdTIyxBKo2mhafJpQOqzZYD2xbk6X9z6QhLguv3jsuTJ1pOXRrV9qXXEYgX_tuG6M_n8k-SOXcDFR1TpbMUTGXXV80IGQsoCh06uFkvyKo8nvn6QpbUZjsi4bLFn_PDWHBj_bPoOdtmF2PEYmehJ1OtZEKiVSSdrdgXnH76L22Yp-M8S_N_ZfkocAKHoZOsf0WmxMswoUmoW1Nh-au3_x4m9bhBvbruvgXcW4oMPl2EZC75pSUtCW49VlJICi3q1tHFbYiEFzM2pshSnoS3G3ElG1CAyh6trxA9ypALsD00krIGdBJt-ErPgTwcOrlNDKQWDFWcyyCTkowAqjbHM0xaf0JeLQHOUhcNpva6MsKNjTwP1QecHJ0numx-7tSMC2AAHHJD8pNb475puno5WcxV8ePqp&xkcb=SoA16_M331x-WqyLNB0MbzkdCdPP&camk=f416UQcMBpBqMpW9kmClkg==&p=1&fvj=0&vjs=3  Title: Entry Level Java Developer Company: Hemma Systems Inc. URL: https://www.indeed.com/rc/clk?jk=13be2d2d47d5bc48&bb=14wI_Ylq6Fgk36O9dVMYwGCSiX5dUUZ6ZcLUyF8Lnifo7lCAQ8ryGR5Hw4N6d1Yuvb_6inOxZYooY1OKQs2qtqBShclWxJtNU1uAAyJxdD-2UaeZCHpi9p9QwiPCXlb1&xkcb=SoAo67M331x-WqyLNB0DbzkdCdPP&fccid=64a01098c675b9d4&cmp=Hemma-Systems-Inc.&ti=Entry+Level+Java+Developer&vjs=3  Title: Software Engineer II - C# (Remote) Company: McDonald's Corporation URL: https://www.indeed.com/rc/clk?jk=5dac47dc41cceea1&bb=14wI_Ylq6Fgk36O9dVMYwBSJVfCXzEqIyC-WhjXcttxXHxDnU9v0QjYpB9Hq6dme1Zz5WbxUtzH_O7Oycpt1rjC0IUor_CIh2qFhwzfg0gy9qQhOGEiacQlpTE-yDMkF&xkcb=SoCc67M331x-WqyLNB0CbzkdCdPP&fccid=f753bb1a40104d82&vjs=3  Title: Manager, Software Engineering Company: Balboa Digital Inc URL: https://www.indeed.com/pagead/clk?mo=r&ad=-6NYlbfkN0Adku816-OBHubz4afTLzY4YO-X5PKDkiA3EF33z0Xey0tXEaTJb6iSYB1WEb4VoejiXbG82ebcqQTNEagchcMMGjElXLUihuNMRNIycqyMLEEIa-mdPyDc0shVNtvLxr6-FiYpbmg00VPhBY0RwCNRphNJ_JoMDk9Es2bNn9qoUxXRo7o0XmsJtE-xQq4O8RGEAD7qVQFpKzx_yfWcIfES-3vSgoZTuffuIEDODy2ASoTtegCgz3LLu2Qg5tCLm28BN2LqiRbYn-nL1XYLmc4lroy9eahPTT41y2b5yc5-JOi22MchoJQsFJBh-tVehiVQ9S2tii9o-A-Px-eh8x3B6Aeqcfz4Y9htEMWn8bXj0A622DQpQdAq_u_x7l8dLmaFbd9bDGYxNj2U5I-wZWmfMi-Hkcn94QLWLqaqKD32lePGwc_6BErXZSr51dKcJjAYWdc4cvZuhtrIDHsDR79BvyaCnanI00sRePtT28l2d8kgqRCRO0SeEo1ceblYDAupXHB1vML1R30XoNjyR0U1nuRk_UfMMSAC-G6DZKAMDcmJEuALTfy22tyZhykynqfmqRPl9jNHsk6yFN0ZAj2pNTYUMTOIbmzW8YWK5yFGv_kDljaaegI1lfOj6NJO708=&xkcb=SoD16_M331x-WqyLNB0BbzkdCdPP&camk=ethIe0s0hedh9yg7E_9g5A==&p=4&fvj=0&vjs=3  Title: Associate Software Developer Company: Aspen Technology URL: https://www.indeed.com/rc/clk?jk=7756b67b5792632f&bb=14wI_Ylq6Fgk36O9dVMYwBeTYi-61Wkb7sWVkrwAyiBStf9NK9vbSPUrNYj0ThY9zJUOjtd-9YX3H_wey0FTAIagHJhHHEaFrWxnvtYgL5t5701wFAdbqQ%3D%3D&xkcb=SoC167M331x-WqyLNB0AbzkdCdPP&fccid=aa61d43e9b452410&vjs=3  Title: Experienced Software Engineer across a wide array of tech stacks Company: Infinity Software Development, Inc URL: https://www.indeed.com/pagead/clk?mo=r&ad=-6NYlbfkN0DXKDYI_yepg0NlIxbNRNpLYk6-xAUlLi5O8UrMeMQSh13NFas3aZcKUoDmffy5epMXeY-zhdbmUkRqvRX4t3icq8DjhhYQs_LwSZn2GVwbjRGidLxi3Sof_2aBeoQD6wYD6m_HuwHaiCyhiBReEuf3nRDx0TjXj-fZp9pfU46PUpQdwUNRUDQJT0pa-nM770SIdJOBVOwl5BJBozcMBPyssDgmqoBbSQg_WDZAvrqw0fvHcFfG-NxdLqjMzmP6cv4mS5ouACuJXWz1yhSlIzhJQpjEvdHHbHFL-dH3SNETQUuig-pGnygaN4hzJn9oPOZgbJV2VB74xCG9U7R7NRZXnH88Oi9W20HtdpArO8z4cagQWXIO6JeyN1AEiqWJ8-ilQXPCQmEo0LXeAXf8vpRnwt8A12E3B9v5cj_bNDt9j-owai9Fms794YXGeJyFDSfJUXyTCVu_wzoASkNE40LY2HLivwdqplfYd_YhKtMZGdcHB0gJV9AzgJlFzXCgNLnZNFeTpJfV-Y0UHg1it7Ehe1GGAnjlFRVp2sAgvFd5HiNEaNnQjZPI5MQP6H1iCPOjG1FNPvmxcDA3ZKOC6d0UuAw0CMhN0qWt9AgKWzGuAdLHDvsxKWJK380yzCo2HR-7l8TbHN55nJrJKwxwT0-jhkkVBjZr3Ug-OBek1mmW20VaW7C-Whs_8746rIWADRk=&xkcb=SoDP6_M331x-WqyLNB0HbzkdCdPP&camk=ethIe0s0hed6QKoT7ElUpg==&p=6&fvj=0&vjs=3  Title: Sr Developer/Full Stack (Remote - Hybrid: Twin Cities/St Peter) Company: Scholarship America URL: https://www.indeed.com/rc/clk?jk=74febd0647bc821a&bb=14wI_Ylq6Fgk36O9dVMYwFwi45UQKQtqk4WZZMmpsiiUz8j4x0zJyLmZC7WZhxfcycZV8yRObikAWhHhoeHagZUjKLiCKo4Bw4YwyZ9erBKg_wUj4oItwQ_aO61CXJ3A&xkcb=SoCP67M331x-WqyLNB0GbzkdCdPP&fccid=cce1c4ec59975253&vjs=3  Title: Junior Front End Engineer Company: minware URL: https://www.indeed.com/rc/clk?jk=1726df0b08d5cb30&bb=14wI_Ylq6Fgk36O9dVMYwIJGuhxgMnyLiRtdAXs1WpMSx4pmjP1NCF6rXmhjL9kmk0VFjkhx2NjKWYuHHI9UT0nJis7mlxKdUe9rQr2MlSVJXTQKjDC84fz4WniMlOTK&xkcb=SoAS67M331x-WqyLNB0FbzkdCdPP&fccid=01b27327b9e5d576&vjs=3  Title: Website Programmer Front End - Entry Level Company: Trib Total Media URL: https://www.indeed.com/rc/clk?jk=0eb7983c4faf698d&bb=14wI_Ylq6Fgk36O9dVMYwNIjrG7D-mlEl58-pC9B-d25tD4J7CygSnkKmUpIzuZa8LaCK7pRibpBYCgeao7FdIrnOYAyyZBS1VAb5vAognOaHjfzzKIRl4H6CFkJ3Wda&xkcb=SoCm67M331x-WqyLNB0EbzkdCdPP&fccid=bfe81a77e3f1c572&vjs=3  Title: Full Stack Java Software Engineer - Remote Company: Kunz, Leigh & Associates URL: https://www.indeed.com/pagead/clk?mo=r&ad=-6NYlbfkN0CG0MOFnlYlPQ1Ern0f6lCNr2JCUFSORbPgdH34SplLNydtjSZB1rlqGTh485AdjPSqq2mha0KhGUAFe_iVnt7WAxoq5oy5SzhnieRSG7F-bqhL2z7e-e0EELbybjnN-nt9yxVpskkxcmIH3RG8CiGEjmqW8QZ-0XsdQHhf81y2draoyxPcj-dWZwJuaZa7WW7jWZtwBxQeslg97BeQYjRKHuu60pedz06vZ6OZDeOaAQUkm6fHNTSO4URZXI60op_5an3tRDVhrAY-YR0231Kyd7F4SrUa3RtD1W6DRYWWCdJ9mEXi6Cbm9pbZll9MbAc5OPCAUSsQRBcZ_JCZqum-1ANE7GxBO8GJgqRUTSuWdK8H1SVoHkytBllgBM8WzXq902wqKpW6oc2WLo_1mXJijpKOj01JybvWbLQPWlwkifDCk81gKvs8vWOg0G8dVtjgqSXSh6iCHPYjJoeRZ6uc0naz8ORpgzOfjtfjG_C7EaFWFs712D9uhTPU0rDmoO1SDsMeedz_Tk29C0r0Y-PUM515B-QtV746k0adcRUs6U_h15g1JCCHCdnP7iyLp2siK8BomkQxFrrbyQvviKSjcnyPgoDvDkePQcAzMwOVXHC_5QCwQwJwXYwaIELtu-VkD6UZyQp2kQ1om-LgprZp8KbfSQsim6jevJMCU3n03a7dxbfabgAuxrdJarQe7HQ=&xkcb=SoB16_M331x-WqyLNB0bbzkdCdPP&camk=ethIe0s0heckLFYoCs5mAw==&p=10&fvj=0&vjs=3  Title: Automation Controls Engineer Company: Actalent URL: https://www.indeed.com/pagead/clk?mo=r&ad=-6NYlbfkN0ChYVx_I3yfZ_JDY3EFoivtqvi_stwnZ_kRt8Dowt_l_TGXG89DEg1MfkawasLJpdJGA_HZgfzeZTJl34XGhVdaz_Cs1jcd2oL_83p86XeBHyQt1xpcm0QBZ1ewavzDCOSeWMhihqthB5aqwE_YTSaqQ073Kj_AkRRU_BJ-fa6aUiUurCeiSnyngWnjm2Z7vIdFA0T7Gfogg9RZcSwG9kI28M5L-AUMSPHjxgKNlD-Eef9hXB_zYfIjzdc7BWtWzFJVxv61AJ_b5JeMmmYOgfS0TN5GZVpAbVZrPSnJKKTMOF20nV-tNuoy5uRoPetrubKqPh2Yz5K8Fpn-c4H3AJ5P8mdVTKR0FdRlLB2YJlC6lN8HBFFaQlc_5vhETCpfZsEjV8xt13C2PkDlAbHlsi2_bc0gwWiY2S2dLVSwFqHdwPPxUgVQU8o8p2bfAampuX1DDnL7uUph4-djTn_r18LatyrvGoTXP0gyr7c9563kGTJs6qM0kp6zTvnn9dY-OwRiZKW9SsbRDKSv5PsAoDwQEsedEFRpbceJ68Tf5s2NfyE-t-Ct5vWUPhDGrQfgDMEOBamhXDSwLSllQva-lUv1eXctYfma69BMDN-cGHNikOyYeIkJMXsGIYAesGxqxiGJgvJtKnaT-Bggz1YksF97HT4dAg3IWLLnw0HIDQ8iaE3tLWz7BEFXJkaw5x0Ex_Qa_lA8lZiPf1u1bGHA4V7OrqmOxAyhWLbiuD6pRdDKs0x6bGVo2jsrG_jOelfxDlhudRGmRHUfcDkYn4HM9KHCkwjVyqM2lUhUtwFiDGfkYR6dLCt9puGalVDfeDDWzQYxz0Mbbhlydk5TiWnEGWKwXDvEkT-7HH_fv6fYVlfrZQ7tl6rVES4ZmtjndPPuNHxUB-fIfNMiAyjBFwR9gC5U-Mn9pggoHd91V_tRyNkU0F0eZR_OII-i-9JTv5hHK7mzS1U97rGeQWHxJdAcmndx9_-aV93etsG0aXzud823Lp8N_hy-yuzaqrKw8wRJtywQvjVM87L0rDKC6ywEPD2SHH2bkYEjbvwqb4JUuWmRix5M9C-cKyGsue0zLU1gwkj3xpvQkFWglW_56Ax1k_AAdEg6nbWKEAwLF9k18ed3CZTCNLx-jXs9Af67AL0sNjWaYM7nK8v2RcVgi7KEDuFZ8PPBlz6QAng=&xkcb=SoDB6_M331x-WqyLNB0abzkdCdPP&camk=ethIe0s0heet03p6ceh7aQ==&p=11&fvj=0&vjs=3  Title: Web Developer Company: Advanced Textiles Association URL: https://www.indeed.com/rc/clk?jk=35d6a1e7d41883c6&bb=14wI_Ylq6Fgk36O9dVMYwPYbJSJTPsz6pBat02VgYD4oAvO1twXWUcA3662iAcbLG9uukrWxckyX1E8I1nooh6VIe5XjWZKCxy1TZUS_Y6KUHX_i9lXEiw5iaWsINs70&xkcb=SoCo67M331x-WqyLNB0ZbzkdCdPP&fccid=bff9bd06a5dfd66c&vjs=3  Title: Front End Developer (contract) Company: BNY Mellon URL: https://www.indeed.com/rc/clk?jk=c9d611112809b2fc&bb=14wI_Ylq6Fgk36O9dVMYwAZBeK7bWdQp88iaoLc3uCoEfOWYIbz6digX5Y2vnsZ_MWfcliQa-OVC8Z2ksf9sUg9iN8BB-oud8IOHDpD0WvCJPqx7a9D_dDEG7VVDJ8WR&xkcb=SoAc67M331x-WqyLNB0YbzkdCdPP&fccid=b4048be2884af072&vjs=3  Title: Junior Software Engineer Company: SureCost URL: https://www.indeed.com/rc/clk?jk=68417c24846ae606&bb=14wI_Ylq6Fgk36O9dVMYwNZPbDmcwIHLTyhI5wapbEJJ4fmF07f-RZK7D0eEsTOiAVa2A30ososwTraie2VAdHTCovYglcdfNEMxRU1iNX3HnctGTkrAsLSEz4015svk&xkcb=SoCS67M331x-WqyLNB0fbzkdCdPP&fccid=dd616958bd9ddc12&vjs=3</td><td>developer</td><td>Work mode: Hybrid Onsite Location(s): Maple Grove, MN, US, 55311 Additional Location(s): US-MN-Maple Grove Diversity - Innovation - Caring - Global Collaboration - Winning Spirit - High Performance At Boston Scientific, we’ll give you the opportunity to harness all that’s within you by working in teams of diverse and high-performing employees, tackling some of the most important health industry challenges. With access to the latest tools, information and training, we’ll help you in advancing your skills and career. Here, you’ll be supported in progressing – whatever your ambitions. The Instructional Designer Content Developer (Cardiology Training) works closely with business partners, subject matter experts (SMEs), and other key stakeholders to plan and develop high-quality learning experiences to support business goals. This individual is responsible for the development of content, which may include interactive, multimedia, instructor led. This position reports to the Cardiology Training Operations Manager. Candidates will provide work portfolio as part of the application process. The interview will include a portfolio review and discussion. Your responsibilities will include: Partnering with subject matter experts and other stakeholders to analyze the learning needs. Planning, organizing, and developing learning solutions using a variety of modalities. Synthesizing and translating technical information into clear, effective, and engaging learning. Ensuring a consistent approach to the learning experience. Being proficient with a wide variety of learning tools, including but not limited to Storyline, RISE, game-based learning, videos, InDesign. Managing multiple projects with frequent priority shifts, working with high attention to accuracy and detail, and delivering within expected timelines. Being familiar with Learning Management Systems, as it relates to ensuring content works appropriately. Managing and organizing content in a centralized repository to ensure accuracy of material. Minimum Qualifications: Bachelor’s degree and/or equivalent of industry experience Four years of Instructional Design and content creation Innovative, curious mindset and ability to work independently to meet deadlines Excellent written and verbal communication skills Experience editing content for clarity and accuracy Experience using Microsoft 365 tools Experience using Articulate 360 software Experience using video editing software Experience using software to create animated characters Experience using Adobe InDesign Preferred Qualifications: Experience working within an FDA regulated environment Experience using Sales and Learning Enablement Platforms, (such as Showpad, Allego, SmartWinnr, etc) Requisition ID: 598020 Minimum Salary: $ 99100 Maximum Salary: $ 188300 Compensation for non-exempt (hourly), non-sales roles may also include variable compensation from time to time (e.g., any overtime and shift differential) and annual bonus target (subject to plan eligibility and other requirements). Compensation for exempt, non-sales roles may also include variable compensation, i.e., annual bonus target and long-term incentives (subject to plan eligibility and other requirements. For MA positions: It is unlawful to require or administer a lie detector test for employment. Violators are subject to criminal penalties and civil liability. As a leader in medical science for more than 40 years, we are committed to solving the challenges that matter most – united by a deep caring for human life. Our mission to advance science for life is about transforming lives through innovative medical solutions that improve patient lives, create value for our customers, and support our employees and the communities in which we operate. Now more than ever, we have a responsibility to apply those values to everything we do – as a global business and as a global corporate citizen. So, choosing a career with Boston Scientific (NYSE: BSX) isn’t just business, it’s personal. And if you’re a natural problem-solver with the imagination, determination, and spirit to make a meaningful difference to people worldwide, we encourage you to apply and look forward to connecting with you! At Boston Scientific, we recognize that nurturing a diverse and inclusive workplace helps us be more innovative and it is important in our work of advancing science for life and improving patient health. That is why we stand for inclusion, equality, and opportunity for all. By embracing the richness of our unique backgrounds and perspectives, we create a better, more rewarding place for our employees to work and reflect the patients, customers, and communities we serve. Boston Scientific Corporation has been and will continue to be an equal opportunity employer. To ensure full implementation of its equal employment policy, the Company will continue to take steps to assure that recruitment, hiring, assignment, promotion, compensation, and all other personnel decisions are made and administered without regard to race, religion, color, national origin, citizenship, sex, sexual orientation, gender identify, gender expression, veteran status, age, mental or physical disability, genetic information or any other protected class. Please be advised that certain US based positions, including without limitation field sales and service positions that call on hospitals and/or health care centers, require acceptable proof of COVID-19 vaccination status. Candidates will be notified during the interview and selection process if the role(s) for which they have applied require proof of vaccination as a condition of employment. Boston Scientific continues to evaluate its policies and protocols regarding the COVID-19 vaccine and will comply with all applicable state and federal law and healthcare credentialing requirements. As employees of the Company, you will be expected to meet the ongoing requirements for your roles, including any new requirements, should the Company’s policies or protocols change with regard to COVID-19 vaccination. Nearest Major Market: Minneapolis Job Segment: Learning, Testing, Developer, Programmer, Information Technology, Human Resources, Technology Title: Software Engineer Company: Specialty Capital URL:   Title: Software Safety Engineer Company: Entegee URL:   Title: Entry Level Java Developer Company: Hemma Systems Inc. URL:   Title: Software Engineer II - C# (Remote) Company: McDonald's Corporation URL:   Title: Manager, Software Engineering Company: Balboa Digital Inc URL:   Title: Associate Software Developer Company: Aspen Technology URL:   Title: Experienced Software Engineer across a wide array of tech stacks Company: Infinity Software Development, Inc URL:   Title: Sr Developer/Full Stack (Remote - Hybrid: Twin Cities/St Peter) Company: Scholarship America URL:   Title: Junior Front End Engineer Company: minware URL:   Title: Website Programmer Front End - Entry Level Company: Trib Total Media URL:   Title: Full Stack Java Software Engineer - Remote Company: Kunz, Leigh & Associates URL:   Title: Automation Controls Engineer Company: Actalent URL:   Title: Web Developer Company: Advanced Textiles Association URL:   Title: Front End Developer (contract) Company: BNY Mellon URL:   Title: Junior Software Engineer Company: SureCost URL: </td><td>Work mode: Hybrid Onsite Location(s): Maple Grove, MN, US, 55311 Additional Location(s): US-MN-Maple Grove Diversity - Innovation - Caring - Global Collaboration - Winning Spirit - High Performance At Boston Scientific, we’ll give you the opportunity to harness all that’s within you by working in teams of diverse and high-performing employees, tackling some of the most important health industry challenges. With access to the latest tools, information and training, we’ll help you in advancing your skills and career. Here, you’ll be supported in progressing – whatever your ambitions. The Instructional Designer Content Developer (Cardiology Training) works closely with business partners, subject matter experts (SMEs), and other key stakeholders to plan and develop high-quality learning experiences to support business goals. This individual is responsible for the development of content, which may include interactive, multimedia, instructor led. This position reports to the Cardiology Training Operations Manager. Candidates will provide work portfolio as part of the application process. The interview will include a portfolio review and discussion. Your responsibilities will include: Partnering with subject matter experts and other stakeholders to analyze the learning needs. Planning, organizing, and developing learning solutions using a variety of modalities. Synthesizing and translating technical information into clear, effective, and engaging learning. Ensuring a consistent approach to the learning experience. Being proficient with a wide variety of learning tools, including but not limited to Storyline, RISE, game-based learning, videos, InDesign. Managing multiple projects with frequent priority shifts, working with high attention to accuracy and detail, and delivering within expected timelines. Being familiar with Learning Management Systems, as it relates to ensuring content works appropriately. Managing and organizing content in a centralized repository to ensure accuracy of material. Minimum Qualifications: Bachelor’s degree and/or equivalent of industry experience Four years of Instructional Design and content creation Innovative, curious mindset and ability to work independently to meet deadlines Excellent written and verbal communication skills Experience editing content for clarity and accuracy Experience using Microsoft 365 tools Experience using Articulate 360 software Experience using video editing software Experience using software to create animated characters Experience using Adobe InDesign Preferred Qualifications: Experience working within an FDA regulated environment Experience using Sales and Learning Enablement Platforms, (such as Showpad, Allego, SmartWinnr, etc) Requisition ID: 598020 Minimum Salary: $ 99100 Maximum Salary: $ 188300 Compensation for non-exempt (hourly), non-sales roles may also include variable compensation from time to time (e.g., any overtime and shift differential) and annual bonus target (subject to plan eligibility and other requirements). Compensation for exempt, non-sales roles may also include variable compensation, i.e., annual bonus target and long-term incentives (subject to plan eligibility and other requirements. For MA positions: It is unlawful to require or administer a lie detector test for employment. Violators are subject to criminal penalties and civil liability. As a leader in medical science for more than 40 years, we are committed to solving the challenges that matter most – united by a deep caring for human life. Our mission to advance science for life is about transforming lives through innovative medical solutions that improve patient lives, create value for our customers, and support our employees and the communities in which we operate. Now more than ever, we have a responsibility to apply those values to everything we do – as a global business and as a global corporate citizen. So, choosing a career with Boston Scientific (NYSE: BSX) isn’t just business, it’s personal. And if you’re a natural problem-solver with the imagination, determination, and spirit to make a meaningful difference to people worldwide, we encourage you to apply and look forward to connecting with you! At Boston Scientific, we recognize that nurturing a diverse and inclusive workplace helps us be more innovative and it is important in our work of advancing science for life and improving patient health. That is why we stand for inclusion, equality, and opportunity for all. By embracing the richness of our unique backgrounds and perspectives, we create a better, more rewarding place for our employees to work and reflect the patients, customers, and communities we serve. Boston Scientific Corporation has been and will continue to be an equal opportunity employer. To ensure full implementation of its equal employment policy, the Company will continue to take steps to assure that recruitment, hiring, assignment, promotion, compensation, and all other personnel decisions are made and administered without regard to race, religion, color, national origin, citizenship, sex, sexual orientation, gender identify, gender expression, veteran status, age, mental or physical disability, genetic information or any other protected class. Please be advised that certain US based positions, including without limitation field sales and service positions that call on hospitals and/or health care centers, require acceptable proof of COVID-19 vaccination status. Candidates will be notified during the interview and selection process if the role(s) for which they have applied require proof of vaccination as a condition of employment. Boston Scientific continues to evaluate its policies and protocols regarding the COVID-19 vaccine and will comply with all applicable state and federal law and healthcare credentialing requirements. As employees of the Company, you will be expected to meet the ongoing requirements for your roles, including any new requirements, should the Company’s policies or protocols change with regard to COVID-19 vaccination. Nearest Major Market: Minneapolis Job Segment: Learning, Testing, Developer, Programmer, Information Technology, Human Resources, Technology Title: Software Engineer Company: Specialty Capital URL:   Title: Software Safety Engineer Company: Entegee URL:   Title: Entry Level Java Developer Company: Hemma Systems Inc. URL:   Title: Software Engineer II - C# (Remote) Company: McDonald's Corporation URL:   Title: Manager, Software Engineering Company: Balboa Digital Inc URL:   Title: Associate Software Developer Company: Aspen Technology URL:   Title: Experienced Software Engineer across a wide array of tech stacks Company: Infinity Software Development, Inc URL:   Title: Sr Developer/Full Stack (Remote - Hybrid: Twin Cities/St Peter) Company: Scholarship America URL:   Title: Junior Front End Engineer Company: minware URL:   Title: Website Programmer Front End - Entry Level Company: Trib Total Media URL:   Title: Full Stack Java Software Engineer - Remote Company: Kunz, Leigh & Associates URL:   Title: Automation Controls Engineer Company: Actalent URL:   Title: Web Developer Company: Advanced Textiles Association URL:   Title: Front End Developer (contract) Company: BNY Mellon URL:   Title: Junior Software Engineer Company: SureCost URL: </td><td>Bachelor’s degree and/or equivalent of industry experience Four years of Instructional Design and content creation Innovative, curious mindset and ability to work independently to meet deadlines Excellent written and verbal communication skills Experience editing content for clarity and accuracy Experience using Microsoft 365 tools Experience using Articulate 360 software Experience using video editing software Experience using software to create animated characters Experience using Adobe InDesign Preferred Qualifications: Experience working within an FDA regulated environment Experience using Sales and Learning Enablement Platforms, (such as Showpad, Allego, SmartWinnr, etc) Requisition ID: 598020 Minimum Salary: $ 99100 Maximum Salary: $ 188300 Compensation for non-exempt (hourly), non-sales roles may also include variable compensation from time to time (e.g., any overtime and shift differential) and annual bonus target (subject to plan eligibility and other requirements). Compensation for exempt, non-sales roles may also include variable compensation, i.e., annual bonus target and long-term incentives (subject to plan eligibility and other requirements. For MA positions: It is unlawful to require or administer a lie detector test for employment. Violators are subject to criminal penalties and civil liability. As a leader in medical science for more than 40 years, we are committed to solving the challenges that matter most – united by a deep caring for human life. Our mission to advance science for life is about transforming lives through innovative medical solutions that improve patient lives, create value for our customers, and support our employees and the communities in which we operate. Now more than ever, we have a responsibility to apply those values to everything we do – as a global business and as a global corporate citizen. So, choosing a career with Boston Scientific (NYSE: BSX) isn’t just business, it’s personal. And if you’re a natural problem-solver with the imagination, determination, and spirit to make a meaningful difference to people worldwide, we encourage you to apply and look forward to connecting with you! At Boston Scientific, we recognize that nurturing a diverse and inclusive workplace helps us be more innovative and it is important in our work of advancing science for life and improving patient health. That is why we stand for inclusion, equality, and opportunity for all. By embracing the richness of our unique backgrounds and perspectives, we create a better, more rewarding place for our employees to work and reflect the patients, customers, and communities we serve. Boston Scientific Corporation has been and will continue to be an equal opportunity employer. To ensure full implementation of its equal employment policy, the Company will continue to take steps to assure that recruitment, hiring, assignment, promotion, compensation, and all other personnel decisions are made and administered without regard to race, religion, color, national origin, citizenship, sex, sexual orientation, gender identify, gender expression, veteran status, age, mental or physical disability, genetic information or any other protected class. Please be advised that certain US based positions, including without limitation field sales and service positions that call on hospitals and/or health care centers, require acceptable proof of COVID-19 vaccination status. Candidates will be notified during the interview and selection process if the role(s) for which they have applied require proof of vaccination as a condition of employment. Boston Scientific continues to evaluate its policies and protocols regarding the COVID-19 vaccine and will comply with all applicable state and federal law and healthcare credentialing requirements. As employees of the Company, you will be expected to meet the ongoing requirements for your roles, including any new requirements, should the Company’s policies or protocols change with regard to COVID-19 vaccination. Nearest Major Market: Minneapolis Job Segment: Learning, Testing, Developer, Programmer, Information Technology, Human Resources, Technology Title: Software Engineer Company: Specialty Capital URL:   Title: Software Safety Engineer Company: Entegee URL:   Title: Entry Level Java Developer Company: Hemma Systems Inc. URL:   Title: Software Engineer II - C# (Remote) Company: McDonald's Corporation URL:   Title: Manager, Software Engineering Company: Balboa Digital Inc URL:   Title: Associate Software Developer Company: Aspen Technology URL:   Title: Experienced Software Engineer across a wide array of tech stacks Company: Infinity Software Development, Inc URL:   Title: Sr Developer/Full Stack (Remote - Hybrid: Twin Cities/St Peter) Company: Scholarship America URL:   Title: Junior Front End Engineer Company: minware URL:   Title: Website Programmer Front End - Entry Level Company: Trib Total Media URL:   Title: Full Stack Java Software Engineer - Remote Company: Kunz, Leigh & Associates URL:   Title: Automation Controls Engineer Company: Actalent URL:   Title: Web Developer Company: Advanced Textiles Association URL:   Title: Front End Developer (contract) Company: BNY Mellon URL:   Title: Junior Software Engineer Company: SureCost URL:</td><td>752</td></tr><tr><td>Junior Software Engineer</td><td>Scholarship America</td><td>Work mode: Hybrid Onsite Location(s): Maple Grove, MN, US, 55311 Additional Location(s): US-MN-Maple Grove Diversity - Innovation - Caring - Global Collaboration - Winning Spirit - High Performance At Boston Scientific, we’ll give you the opportunity to harness all that’s within you by working in teams of diverse and high-performing employees, tackling some of the most important health industry challenges. With access to the latest tools, information and training, we’ll help you in advancing your skills and career. Here, you’ll be supported in progressing – whatever your ambitions. The Instructional Designer Content Developer (Cardiology Training) works closely with business partners, subject matter experts (SMEs), and other key stakeholders to plan and develop high-quality learning experiences to support business goals. This individual is responsible for the development of content, which may include interactive, multimedia, instructor led. This position reports to the Cardiology Training Operations Manager. Candidates will provide work portfolio as part of the application process. The interview will include a portfolio review and discussion. Your responsibilities will include: Partnering with subject matter experts and other stakeholders to analyze the learning needs. Planning, organizing, and developing learning solutions using a variety of modalities. Synthesizing and translating technical information into clear, effective, and engaging learning. Ensuring a consistent approach to the learning experience. Being proficient with a wide variety of learning tools, including but not limited to Storyline, RISE, game-based learning, videos, InDesign. Managing multiple projects with frequent priority shifts, working with high attention to accuracy and detail, and delivering within expected timelines. Being familiar with Learning Management Systems, as it relates to ensuring content works appropriately. Managing and organizing content in a centralized repository to ensure accuracy of material. Minimum Qualifications: Bachelor’s degree and/or equivalent of industry experience Four years of Instructional Design and content creation Innovative, curious mindset and ability to work independently to meet deadlines Excellent written and verbal communication skills Experience editing content for clarity and accuracy Experience using Microsoft 365 tools Experience using Articulate 360 software Experience using video editing software Experience using software to create animated characters Experience using Adobe InDesign Preferred Qualifications: Experience working within an FDA regulated environment Experience using Sales and Learning Enablement Platforms, (such as Showpad, Allego, SmartWinnr, etc) Requisition ID: 598020 Minimum Salary: $ 99100 Maximum Salary: $ 188300 Compensation for non-exempt (hourly), non-sales roles may also include variable compensation from time to time (e.g., any overtime and shift differential) and annual bonus target (subject to plan eligibility and other requirements). Compensation for exempt, non-sales roles may also include variable compensation, i.e., annual bonus target and long-term incentives (subject to plan eligibility and other requirements. For MA positions: It is unlawful to require or administer a lie detector test for employment. Violators are subject to criminal penalties and civil liability. As a leader in medical science for more than 40 years, we are committed to solving the challenges that matter most – united by a deep caring for human life. Our mission to advance science for life is about transforming lives through innovative medical solutions that improve patient lives, create value for our customers, and support our employees and the communities in which we operate. Now more than ever, we have a responsibility to apply those values to everything we do – as a global business and as a global corporate citizen. So, choosing a career with Boston Scientific (NYSE: BSX) isn’t just business, it’s personal. And if you’re a natural problem-solver with the imagination, determination, and spirit to make a meaningful difference to people worldwide, we encourage you to apply and look forward to connecting with you! At Boston Scientific, we recognize that nurturing a diverse and inclusive workplace helps us be more innovative and it is important in our work of advancing science for life and improving patient health. That is why we stand for inclusion, equality, and opportunity for all. By embracing the richness of our unique backgrounds and perspectives, we create a better, more rewarding place for our employees to work and reflect the patients, customers, and communities we serve. Boston Scientific Corporation has been and will continue to be an equal opportunity employer. To ensure full implementation of its equal employment policy, the Company will continue to take steps to assure that recruitment, hiring, assignment, promotion, compensation, and all other personnel decisions are made and administered without regard to race, religion, color, national origin, citizenship, sex, sexual orientation, gender identify, gender expression, veteran status, age, mental or physical disability, genetic information or any other protected class. Please be advised that certain US based positions, including without limitation field sales and service positions that call on hospitals and/or health care centers, require acceptable proof of COVID-19 vaccination status. Candidates will be notified during the interview and selection process if the role(s) for which they have applied require proof of vaccination as a condition of employment. Boston Scientific continues to evaluate its policies and protocols regarding the COVID-19 vaccine and will comply with all applicable state and federal law and healthcare credentialing requirements. As employees of the Company, you will be expected to meet the ongoing requirements for your roles, including any new requirements, should the Company’s policies or protocols change with regard to COVID-19 vaccination. Nearest Major Market: Minneapolis Job Segment: Learning, Testing, Developer, Programmer, Information Technology, Human Resources, Technology</td><td>developer</td><td>Work mode: Hybrid Onsite Location(s): Maple Grove, MN, US, 55311 Additional Location(s): US-MN-Maple Grove Diversity - Innovation - Caring - Global Collaboration - Winning Spirit - High Performance At Boston Scientific, we’ll give you the opportunity to harness all that’s within you by working in teams of diverse and high-performing employees, tackling some of the most important health industry challenges. With access to the latest tools, information and training, we’ll help you in advancing your skills and career. Here, you’ll be supported in progressing – whatever your ambitions. The Instructional Designer Content Developer (Cardiology Training) works closely with business partners, subject matter experts (SMEs), and other key stakeholders to plan and develop high-quality learning experiences to support business goals. This individual is responsible for the development of content, which may include interactive, multimedia, instructor led. This position reports to the Cardiology Training Operations Manager. Candidates will provide work portfolio as part of the application process. The interview will include a portfolio review and discussion. Your responsibilities will include: Partnering with subject matter experts and other stakeholders to analyze the learning needs. Planning, organizing, and developing learning solutions using a variety of modalities. Synthesizing and translating technical information into clear, effective, and engaging learning. Ensuring a consistent approach to the learning experience. Being proficient with a wide variety of learning tools, including but not limited to Storyline, RISE, game-based learning, videos, InDesign. Managing multiple projects with frequent priority shifts, working with high attention to accuracy and detail, and delivering within expected timelines. Being familiar with Learning Management Systems, as it relates to ensuring content works appropriately. Managing and organizing content in a centralized repository to ensure accuracy of material. Minimum Qualifications: Bachelor’s degree and/or equivalent of industry experience Four years of Instructional Design and content creation Innovative, curious mindset and ability to work independently to meet deadlines Excellent written and verbal communication skills Experience editing content for clarity and accuracy Experience using Microsoft 365 tools Experience using Articulate 360 software Experience using video editing software Experience using software to create animated characters Experience using Adobe InDesign Preferred Qualifications: Experience working within an FDA regulated environment Experience using Sales and Learning Enablement Platforms, (such as Showpad, Allego, SmartWinnr, etc) Requisition ID: 598020 Minimum Salary: $ 99100 Maximum Salary: $ 188300 Compensation for non-exempt (hourly), non-sales roles may also include variable compensation from time to time (e.g., any overtime and shift differential) and annual bonus target (subject to plan eligibility and other requirements). Compensation for exempt, non-sales roles may also include variable compensation, i.e., annual bonus target and long-term incentives (subject to plan eligibility and other requirements. For MA positions: It is unlawful to require or administer a lie detector test for employment. Violators are subject to criminal penalties and civil liability. As a leader in medical science for more than 40 years, we are committed to solving the challenges that matter most – united by a deep caring for human life. Our mission to advance science for life is about transforming lives through innovative medical solutions that improve patient lives, create value for our customers, and support our employees and the communities in which we operate. Now more than ever, we have a responsibility to apply those values to everything we do – as a global business and as a global corporate citizen. So, choosing a career with Boston Scientific (NYSE: BSX) isn’t just business, it’s personal. And if you’re a natural problem-solver with the imagination, determination, and spirit to make a meaningful difference to people worldwide, we encourage you to apply and look forward to connecting with you! At Boston Scientific, we recognize that nurturing a diverse and inclusive workplace helps us be more innovative and it is important in our work of advancing science for life and improving patient health. That is why we stand for inclusion, equality, and opportunity for all. By embracing the richness of our unique backgrounds and perspectives, we create a better, more rewarding place for our employees to work and reflect the patients, customers, and communities we serve. Boston Scientific Corporation has been and will continue to be an equal opportunity employer. To ensure full implementation of its equal employment policy, the Company will continue to take steps to assure that recruitment, hiring, assignment, promotion, compensation, and all other personnel decisions are made and administered without regard to race, religion, color, national origin, citizenship, sex, sexual orientation, gender identify, gender expression, veteran status, age, mental or physical disability, genetic information or any other protected class. Please be advised that certain US based positions, including without limitation field sales and service positions that call on hospitals and/or health care centers, require acceptable proof of COVID-19 vaccination status. Candidates will be notified during the interview and selection process if the role(s) for which they have applied require proof of vaccination as a condition of employment. Boston Scientific continues to evaluate its policies and protocols regarding the COVID-19 vaccine and will comply with all applicable state and federal law and healthcare credentialing requirements. As employees of the Company, you will be expected to meet the ongoing requirements for your roles, including any new requirements, should the Company’s policies or protocols change with regard to COVID-19 vaccination. Nearest Major Market: Minneapolis Job Segment: Learning, Testing, Developer, Programmer, Information Technology, Human Resources, Technology</td><td>Work mode: Hybrid Onsite Location(s): Maple Grove, MN, US, 55311 Additional Location(s): US-MN-Maple Grove Diversity - Innovation - Caring - Global Collaboration - Winning Spirit - High Performance At Boston Scientific, we’ll give you the opportunity to harness all that’s within you by working in teams of diverse and high-performing employees, tackling some of the most important health industry challenges. With access to the latest tools, information and training, we’ll help you in advancing your skills and career. Here, you’ll be supported in progressing – whatever your ambitions. The Instructional Designer Content Developer (Cardiology Training) works closely with business partners, subject matter experts (SMEs), and other key stakeholders to plan and develop high-quality learning experiences to support business goals. This individual is responsible for the development of content, which may include interactive, multimedia, instructor led. This position reports to the Cardiology Training Operations Manager. Candidates will provide work portfolio as part of the application process. The interview will include a portfolio review and discussion. Your responsibilities will include: Partnering with subject matter experts and other stakeholders to analyze the learning needs. Planning, organizing, and developing learning solutions using a variety of modalities. Synthesizing and translating technical information into clear, effective, and engaging learning. Ensuring a consistent approach to the learning experience. Being proficient with a wide variety of learning tools, including but not limited to Storyline, RISE, game-based learning, videos, InDesign. Managing multiple projects with frequent priority shifts, working with high attention to accuracy and detail, and delivering within expected timelines. Being familiar with Learning Management Systems, as it relates to ensuring content works appropriately. Managing and organizing content in a centralized repository to ensure accuracy of material. Minimum Qualifications: Bachelor’s degree and/or equivalent of industry experience Four years of Instructional Design and content creation Innovative, curious mindset and ability to work independently to meet deadlines Excellent written and verbal communication skills Experience editing content for clarity and accuracy Experience using Microsoft 365 tools Experience using Articulate 360 software Experience using video editing software Experience using software to create animated characters Experience using Adobe InDesign Preferred Qualifications: Experience working within an FDA regulated environment Experience using Sales and Learning Enablement Platforms, (such as Showpad, Allego, SmartWinnr, etc) Requisition ID: 598020 Minimum Salary: $ 99100 Maximum Salary: $ 188300 Compensation for non-exempt (hourly), non-sales roles may also include variable compensation from time to time (e.g., any overtime and shift differential) and annual bonus target (subject to plan eligibility and other requirements). Compensation for exempt, non-sales roles may also include variable compensation, i.e., annual bonus target and long-term incentives (subject to plan eligibility and other requirements. For MA positions: It is unlawful to require or administer a lie detector test for employment. Violators are subject to criminal penalties and civil liability. As a leader in medical science for more than 40 years, we are committed to solving the challenges that matter most – united by a deep caring for human life. Our mission to advance science for life is about transforming lives through innovative medical solutions that improve patient lives, create value for our customers, and support our employees and the communities in which we operate. Now more than ever, we have a responsibility to apply those values to everything we do – as a global business and as a global corporate citizen. So, choosing a career with Boston Scientific (NYSE: BSX) isn’t just business, it’s personal. And if you’re a natural problem-solver with the imagination, determination, and spirit to make a meaningful difference to people worldwide, we encourage you to apply and look forward to connecting with you! At Boston Scientific, we recognize that nurturing a diverse and inclusive workplace helps us be more innovative and it is important in our work of advancing science for life and improving patient health. That is why we stand for inclusion, equality, and opportunity for all. By embracing the richness of our unique backgrounds and perspectives, we create a better, more rewarding place for our employees to work and reflect the patients, customers, and communities we serve. Boston Scientific Corporation has been and will continue to be an equal opportunity employer. To ensure full implementation of its equal employment policy, the Company will continue to take steps to assure that recruitment, hiring, assignment, promotion, compensation, and all other personnel decisions are made and administered without regard to race, religion, color, national origin, citizenship, sex, sexual orientation, gender identify, gender expression, veteran status, age, mental or physical disability, genetic information or any other protected class. Please be advised that certain US based positions, including without limitation field sales and service positions that call on hospitals and/or health care centers, require acceptable proof of COVID-19 vaccination status. Candidates will be notified during the interview and selection process if the role(s) for which they have applied require proof of vaccination as a condition of employment. Boston Scientific continues to evaluate its policies and protocols regarding the COVID-19 vaccine and will comply with all applicable state and federal law and healthcare credentialing requirements. As employees of the Company, you will be expected to meet the ongoing requirements for your roles, including any new requirements, should the Company’s policies or protocols change with regard to COVID-19 vaccination. Nearest Major Market: Minneapolis Job Segment: Learning, Testing, Developer, Programmer, Information Technology, Human Resources, Technology</td><td>Bachelor’s degree and/or equivalent of industry experience Four years of Instructional Design and content creation Innovative, curious mindset and ability to work independently to meet deadlines Excellent written and verbal communication skills Experience editing content for clarity and accuracy Experience using Microsoft 365 tools Experience using Articulate 360 software Experience using video editing software Experience using software to create animated characters Experience using Adobe InDesign Preferred Qualifications: Experience working within an FDA regulated environment Experience using Sales and Learning Enablement Platforms, (such as Showpad, Allego, SmartWinnr, etc) Requisition ID: 598020 Minimum Salary: $ 99100 Maximum Salary: $ 188300 Compensation for non-exempt (hourly), non-sales roles may also include variable compensation from time to time (e.g., any overtime and shift differential) and annual bonus target (subject to plan eligibility and other requirements). Compensation for exempt, non-sales roles may also include variable compensation, i.e., annual bonus target and long-term incentives (subject to plan eligibility and other requirements. For MA positions: It is unlawful to require or administer a lie detector test for employment. Violators are subject to criminal penalties and civil liability. As a leader in medical science for more than 40 years, we are committed to solving the challenges that matter most – united by a deep caring for human life. Our mission to advance science for life is about transforming lives through innovative medical solutions that improve patient lives, create value for our customers, and support our employees and the communities in which we operate. Now more than ever, we have a responsibility to apply those values to everything we do – as a global business and as a global corporate citizen. So, choosing a career with Boston Scientific (NYSE: BSX) isn’t just business, it’s personal. And if you’re a natural problem-solver with the imagination, determination, and spirit to make a meaningful difference to people worldwide, we encourage you to apply and look forward to connecting with you! At Boston Scientific, we recognize that nurturing a diverse and inclusive workplace helps us be more innovative and it is important in our work of advancing science for life and improving patient health. That is why we stand for inclusion, equality, and opportunity for all. By embracing the richness of our unique backgrounds and perspectives, we create a better, more rewarding place for our employees to work and reflect the patients, customers, and communities we serve. Boston Scientific Corporation has been and will continue to be an equal opportunity employer. To ensure full implementation of its equal employment policy, the Company will continue to take steps to assure that recruitment, hiring, assignment, promotion, compensation, and all other personnel decisions are made and administered without regard to race, religion, color, national origin, citizenship, sex, sexual orientation, gender identify, gender expression, veteran status, age, mental or physical disability, genetic information or any other protected class. Please be advised that certain US based positions, including without limitation field sales and service positions that call on hospitals and/or health care centers, require acceptable proof of COVID-19 vaccination status. Candidates will be notified during the interview and selection process if the role(s) for which they have applied require proof of vaccination as a condition of employment. Boston Scientific continues to evaluate its policies and protocols regarding the COVID-19 vaccine and will comply with all applicable state and federal law and healthcare credentialing requirements. As employees of the Company, you will be expected to meet the ongoing requirements for your roles, including any new requirements, should the Company’s policies or protocols change with regard to COVID-19 vaccination. Nearest Major Market: Minneapolis Job Segment: Learning, Testing, Developer, Programmer, Information Technology, Human Resources, Technology</td><td>603</td></tr><tr><td>Software Engineer, Backend</td><td>CyberBalance, LLC</td><td>Work mode: Hybrid Onsite Location(s): Maple Grove, MN, US, 55311 Additional Location(s): US-MN-Maple Grove Diversity - Innovation - Caring - Global Collaboration - Winning Spirit - High Performance At Boston Scientific, we’ll give you the opportunity to harness all that’s within you by working in teams of diverse and high-performing employees, tackling some of the most important health industry challenges. With access to the latest tools, information and training, we’ll help you in advancing your skills and career. Here, you’ll be supported in progressing – whatever your ambitions. The Instructional Designer Content Developer (Cardiology Training) works closely with business partners, subject matter experts (SMEs), and other key stakeholders to plan and develop high-quality learning experiences to support business goals. This individual is responsible for the development of content, which may include interactive, multimedia, instructor led. This position reports to the Cardiology Training Operations Manager. Candidates will provide work portfolio as part of the application process. The interview will include a portfolio review and discussion. Your responsibilities will include: Partnering with subject matter experts and other stakeholders to analyze the learning needs. Planning, organizing, and developing learning solutions using a variety of modalities. Synthesizing and translating technical information into clear, effective, and engaging learning. Ensuring a consistent approach to the learning experience. Being proficient with a wide variety of learning tools, including but not limited to Storyline, RISE, game-based learning, videos, InDesign. Managing multiple projects with frequent priority shifts, working with high attention to accuracy and detail, and delivering within expected timelines. Being familiar with Learning Management Systems, as it relates to ensuring content works appropriately. Managing and organizing content in a centralized repository to ensure accuracy of material. Minimum Qualifications: Bachelor’s degree and/or equivalent of industry experience Four years of Instructional Design and content creation Innovative, curious mindset and ability to work independently to meet deadlines Excellent written and verbal communication skills Experience editing content for clarity and accuracy Experience using Microsoft 365 tools Experience using Articulate 360 software Experience using video editing software Experience using software to create animated characters Experience using Adobe InDesign Preferred Qualifications: Experience working within an FDA regulated environment Experience using Sales and Learning Enablement Platforms, (such as Showpad, Allego, SmartWinnr, etc) Requisition ID: 598020 Minimum Salary: $ 99100 Maximum Salary: $ 188300 Compensation for non-exempt (hourly), non-sales roles may also include variable compensation from time to time (e.g., any overtime and shift differential) and annual bonus target (subject to plan eligibility and other requirements). Compensation for exempt, non-sales roles may also include variable compensation, i.e., annual bonus target and long-term incentives (subject to plan eligibility and other requirements. For MA positions: It is unlawful to require or administer a lie detector test for employment. Violators are subject to criminal penalties and civil liability. As a leader in medical science for more than 40 years, we are committed to solving the challenges that matter most – united by a deep caring for human life. Our mission to advance science for life is about transforming lives through innovative medical solutions that improve patient lives, create value for our customers, and support our employees and the communities in which we operate. Now more than ever, we have a responsibility to apply those values to everything we do – as a global business and as a global corporate citizen. So, choosing a career with Boston Scientific (NYSE: BSX) isn’t just business, it’s personal. And if you’re a natural problem-solver with the imagination, determination, and spirit to make a meaningful difference to people worldwide, we encourage you to apply and look forward to connecting with you! At Boston Scientific, we recognize that nurturing a diverse and inclusive workplace helps us be more innovative and it is important in our work of advancing science for life and improving patient health. That is why we stand for inclusion, equality, and opportunity for all. By embracing the richness of our unique backgrounds and perspectives, we create a better, more rewarding place for our employees to work and reflect the patients, customers, and communities we serve. Boston Scientific Corporation has been and will continue to be an equal opportunity employer. To ensure full implementation of its equal employment policy, the Company will continue to take steps to assure that recruitment, hiring, assignment, promotion, compensation, and all other personnel decisions are made and administered without regard to race, religion, color, national origin, citizenship, sex, sexual orientation, gender identify, gender expression, veteran status, age, mental or physical disability, genetic information or any other protected class. Please be advised that certain US based positions, including without limitation field sales and service positions that call on hospitals and/or health care centers, require acceptable proof of COVID-19 vaccination status. Candidates will be notified during the interview and selection process if the role(s) for which they have applied require proof of vaccination as a condition of employment. Boston Scientific continues to evaluate its policies and protocols regarding the COVID-19 vaccine and will comply with all applicable state and federal law and healthcare credentialing requirements. As employees of the Company, you will be expected to meet the ongoing requirements for your roles, including any new requirements, should the Company’s policies or protocols change with regard to COVID-19 vaccination. Nearest Major Market: Minneapolis Job Segment: Learning, Testing, Developer, Programmer, Information Technology, Human Resources, Technology</td><td>developer</td><td>Work mode: Hybrid Onsite Location(s): Maple Grove, MN, US, 55311 Additional Location(s): US-MN-Maple Grove Diversity - Innovation - Caring - Global Collaboration - Winning Spirit - High Performance At Boston Scientific, we’ll give you the opportunity to harness all that’s within you by working in teams of diverse and high-performing employees, tackling some of the most important health industry challenges. With access to the latest tools, information and training, we’ll help you in advancing your skills and career. Here, you’ll be supported in progressing – whatever your ambitions. The Instructional Designer Content Developer (Cardiology Training) works closely with business partners, subject matter experts (SMEs), and other key stakeholders to plan and develop high-quality learning experiences to support business goals. This individual is responsible for the development of content, which may include interactive, multimedia, instructor led. This position reports to the Cardiology Training Operations Manager. Candidates will provide work portfolio as part of the application process. The interview will include a portfolio review and discussion. Your responsibilities will include: Partnering with subject matter experts and other stakeholders to analyze the learning needs. Planning, organizing, and developing learning solutions using a variety of modalities. Synthesizing and translating technical information into clear, effective, and engaging learning. Ensuring a consistent approach to the learning experience. Being proficient with a wide variety of learning tools, including but not limited to Storyline, RISE, game-based learning, videos, InDesign. Managing multiple projects with frequent priority shifts, working with high attention to accuracy and detail, and delivering within expected timelines. Being familiar with Learning Management Systems, as it relates to ensuring content works appropriately. Managing and organizing content in a centralized repository to ensure accuracy of material. Minimum Qualifications: Bachelor’s degree and/or equivalent of industry experience Four years of Instructional Design and content creation Innovative, curious mindset and ability to work independently to meet deadlines Excellent written and verbal communication skills Experience editing content for clarity and accuracy Experience using Microsoft 365 tools Experience using Articulate 360 software Experience using video editing software Experience using software to create animated characters Experience using Adobe InDesign Preferred Qualifications: Experience working within an FDA regulated environment Experience using Sales and Learning Enablement Platforms, (such as Showpad, Allego, SmartWinnr, etc) Requisition ID: 598020 Minimum Salary: $ 99100 Maximum Salary: $ 188300 Compensation for non-exempt (hourly), non-sales roles may also include variable compensation from time to time (e.g., any overtime and shift differential) and annual bonus target (subject to plan eligibility and other requirements). Compensation for exempt, non-sales roles may also include variable compensation, i.e., annual bonus target and long-term incentives (subject to plan eligibility and other requirements. For MA positions: It is unlawful to require or administer a lie detector test for employment. Violators are subject to criminal penalties and civil liability. As a leader in medical science for more than 40 years, we are committed to solving the challenges that matter most – united by a deep caring for human life. Our mission to advance science for life is about transforming lives through innovative medical solutions that improve patient lives, create value for our customers, and support our employees and the communities in which we operate. Now more than ever, we have a responsibility to apply those values to everything we do – as a global business and as a global corporate citizen. So, choosing a career with Boston Scientific (NYSE: BSX) isn’t just business, it’s personal. And if you’re a natural problem-solver with the imagination, determination, and spirit to make a meaningful difference to people worldwide, we encourage you to apply and look forward to connecting with you! At Boston Scientific, we recognize that nurturing a diverse and inclusive workplace helps us be more innovative and it is important in our work of advancing science for life and improving patient health. That is why we stand for inclusion, equality, and opportunity for all. By embracing the richness of our unique backgrounds and perspectives, we create a better, more rewarding place for our employees to work and reflect the patients, customers, and communities we serve. Boston Scientific Corporation has been and will continue to be an equal opportunity employer. To ensure full implementation of its equal employment policy, the Company will continue to take steps to assure that recruitment, hiring, assignment, promotion, compensation, and all other personnel decisions are made and administered without regard to race, religion, color, national origin, citizenship, sex, sexual orientation, gender identify, gender expression, veteran status, age, mental or physical disability, genetic information or any other protected class. Please be advised that certain US based positions, including without limitation field sales and service positions that call on hospitals and/or health care centers, require acceptable proof of COVID-19 vaccination status. Candidates will be notified during the interview and selection process if the role(s) for which they have applied require proof of vaccination as a condition of employment. Boston Scientific continues to evaluate its policies and protocols regarding the COVID-19 vaccine and will comply with all applicable state and federal law and healthcare credentialing requirements. As employees of the Company, you will be expected to meet the ongoing requirements for your roles, including any new requirements, should the Company’s policies or protocols change with regard to COVID-19 vaccination. Nearest Major Market: Minneapolis Job Segment: Learning, Testing, Developer, Programmer, Information Technology, Human Resources, Technology</td><td>Work mode: Hybrid Onsite Location(s): Maple Grove, MN, US, 55311 Additional Location(s): US-MN-Maple Grove Diversity - Innovation - Caring - Global Collaboration - Winning Spirit - High Performance At Boston Scientific, we’ll give you the opportunity to harness all that’s within you by working in teams of diverse and high-performing employees, tackling some of the most important health industry challenges. With access to the latest tools, information and training, we’ll help you in advancing your skills and career. Here, you’ll be supported in progressing – whatever your ambitions. The Instructional Designer Content Developer (Cardiology Training) works closely with business partners, subject matter experts (SMEs), and other key stakeholders to plan and develop high-quality learning experiences to support business goals. This individual is responsible for the development of content, which may include interactive, multimedia, instructor led. This position reports to the Cardiology Training Operations Manager. Candidates will provide work portfolio as part of the application process. The interview will include a portfolio review and discussion. Your responsibilities will include: Partnering with subject matter experts and other stakeholders to analyze the learning needs. Planning, organizing, and developing learning solutions using a variety of modalities. Synthesizing and translating technical information into clear, effective, and engaging learning. Ensuring a consistent approach to the learning experience. Being proficient with a wide variety of learning tools, including but not limited to Storyline, RISE, game-based learning, videos, InDesign. Managing multiple projects with frequent priority shifts, working with high attention to accuracy and detail, and delivering within expected timelines. Being familiar with Learning Management Systems, as it relates to ensuring content works appropriately. Managing and organizing content in a centralized repository to ensure accuracy of material. Minimum Qualifications: Bachelor’s degree and/or equivalent of industry experience Four years of Instructional Design and content creation Innovative, curious mindset and ability to work independently to meet deadlines Excellent written and verbal communication skills Experience editing content for clarity and accuracy Experience using Microsoft 365 tools Experience using Articulate 360 software Experience using video editing software Experience using software to create animated characters Experience using Adobe InDesign Preferred Qualifications: Experience working within an FDA regulated environment Experience using Sales and Learning Enablement Platforms, (such as Showpad, Allego, SmartWinnr, etc) Requisition ID: 598020 Minimum Salary: $ 99100 Maximum Salary: $ 188300 Compensation for non-exempt (hourly), non-sales roles may also include variable compensation from time to time (e.g., any overtime and shift differential) and annual bonus target (subject to plan eligibility and other requirements). Compensation for exempt, non-sales roles may also include variable compensation, i.e., annual bonus target and long-term incentives (subject to plan eligibility and other requirements. For MA positions: It is unlawful to require or administer a lie detector test for employment. Violators are subject to criminal penalties and civil liability. As a leader in medical science for more than 40 years, we are committed to solving the challenges that matter most – united by a deep caring for human life. Our mission to advance science for life is about transforming lives through innovative medical solutions that improve patient lives, create value for our customers, and support our employees and the communities in which we operate. Now more than ever, we have a responsibility to apply those values to everything we do – as a global business and as a global corporate citizen. So, choosing a career with Boston Scientific (NYSE: BSX) isn’t just business, it’s personal. And if you’re a natural problem-solver with the imagination, determination, and spirit to make a meaningful difference to people worldwide, we encourage you to apply and look forward to connecting with you! At Boston Scientific, we recognize that nurturing a diverse and inclusive workplace helps us be more innovative and it is important in our work of advancing science for life and improving patient health. That is why we stand for inclusion, equality, and opportunity for all. By embracing the richness of our unique backgrounds and perspectives, we create a better, more rewarding place for our employees to work and reflect the patients, customers, and communities we serve. Boston Scientific Corporation has been and will continue to be an equal opportunity employer. To ensure full implementation of its equal employment policy, the Company will continue to take steps to assure that recruitment, hiring, assignment, promotion, compensation, and all other personnel decisions are made and administered without regard to race, religion, color, national origin, citizenship, sex, sexual orientation, gender identify, gender expression, veteran status, age, mental or physical disability, genetic information or any other protected class. Please be advised that certain US based positions, including without limitation field sales and service positions that call on hospitals and/or health care centers, require acceptable proof of COVID-19 vaccination status. Candidates will be notified during the interview and selection process if the role(s) for which they have applied require proof of vaccination as a condition of employment. Boston Scientific continues to evaluate its policies and protocols regarding the COVID-19 vaccine and will comply with all applicable state and federal law and healthcare credentialing requirements. As employees of the Company, you will be expected to meet the ongoing requirements for your roles, including any new requirements, should the Company’s policies or protocols change with regard to COVID-19 vaccination. Nearest Major Market: Minneapolis Job Segment: Learning, Testing, Developer, Programmer, Information Technology, Human Resources, Technology</td><td>Bachelor’s degree and/or equivalent of industry experience Four years of Instructional Design and content creation Innovative, curious mindset and ability to work independently to meet deadlines Excellent written and verbal communication skills Experience editing content for clarity and accuracy Experience using Microsoft 365 tools Experience using Articulate 360 software Experience using video editing software Experience using software to create animated characters Experience using Adobe InDesign Preferred Qualifications: Experience working within an FDA regulated environment Experience using Sales and Learning Enablement Platforms, (such as Showpad, Allego, SmartWinnr, etc) Requisition ID: 598020 Minimum Salary: $ 99100 Maximum Salary: $ 188300 Compensation for non-exempt (hourly), non-sales roles may also include variable compensation from time to time (e.g., any overtime and shift differential) and annual bonus target (subject to plan eligibility and other requirements). Compensation for exempt, non-sales roles may also include variable compensation, i.e., annual bonus target and long-term incentives (subject to plan eligibility and other requirements. For MA positions: It is unlawful to require or administer a lie detector test for employment. Violators are subject to criminal penalties and civil liability. As a leader in medical science for more than 40 years, we are committed to solving the challenges that matter most – united by a deep caring for human life. Our mission to advance science for life is about transforming lives through innovative medical solutions that improve patient lives, create value for our customers, and support our employees and the communities in which we operate. Now more than ever, we have a responsibility to apply those values to everything we do – as a global business and as a global corporate citizen. So, choosing a career with Boston Scientific (NYSE: BSX) isn’t just business, it’s personal. And if you’re a natural problem-solver with the imagination, determination, and spirit to make a meaningful difference to people worldwide, we encourage you to apply and look forward to connecting with you! At Boston Scientific, we recognize that nurturing a diverse and inclusive workplace helps us be more innovative and it is important in our work of advancing science for life and improving patient health. That is why we stand for inclusion, equality, and opportunity for all. By embracing the richness of our unique backgrounds and perspectives, we create a better, more rewarding place for our employees to work and reflect the patients, customers, and communities we serve. Boston Scientific Corporation has been and will continue to be an equal opportunity employer. To ensure full implementation of its equal employment policy, the Company will continue to take steps to assure that recruitment, hiring, assignment, promotion, compensation, and all other personnel decisions are made and administered without regard to race, religion, color, national origin, citizenship, sex, sexual orientation, gender identify, gender expression, veteran status, age, mental or physical disability, genetic information or any other protected class. Please be advised that certain US based positions, including without limitation field sales and service positions that call on hospitals and/or health care centers, require acceptable proof of COVID-19 vaccination status. Candidates will be notified during the interview and selection process if the role(s) for which they have applied require proof of vaccination as a condition of employment. Boston Scientific continues to evaluate its policies and protocols regarding the COVID-19 vaccine and will comply with all applicable state and federal law and healthcare credentialing requirements. As employees of the Company, you will be expected to meet the ongoing requirements for your roles, including any new requirements, should the Company’s policies or protocols change with regard to COVID-19 vaccination. Nearest Major Market: Minneapolis Job Segment: Learning, Testing, Developer, Programmer, Information Technology, Human Resources, Technology</td><td>603</td></tr><tr><td>null</td><td>Steelgate LLC</td><td>Work mode: Hybrid Onsite Location(s): Maple Grove, MN, US, 55311 Additional Location(s): US-MN-Maple Grove Diversity - Innovation - Caring - Global Collaboration - Winning Spirit - High Performance At Boston Scientific, we’ll give you the opportunity to harness all that’s within you by working in teams of diverse and high-performing employees, tackling some of the most important health industry challenges. With access to the latest tools, information and training, we’ll help you in advancing your skills and career. Here, you’ll be supported in progressing – whatever your ambitions. The Instructional Designer Content Developer (Cardiology Training) works closely with business partners, subject matter experts (SMEs), and other key stakeholders to plan and develop high-quality learning experiences to support business goals. This individual is responsible for the development of content, which may include interactive, multimedia, instructor led. This position reports to the Cardiology Training Operations Manager. Candidates will provide work portfolio as part of the application process. The interview will include a portfolio review and discussion. Your responsibilities will include: Partnering with subject matter experts and other stakeholders to analyze the learning needs. Planning, organizing, and developing learning solutions using a variety of modalities. Synthesizing and translating technical information into clear, effective, and engaging learning. Ensuring a consistent approach to the learning experience. Being proficient with a wide variety of learning tools, including but not limited to Storyline, RISE, game-based learning, videos, InDesign. Managing multiple projects with frequent priority shifts, working with high attention to accuracy and detail, and delivering within expected timelines. Being familiar with Learning Management Systems, as it relates to ensuring content works appropriately. Managing and organizing content in a centralized repository to ensure accuracy of material. Minimum Qualifications: Bachelor’s degree and/or equivalent of industry experience Four years of Instructional Design and content creation Innovative, curious mindset and ability to work independently to meet deadlines Excellent written and verbal communication skills Experience editing content for clarity and accuracy Experience using Microsoft 365 tools Experience using Articulate 360 software Experience using video editing software Experience using software to create animated characters Experience using Adobe InDesign Preferred Qualifications: Experience working within an FDA regulated environment Experience using Sales and Learning Enablement Platforms, (such as Showpad, Allego, SmartWinnr, etc) Requisition ID: 598020 Minimum Salary: $ 99100 Maximum Salary: $ 188300 Compensation for non-exempt (hourly), non-sales roles may also include variable compensation from time to time (e.g., any overtime and shift differential) and annual bonus target (subject to plan eligibility and other requirements). Compensation for exempt, non-sales roles may also include variable compensation, i.e., annual bonus target and long-term incentives (subject to plan eligibility and other requirements. For MA positions: It is unlawful to require or administer a lie detector test for employment. Violators are subject to criminal penalties and civil liability. As a leader in medical science for more than 40 years, we are committed to solving the challenges that matter most – united by a deep caring for human life. Our mission to advance science for life is about transforming lives through innovative medical solutions that improve patient lives, create value for our customers, and support our employees and the communities in which we operate. Now more than ever, we have a responsibility to apply those values to everything we do – as a global business and as a global corporate citizen. So, choosing a career with Boston Scientific (NYSE: BSX) isn’t just business, it’s personal. And if you’re a natural problem-solver with the imagination, determination, and spirit to make a meaningful difference to people worldwide, we encourage you to apply and look forward to connecting with you! At Boston Scientific, we recognize that nurturing a diverse and inclusive workplace helps us be more innovative and it is important in our work of advancing science for life and improving patient health. That is why we stand for inclusion, equality, and opportunity for all. By embracing the richness of our unique backgrounds and perspectives, we create a better, more rewarding place for our employees to work and reflect the patients, customers, and communities we serve. Boston Scientific Corporation has been and will continue to be an equal opportunity employer. To ensure full implementation of its equal employment policy, the Company will continue to take steps to assure that recruitment, hiring, assignment, promotion, compensation, and all other personnel decisions are made and administered without regard to race, religion, color, national origin, citizenship, sex, sexual orientation, gender identify, gender expression, veteran status, age, mental or physical disability, genetic information or any other protected class. Please be advised that certain US based positions, including without limitation field sales and service positions that call on hospitals and/or health care centers, require acceptable proof of COVID-19 vaccination status. Candidates will be notified during the interview and selection process if the role(s) for which they have applied require proof of vaccination as a condition of employment. Boston Scientific continues to evaluate its policies and protocols regarding the COVID-19 vaccine and will comply with all applicable state and federal law and healthcare credentialing requirements. As employees of the Company, you will be expected to meet the ongoing requirements for your roles, including any new requirements, should the Company’s policies or protocols change with regard to COVID-19 vaccination. Nearest Major Market: Minneapolis Job Segment: Learning, Testing, Developer, Programmer, Information Technology, Human Resources, Technology</td><td>developer</td><td>Work mode: Hybrid Onsite Location(s): Maple Grove, MN, US, 55311 Additional Location(s): US-MN-Maple Grove Diversity - Innovation - Caring - Global Collaboration - Winning Spirit - High Performance At Boston Scientific, we’ll give you the opportunity to harness all that’s within you by working in teams of diverse and high-performing employees, tackling some of the most important health industry challenges. With access to the latest tools, information and training, we’ll help you in advancing your skills and career. Here, you’ll be supported in progressing – whatever your ambitions. The Instructional Designer Content Developer (Cardiology Training) works closely with business partners, subject matter experts (SMEs), and other key stakeholders to plan and develop high-quality learning experiences to support business goals. This individual is responsible for the development of content, which may include interactive, multimedia, instructor led. This position reports to the Cardiology Training Operations Manager. Candidates will provide work portfolio as part of the application process. The interview will include a portfolio review and discussion. Your responsibilities will include: Partnering with subject matter experts and other stakeholders to analyze the learning needs. Planning, organizing, and developing learning solutions using a variety of modalities. Synthesizing and translating technical information into clear, effective, and engaging learning. Ensuring a consistent approach to the learning experience. Being proficient with a wide variety of learning tools, including but not limited to Storyline, RISE, game-based learning, videos, InDesign. Managing multiple projects with frequent priority shifts, working with high attention to accuracy and detail, and delivering within expected timelines. Being familiar with Learning Management Systems, as it relates to ensuring content works appropriately. Managing and organizing content in a centralized repository to ensure accuracy of material. Minimum Qualifications: Bachelor’s degree and/or equivalent of industry experience Four years of Instructional Design and content creation Innovative, curious mindset and ability to work independently to meet deadlines Excellent written and verbal communication skills Experience editing content for clarity and accuracy Experience using Microsoft 365 tools Experience using Articulate 360 software Experience using video editing software Experience using software to create animated characters Experience using Adobe InDesign Preferred Qualifications: Experience working within an FDA regulated environment Experience using Sales and Learning Enablement Platforms, (such as Showpad, Allego, SmartWinnr, etc) Requisition ID: 598020 Minimum Salary: $ 99100 Maximum Salary: $ 188300 Compensation for non-exempt (hourly), non-sales roles may also include variable compensation from time to time (e.g., any overtime and shift differential) and annual bonus target (subject to plan eligibility and other requirements). Compensation for exempt, non-sales roles may also include variable compensation, i.e., annual bonus target and long-term incentives (subject to plan eligibility and other requirements. For MA positions: It is unlawful to require or administer a lie detector test for employment. Violators are subject to criminal penalties and civil liability. As a leader in medical science for more than 40 years, we are committed to solving the challenges that matter most – united by a deep caring for human life. Our mission to advance science for life is about transforming lives through innovative medical solutions that improve patient lives, create value for our customers, and support our employees and the communities in which we operate. Now more than ever, we have a responsibility to apply those values to everything we do – as a global business and as a global corporate citizen. So, choosing a career with Boston Scientific (NYSE: BSX) isn’t just business, it’s personal. And if you’re a natural problem-solver with the imagination, determination, and spirit to make a meaningful difference to people worldwide, we encourage you to apply and look forward to connecting with you! At Boston Scientific, we recognize that nurturing a diverse and inclusive workplace helps us be more innovative and it is important in our work of advancing science for life and improving patient health. That is why we stand for inclusion, equality, and opportunity for all. By embracing the richness of our unique backgrounds and perspectives, we create a better, more rewarding place for our employees to work and reflect the patients, customers, and communities we serve. Boston Scientific Corporation has been and will continue to be an equal opportunity employer. To ensure full implementation of its equal employment policy, the Company will continue to take steps to assure that recruitment, hiring, assignment, promotion, compensation, and all other personnel decisions are made and administered without regard to race, religion, color, national origin, citizenship, sex, sexual orientation, gender identify, gender expression, veteran status, age, mental or physical disability, genetic information or any other protected class. Please be advised that certain US based positions, including without limitation field sales and service positions that call on hospitals and/or health care centers, require acceptable proof of COVID-19 vaccination status. Candidates will be notified during the interview and selection process if the role(s) for which they have applied require proof of vaccination as a condition of employment. Boston Scientific continues to evaluate its policies and protocols regarding the COVID-19 vaccine and will comply with all applicable state and federal law and healthcare credentialing requirements. As employees of the Company, you will be expected to meet the ongoing requirements for your roles, including any new requirements, should the Company’s policies or protocols change with regard to COVID-19 vaccination. Nearest Major Market: Minneapolis Job Segment: Learning, Testing, Developer, Programmer, Information Technology, Human Resources, Technology</td><td>Work mode: Hybrid Onsite Location(s): Maple Grove, MN, US, 55311 Additional Location(s): US-MN-Maple Grove Diversity - Innovation - Caring - Global Collaboration - Winning Spirit - High Performance At Boston Scientific, we’ll give you the opportunity to harness all that’s within you by working in teams of diverse and high-performing employees, tackling some of the most important health industry challenges. With access to the latest tools, information and training, we’ll help you in advancing your skills and career. Here, you’ll be supported in progressing – whatever your ambitions. The Instructional Designer Content Developer (Cardiology Training) works closely with business partners, subject matter experts (SMEs), and other key stakeholders to plan and develop high-quality learning experiences to support business goals. This individual is responsible for the development of content, which may include interactive, multimedia, instructor led. This position reports to the Cardiology Training Operations Manager. Candidates will provide work portfolio as part of the application process. The interview will include a portfolio review and discussion. Your responsibilities will include: Partnering with subject matter experts and other stakeholders to analyze the learning needs. Planning, organizing, and developing learning solutions using a variety of modalities. Synthesizing and translating technical information into clear, effective, and engaging learning. Ensuring a consistent approach to the learning experience. Being proficient with a wide variety of learning tools, including but not limited to Storyline, RISE, game-based learning, videos, InDesign. Managing multiple projects with frequent priority shifts, working with high attention to accuracy and detail, and delivering within expected timelines. Being familiar with Learning Management Systems, as it relates to ensuring content works appropriately. Managing and organizing content in a centralized repository to ensure accuracy of material. Minimum Qualifications: Bachelor’s degree and/or equivalent of industry experience Four years of Instructional Design and content creation Innovative, curious mindset and ability to work independently to meet deadlines Excellent written and verbal communication skills Experience editing content for clarity and accuracy Experience using Microsoft 365 tools Experience using Articulate 360 software Experience using video editing software Experience using software to create animated characters Experience using Adobe InDesign Preferred Qualifications: Experience working within an FDA regulated environment Experience using Sales and Learning Enablement Platforms, (such as Showpad, Allego, SmartWinnr, etc) Requisition ID: 598020 Minimum Salary: $ 99100 Maximum Salary: $ 188300 Compensation for non-exempt (hourly), non-sales roles may also include variable compensation from time to time (e.g., any overtime and shift differential) and annual bonus target (subject to plan eligibility and other requirements). Compensation for exempt, non-sales roles may also include variable compensation, i.e., annual bonus target and long-term incentives (subject to plan eligibility and other requirements. For MA positions: It is unlawful to require or administer a lie detector test for employment. Violators are subject to criminal penalties and civil liability. As a leader in medical science for more than 40 years, we are committed to solving the challenges that matter most – united by a deep caring for human life. Our mission to advance science for life is about transforming lives through innovative medical solutions that improve patient lives, create value for our customers, and support our employees and the communities in which we operate. Now more than ever, we have a responsibility to apply those values to everything we do – as a global business and as a global corporate citizen. So, choosing a career with Boston Scientific (NYSE: BSX) isn’t just business, it’s personal. And if you’re a natural problem-solver with the imagination, determination, and spirit to make a meaningful difference to people worldwide, we encourage you to apply and look forward to connecting with you! At Boston Scientific, we recognize that nurturing a diverse and inclusive workplace helps us be more innovative and it is important in our work of advancing science for life and improving patient health. That is why we stand for inclusion, equality, and opportunity for all. By embracing the richness of our unique backgrounds and perspectives, we create a better, more rewarding place for our employees to work and reflect the patients, customers, and communities we serve. Boston Scientific Corporation has been and will continue to be an equal opportunity employer. To ensure full implementation of its equal employment policy, the Company will continue to take steps to assure that recruitment, hiring, assignment, promotion, compensation, and all other personnel decisions are made and administered without regard to race, religion, color, national origin, citizenship, sex, sexual orientation, gender identify, gender expression, veteran status, age, mental or physical disability, genetic information or any other protected class. Please be advised that certain US based positions, including without limitation field sales and service positions that call on hospitals and/or health care centers, require acceptable proof of COVID-19 vaccination status. Candidates will be notified during the interview and selection process if the role(s) for which they have applied require proof of vaccination as a condition of employment. Boston Scientific continues to evaluate its policies and protocols regarding the COVID-19 vaccine and will comply with all applicable state and federal law and healthcare credentialing requirements. As employees of the Company, you will be expected to meet the ongoing requirements for your roles, including any new requirements, should the Company’s policies or protocols change with regard to COVID-19 vaccination. Nearest Major Market: Minneapolis Job Segment: Learning, Testing, Developer, Programmer, Information Technology, Human Resources, Technology</td><td>Bachelor’s degree and/or equivalent of industry experience Four years of Instructional Design and content creation Innovative, curious mindset and ability to work independently to meet deadlines Excellent written and verbal communication skills Experience editing content for clarity and accuracy Experience using Microsoft 365 tools Experience using Articulate 360 software Experience using video editing software Experience using software to create animated characters Experience using Adobe InDesign Preferred Qualifications: Experience working within an FDA regulated environment Experience using Sales and Learning Enablement Platforms, (such as Showpad, Allego, SmartWinnr, etc) Requisition ID: 598020 Minimum Salary: $ 99100 Maximum Salary: $ 188300 Compensation for non-exempt (hourly), non-sales roles may also include variable compensation from time to time (e.g., any overtime and shift differential) and annual bonus target (subject to plan eligibility and other requirements). Compensation for exempt, non-sales roles may also include variable compensation, i.e., annual bonus target and long-term incentives (subject to plan eligibility and other requirements. For MA positions: It is unlawful to require or administer a lie detector test for employment. Violators are subject to criminal penalties and civil liability. As a leader in medical science for more than 40 years, we are committed to solving the challenges that matter most – united by a deep caring for human life. Our mission to advance science for life is about transforming lives through innovative medical solutions that improve patient lives, create value for our customers, and support our employees and the communities in which we operate. Now more than ever, we have a responsibility to apply those values to everything we do – as a global business and as a global corporate citizen. So, choosing a career with Boston Scientific (NYSE: BSX) isn’t just business, it’s personal. And if you’re a natural problem-solver with the imagination, determination, and spirit to make a meaningful difference to people worldwide, we encourage you to apply and look forward to connecting with you! At Boston Scientific, we recognize that nurturing a diverse and inclusive workplace helps us be more innovative and it is important in our work of advancing science for life and improving patient health. That is why we stand for inclusion, equality, and opportunity for all. By embracing the richness of our unique backgrounds and perspectives, we create a better, more rewarding place for our employees to work and reflect the patients, customers, and communities we serve. Boston Scientific Corporation has been and will continue to be an equal opportunity employer. To ensure full implementation of its equal employment policy, the Company will continue to take steps to assure that recruitment, hiring, assignment, promotion, compensation, and all other personnel decisions are made and administered without regard to race, religion, color, national origin, citizenship, sex, sexual orientation, gender identify, gender expression, veteran status, age, mental or physical disability, genetic information or any other protected class. Please be advised that certain US based positions, including without limitation field sales and service positions that call on hospitals and/or health care centers, require acceptable proof of COVID-19 vaccination status. Candidates will be notified during the interview and selection process if the role(s) for which they have applied require proof of vaccination as a condition of employment. Boston Scientific continues to evaluate its policies and protocols regarding the COVID-19 vaccine and will comply with all applicable state and federal law and healthcare credentialing requirements. As employees of the Company, you will be expected to meet the ongoing requirements for your roles, including any new requirements, should the Company’s policies or protocols change with regard to COVID-19 vaccination. Nearest Major Market: Minneapolis Job Segment: Learning, Testing, Developer, Programmer, Information Technology, Human Resources, Technology</td><td>603</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         null,
         "events and celebrations",
         "Job Description Data Scientist (GenAI) We're hiring an exceptional Data Scientist to join our growing team of data science & AI experts! In this role, you’ll have the opportunity to design and deploy end-to-end AIML solutions that push the boundaries of financial technology, using advanced techniques in Generative AI, NLP, and predictive modeling. You’ll tackle complex business challenges, automate manual processes and help Tipalti maintain its edge in driving innovation across the fintech landscape. The ideal candidate is a problem solver with a strong technical background who thrives on transforming complex business challenges into scalable AIML solutions. Why join Tipalti Tipalti is one of the world’s fastest-growing fintech companies. We free finance professionals to lead by modernizing the entire payables operation. We are a well-funded, late-stage start-up backed by high-profile investors. Our 2021 Series F funding round raised $270 million, valuing us at over $8.3 billion. With total funding of just over $550 million, and with more than 4000 global customers, Tipalti is one of the most valuable private fintech companies in the world. At Tipalti, we pride ourselves on our collaborative culture, the quality of our product and the capabilities of our people. Tipaltians are passionate about the work they do, and keen to get the job done. Tipalti oﬀers competitive benefits, a flexible workplace, career coaching, and an environment where diverse individuals can thrive and make an impact. Our culture ensures everyone checks their egos at the door and stands ready to reach for success together. Founded in Israel in 2010, Tipalti is a global business headquartered in the San Francisco Bay Area (Foster City) with offices in Tel Aviv, Plano, Toronto, Vancouver, London, Amsterdam and Tbilisi. In This Role, You Will Be Responsible For End-to-End Solution Development Designing, developing, and deploying robust AIML solutions that address key challenges in the fintech space, from data preprocessing through production deployment. Gen AI & NLP Applications Building and fine-tuning generative AI models for innovative applications, including LLMs for text generation, summarization, categorization and document processing. Applying NLP techniques to analyze unstructured data, uncover insights, and enable capabilities like sentiment analysis, entity recognition, and text classification. Predictive Modeling Creating predictive models that forecast critical business outcomes, identify trends, and provide actionable insights to optimize decision-making. Model Deployment and Optimization Implementing best practices for model deployment, monitoring, and continuous improvement to ensure high performance and scalability of AI solutions in production. Cross-Functional Collaboration Partnering with key stakeholders across departments to understand business requirements, align on objectives, and deliver impactful solutions. About You Bachelor’s degree in Computer Science, Engineering, Mathematics, Physics, Statistics or a related field, with focus on AIML. 3+ years of hands-on experience in data science or AI engineering, ideally within the fintech industry or a related sector, with a track record of deploying impactful AIML solutions. Strong technical skills Proficiency in Python and SQL for data manipulation, analysis, and model building. Deep experience with LLMs and prompt engineering, including systematic evaluation of enterprise AI solutions Experience with building RAG systems and Conversational chatbots - Advantage Strong experience with machine learning libraries such as TensorFlow, PyTorch, or scikit-learn. Experience with cloud platforms (AWS, GCP, or Azure) for model deployment and MLOps practices. Analytical Mindset You’re adept at statistical analysis, understand key machine learning algorithms, and can evaluate models with a critical eye. Project Management You can manage and prioritize multiple tasks, balancing short-term and long-term goals to deliver timely, high-impact results. Our tech teams are the engine behind our business. Tipalti’s tech ecosystem is extremely rich and we continually add new features to our products, ensuring that we respond to our clients’ needs at scale. Our tech teams retain a fast-paced, start-up vibe that encourages innovation and critical thinking. At Tipalti, you’ll have the opportunity to work with a diverse, global team of engineers, developers and product leaders who are collectively building the future of our best-in-class product suite as we transform financial operations for the future. Interested in learning more about us Tipalti is the only company handling both global partner payments and accounts payable workflows for high-velocity companies across the entire financial operations cycle onboarding and managing global suppliers, instituting procurement controls, streamlining invoice processing and approvals, executing payments around the world, and reconciling payables data across a multi-subsidiary finance organization. Tipalti enables companies to scale quickly by making payables strategic with operational, compliance, and financial controls. Through Tipalti, our clients can efficiently and securely pay thousands of partners and suppliers in 196 countries within minutes. Tipalti is fueled by a commitment to our customers and a desire to build lasting connections. Our client portfolio includes high-velocity businesses such as Amazon Twitch, GoDaddy, Roku, WordPress.com, and ZipRecruiter. We work hard for our 98% customer retention rate which is built on trust, reliability and innovation. Tipalti means we handled it - a mission to which we are constantly committed. #LI-AA1 #LI-hybrid Interested in learning more about us Tipalti is the only company handling both global partner payments and accounts payable workflows for high-velocity companies across the entire financial operations cycle onboarding and managing global suppliers, instituting procurement controls, streamlining invoice processing and approvals, executing payments around the world, and reconciling payables data across a multi-subsidiary finance organization. Tipalti enables companies to scale quickly by making payables strategic with operational, compliance, and financial controls. Through Tipalti, our clients can efficiently and securely pay thousands of partners and suppliers in 196 countries within minutes. Tipalti is fueled by a commitment to our customers and a desire to build lasting connections. Our client portfolio includes high-velocity businesses such as Amazon Twitch, GoDaddy, Roku, WordPress.com, and ZipRecruiter. We work hard for our 98% customer retention rate which is built on trust, reliability and innovation. Tipalti means we handled it - a mission to which we are constantly committed. Accommodations Tipalti champions inclusive teams, in which every voice counts. We are committed to recruiting diverse candidates with varied personal experiences and abilities. We welcome applications from candidates belonging to historically underrepresented or disadvantaged groups, and maintain an equitable Talent Acquisition process that is free from discrimination. As an equal opportunities employer, Tipalti complies with employment and human rights laws across the various jurisdictions in which we operate. Should you require reasonable adjustments or accommodations during the recruitment process, including access to alternate formats of materials, meeting spaces, or other accommodations that could better enable your full participation, please reach out to hr@tipalti.com for assistance. Privacy We are committed to protecting the privacy interests of job applicants and candidates. For more information about our privacy practices during our Talent Acquisition process, please refer to our Job Candidate Privacy Notice below Opened URL httpsil.indeed.comrcclkjk=2f56ea143e968cf4&bb=zk7LYUIixjhkbKO7XrB0tlDEjZfP-jhN3oJXLsQv5a7cbHU5xos_zXSpDDtJtOGYPQlFPEKIl6j6alQiN500YEFPMZ1N2Y4PgeROuVHOyDIOMeYOs-kZhFFOCkHjDxMw&xkcb=SoDk67M33wfbB8xCCB0FbzkdCdPP&fccid=c26e6911bfdb0c15&vjs=3",
         "ds",
         "Job Description Data Scientist (GenAI) We're hiring an exceptional Data Scientist to join our growing team of data science & AI experts! In this role, you’ll have the opportunity to design and deploy end-to-end AIML solutions that push the boundaries of financial technology, using advanced techniques in Generative AI, NLP, and predictive modeling. You’ll tackle complex business challenges, automate manual processes and help Tipalti maintain its edge in driving innovation across the fintech landscape. The ideal candidate is a problem solver with a strong technical background who thrives on transforming complex business challenges into scalable AIML solutions. Why join Tipalti Tipalti is one of the world’s fastest-growing fintech companies. We free finance professionals to lead by modernizing the entire payables operation. We are a well-funded, late-stage start-up backed by high-profile investors. Our 2021 Series F funding round raised $270 million, valuing us at over $8.3 billion. With total funding of just over $550 million, and with more than 4000 global customers, Tipalti is one of the most valuable private fintech companies in the world. At Tipalti, we pride ourselves on our collaborative culture, the quality of our product and the capabilities of our people. Tipaltians are passionate about the work they do, and keen to get the job done. Tipalti oﬀers competitive benefits, a flexible workplace, career coaching, and an environment where diverse individuals can thrive and make an impact. Our culture ensures everyone checks their egos at the door and stands ready to reach for success together. Founded in Israel in 2010, Tipalti is a global business headquartered in the San Francisco Bay Area (Foster City) with offices in Tel Aviv, Plano, Toronto, Vancouver, London, Amsterdam and Tbilisi. In This Role, You Will Be Responsible For End-to-End Solution Development Designing, developing, and deploying robust AIML solutions that address key challenges in the fintech space, from data preprocessing through production deployment. Gen AI & NLP Applications Building and fine-tuning generative AI models for innovative applications, including LLMs for text generation, summarization, categorization and document processing. Applying NLP techniques to analyze unstructured data, uncover insights, and enable capabilities like sentiment analysis, entity recognition, and text classification. Predictive Modeling Creating predictive models that forecast critical business outcomes, identify trends, and provide actionable insights to optimize decision-making. Model Deployment and Optimization Implementing best practices for model deployment, monitoring, and continuous improvement to ensure high performance and scalability of AI solutions in production. Cross-Functional Collaboration Partnering with key stakeholders across departments to understand business requirements, align on objectives, and deliver impactful solutions. About You Bachelor’s degree in Computer Science, Engineering, Mathematics, Physics, Statistics or a related field, with focus on AIML. 3+ years of hands-on experience in data science or AI engineering, ideally within the fintech industry or a related sector, with a track record of deploying impactful AIML solutions. Strong technical skills Proficiency in Python and SQL for data manipulation, analysis, and model building. Deep experience with LLMs and prompt engineering, including systematic evaluation of enterprise AI solutions Experience with building RAG systems and Conversational chatbots - Advantage Strong experience with machine learning libraries such as TensorFlow, PyTorch, or scikit-learn. Experience with cloud platforms (AWS, GCP, or Azure) for model deployment and MLOps practices. Analytical Mindset You’re adept at statistical analysis, understand key machine learning algorithms, and can evaluate models with a critical eye. Project Management You can manage and prioritize multiple tasks, balancing short-term and long-term goals to deliver timely, high-impact results. Our tech teams are the engine behind our business. Tipalti’s tech ecosystem is extremely rich and we continually add new features to our products, ensuring that we respond to our clients’ needs at scale. Our tech teams retain a fast-paced, start-up vibe that encourages innovation and critical thinking. At Tipalti, you’ll have the opportunity to work with a diverse, global team of engineers, developers and product leaders who are collectively building the future of our best-in-class product suite as we transform financial operations for the future. Interested in learning more about us Tipalti is the only company handling both global partner payments and accounts payable workflows for high-velocity companies across the entire financial operations cycle onboarding and managing global suppliers, instituting procurement controls, streamlining invoice processing and approvals, executing payments around the world, and reconciling payables data across a multi-subsidiary finance organization. Tipalti enables companies to scale quickly by making payables strategic with operational, compliance, and financial controls. Through Tipalti, our clients can efficiently and securely pay thousands of partners and suppliers in 196 countries within minutes. Tipalti is fueled by a commitment to our customers and a desire to build lasting connections. Our client portfolio includes high-velocity businesses such as Amazon Twitch, GoDaddy, Roku, WordPress.com, and ZipRecruiter. We work hard for our 98% customer retention rate which is built on trust, reliability and innovation. Tipalti means we handled it - a mission to which we are constantly committed. #LI-AA1 #LI-hybrid Interested in learning more about us Tipalti is the only company handling both global partner payments and accounts payable workflows for high-velocity companies across the entire financial operations cycle onboarding and managing global suppliers, instituting procurement controls, streamlining invoice processing and approvals, executing payments around the world, and reconciling payables data across a multi-subsidiary finance organization. Tipalti enables companies to scale quickly by making payables strategic with operational, compliance, and financial controls. Through Tipalti, our clients can efficiently and securely pay thousands of partners and suppliers in 196 countries within minutes. Tipalti is fueled by a commitment to our customers and a desire to build lasting connections. Our client portfolio includes high-velocity businesses such as Amazon Twitch, GoDaddy, Roku, WordPress.com, and ZipRecruiter. We work hard for our 98% customer retention rate which is built on trust, reliability and innovation. Tipalti means we handled it - a mission to which we are constantly committed. Accommodations Tipalti champions inclusive teams, in which every voice counts. We are committed to recruiting diverse candidates with varied personal experiences and abilities. We welcome applications from candidates belonging to historically underrepresented or disadvantaged groups, and maintain an equitable Talent Acquisition process that is free from discrimination. As an equal opportunities employer, Tipalti complies with employment and human rights laws across the various jurisdictions in which we operate. Should you require reasonable adjustments or accommodations during the recruitment process, including access to alternate formats of materials, meeting spaces, or other accommodations that could better enable your full participation, please reach out to hr@tipalti.com for assistance. Privacy We are committed to protecting the privacy interests of job applicants and candidates. For more information about our privacy practices during our Talent Acquisition process, please refer to our Job Candidate Privacy Notice below",
         "Job Description Data Scientist (GenAI) We're hiring an exceptional Data Scientist to join our growing team of data science & AI experts! In this role, you’ll have the opportunity to design and deploy end-to-end AIML solutions that push the boundaries of financial technology, using advanced techniques in Generative AI, NLP, and predictive modeling. You’ll tackle complex business challenges, automate manual processes and help Tipalti maintain its edge in driving innovation across the fintech landscape. The ideal candidate is a problem solver with a strong technical background who thrives on transforming complex business challenges into scalable AIML solutions. Why join Tipalti Tipalti is one of the world’s fastest-growing fintech companies. We free finance professionals to lead by modernizing the entire payables operation. We are a well-funded, late-stage start-up backed by high-profile investors. Our 2021 Series F funding round raised $270 million, valuing us at over $8.3 billion. With total funding of just over $550 million, and with more than 4000 global customers, Tipalti is one of the most valuable private fintech companies in the world. At Tipalti, we pride ourselves on our collaborative culture, the quality of our product and the capabilities of our people. Tipaltians are passionate about the work they do, and keen to get the job done. Tipalti oﬀers competitive benefits, a flexible workplace, career coaching, and an environment where diverse individuals can thrive and make an impact. Our culture ensures everyone checks their egos at the door and stands ready to reach for success together. Founded in Israel in 2010, Tipalti is a global business headquartered in the San Francisco Bay Area (Foster City) with offices in Tel Aviv, Plano, Toronto, Vancouver, London, Amsterdam and Tbilisi. In This Role, You Will Be Responsible For End-to-End Solution Development Designing, developing, and deploying robust AIML solutions that address key challenges in the fintech space, from data preprocessing through production deployment. Gen AI & NLP Applications Building and fine-tuning generative AI models for innovative applications, including LLMs for text generation, summarization, categorization and document processing. Applying NLP techniques to analyze unstructured data, uncover insights, and enable capabilities like sentiment analysis, entity recognition, and text classification. Predictive Modeling Creating predictive models that forecast critical business outcomes, identify trends, and provide actionable insights to optimize decision-making. Model Deployment and Optimization Implementing best practices for model deployment, monitoring, and continuous improvement to ensure high performance and scalability of AI solutions in production. Cross-Functional Collaboration Partnering with key stakeholders across departments to understand business requirements, align on objectives, and deliver impactful solutions. About You Bachelor’s degree in Computer Science, Engineering, Mathematics, Physics, Statistics or a related field, with focus on AIML. 3+ years of hands-on experience in data science or AI engineering, ideally within the fintech industry or a related sector, with a track record of deploying impactful AIML solutions. Strong technical skills Proficiency in Python and SQL for data manipulation, analysis, and model building. Deep experience with LLMs and prompt engineering, including systematic evaluation of enterprise AI solutions Experience with building RAG systems and Conversational chatbots - Advantage Strong experience with machine learning libraries such as TensorFlow, PyTorch, or scikit-learn. Experience with cloud platforms (AWS, GCP, or Azure) for model deployment and MLOps practices. Analytical Mindset You’re adept at statistical analysis, understand key machine learning algorithms, and can evaluate models with a critical eye. Project Management You can manage and prioritize multiple tasks, balancing short-term and long-term goals to deliver timely, high-impact results. Our tech teams are the engine behind our business. Tipalti’s tech ecosystem is extremely rich and we continually add new features to our products, ensuring that we respond to our clients’ needs at scale. Our tech teams retain a fast-paced, start-up vibe that encourages innovation and critical thinking. At Tipalti, you’ll have the opportunity to work with a diverse, global team of engineers, developers and product leaders who are collectively building the future of our best-in-class product suite as we transform financial operations for the future. Interested in learning more about us Tipalti is the only company handling both global partner payments and accounts payable workflows for high-velocity companies across the entire financial operations cycle onboarding and managing global suppliers, instituting procurement controls, streamlining invoice processing and approvals, executing payments around the world, and reconciling payables data across a multi-subsidiary finance organization. Tipalti enables companies to scale quickly by making payables strategic with operational, compliance, and financial controls. Through Tipalti, our clients can efficiently and securely pay thousands of partners and suppliers in 196 countries within minutes. Tipalti is fueled by a commitment to our customers and a desire to build lasting connections. Our client portfolio includes high-velocity businesses such as Amazon Twitch, GoDaddy, Roku, WordPress.com, and ZipRecruiter. We work hard for our 98% customer retention rate which is built on trust, reliability and innovation. Tipalti means we handled it - a mission to which we are constantly committed. #LI-AA1 #LI-hybrid Interested in learning more about us Tipalti is the only company handling both global partner payments and accounts payable workflows for high-velocity companies across the entire financial operations cycle onboarding and managing global suppliers, instituting procurement controls, streamlining invoice processing and approvals, executing payments around the world, and reconciling payables data across a multi-subsidiary finance organization. Tipalti enables companies to scale quickly by making payables strategic with operational, compliance, and financial controls. Through Tipalti, our clients can efficiently and securely pay thousands of partners and suppliers in 196 countries within minutes. Tipalti is fueled by a commitment to our customers and a desire to build lasting connections. Our client portfolio includes high-velocity businesses such as Amazon Twitch, GoDaddy, Roku, WordPress.com, and ZipRecruiter. We work hard for our 98% customer retention rate which is built on trust, reliability and innovation. Tipalti means we handled it - a mission to which we are constantly committed. Accommodations Tipalti champions inclusive teams, in which every voice counts. We are committed to recruiting diverse candidates with varied personal experiences and abilities. We welcome applications from candidates belonging to historically underrepresented or disadvantaged groups, and maintain an equitable Talent Acquisition process that is free from discrimination. As an equal opportunities employer, Tipalti complies with employment and human rights laws across the various jurisdictions in which we operate. Should you require reasonable adjustments or accommodations during the recruitment process, including access to alternate formats of materials, meeting spaces, or other accommodations that could better enable your full participation, please reach out to hr@tipalti.com for assistance. Privacy We are committed to protecting the privacy interests of job applicants and candidates. For more information about our privacy practices during our Talent Acquisition process, please refer to our Job Candidate Privacy Notice below",
         "Bachelor’s degree in Computer Science, Engineering, Mathematics, Physics, Statistics or a related field, with focus on AIML. 3+ years of hands-on experience in data science or AI engineering, ideally within the fintech industry or a related sector, with a track record of deploying impactful AIML solutions. Strong technical skills Proficiency in Python and SQL for data manipulation, analysis, and model building. Deep experience with LLMs and prompt engineering, including systematic evaluation of enterprise AI solutions Experience with building RAG systems and Conversational chatbots - Advantage Strong experience with machine learning libraries such as TensorFlow, PyTorch, or scikit-learn. Experience with cloud platforms (AWS, GCP, or Azure) for model deployment and MLOps practices. Analytical Mindset You’re adept at statistical analysis, understand key machine learning algorithms, and can evaluate models with a critical eye. Project Management You can manage and prioritize multiple tasks, balancing short-term and long-term goals to deliver timely, high-impact results. Our tech teams are the engine behind our business. Tipalti’s tech ecosystem is extremely rich and we continually add new features to our products, ensuring that we respond to our clients’ needs at scale. Our tech teams retain a fast-paced, start-up vibe that encourages innovation and critical thinking. At Tipalti, you’ll have the opportunity to work with a diverse, global team of engineers, developers and product leaders who are collectively building the future of our best-in-class product suite as we transform financial operations for the future. Interested in learning more about us Tipalti is the only company handling both global partner payments and accounts payable workflows for high-velocity companies across the entire financial operations cycle onboarding and managing global suppliers, instituting procurement controls, streamlining invoice processing and approvals, executing payments around the world, and reconciling payables data across a multi-subsidiary finance organization. Tipalti enables companies to scale quickly by making payables strategic with operational, compliance, and financial controls. Through Tipalti, our clients can efficiently and securely pay thousands of partners and suppliers in 196 countries within minutes. Tipalti is fueled by a commitment to our customers and a desire to build lasting connections. Our client portfolio includes high-velocity businesses such as Amazon Twitch, GoDaddy, Roku, WordPress.com, and ZipRecruiter. We work hard for our 98% customer retention rate which is built on trust, reliability and innovation. Tipalti means we handled it - a mission to which we are constantly committed. #LI-AA1 #LI-hybrid Interested in learning more about us Tipalti is the only company handling both global partner payments and accounts payable workflows for high-velocity companies across the entire financial operations cycle onboarding and managing global suppliers, instituting procurement controls, streamlining invoice processing and approvals, executing payments around the world, and reconciling payables data across a multi-subsidiary finance organization. Tipalti enables companies to scale quickly by making payables strategic with operational, compliance, and financial controls. Through Tipalti, our clients can efficiently and securely pay thousands of partners and suppliers in 196 countries within minutes. Tipalti is fueled by a commitment to our customers and a desire to build lasting connections. Our client portfolio includes high-velocity businesses such as Amazon Twitch, GoDaddy, Roku, WordPress.com, and ZipRecruiter. We work hard for our 98% customer retention rate which is built on trust, reliability and innovation. Tipalti means we handled it - a mission to which we are constantly committed. Accommodations Tipalti champions inclusive teams, in which every voice counts. We are committed to recruiting diverse candidates with varied personal experiences and abilities. We welcome applications from candidates belonging to historically underrepresented or disadvantaged groups, and maintain an equitable Talent Acquisition process that is free from discrimination. As an equal opportunities employer, Tipalti complies with employment and human rights laws across the various jurisdictions in which we operate. Should you require reasonable adjustments or accommodations during the recruitment process, including access to alternate formats of materials, meeting spaces, or other accommodations that could better enable your full participation, please reach out to hr@tipalti.com for assistance. Privacy We are committed to protecting the privacy interests of job applicants and candidates. For more information about our privacy practices during our Talent Acquisition process, please refer to our Job Candidate Privacy Notice below",
         684
        ],
        [
         "Data Engineer",
         "The Helper Bees",
         "Description: Join our winning team, recently honored as #67 on Forbes’ list of America’s Best Startup Employers for 2024! About The Helper Bees The Helper Bees’ mission is to help people stay home longer through data-driven services that transform both the payer and the care-recipient experience. At The Helper Bees, we are reshaping how care is delivered to aging individuals by leveraging innovative technology and insightful data solutions. We maintain multiple SaaS products and payment solutions through our web applications (internal and external facing), a mobile app, and reporting integrations. As part of our growing Data Engineering team, you’ll iterate quickly, have a high impact, and be challenged to design and implement cutting-edge solutions. At THB, we define our company culture through our Core Values: Quickly iterate through solutions: We move at a fast pace which requires quick iterations to find a path to a repeatable solution. Seek ways to create immediate impact: Be thoughtful and proactive in how you make an impact on your team. Actively look for ways to make a fast, positive impact. Bee the teammate you want to work with: We work as a team, help each other, and encourage each other. Ask questions, answer questions: You can't iterate through solutions if you don't ask the right questions, which is why there is an expectation that questions should be asked. When you know the answer, being a good teammate means chiming in to get others up to speed. Take the time to celebrate wins: It's so easy for a team that is heads down to forget about all the great things they've accomplished. That's why we make it a priority to remind ourselves to create space to celebrate wins, big or small. Job Summary We are seeking a motivated Data Engineer to join our team and help improve our tools, processes, and technical infrastructure. In this role, you will ensure the availability and quality of our data while contributing to the design, implementation, and maintenance of The Helper Bees’ products. You’ll collaborate across teams to create scalable and optimized software systems and play a key role in refining our development processes. This position offers a unique opportunity to learn and leverage cutting-edge AI development tools to enhance coding efficiency and develop advanced data tools and solutions. Supervisory Responsibilities: None Key Responsibilities Data Infrastructure: Design, implement, and maintain data pipelines, ensuring data availability, quality, and scalability. Product Development: Build and enhance products using Python, SQL, and modern technologies. AI Integration: Leverage cutting-edge AI tools, including Cursor, ChatGPT, and Claude to improve development processes, automate workflows, and create innovative data solutions. Collaboration: Communicate across departments to design, build, test, and implement new features and enhancements. Code Excellence: Produce quality, testable, and maintainable code while participating in code reviews. Problem Solving: Debug complex issues, interact with stakeholders, and design viable solutions with clear trade-offs. Process Optimization: Contribute to improving development processes, including deployment, on-call systems, and sprint planning. Team Growth: Collaborate within the development team to help each other grow and continuously learn. Stakeholder Engagement: Partner with analysts, scientists, and IT to ensure alignment and deliver data-driven solutions. Other duties as assigned/necessary Performance Metrics Code Quality: Maintain high coding standards through regular code reviews and adherence to best practices. Development Efficiency: Deliver high-quality features and fixes within efficient timeframes. Bug Resolution Time: Reduce the time taken to identify and resolve issues. System Scalability: Optimize system performance to handle increasing user demands. Collaboration: Foster a collaborative environment that encourages teamwork and knowledge sharing. Customer Satisfaction: Incorporate stakeholder feedback to improve solutions and enhance the customer experience. Continuous Learning: Pursue opportunities for skill development and share knowledge with the team. Requirements: Required Skills & Qualifications Technical Tools: Experience with in Python and/or SQL. Experience with Bash, Shell scripting, Big Query, Airflow, and is a plus. Programming: Cleaning data using code-based approach. AI Proficiency: Interest or experience in using AI tools for coding and development of data solutions. Soft Skills: Problem-solving, cross-team collaboration, data storytelling, and stakeholder engagement. Adaptability: Thrives in a fast-paced startup environment and embraces change. Proactivity: Self-directed, organized, and able to prioritize effectively. Collaboration: Ability to work effectively with cross-functional teams. Education & Experience: A bachelor’s degree is required, and a graduate degree is preferred. Relevant experience in data engineering, software development, STEM, or related fields. Strong experience with SQL and Python is highly desirable. Mindset: A passion for innovation, continuous improvement, and delivering high-quality results from messy data. Preferred Qualifications Familiarity with cloud-based solutions (e.g., Google Cloud Platform, Azure). Experience with ETL processes and tools. Experience building data visualization reports and dashboards Knowledge of modern data storage solutions and database management systems. Exposure to DevOps practices and tools for deployment and monitoring. Why Join Us? Work with a talented, collaborative team dedicated to making a difference. Gain exposure to innovative technologies and opportunities for growth. Learn and utilize cutting-edge AI tools to enhance your development skills and create impactful solutions. Be part of a company that values your contributions and encourages professional development. Join a rapidly expanding health-tech startup (~200 employees and growing) with a state-of-the-art technology office located in Hyde Park, offering a variety of exceptional benefits. Career Progression Timeline In 3 months: Gain a comprehensive understanding of our data infrastructure, technical stacks, and development cycles. Actively participate in team meetings and contribute to the development of new data pipelines. Begin leveraging AI tools, such as Cursor and ChatGPT, to enhance coding efficiency and workflow automation. In 6 months: Contribute to product enhancements and data reporting Collaborate effectively with cross-functional teams, providing insights and solutions for data-related challenges. Demonstrate proficiency in utilizing AI tools for coding and development, actively sharing knowledge with the team. In 12 months: Contribute to data engineering projects, ensuring scalability and performance optimization. Mentor non-technical internal partners to improve company-wide data literacy Contribute to the integration of advanced AI solutions into our development processes, contributing to the company's technological advancement. Physical Requirements: Ability to remain at your designated workstation for the duration of the workday Constantly operates a computer and other office productivity machinery, such as a phone and Voice over Internet Protocol (VoIP). The ability to communicate information and ideas so others will understand. Must be able to exchange accurate information in these situations. The ability to observe details at close range (typically on a computer screen) This position offers the flexibility of remote work at approved locations within the United States. Candidates must have a reliable internet connection and a designated work environment conducive to professional phone calls and sensitive data. Enjoy the convenience and comfort of working remotely while contributing to our team's success. Apply Today If you’re ready to take on challenging problems, contribute to impactful solutions, and grow as a data engineer, we’d love to hear from you. Join us at The Helper Bees and be part of a team that’s making a meaningful difference every day! The Helper Bees is committed to building a workplace where diversity, equity, and inclusion are valued and prioritized. We are an equal opportunity employer that welcomes all qualified applicants without discrimination based on race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or any non-merit based or legally protected grounds. The Helper Bees provides reasonable accommodations to qualified individuals with disabilities during the job application and interview process. To request accommodation, please let your recruiter know. As part of our standard hiring process, selected candidates may be required to undergo a background check and/or drug screen. The Helper Bees adheres to applicable federal, state, and local laws regarding these screenings, and the results will be considered in accordance with applicable regulations. The Helper Bees was recently made aware of a fraudulent entity posing as our organization and requesting personal information. Please be aware of and protect yourself from scams. Visit thehelperbees.com/careers to view all current job openings. Title: Junior Data Analyst Company: Curacao URL: https://www.indeed.com/pagead/clk?mo=r&ad=-6NYlbfkN0Aq-L5QtgCSXItUR-L7wo_YpcMWMcXbWnKpokPTLYWJk00hIQTwrRAUWMrpcxD4pwN6x-e9cnjRHCoaks6Dcg8QCGHyMkaYmHVMqcsMJtQqSjmImu6WGs5p5vCcpE2-CI15N0E8AbGD3yVS9xEHzBgfQUYd4GSBmD72CNRYeHM9H9PWqAAVtEx1R0S1ZzkqfjGDtp2QdPRY7DsiPImVGKS38M0HWeFgke4S_jsaf60ECq913qNbNgfgbdGMG1XTF1EZttwp3V7XLVaz3NoQly4IkDMzNW8y1ItfMhOn5s-Q_3FqP1DWP-yV5z7tKpScnPltd2hs_MePtbVWuhWpWCAvxqG8ZHnkhDcF2MNcbT5E9FZQdWbVIagw9c9ojMN_Nh1nGuU3zpUeZwU5YVsiQUKKnOmoAZwTrfTrd4zGioNwHgLXWMa7_dfNDkjqnfYZrl0maaH2euLhE328LW5iF0XIvZS3xgcpKiCul4Dp6N99bhD9KdG176KNCe_WwWWbFGKODRcXKugHVrqeov8H2fnGZDBtdPb17-MuLk7S6TJojU8pxdrYhIHxe-f9TSxAqxUNOXLWRWoMzEyosHKf5WBn1m5Lm--X1wB9iqgl43DM-dYINN6V2uw7&xkcb=SoCZ6_M33zC0QjygyR0LbzkdCdPP&camk=ethIe0s0hecgR0GfLS0rMw==&p=0&fvj=0&vjs=3  Title: Data Engineer Company: The Helper Bees URL: https://www.indeed.com/rc/clk?jk=6253474d1b58f413&bb=PoicSlG4oL4KE_mzfAfPJQkIIUr906XH83FgvCImzLRo_KbBAPJJqTbRCgC0sB6KQhnawYgVPRMSBCOWgvavXShvmNK4soVgF9Ps3nHZzOogM0sa-6i_wdIQ2fBIUtVg&xkcb=SoDZ67M33zC0QjygyR0KbzkdCdPP&fccid=8ce618308adea162&vjs=3  Title: Full-time Parts manager and farm data processor. Company: Broughton Farm Operations, LLC. URL: https://www.indeed.com/pagead/clk?mo=r&ad=-6NYlbfkN0Ce8sur-WsqcuJMUqQHPG5JjXNycrhCnmbCp4c_D_ButZkF_gTtnBVK85GrGLECNO3rIlBKOfzAtyZOQVTzelX9C8yOhOTinNcV9BZnRXTTjGL8A3Oq1Cl7IGC2Xzpg7tEA0_r43KM3DpNRvwbs3I3uyrVCJB2vHXaqG7klLxsrPgWZJ2WYjg6tSATO4jC_gAaCGDII7rbhbn_dTUaM9P75wYzTC2ozUeGifr0lfPd65OzIXKfPDYXlkLl5qrTmdGg9Rkvo_0eNGQ4_oL2nvYB4zdISAv5bXWjR-edYUMnsMweH28DCMre4kEAHDy9y9cr74mPTCRONjv_9TMy4cKabNfmC-Jf_KCNel0pj8cqyLXzdM2IXPZ3nPOzRImz1QL0vDqpACFlVtwjkji1oecA9k-Ct6JgVFjmXcvHhVtOKNxLyMPC_DvDcdnNxfTf68GUtsKLbJdTasg3zOA5Yx6VeqakPeJQdbUM8SvavC0EfIHiLjg2P8KtudMWnnhm9iE4mRkFBIpO06I3u1fwov2HXPqJR_KuCmX0zg2AsVNWDolGd7MQq2fL8vTqWZmImBY0_jESWcdf1nyAXKCSnIknRB6vjrMv4133NYwk78OwzmBPPyuOM-85E0vTSs2K444g4lH0vHndxyjLpN5JdnHf0rULZR5KoqzDia4KHXx6rFaKAt4f4bET5&xkcb=SoCw6_M33zC0QjygyR0JbzkdCdPP&camk=nUmJqO2E8rjB9PLQ-tQq_A==&p=2&fvj=0&vjs=3  Title: AI Data Engineer Company: Scully Company URL: https://www.indeed.com/pagead/clk?mo=r&ad=-6NYlbfkN0B0AU1f8KL9plP4iOu5S7KeQNBJvzuLdrovCp0hxvT8W3VRUq-0M1DwmsMXGNv3Vgc8rE7QIt-RapnAZ7wyj5fBABOpDoowk-H_nYWyLvNUWpWWY47YbJnAhj1YP_uV8yJhbabCHVBsGcfeDblRmLdVOfc9z89CztqtuJVDX3aTf8e1E5d2kH6Y060f5XWwMiYix9Epv9uQNmKbbRRPvkZDwTFpQuFCETcW1kf2lR9moxcUiIY09YArmQCHT3bnS-8vqIOj0pggWLoLRqZu7oB7LdZlvaxRtqrup8RsE89BZlSi58dBduIak_MwotVqtsOSCoXYyyyjMRW0RXsDsq0o1cQuhaw7nnjOf2BqFfKjNU1JeMdJ7_DrmjY8sOlrYGZy0XEpJ7Q6Lg-Unhx7n2o0q8l4JFq4uRY3fx-fy2UKHj0bWM4zPy6CcxaNSLCtuJGMv_tIjASAkqAh3UUM62prbn4eUtl-cVH2hCPeERc117AF7D5Zjym-8uvsq5cfMHuWn_JVXJV02uRZHb9wZmhKdt5iSORZY1nkqB824f0ESwAY2DCyQ6VCu2_PU4x-srms_1_S97zPRAe82jJ41yf5Q8jrgBvjCX1JXBrnTpCaQ42K2SshVTyt-XA3PfiYs4I-RWZ2_KmCDDsWOgG_pojJkr5M4TJXC5cIGywm_fRXaxyNwey3HdEtErFud3RiiLwUMOSNb1jdF9Kc1p7fG1fQkhYxD1CDDdM=&xkcb=SoAE6_M33zC0QjygyR0IbzkdCdPP&camk=nUmJqO2E8rgrZNC7156Nog==&p=3&fvj=0&vjs=3  Title: FBI Special Agent: Data Science & Intelligence Expertise Company: Federal Bureau of Investigation URL: https://www.indeed.com/pagead/clk?mo=r&ad=-6NYlbfkN0D5o2Oz3HqsSm2luAX6nIBL6zkznp9GLNwT6U20ynRgySMR2FkhZ1fxxY3hN9eOu-R0sb6uPSdXFH8qzEDJCtXBD2fYjEVZpzNm8nf5ZGyPDNmKAaV7GFRLjyyPflEoyPjNumqkZxNEOlL8xus8VfncfJpOXeBaqBR8Wya3y9f0kdNp-YhVvjHSznZKy1axj92iUL6RkjMO13c6jIk2yqHausQuGG23AZcPr6IOojd5vOW4U07WXGECmpV-Zk1meXzK0EfsAWEtbmGtoYfpKWd7FuEVGrxe9wu_lwvY3Z2iHq0JR-hGt7FXaU_ZpG_qVNfXSvNIRiF28thcfgDVaGAfrXw_IsyE0g6BRYI1sdECwhusB1d8F8d1JHbilKzxibS0Ar5VDN9iWnTOIgrienkvQ93Ytj7TvedgypOXJywgWISb-NMA1ByKuhqTT4tDzg9DXKY18OcUpRpvntc0FJv3lg1MrwYfKWeRJ9vdm4ybz9uzskCw8ndv8f6snUZtVwyOvY3KrC0TJjDND1-zAFGQKJnMGOdQbUWW1PXoyc-TQtGcZpMyW24PHtIA6KTdhtiLSKG-hK8EcQp6a0zo9qcSvyMLVMGur4t1WkTiXqKtUWVcBRBATHzz1e_B-SZpDqOts25iL2xFiukvUNBhCg2_mZ5lkscvkWg8XpP8mDhzMAzkoIo5EKSe1CiBMYJpEzp-8YLfqCQDv37lOLzKCBPlvOcGcNcyLLM1fqDUUH5p6aDJ5n7rREsbhqTdybwXHjHaefGUIjGd6_Ykr4xCc7dfc1HO9pnJYJ7JRwX11qR5pNOZTJ__FiW-9HcBR05o30XrKlXWjXLL9ICveJ2vMGtLDWni7mq4WzG33vDAbDUQ-e53kgYGb6CqfSWqNAbb_XO3FCFj4N9y-5_5pfC4516-8smBRTMuAgcRXNwy2lc4df6boRMkLm6mzoLvt1TnDro=&xkcb=SoCK6_M33zC0QjygyR0PbzkdCdPP&camk=ethIe0s0hefZAnnQPddW2w==&p=4&fvj=0&vjs=3  Title: Data Engineer I (R-17233) Company: Dun & Bradstreet URL: https://www.indeed.com/rc/clk?jk=f039623f105630f2&bb=PoicSlG4oL4KE_mzfAfPJQLW9-QeUhNE-LnLhssjIUMi376plMIitIVnT7mHsSmSASycmHVr1VH9VhABennBaEtofFSreiRn1aJqF_U3sMJHaSkapKMA8gFQ9MK55n2-&xkcb=SoDK67M33zC0QjygyR0ObzkdCdPP&fccid=fa0ca3b638673d62&vjs=3  Title: CREATIVE DATA ENGINEER Company: Cella URL: https://www.indeed.com/rc/clk?jk=b0c723def39603d4&bb=PoicSlG4oL4KE_mzfAfPJVAExLkVvzav5xGULH5rInxqP_VOZvp7gIYKHqCbThZnz74iHJSrpwyLvY_tDnNB1qNot1o3pgaCTHDhUgiodMvTePfp19wkaz-MSGJlus8W&xkcb=SoBX67M33zC0QjygyR0NbzkdCdPP&fccid=d306bce47a67346c&vjs=3  Title: Data Engineer Company: Index Analytics Llc URL: https://www.indeed.com/rc/clk?jk=7b85b76ecc3b54d6&bb=PoicSlG4oL4KE_mzfAfPJY4Dgjs89jD-8RFjiEfPnEzhc0hOX-aSPF40EqrIu8YiA6s8Oq_eiggSWYMvfK_q8EeLkdvssJJ_JWyu_ecKBnzuC3rVCeLzZQFP83W9ZrAp&xkcb=SoDj67M33zC0QjygyR0MbzkdCdPP&fccid=8cbf9de34e58e41b&vjs=3  Title: Data Engineer/ SQL Company: VForce InfoTech URL: https://www.indeed.com/pagead/clk?mo=r&ad=-6NYlbfkN0BoslJVGns8qfR_aOiNbQuDVC0Y27-j1RL-pKQzTNZtWfIQva2k7RlVGWpZ7oj2R4ylb0Kg62Z-SSkwYRUxa-meEqsK1kednCikHmTaN33bQ8F7ZO1559Ws-z4x_C6rberdZi12TNcKAKpFQ-fC374Vr6z8Tz5SEhqXzVJ9scX7NDOuRvRL1euuXx2pN7UO-zJFnmF3cdV8gSYjf92zw3w6knkC0a7D6QKwaiuNfF8d8LSlcVEBDQicLusNAknWYtrdmnMHIsVOq_zx4V6Q68LZIZ8-hsB3D5LzxOtpbB30gr8Waq9BKKStfa4TAhKtPKm2-77Q2PvvefnqIrXBfwMwenjvUVCDO8HxnDiSAGnRkjql6noSIKV63FaAqqlG5o83048tf683Ij-onLSNCaatFys1NzNnPAEcoVWEkCcPifpyJXTFUm0SiTXYLKythW23AdZBJ-3LEvZZ7b_MW4O2NwN_pOiQzKv98z1mRk54efuwg9UHUN42Vs-fCAt61v3E64QjIupY2azYZilCmGbKIMqxswiGEjmg0dCvLdhuhTfAgL5gGTu_PL6y6ZPTc3XqIrd3d8Vjsx1egEoWyoaz98z1fSxb6okVmi63g9anVZ6zrxqft6OI&xkcb=SoD-6_M33zC0QjygyR0DbzkdCdPP&camk=ethIe0s0hedRVYebutXmHw==&p=8&fvj=0&vjs=3  Title: Data Analyst Company: Fix-It 24/7 URL: https://www.indeed.com/rc/clk?jk=06050d41e9f16407&bb=PoicSlG4oL4KE_mzfAfPJcNDVm6or-NNAyXlZWh9lXFRtdo0uyvpn7kUUMr_VtjQOlrGg4zo5d1KEwrEdT-eRV_WQR4VBjrpc_vXphj0PfPcm7USRlPWyO_RNSeTtTup&xkcb=SoC-67M33zC0QjygyR0CbzkdCdPP&fccid=61e4e7d2ce056d37&vjs=3  Title: Data Analyst Company: Munich Re Specialty - North America URL: https://www.indeed.com/rc/clk?jk=ab2d8d19d1cd0ba2&bb=PoicSlG4oL4KE_mzfAfPJavgGXVCAXmVEBSucc3YFraHOlH2kh32HgjVOBeNG3FI-7-vWYmOqtpAvRLhliZCWkEocJRMdjsG-X-9NAVX2fEUvg7YbkQtOg%3D%3D&xkcb=SoAj67M33zC0QjygyR0BbzkdCdPP&fccid=dd616958bd9ddc12&vjs=3  Title: Data Engineer Company: KesarWeb URL: https://www.indeed.com/rc/clk?jk=375bf3b4e704091b&bb=PoicSlG4oL4KE_mzfAfPJfbKlByUIdhRJLa8Sz_HeJa00xcyA3EGfchbV2MZ7DteGJm1-OJRhhwuYN8722Kq2t8l5gXe4PhqDfaVlyiLT4ELXjZ4iAfmQVcBEBGAvyUR&xkcb=SoCX67M33zC0QjygyR0AbzkdCdPP&fccid=36a6953a97504177&cmp=KesarWeb&ti=Data+Engineer&vjs=3  Title: Junior Data Analyst Company: BIGEYE Agency URL: https://www.indeed.com/rc/clk?jk=1bd637c0266670f9&bb=PoicSlG4oL4KE_mzfAfPJdZcwBLmA7r48FTyouCeFKZuoODWqcYrY4l_U-Yz8_g20Z_JVOmOFiNGhiVABTH9V7kNbeQ2PdEBVvpUnwQuZjd_MNBMsCTdde1-ab6iBRLu&xkcb=SoAZ67M33zC0QjygyR0HbzkdCdPP&fccid=a82b8d0828c4dc85&vjs=3  Title: Data Engineer Company: Intone Networks URL: https://www.indeed.com/rc/clk?jk=672fe0f4f3692aaf&bb=PoicSlG4oL4KE_mzfAfPJRxx6B42VjRnVyQUl8_FL0gQ_sXGmkaKqW7FmZGQ8Rz823_QPS2sPW000nZdYp_BwyZnhbKLYiG3rRPH7zQTOEOry731wTWVwFQjWhlKq_wD&xkcb=SoCt67M33zC0QjygyR0GbzkdCdPP&fccid=3ed0572c448b2368&vjs=3  Title: Data Engineer Company: Tixr URL: https://www.indeed.com/rc/clk?jk=8c7fc3318df61439&bb=PoicSlG4oL4KE_mzfAfPJQdkRLvimhkRu14iVvKd8Qu_VLxH_uafJx7tpA2cEyVgnS2nunvTq1lqeVlMtSm-Tem2fhZgxEKXtxHcfj92jEN68X-999n3_Bbt_VCOnYKy&xkcb=SoAw67M33zC0QjygyR0FbzkdCdPP&fccid=e0708763009091cb&vjs=3",
         "data",
         "Description: Join our winning team, recently honored as #67 on Forbes’ list of America’s Best Startup Employers for 2024! About The Helper Bees The Helper Bees’ mission is to help people stay home longer through data-driven services that transform both the payer and the care-recipient experience. At The Helper Bees, we are reshaping how care is delivered to aging individuals by leveraging innovative technology and insightful data solutions. We maintain multiple SaaS products and payment solutions through our web applications (internal and external facing), a mobile app, and reporting integrations. As part of our growing Data Engineering team, you’ll iterate quickly, have a high impact, and be challenged to design and implement cutting-edge solutions. At THB, we define our company culture through our Core Values: Quickly iterate through solutions: We move at a fast pace which requires quick iterations to find a path to a repeatable solution. Seek ways to create immediate impact: Be thoughtful and proactive in how you make an impact on your team. Actively look for ways to make a fast, positive impact. Bee the teammate you want to work with: We work as a team, help each other, and encourage each other. Ask questions, answer questions: You can't iterate through solutions if you don't ask the right questions, which is why there is an expectation that questions should be asked. When you know the answer, being a good teammate means chiming in to get others up to speed. Take the time to celebrate wins: It's so easy for a team that is heads down to forget about all the great things they've accomplished. That's why we make it a priority to remind ourselves to create space to celebrate wins, big or small. Job Summary We are seeking a motivated Data Engineer to join our team and help improve our tools, processes, and technical infrastructure. In this role, you will ensure the availability and quality of our data while contributing to the design, implementation, and maintenance of The Helper Bees’ products. You’ll collaborate across teams to create scalable and optimized software systems and play a key role in refining our development processes. This position offers a unique opportunity to learn and leverage cutting-edge AI development tools to enhance coding efficiency and develop advanced data tools and solutions. Supervisory Responsibilities: None Key Responsibilities Data Infrastructure: Design, implement, and maintain data pipelines, ensuring data availability, quality, and scalability. Product Development: Build and enhance products using Python, SQL, and modern technologies. AI Integration: Leverage cutting-edge AI tools, including Cursor, ChatGPT, and Claude to improve development processes, automate workflows, and create innovative data solutions. Collaboration: Communicate across departments to design, build, test, and implement new features and enhancements. Code Excellence: Produce quality, testable, and maintainable code while participating in code reviews. Problem Solving: Debug complex issues, interact with stakeholders, and design viable solutions with clear trade-offs. Process Optimization: Contribute to improving development processes, including deployment, on-call systems, and sprint planning. Team Growth: Collaborate within the development team to help each other grow and continuously learn. Stakeholder Engagement: Partner with analysts, scientists, and IT to ensure alignment and deliver data-driven solutions. Other duties as assigned/necessary Performance Metrics Code Quality: Maintain high coding standards through regular code reviews and adherence to best practices. Development Efficiency: Deliver high-quality features and fixes within efficient timeframes. Bug Resolution Time: Reduce the time taken to identify and resolve issues. System Scalability: Optimize system performance to handle increasing user demands. Collaboration: Foster a collaborative environment that encourages teamwork and knowledge sharing. Customer Satisfaction: Incorporate stakeholder feedback to improve solutions and enhance the customer experience. Continuous Learning: Pursue opportunities for skill development and share knowledge with the team. Requirements: Required Skills & Qualifications Technical Tools: Experience with in Python and/or SQL. Experience with Bash, Shell scripting, Big Query, Airflow, and is a plus. Programming: Cleaning data using code-based approach. AI Proficiency: Interest or experience in using AI tools for coding and development of data solutions. Soft Skills: Problem-solving, cross-team collaboration, data storytelling, and stakeholder engagement. Adaptability: Thrives in a fast-paced startup environment and embraces change. Proactivity: Self-directed, organized, and able to prioritize effectively. Collaboration: Ability to work effectively with cross-functional teams. Education & Experience: A bachelor’s degree is required, and a graduate degree is preferred. Relevant experience in data engineering, software development, STEM, or related fields. Strong experience with SQL and Python is highly desirable. Mindset: A passion for innovation, continuous improvement, and delivering high-quality results from messy data. Preferred Qualifications Familiarity with cloud-based solutions (e.g., Google Cloud Platform, Azure). Experience with ETL processes and tools. Experience building data visualization reports and dashboards Knowledge of modern data storage solutions and database management systems. Exposure to DevOps practices and tools for deployment and monitoring. Why Join Us? Work with a talented, collaborative team dedicated to making a difference. Gain exposure to innovative technologies and opportunities for growth. Learn and utilize cutting-edge AI tools to enhance your development skills and create impactful solutions. Be part of a company that values your contributions and encourages professional development. Join a rapidly expanding health-tech startup (~200 employees and growing) with a state-of-the-art technology office located in Hyde Park, offering a variety of exceptional benefits. Career Progression Timeline In 3 months: Gain a comprehensive understanding of our data infrastructure, technical stacks, and development cycles. Actively participate in team meetings and contribute to the development of new data pipelines. Begin leveraging AI tools, such as Cursor and ChatGPT, to enhance coding efficiency and workflow automation. In 6 months: Contribute to product enhancements and data reporting Collaborate effectively with cross-functional teams, providing insights and solutions for data-related challenges. Demonstrate proficiency in utilizing AI tools for coding and development, actively sharing knowledge with the team. In 12 months: Contribute to data engineering projects, ensuring scalability and performance optimization. Mentor non-technical internal partners to improve company-wide data literacy Contribute to the integration of advanced AI solutions into our development processes, contributing to the company's technological advancement. Physical Requirements: Ability to remain at your designated workstation for the duration of the workday Constantly operates a computer and other office productivity machinery, such as a phone and Voice over Internet Protocol (VoIP). The ability to communicate information and ideas so others will understand. Must be able to exchange accurate information in these situations. The ability to observe details at close range (typically on a computer screen) This position offers the flexibility of remote work at approved locations within the United States. Candidates must have a reliable internet connection and a designated work environment conducive to professional phone calls and sensitive data. Enjoy the convenience and comfort of working remotely while contributing to our team's success. Apply Today If you’re ready to take on challenging problems, contribute to impactful solutions, and grow as a data engineer, we’d love to hear from you. Join us at The Helper Bees and be part of a team that’s making a meaningful difference every day! The Helper Bees is committed to building a workplace where diversity, equity, and inclusion are valued and prioritized. We are an equal opportunity employer that welcomes all qualified applicants without discrimination based on race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or any non-merit based or legally protected grounds. The Helper Bees provides reasonable accommodations to qualified individuals with disabilities during the job application and interview process. To request accommodation, please let your recruiter know. As part of our standard hiring process, selected candidates may be required to undergo a background check and/or drug screen. The Helper Bees adheres to applicable federal, state, and local laws regarding these screenings, and the results will be considered in accordance with applicable regulations. The Helper Bees was recently made aware of a fraudulent entity posing as our organization and requesting personal information. Please be aware of and protect yourself from scams. Visit thehelperbees.com/careers to view all current job openings. Title: Junior Data Analyst Company: Curacao URL:   Title: Data Engineer Company: The Helper Bees URL:   Title: Full-time Parts manager and farm data processor. Company: Broughton Farm Operations, LLC. URL:   Title: AI Data Engineer Company: Scully Company URL:   Title: FBI Special Agent: Data Science & Intelligence Expertise Company: Federal Bureau of Investigation URL:   Title: Data Engineer I (R-17233) Company: Dun & Bradstreet URL:   Title: CREATIVE DATA ENGINEER Company: Cella URL:   Title: Data Engineer Company: Index Analytics Llc URL:   Title: Data Engineer/ SQL Company: VForce InfoTech URL:   Title: Data Analyst Company: Fix-It 24/7 URL:   Title: Data Analyst Company: Munich Re Specialty - North America URL:   Title: Data Engineer Company: KesarWeb URL:   Title: Junior Data Analyst Company: BIGEYE Agency URL:   Title: Data Engineer Company: Intone Networks URL:   Title: Data Engineer Company: Tixr URL: ",
         "Description: Join our winning team, recently honored as #67 on Forbes’ list of America’s Best Startup Employers for 2024! About The Helper Bees The Helper Bees’ mission is to help people stay home longer through data-driven services that transform both the payer and the care-recipient experience. At The Helper Bees, we are reshaping how care is delivered to aging individuals by leveraging innovative technology and insightful data solutions. We maintain multiple SaaS products and payment solutions through our web applications (internal and external facing), a mobile app, and reporting integrations. As part of our growing Data Engineering team, you’ll iterate quickly, have a high impact, and be challenged to design and implement cutting-edge solutions. At THB, we define our company culture through our Core Values: Quickly iterate through solutions: We move at a fast pace which requires quick iterations to find a path to a repeatable solution. Seek ways to create immediate impact: Be thoughtful and proactive in how you make an impact on your team. Actively look for ways to make a fast, positive impact. Bee the teammate you want to work with: We work as a team, help each other, and encourage each other. Ask questions, answer questions: You can't iterate through solutions if you don't ask the right questions, which is why there is an expectation that questions should be asked. When you know the answer, being a good teammate means chiming in to get others up to speed. Take the time to celebrate wins: It's so easy for a team that is heads down to forget about all the great things they've accomplished. That's why we make it a priority to remind ourselves to create space to celebrate wins, big or small. Job Summary We are seeking a motivated Data Engineer to join our team and help improve our tools, processes, and technical infrastructure. In this role, you will ensure the availability and quality of our data while contributing to the design, implementation, and maintenance of The Helper Bees’ products. You’ll collaborate across teams to create scalable and optimized software systems and play a key role in refining our development processes. This position offers a unique opportunity to learn and leverage cutting-edge AI development tools to enhance coding efficiency and develop advanced data tools and solutions. Supervisory Responsibilities: None Key Responsibilities Data Infrastructure: Design, implement, and maintain data pipelines, ensuring data availability, quality, and scalability. Product Development: Build and enhance products using Python, SQL, and modern technologies. AI Integration: Leverage cutting-edge AI tools, including Cursor, ChatGPT, and Claude to improve development processes, automate workflows, and create innovative data solutions. Collaboration: Communicate across departments to design, build, test, and implement new features and enhancements. Code Excellence: Produce quality, testable, and maintainable code while participating in code reviews. Problem Solving: Debug complex issues, interact with stakeholders, and design viable solutions with clear trade-offs. Process Optimization: Contribute to improving development processes, including deployment, on-call systems, and sprint planning. Team Growth: Collaborate within the development team to help each other grow and continuously learn. Stakeholder Engagement: Partner with analysts, scientists, and IT to ensure alignment and deliver data-driven solutions. Other duties as assigned/necessary Performance Metrics Code Quality: Maintain high coding standards through regular code reviews and adherence to best practices. Development Efficiency: Deliver high-quality features and fixes within efficient timeframes. Bug Resolution Time: Reduce the time taken to identify and resolve issues. System Scalability: Optimize system performance to handle increasing user demands. Collaboration: Foster a collaborative environment that encourages teamwork and knowledge sharing. Customer Satisfaction: Incorporate stakeholder feedback to improve solutions and enhance the customer experience. Continuous Learning: Pursue opportunities for skill development and share knowledge with the team. Requirements: Required Skills & Qualifications Technical Tools: Experience with in Python and/or SQL. Experience with Bash, Shell scripting, Big Query, Airflow, and is a plus. Programming: Cleaning data using code-based approach. AI Proficiency: Interest or experience in using AI tools for coding and development of data solutions. Soft Skills: Problem-solving, cross-team collaboration, data storytelling, and stakeholder engagement. Adaptability: Thrives in a fast-paced startup environment and embraces change. Proactivity: Self-directed, organized, and able to prioritize effectively. Collaboration: Ability to work effectively with cross-functional teams. Education & Experience: A bachelor’s degree is required, and a graduate degree is preferred. Relevant experience in data engineering, software development, STEM, or related fields. Strong experience with SQL and Python is highly desirable. Mindset: A passion for innovation, continuous improvement, and delivering high-quality results from messy data. Preferred Qualifications Familiarity with cloud-based solutions (e.g., Google Cloud Platform, Azure). Experience with ETL processes and tools. Experience building data visualization reports and dashboards Knowledge of modern data storage solutions and database management systems. Exposure to DevOps practices and tools for deployment and monitoring. Why Join Us? Work with a talented, collaborative team dedicated to making a difference. Gain exposure to innovative technologies and opportunities for growth. Learn and utilize cutting-edge AI tools to enhance your development skills and create impactful solutions. Be part of a company that values your contributions and encourages professional development. Join a rapidly expanding health-tech startup (~200 employees and growing) with a state-of-the-art technology office located in Hyde Park, offering a variety of exceptional benefits. Career Progression Timeline In 3 months: Gain a comprehensive understanding of our data infrastructure, technical stacks, and development cycles. Actively participate in team meetings and contribute to the development of new data pipelines. Begin leveraging AI tools, such as Cursor and ChatGPT, to enhance coding efficiency and workflow automation. In 6 months: Contribute to product enhancements and data reporting Collaborate effectively with cross-functional teams, providing insights and solutions for data-related challenges. Demonstrate proficiency in utilizing AI tools for coding and development, actively sharing knowledge with the team. In 12 months: Contribute to data engineering projects, ensuring scalability and performance optimization. Mentor non-technical internal partners to improve company-wide data literacy Contribute to the integration of advanced AI solutions into our development processes, contributing to the company's technological advancement. Physical Requirements: Ability to remain at your designated workstation for the duration of the workday Constantly operates a computer and other office productivity machinery, such as a phone and Voice over Internet Protocol (VoIP). The ability to communicate information and ideas so others will understand. Must be able to exchange accurate information in these situations. The ability to observe details at close range (typically on a computer screen) This position offers the flexibility of remote work at approved locations within the United States. Candidates must have a reliable internet connection and a designated work environment conducive to professional phone calls and sensitive data. Enjoy the convenience and comfort of working remotely while contributing to our team's success. Apply Today If you’re ready to take on challenging problems, contribute to impactful solutions, and grow as a data engineer, we’d love to hear from you. Join us at The Helper Bees and be part of a team that’s making a meaningful difference every day! The Helper Bees is committed to building a workplace where diversity, equity, and inclusion are valued and prioritized. We are an equal opportunity employer that welcomes all qualified applicants without discrimination based on race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or any non-merit based or legally protected grounds. The Helper Bees provides reasonable accommodations to qualified individuals with disabilities during the job application and interview process. To request accommodation, please let your recruiter know. As part of our standard hiring process, selected candidates may be required to undergo a background check and/or drug screen. The Helper Bees adheres to applicable federal, state, and local laws regarding these screenings, and the results will be considered in accordance with applicable regulations. The Helper Bees was recently made aware of a fraudulent entity posing as our organization and requesting personal information. Please be aware of and protect yourself from scams. Visit thehelperbees.com/careers to view all current job openings. Title: Junior Data Analyst Company: Curacao URL:   Title: Data Engineer Company: The Helper Bees URL:   Title: Full-time Parts manager and farm data processor. Company: Broughton Farm Operations, LLC. URL:   Title: AI Data Engineer Company: Scully Company URL:   Title: FBI Special Agent: Data Science & Intelligence Expertise Company: Federal Bureau of Investigation URL:   Title: Data Engineer I (R-17233) Company: Dun & Bradstreet URL:   Title: CREATIVE DATA ENGINEER Company: Cella URL:   Title: Data Engineer Company: Index Analytics Llc URL:   Title: Data Engineer/ SQL Company: VForce InfoTech URL:   Title: Data Analyst Company: Fix-It 24/7 URL:   Title: Data Analyst Company: Munich Re Specialty - North America URL:   Title: Data Engineer Company: KesarWeb URL:   Title: Junior Data Analyst Company: BIGEYE Agency URL:   Title: Data Engineer Company: Intone Networks URL:   Title: Data Engineer Company: Tixr URL: ",
         "Technical Tools: Experience with in Python and/or SQL. Experience with Bash, Shell scripting, Big Query, Airflow, and is a plus. Programming: Cleaning data using code-based approach. AI Proficiency: Interest or experience in using AI tools for coding and development of data solutions. Soft Skills: Problem-solving, cross-team collaboration, data storytelling, and stakeholder engagement. Adaptability: Thrives in a fast-paced startup environment and embraces change. Proactivity: Self-directed, organized, and able to prioritize effectively. Collaboration: Ability to work effectively with cross-functional teams. Education & Experience: A bachelor’s degree is required, and a graduate degree is preferred. Relevant experience in data engineering, software development, STEM, or related fields. Strong experience with SQL and Python is highly desirable. Mindset: A passion for innovation, continuous improvement, and delivering high-quality results from messy data. Preferred Qualifications Familiarity with cloud-based solutions (e.g., Google Cloud Platform, Azure). Experience with ETL processes and tools. Experience building data visualization reports and dashboards Knowledge of modern data storage solutions and database management systems. Exposure to DevOps practices and tools for deployment and monitoring. Why Join Us? Work with a talented, collaborative team dedicated to making a difference. Gain exposure to innovative technologies and opportunities for growth. Learn and utilize cutting-edge AI tools to enhance your development skills and create impactful solutions. Be part of a company that values your contributions and encourages professional development. Join a rapidly expanding health-tech startup (~200 employees and growing) with a state-of-the-art technology office located in Hyde Park, offering a variety of exceptional benefits. Career Progression Timeline In 3 months: Gain a comprehensive understanding of our data infrastructure, technical stacks, and development cycles. Actively participate in team meetings and contribute to the development of new data pipelines. Begin leveraging AI tools, such as Cursor and ChatGPT, to enhance coding efficiency and workflow automation. In 6 months: Contribute to product enhancements and data reporting Collaborate effectively with cross-functional teams, providing insights and solutions for data-related challenges. Demonstrate proficiency in utilizing AI tools for coding and development, actively sharing knowledge with the team. In 12 months: Contribute to data engineering projects, ensuring scalability and performance optimization. Mentor non-technical internal partners to improve company-wide data literacy Contribute to the integration of advanced AI solutions into our development processes, contributing to the company's technological advancement. Physical Requirements: Ability to remain at your designated workstation for the duration of the workday Constantly operates a computer and other office productivity machinery, such as a phone and Voice over Internet Protocol (VoIP). The ability to communicate information and ideas so others will understand. Must be able to exchange accurate information in these situations. The ability to observe details at close range (typically on a computer screen) This position offers the flexibility of remote work at approved locations within the United States. Candidates must have a reliable internet connection and a designated work environment conducive to professional phone calls and sensitive data. Enjoy the convenience and comfort of working remotely while contributing to our team's success. Apply Today If you’re ready to take on challenging problems, contribute to impactful solutions, and grow as a data engineer, we’d love to hear from you. Join us at The Helper Bees and be part of a team that’s making a meaningful difference every day! The Helper Bees is committed to building a workplace where diversity, equity, and inclusion are valued and prioritized. We are an equal opportunity employer that welcomes all qualified applicants without discrimination based on race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or any non-merit based or legally protected grounds. The Helper Bees provides reasonable accommodations to qualified individuals with disabilities during the job application and interview process. To request accommodation, please let your recruiter know. As part of our standard hiring process, selected candidates may be required to undergo a background check and/or drug screen. The Helper Bees adheres to applicable federal, state, and local laws regarding these screenings, and the results will be considered in accordance with applicable regulations. The Helper Bees was recently made aware of a fraudulent entity posing as our organization and requesting personal information. Please be aware of and protect yourself from scams. Visit thehelperbees.com/careers to view all current job openings. Title: Junior Data Analyst Company: Curacao URL:   Title: Data Engineer Company: The Helper Bees URL:   Title: Full-time Parts manager and farm data processor. Company: Broughton Farm Operations, LLC. URL:   Title: AI Data Engineer Company: Scully Company URL:   Title: FBI Special Agent: Data Science & Intelligence Expertise Company: Federal Bureau of Investigation URL:   Title: Data Engineer I (R-17233) Company: Dun & Bradstreet URL:   Title: CREATIVE DATA ENGINEER Company: Cella URL:   Title: Data Engineer Company: Index Analytics Llc URL:   Title: Data Engineer/ SQL Company: VForce InfoTech URL:   Title: Data Analyst Company: Fix-It 24/7 URL:   Title: Data Analyst Company: Munich Re Specialty - North America URL:   Title: Data Engineer Company: KesarWeb URL:   Title: Junior Data Analyst Company: BIGEYE Agency URL:   Title: Data Engineer Company: Intone Networks URL:   Title: Data Engineer Company: Tixr URL:",
         828
        ],
        [
         "Data Engineer",
         "#NAME?",
         "Description: Join our winning team, recently honored as #67 on Forbes’ list of America’s Best Startup Employers for 2024! About The Helper Bees The Helper Bees’ mission is to help people stay home longer through data-driven services that transform both the payer and the care-recipient experience. At The Helper Bees, we are reshaping how care is delivered to aging individuals by leveraging innovative technology and insightful data solutions. We maintain multiple SaaS products and payment solutions through our web applications (internal and external facing), a mobile app, and reporting integrations. As part of our growing Data Engineering team, you’ll iterate quickly, have a high impact, and be challenged to design and implement cutting-edge solutions. At THB, we define our company culture through our Core Values: Quickly iterate through solutions: We move at a fast pace which requires quick iterations to find a path to a repeatable solution. Seek ways to create immediate impact: Be thoughtful and proactive in how you make an impact on your team. Actively look for ways to make a fast, positive impact. Bee the teammate you want to work with: We work as a team, help each other, and encourage each other. Ask questions, answer questions: You can't iterate through solutions if you don't ask the right questions, which is why there is an expectation that questions should be asked. When you know the answer, being a good teammate means chiming in to get others up to speed. Take the time to celebrate wins: It's so easy for a team that is heads down to forget about all the great things they've accomplished. That's why we make it a priority to remind ourselves to create space to celebrate wins, big or small. Job Summary We are seeking a motivated Data Engineer to join our team and help improve our tools, processes, and technical infrastructure. In this role, you will ensure the availability and quality of our data while contributing to the design, implementation, and maintenance of The Helper Bees’ products. You’ll collaborate across teams to create scalable and optimized software systems and play a key role in refining our development processes. This position offers a unique opportunity to learn and leverage cutting-edge AI development tools to enhance coding efficiency and develop advanced data tools and solutions. Supervisory Responsibilities: None Key Responsibilities Data Infrastructure: Design, implement, and maintain data pipelines, ensuring data availability, quality, and scalability. Product Development: Build and enhance products using Python, SQL, and modern technologies. AI Integration: Leverage cutting-edge AI tools, including Cursor, ChatGPT, and Claude to improve development processes, automate workflows, and create innovative data solutions. Collaboration: Communicate across departments to design, build, test, and implement new features and enhancements. Code Excellence: Produce quality, testable, and maintainable code while participating in code reviews. Problem Solving: Debug complex issues, interact with stakeholders, and design viable solutions with clear trade-offs. Process Optimization: Contribute to improving development processes, including deployment, on-call systems, and sprint planning. Team Growth: Collaborate within the development team to help each other grow and continuously learn. Stakeholder Engagement: Partner with analysts, scientists, and IT to ensure alignment and deliver data-driven solutions. Other duties as assigned/necessary Performance Metrics Code Quality: Maintain high coding standards through regular code reviews and adherence to best practices. Development Efficiency: Deliver high-quality features and fixes within efficient timeframes. Bug Resolution Time: Reduce the time taken to identify and resolve issues. System Scalability: Optimize system performance to handle increasing user demands. Collaboration: Foster a collaborative environment that encourages teamwork and knowledge sharing. Customer Satisfaction: Incorporate stakeholder feedback to improve solutions and enhance the customer experience. Continuous Learning: Pursue opportunities for skill development and share knowledge with the team. Requirements: Required Skills & Qualifications Technical Tools: Experience with in Python and/or SQL. Experience with Bash, Shell scripting, Big Query, Airflow, and is a plus. Programming: Cleaning data using code-based approach. AI Proficiency: Interest or experience in using AI tools for coding and development of data solutions. Soft Skills: Problem-solving, cross-team collaboration, data storytelling, and stakeholder engagement. Adaptability: Thrives in a fast-paced startup environment and embraces change. Proactivity: Self-directed, organized, and able to prioritize effectively. Collaboration: Ability to work effectively with cross-functional teams. Education & Experience: A bachelor’s degree is required, and a graduate degree is preferred. Relevant experience in data engineering, software development, STEM, or related fields. Strong experience with SQL and Python is highly desirable. Mindset: A passion for innovation, continuous improvement, and delivering high-quality results from messy data. Preferred Qualifications Familiarity with cloud-based solutions (e.g., Google Cloud Platform, Azure). Experience with ETL processes and tools. Experience building data visualization reports and dashboards Knowledge of modern data storage solutions and database management systems. Exposure to DevOps practices and tools for deployment and monitoring. Why Join Us? Work with a talented, collaborative team dedicated to making a difference. Gain exposure to innovative technologies and opportunities for growth. Learn and utilize cutting-edge AI tools to enhance your development skills and create impactful solutions. Be part of a company that values your contributions and encourages professional development. Join a rapidly expanding health-tech startup (~200 employees and growing) with a state-of-the-art technology office located in Hyde Park, offering a variety of exceptional benefits. Career Progression Timeline In 3 months: Gain a comprehensive understanding of our data infrastructure, technical stacks, and development cycles. Actively participate in team meetings and contribute to the development of new data pipelines. Begin leveraging AI tools, such as Cursor and ChatGPT, to enhance coding efficiency and workflow automation. In 6 months: Contribute to product enhancements and data reporting Collaborate effectively with cross-functional teams, providing insights and solutions for data-related challenges. Demonstrate proficiency in utilizing AI tools for coding and development, actively sharing knowledge with the team. In 12 months: Contribute to data engineering projects, ensuring scalability and performance optimization. Mentor non-technical internal partners to improve company-wide data literacy Contribute to the integration of advanced AI solutions into our development processes, contributing to the company's technological advancement. Physical Requirements: Ability to remain at your designated workstation for the duration of the workday Constantly operates a computer and other office productivity machinery, such as a phone and Voice over Internet Protocol (VoIP). The ability to communicate information and ideas so others will understand. Must be able to exchange accurate information in these situations. The ability to observe details at close range (typically on a computer screen) This position offers the flexibility of remote work at approved locations within the United States. Candidates must have a reliable internet connection and a designated work environment conducive to professional phone calls and sensitive data. Enjoy the convenience and comfort of working remotely while contributing to our team's success. Apply Today If you’re ready to take on challenging problems, contribute to impactful solutions, and grow as a data engineer, we’d love to hear from you. Join us at The Helper Bees and be part of a team that’s making a meaningful difference every day! The Helper Bees is committed to building a workplace where diversity, equity, and inclusion are valued and prioritized. We are an equal opportunity employer that welcomes all qualified applicants without discrimination based on race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or any non-merit based or legally protected grounds. The Helper Bees provides reasonable accommodations to qualified individuals with disabilities during the job application and interview process. To request accommodation, please let your recruiter know. As part of our standard hiring process, selected candidates may be required to undergo a background check and/or drug screen. The Helper Bees adheres to applicable federal, state, and local laws regarding these screenings, and the results will be considered in accordance with applicable regulations. The Helper Bees was recently made aware of a fraudulent entity posing as our organization and requesting personal information. Please be aware of and protect yourself from scams. Visit thehelperbees.com/careers to view all current job openings.",
         "data",
         "Description: Join our winning team, recently honored as #67 on Forbes’ list of America’s Best Startup Employers for 2024! About The Helper Bees The Helper Bees’ mission is to help people stay home longer through data-driven services that transform both the payer and the care-recipient experience. At The Helper Bees, we are reshaping how care is delivered to aging individuals by leveraging innovative technology and insightful data solutions. We maintain multiple SaaS products and payment solutions through our web applications (internal and external facing), a mobile app, and reporting integrations. As part of our growing Data Engineering team, you’ll iterate quickly, have a high impact, and be challenged to design and implement cutting-edge solutions. At THB, we define our company culture through our Core Values: Quickly iterate through solutions: We move at a fast pace which requires quick iterations to find a path to a repeatable solution. Seek ways to create immediate impact: Be thoughtful and proactive in how you make an impact on your team. Actively look for ways to make a fast, positive impact. Bee the teammate you want to work with: We work as a team, help each other, and encourage each other. Ask questions, answer questions: You can't iterate through solutions if you don't ask the right questions, which is why there is an expectation that questions should be asked. When you know the answer, being a good teammate means chiming in to get others up to speed. Take the time to celebrate wins: It's so easy for a team that is heads down to forget about all the great things they've accomplished. That's why we make it a priority to remind ourselves to create space to celebrate wins, big or small. Job Summary We are seeking a motivated Data Engineer to join our team and help improve our tools, processes, and technical infrastructure. In this role, you will ensure the availability and quality of our data while contributing to the design, implementation, and maintenance of The Helper Bees’ products. You’ll collaborate across teams to create scalable and optimized software systems and play a key role in refining our development processes. This position offers a unique opportunity to learn and leverage cutting-edge AI development tools to enhance coding efficiency and develop advanced data tools and solutions. Supervisory Responsibilities: None Key Responsibilities Data Infrastructure: Design, implement, and maintain data pipelines, ensuring data availability, quality, and scalability. Product Development: Build and enhance products using Python, SQL, and modern technologies. AI Integration: Leverage cutting-edge AI tools, including Cursor, ChatGPT, and Claude to improve development processes, automate workflows, and create innovative data solutions. Collaboration: Communicate across departments to design, build, test, and implement new features and enhancements. Code Excellence: Produce quality, testable, and maintainable code while participating in code reviews. Problem Solving: Debug complex issues, interact with stakeholders, and design viable solutions with clear trade-offs. Process Optimization: Contribute to improving development processes, including deployment, on-call systems, and sprint planning. Team Growth: Collaborate within the development team to help each other grow and continuously learn. Stakeholder Engagement: Partner with analysts, scientists, and IT to ensure alignment and deliver data-driven solutions. Other duties as assigned/necessary Performance Metrics Code Quality: Maintain high coding standards through regular code reviews and adherence to best practices. Development Efficiency: Deliver high-quality features and fixes within efficient timeframes. Bug Resolution Time: Reduce the time taken to identify and resolve issues. System Scalability: Optimize system performance to handle increasing user demands. Collaboration: Foster a collaborative environment that encourages teamwork and knowledge sharing. Customer Satisfaction: Incorporate stakeholder feedback to improve solutions and enhance the customer experience. Continuous Learning: Pursue opportunities for skill development and share knowledge with the team. Requirements: Required Skills & Qualifications Technical Tools: Experience with in Python and/or SQL. Experience with Bash, Shell scripting, Big Query, Airflow, and is a plus. Programming: Cleaning data using code-based approach. AI Proficiency: Interest or experience in using AI tools for coding and development of data solutions. Soft Skills: Problem-solving, cross-team collaboration, data storytelling, and stakeholder engagement. Adaptability: Thrives in a fast-paced startup environment and embraces change. Proactivity: Self-directed, organized, and able to prioritize effectively. Collaboration: Ability to work effectively with cross-functional teams. Education & Experience: A bachelor’s degree is required, and a graduate degree is preferred. Relevant experience in data engineering, software development, STEM, or related fields. Strong experience with SQL and Python is highly desirable. Mindset: A passion for innovation, continuous improvement, and delivering high-quality results from messy data. Preferred Qualifications Familiarity with cloud-based solutions (e.g., Google Cloud Platform, Azure). Experience with ETL processes and tools. Experience building data visualization reports and dashboards Knowledge of modern data storage solutions and database management systems. Exposure to DevOps practices and tools for deployment and monitoring. Why Join Us? Work with a talented, collaborative team dedicated to making a difference. Gain exposure to innovative technologies and opportunities for growth. Learn and utilize cutting-edge AI tools to enhance your development skills and create impactful solutions. Be part of a company that values your contributions and encourages professional development. Join a rapidly expanding health-tech startup (~200 employees and growing) with a state-of-the-art technology office located in Hyde Park, offering a variety of exceptional benefits. Career Progression Timeline In 3 months: Gain a comprehensive understanding of our data infrastructure, technical stacks, and development cycles. Actively participate in team meetings and contribute to the development of new data pipelines. Begin leveraging AI tools, such as Cursor and ChatGPT, to enhance coding efficiency and workflow automation. In 6 months: Contribute to product enhancements and data reporting Collaborate effectively with cross-functional teams, providing insights and solutions for data-related challenges. Demonstrate proficiency in utilizing AI tools for coding and development, actively sharing knowledge with the team. In 12 months: Contribute to data engineering projects, ensuring scalability and performance optimization. Mentor non-technical internal partners to improve company-wide data literacy Contribute to the integration of advanced AI solutions into our development processes, contributing to the company's technological advancement. Physical Requirements: Ability to remain at your designated workstation for the duration of the workday Constantly operates a computer and other office productivity machinery, such as a phone and Voice over Internet Protocol (VoIP). The ability to communicate information and ideas so others will understand. Must be able to exchange accurate information in these situations. The ability to observe details at close range (typically on a computer screen) This position offers the flexibility of remote work at approved locations within the United States. Candidates must have a reliable internet connection and a designated work environment conducive to professional phone calls and sensitive data. Enjoy the convenience and comfort of working remotely while contributing to our team's success. Apply Today If you’re ready to take on challenging problems, contribute to impactful solutions, and grow as a data engineer, we’d love to hear from you. Join us at The Helper Bees and be part of a team that’s making a meaningful difference every day! The Helper Bees is committed to building a workplace where diversity, equity, and inclusion are valued and prioritized. We are an equal opportunity employer that welcomes all qualified applicants without discrimination based on race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or any non-merit based or legally protected grounds. The Helper Bees provides reasonable accommodations to qualified individuals with disabilities during the job application and interview process. To request accommodation, please let your recruiter know. As part of our standard hiring process, selected candidates may be required to undergo a background check and/or drug screen. The Helper Bees adheres to applicable federal, state, and local laws regarding these screenings, and the results will be considered in accordance with applicable regulations. The Helper Bees was recently made aware of a fraudulent entity posing as our organization and requesting personal information. Please be aware of and protect yourself from scams. Visit thehelperbees.com/careers to view all current job openings.",
         "Description: Join our winning team, recently honored as #67 on Forbes’ list of America’s Best Startup Employers for 2024! About The Helper Bees The Helper Bees’ mission is to help people stay home longer through data-driven services that transform both the payer and the care-recipient experience. At The Helper Bees, we are reshaping how care is delivered to aging individuals by leveraging innovative technology and insightful data solutions. We maintain multiple SaaS products and payment solutions through our web applications (internal and external facing), a mobile app, and reporting integrations. As part of our growing Data Engineering team, you’ll iterate quickly, have a high impact, and be challenged to design and implement cutting-edge solutions. At THB, we define our company culture through our Core Values: Quickly iterate through solutions: We move at a fast pace which requires quick iterations to find a path to a repeatable solution. Seek ways to create immediate impact: Be thoughtful and proactive in how you make an impact on your team. Actively look for ways to make a fast, positive impact. Bee the teammate you want to work with: We work as a team, help each other, and encourage each other. Ask questions, answer questions: You can't iterate through solutions if you don't ask the right questions, which is why there is an expectation that questions should be asked. When you know the answer, being a good teammate means chiming in to get others up to speed. Take the time to celebrate wins: It's so easy for a team that is heads down to forget about all the great things they've accomplished. That's why we make it a priority to remind ourselves to create space to celebrate wins, big or small. Job Summary We are seeking a motivated Data Engineer to join our team and help improve our tools, processes, and technical infrastructure. In this role, you will ensure the availability and quality of our data while contributing to the design, implementation, and maintenance of The Helper Bees’ products. You’ll collaborate across teams to create scalable and optimized software systems and play a key role in refining our development processes. This position offers a unique opportunity to learn and leverage cutting-edge AI development tools to enhance coding efficiency and develop advanced data tools and solutions. Supervisory Responsibilities: None Key Responsibilities Data Infrastructure: Design, implement, and maintain data pipelines, ensuring data availability, quality, and scalability. Product Development: Build and enhance products using Python, SQL, and modern technologies. AI Integration: Leverage cutting-edge AI tools, including Cursor, ChatGPT, and Claude to improve development processes, automate workflows, and create innovative data solutions. Collaboration: Communicate across departments to design, build, test, and implement new features and enhancements. Code Excellence: Produce quality, testable, and maintainable code while participating in code reviews. Problem Solving: Debug complex issues, interact with stakeholders, and design viable solutions with clear trade-offs. Process Optimization: Contribute to improving development processes, including deployment, on-call systems, and sprint planning. Team Growth: Collaborate within the development team to help each other grow and continuously learn. Stakeholder Engagement: Partner with analysts, scientists, and IT to ensure alignment and deliver data-driven solutions. Other duties as assigned/necessary Performance Metrics Code Quality: Maintain high coding standards through regular code reviews and adherence to best practices. Development Efficiency: Deliver high-quality features and fixes within efficient timeframes. Bug Resolution Time: Reduce the time taken to identify and resolve issues. System Scalability: Optimize system performance to handle increasing user demands. Collaboration: Foster a collaborative environment that encourages teamwork and knowledge sharing. Customer Satisfaction: Incorporate stakeholder feedback to improve solutions and enhance the customer experience. Continuous Learning: Pursue opportunities for skill development and share knowledge with the team. Requirements: Required Skills & Qualifications Technical Tools: Experience with in Python and/or SQL. Experience with Bash, Shell scripting, Big Query, Airflow, and is a plus. Programming: Cleaning data using code-based approach. AI Proficiency: Interest or experience in using AI tools for coding and development of data solutions. Soft Skills: Problem-solving, cross-team collaboration, data storytelling, and stakeholder engagement. Adaptability: Thrives in a fast-paced startup environment and embraces change. Proactivity: Self-directed, organized, and able to prioritize effectively. Collaboration: Ability to work effectively with cross-functional teams. Education & Experience: A bachelor’s degree is required, and a graduate degree is preferred. Relevant experience in data engineering, software development, STEM, or related fields. Strong experience with SQL and Python is highly desirable. Mindset: A passion for innovation, continuous improvement, and delivering high-quality results from messy data. Preferred Qualifications Familiarity with cloud-based solutions (e.g., Google Cloud Platform, Azure). Experience with ETL processes and tools. Experience building data visualization reports and dashboards Knowledge of modern data storage solutions and database management systems. Exposure to DevOps practices and tools for deployment and monitoring. Why Join Us? Work with a talented, collaborative team dedicated to making a difference. Gain exposure to innovative technologies and opportunities for growth. Learn and utilize cutting-edge AI tools to enhance your development skills and create impactful solutions. Be part of a company that values your contributions and encourages professional development. Join a rapidly expanding health-tech startup (~200 employees and growing) with a state-of-the-art technology office located in Hyde Park, offering a variety of exceptional benefits. Career Progression Timeline In 3 months: Gain a comprehensive understanding of our data infrastructure, technical stacks, and development cycles. Actively participate in team meetings and contribute to the development of new data pipelines. Begin leveraging AI tools, such as Cursor and ChatGPT, to enhance coding efficiency and workflow automation. In 6 months: Contribute to product enhancements and data reporting Collaborate effectively with cross-functional teams, providing insights and solutions for data-related challenges. Demonstrate proficiency in utilizing AI tools for coding and development, actively sharing knowledge with the team. In 12 months: Contribute to data engineering projects, ensuring scalability and performance optimization. Mentor non-technical internal partners to improve company-wide data literacy Contribute to the integration of advanced AI solutions into our development processes, contributing to the company's technological advancement. Physical Requirements: Ability to remain at your designated workstation for the duration of the workday Constantly operates a computer and other office productivity machinery, such as a phone and Voice over Internet Protocol (VoIP). The ability to communicate information and ideas so others will understand. Must be able to exchange accurate information in these situations. The ability to observe details at close range (typically on a computer screen) This position offers the flexibility of remote work at approved locations within the United States. Candidates must have a reliable internet connection and a designated work environment conducive to professional phone calls and sensitive data. Enjoy the convenience and comfort of working remotely while contributing to our team's success. Apply Today If you’re ready to take on challenging problems, contribute to impactful solutions, and grow as a data engineer, we’d love to hear from you. Join us at The Helper Bees and be part of a team that’s making a meaningful difference every day! The Helper Bees is committed to building a workplace where diversity, equity, and inclusion are valued and prioritized. We are an equal opportunity employer that welcomes all qualified applicants without discrimination based on race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or any non-merit based or legally protected grounds. The Helper Bees provides reasonable accommodations to qualified individuals with disabilities during the job application and interview process. To request accommodation, please let your recruiter know. As part of our standard hiring process, selected candidates may be required to undergo a background check and/or drug screen. The Helper Bees adheres to applicable federal, state, and local laws regarding these screenings, and the results will be considered in accordance with applicable regulations. The Helper Bees was recently made aware of a fraudulent entity posing as our organization and requesting personal information. Please be aware of and protect yourself from scams. Visit thehelperbees.com/careers to view all current job openings.",
         "Technical Tools: Experience with in Python and/or SQL. Experience with Bash, Shell scripting, Big Query, Airflow, and is a plus. Programming: Cleaning data using code-based approach. AI Proficiency: Interest or experience in using AI tools for coding and development of data solutions. Soft Skills: Problem-solving, cross-team collaboration, data storytelling, and stakeholder engagement. Adaptability: Thrives in a fast-paced startup environment and embraces change. Proactivity: Self-directed, organized, and able to prioritize effectively. Collaboration: Ability to work effectively with cross-functional teams. Education & Experience: A bachelor’s degree is required, and a graduate degree is preferred. Relevant experience in data engineering, software development, STEM, or related fields. Strong experience with SQL and Python is highly desirable. Mindset: A passion for innovation, continuous improvement, and delivering high-quality results from messy data. Preferred Qualifications Familiarity with cloud-based solutions (e.g., Google Cloud Platform, Azure). Experience with ETL processes and tools. Experience building data visualization reports and dashboards Knowledge of modern data storage solutions and database management systems. Exposure to DevOps practices and tools for deployment and monitoring. Why Join Us? Work with a talented, collaborative team dedicated to making a difference. Gain exposure to innovative technologies and opportunities for growth. Learn and utilize cutting-edge AI tools to enhance your development skills and create impactful solutions. Be part of a company that values your contributions and encourages professional development. Join a rapidly expanding health-tech startup (~200 employees and growing) with a state-of-the-art technology office located in Hyde Park, offering a variety of exceptional benefits. Career Progression Timeline In 3 months: Gain a comprehensive understanding of our data infrastructure, technical stacks, and development cycles. Actively participate in team meetings and contribute to the development of new data pipelines. Begin leveraging AI tools, such as Cursor and ChatGPT, to enhance coding efficiency and workflow automation. In 6 months: Contribute to product enhancements and data reporting Collaborate effectively with cross-functional teams, providing insights and solutions for data-related challenges. Demonstrate proficiency in utilizing AI tools for coding and development, actively sharing knowledge with the team. In 12 months: Contribute to data engineering projects, ensuring scalability and performance optimization. Mentor non-technical internal partners to improve company-wide data literacy Contribute to the integration of advanced AI solutions into our development processes, contributing to the company's technological advancement. Physical Requirements: Ability to remain at your designated workstation for the duration of the workday Constantly operates a computer and other office productivity machinery, such as a phone and Voice over Internet Protocol (VoIP). The ability to communicate information and ideas so others will understand. Must be able to exchange accurate information in these situations. The ability to observe details at close range (typically on a computer screen) This position offers the flexibility of remote work at approved locations within the United States. Candidates must have a reliable internet connection and a designated work environment conducive to professional phone calls and sensitive data. Enjoy the convenience and comfort of working remotely while contributing to our team's success. Apply Today If you’re ready to take on challenging problems, contribute to impactful solutions, and grow as a data engineer, we’d love to hear from you. Join us at The Helper Bees and be part of a team that’s making a meaningful difference every day! The Helper Bees is committed to building a workplace where diversity, equity, and inclusion are valued and prioritized. We are an equal opportunity employer that welcomes all qualified applicants without discrimination based on race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or any non-merit based or legally protected grounds. The Helper Bees provides reasonable accommodations to qualified individuals with disabilities during the job application and interview process. To request accommodation, please let your recruiter know. As part of our standard hiring process, selected candidates may be required to undergo a background check and/or drug screen. The Helper Bees adheres to applicable federal, state, and local laws regarding these screenings, and the results will be considered in accordance with applicable regulations. The Helper Bees was recently made aware of a fraudulent entity posing as our organization and requesting personal information. Please be aware of and protect yourself from scams. Visit thehelperbees.com/careers to view all current job openings.",
         698
        ],
        [
         ":",
         "Curacao",
         "Description: Join our winning team, recently honored as #67 on Forbes’ list of America’s Best Startup Employers for 2024! About The Helper Bees The Helper Bees’ mission is to help people stay home longer through data-driven services that transform both the payer and the care-recipient experience. At The Helper Bees, we are reshaping how care is delivered to aging individuals by leveraging innovative technology and insightful data solutions. We maintain multiple SaaS products and payment solutions through our web applications (internal and external facing), a mobile app, and reporting integrations. As part of our growing Data Engineering team, you’ll iterate quickly, have a high impact, and be challenged to design and implement cutting-edge solutions. At THB, we define our company culture through our Core Values: Quickly iterate through solutions: We move at a fast pace which requires quick iterations to find a path to a repeatable solution. Seek ways to create immediate impact: Be thoughtful and proactive in how you make an impact on your team. Actively look for ways to make a fast, positive impact. Bee the teammate you want to work with: We work as a team, help each other, and encourage each other. Ask questions, answer questions: You can't iterate through solutions if you don't ask the right questions, which is why there is an expectation that questions should be asked. When you know the answer, being a good teammate means chiming in to get others up to speed. Take the time to celebrate wins: It's so easy for a team that is heads down to forget about all the great things they've accomplished. That's why we make it a priority to remind ourselves to create space to celebrate wins, big or small. Job Summary We are seeking a motivated Data Engineer to join our team and help improve our tools, processes, and technical infrastructure. In this role, you will ensure the availability and quality of our data while contributing to the design, implementation, and maintenance of The Helper Bees’ products. You’ll collaborate across teams to create scalable and optimized software systems and play a key role in refining our development processes. This position offers a unique opportunity to learn and leverage cutting-edge AI development tools to enhance coding efficiency and develop advanced data tools and solutions. Supervisory Responsibilities: None Key Responsibilities Data Infrastructure: Design, implement, and maintain data pipelines, ensuring data availability, quality, and scalability. Product Development: Build and enhance products using Python, SQL, and modern technologies. AI Integration: Leverage cutting-edge AI tools, including Cursor, ChatGPT, and Claude to improve development processes, automate workflows, and create innovative data solutions. Collaboration: Communicate across departments to design, build, test, and implement new features and enhancements. Code Excellence: Produce quality, testable, and maintainable code while participating in code reviews. Problem Solving: Debug complex issues, interact with stakeholders, and design viable solutions with clear trade-offs. Process Optimization: Contribute to improving development processes, including deployment, on-call systems, and sprint planning. Team Growth: Collaborate within the development team to help each other grow and continuously learn. Stakeholder Engagement: Partner with analysts, scientists, and IT to ensure alignment and deliver data-driven solutions. Other duties as assigned/necessary Performance Metrics Code Quality: Maintain high coding standards through regular code reviews and adherence to best practices. Development Efficiency: Deliver high-quality features and fixes within efficient timeframes. Bug Resolution Time: Reduce the time taken to identify and resolve issues. System Scalability: Optimize system performance to handle increasing user demands. Collaboration: Foster a collaborative environment that encourages teamwork and knowledge sharing. Customer Satisfaction: Incorporate stakeholder feedback to improve solutions and enhance the customer experience. Continuous Learning: Pursue opportunities for skill development and share knowledge with the team. Requirements: Required Skills & Qualifications Technical Tools: Experience with in Python and/or SQL. Experience with Bash, Shell scripting, Big Query, Airflow, and is a plus. Programming: Cleaning data using code-based approach. AI Proficiency: Interest or experience in using AI tools for coding and development of data solutions. Soft Skills: Problem-solving, cross-team collaboration, data storytelling, and stakeholder engagement. Adaptability: Thrives in a fast-paced startup environment and embraces change. Proactivity: Self-directed, organized, and able to prioritize effectively. Collaboration: Ability to work effectively with cross-functional teams. Education & Experience: A bachelor’s degree is required, and a graduate degree is preferred. Relevant experience in data engineering, software development, STEM, or related fields. Strong experience with SQL and Python is highly desirable. Mindset: A passion for innovation, continuous improvement, and delivering high-quality results from messy data. Preferred Qualifications Familiarity with cloud-based solutions (e.g., Google Cloud Platform, Azure). Experience with ETL processes and tools. Experience building data visualization reports and dashboards Knowledge of modern data storage solutions and database management systems. Exposure to DevOps practices and tools for deployment and monitoring. Why Join Us? Work with a talented, collaborative team dedicated to making a difference. Gain exposure to innovative technologies and opportunities for growth. Learn and utilize cutting-edge AI tools to enhance your development skills and create impactful solutions. Be part of a company that values your contributions and encourages professional development. Join a rapidly expanding health-tech startup (~200 employees and growing) with a state-of-the-art technology office located in Hyde Park, offering a variety of exceptional benefits. Career Progression Timeline In 3 months: Gain a comprehensive understanding of our data infrastructure, technical stacks, and development cycles. Actively participate in team meetings and contribute to the development of new data pipelines. Begin leveraging AI tools, such as Cursor and ChatGPT, to enhance coding efficiency and workflow automation. In 6 months: Contribute to product enhancements and data reporting Collaborate effectively with cross-functional teams, providing insights and solutions for data-related challenges. Demonstrate proficiency in utilizing AI tools for coding and development, actively sharing knowledge with the team. In 12 months: Contribute to data engineering projects, ensuring scalability and performance optimization. Mentor non-technical internal partners to improve company-wide data literacy Contribute to the integration of advanced AI solutions into our development processes, contributing to the company's technological advancement. Physical Requirements: Ability to remain at your designated workstation for the duration of the workday Constantly operates a computer and other office productivity machinery, such as a phone and Voice over Internet Protocol (VoIP). The ability to communicate information and ideas so others will understand. Must be able to exchange accurate information in these situations. The ability to observe details at close range (typically on a computer screen) This position offers the flexibility of remote work at approved locations within the United States. Candidates must have a reliable internet connection and a designated work environment conducive to professional phone calls and sensitive data. Enjoy the convenience and comfort of working remotely while contributing to our team's success. Apply Today If you’re ready to take on challenging problems, contribute to impactful solutions, and grow as a data engineer, we’d love to hear from you. Join us at The Helper Bees and be part of a team that’s making a meaningful difference every day! The Helper Bees is committed to building a workplace where diversity, equity, and inclusion are valued and prioritized. We are an equal opportunity employer that welcomes all qualified applicants without discrimination based on race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or any non-merit based or legally protected grounds. The Helper Bees provides reasonable accommodations to qualified individuals with disabilities during the job application and interview process. To request accommodation, please let your recruiter know. As part of our standard hiring process, selected candidates may be required to undergo a background check and/or drug screen. The Helper Bees adheres to applicable federal, state, and local laws regarding these screenings, and the results will be considered in accordance with applicable regulations. The Helper Bees was recently made aware of a fraudulent entity posing as our organization and requesting personal information. Please be aware of and protect yourself from scams. Visit thehelperbees.com/careers to view all current job openings.",
         "data",
         "Description: Join our winning team, recently honored as #67 on Forbes’ list of America’s Best Startup Employers for 2024! About The Helper Bees The Helper Bees’ mission is to help people stay home longer through data-driven services that transform both the payer and the care-recipient experience. At The Helper Bees, we are reshaping how care is delivered to aging individuals by leveraging innovative technology and insightful data solutions. We maintain multiple SaaS products and payment solutions through our web applications (internal and external facing), a mobile app, and reporting integrations. As part of our growing Data Engineering team, you’ll iterate quickly, have a high impact, and be challenged to design and implement cutting-edge solutions. At THB, we define our company culture through our Core Values: Quickly iterate through solutions: We move at a fast pace which requires quick iterations to find a path to a repeatable solution. Seek ways to create immediate impact: Be thoughtful and proactive in how you make an impact on your team. Actively look for ways to make a fast, positive impact. Bee the teammate you want to work with: We work as a team, help each other, and encourage each other. Ask questions, answer questions: You can't iterate through solutions if you don't ask the right questions, which is why there is an expectation that questions should be asked. When you know the answer, being a good teammate means chiming in to get others up to speed. Take the time to celebrate wins: It's so easy for a team that is heads down to forget about all the great things they've accomplished. That's why we make it a priority to remind ourselves to create space to celebrate wins, big or small. Job Summary We are seeking a motivated Data Engineer to join our team and help improve our tools, processes, and technical infrastructure. In this role, you will ensure the availability and quality of our data while contributing to the design, implementation, and maintenance of The Helper Bees’ products. You’ll collaborate across teams to create scalable and optimized software systems and play a key role in refining our development processes. This position offers a unique opportunity to learn and leverage cutting-edge AI development tools to enhance coding efficiency and develop advanced data tools and solutions. Supervisory Responsibilities: None Key Responsibilities Data Infrastructure: Design, implement, and maintain data pipelines, ensuring data availability, quality, and scalability. Product Development: Build and enhance products using Python, SQL, and modern technologies. AI Integration: Leverage cutting-edge AI tools, including Cursor, ChatGPT, and Claude to improve development processes, automate workflows, and create innovative data solutions. Collaboration: Communicate across departments to design, build, test, and implement new features and enhancements. Code Excellence: Produce quality, testable, and maintainable code while participating in code reviews. Problem Solving: Debug complex issues, interact with stakeholders, and design viable solutions with clear trade-offs. Process Optimization: Contribute to improving development processes, including deployment, on-call systems, and sprint planning. Team Growth: Collaborate within the development team to help each other grow and continuously learn. Stakeholder Engagement: Partner with analysts, scientists, and IT to ensure alignment and deliver data-driven solutions. Other duties as assigned/necessary Performance Metrics Code Quality: Maintain high coding standards through regular code reviews and adherence to best practices. Development Efficiency: Deliver high-quality features and fixes within efficient timeframes. Bug Resolution Time: Reduce the time taken to identify and resolve issues. System Scalability: Optimize system performance to handle increasing user demands. Collaboration: Foster a collaborative environment that encourages teamwork and knowledge sharing. Customer Satisfaction: Incorporate stakeholder feedback to improve solutions and enhance the customer experience. Continuous Learning: Pursue opportunities for skill development and share knowledge with the team. Requirements: Required Skills & Qualifications Technical Tools: Experience with in Python and/or SQL. Experience with Bash, Shell scripting, Big Query, Airflow, and is a plus. Programming: Cleaning data using code-based approach. AI Proficiency: Interest or experience in using AI tools for coding and development of data solutions. Soft Skills: Problem-solving, cross-team collaboration, data storytelling, and stakeholder engagement. Adaptability: Thrives in a fast-paced startup environment and embraces change. Proactivity: Self-directed, organized, and able to prioritize effectively. Collaboration: Ability to work effectively with cross-functional teams. Education & Experience: A bachelor’s degree is required, and a graduate degree is preferred. Relevant experience in data engineering, software development, STEM, or related fields. Strong experience with SQL and Python is highly desirable. Mindset: A passion for innovation, continuous improvement, and delivering high-quality results from messy data. Preferred Qualifications Familiarity with cloud-based solutions (e.g., Google Cloud Platform, Azure). Experience with ETL processes and tools. Experience building data visualization reports and dashboards Knowledge of modern data storage solutions and database management systems. Exposure to DevOps practices and tools for deployment and monitoring. Why Join Us? Work with a talented, collaborative team dedicated to making a difference. Gain exposure to innovative technologies and opportunities for growth. Learn and utilize cutting-edge AI tools to enhance your development skills and create impactful solutions. Be part of a company that values your contributions and encourages professional development. Join a rapidly expanding health-tech startup (~200 employees and growing) with a state-of-the-art technology office located in Hyde Park, offering a variety of exceptional benefits. Career Progression Timeline In 3 months: Gain a comprehensive understanding of our data infrastructure, technical stacks, and development cycles. Actively participate in team meetings and contribute to the development of new data pipelines. Begin leveraging AI tools, such as Cursor and ChatGPT, to enhance coding efficiency and workflow automation. In 6 months: Contribute to product enhancements and data reporting Collaborate effectively with cross-functional teams, providing insights and solutions for data-related challenges. Demonstrate proficiency in utilizing AI tools for coding and development, actively sharing knowledge with the team. In 12 months: Contribute to data engineering projects, ensuring scalability and performance optimization. Mentor non-technical internal partners to improve company-wide data literacy Contribute to the integration of advanced AI solutions into our development processes, contributing to the company's technological advancement. Physical Requirements: Ability to remain at your designated workstation for the duration of the workday Constantly operates a computer and other office productivity machinery, such as a phone and Voice over Internet Protocol (VoIP). The ability to communicate information and ideas so others will understand. Must be able to exchange accurate information in these situations. The ability to observe details at close range (typically on a computer screen) This position offers the flexibility of remote work at approved locations within the United States. Candidates must have a reliable internet connection and a designated work environment conducive to professional phone calls and sensitive data. Enjoy the convenience and comfort of working remotely while contributing to our team's success. Apply Today If you’re ready to take on challenging problems, contribute to impactful solutions, and grow as a data engineer, we’d love to hear from you. Join us at The Helper Bees and be part of a team that’s making a meaningful difference every day! The Helper Bees is committed to building a workplace where diversity, equity, and inclusion are valued and prioritized. We are an equal opportunity employer that welcomes all qualified applicants without discrimination based on race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or any non-merit based or legally protected grounds. The Helper Bees provides reasonable accommodations to qualified individuals with disabilities during the job application and interview process. To request accommodation, please let your recruiter know. As part of our standard hiring process, selected candidates may be required to undergo a background check and/or drug screen. The Helper Bees adheres to applicable federal, state, and local laws regarding these screenings, and the results will be considered in accordance with applicable regulations. The Helper Bees was recently made aware of a fraudulent entity posing as our organization and requesting personal information. Please be aware of and protect yourself from scams. Visit thehelperbees.com/careers to view all current job openings.",
         "Description: Join our winning team, recently honored as #67 on Forbes’ list of America’s Best Startup Employers for 2024! About The Helper Bees The Helper Bees’ mission is to help people stay home longer through data-driven services that transform both the payer and the care-recipient experience. At The Helper Bees, we are reshaping how care is delivered to aging individuals by leveraging innovative technology and insightful data solutions. We maintain multiple SaaS products and payment solutions through our web applications (internal and external facing), a mobile app, and reporting integrations. As part of our growing Data Engineering team, you’ll iterate quickly, have a high impact, and be challenged to design and implement cutting-edge solutions. At THB, we define our company culture through our Core Values: Quickly iterate through solutions: We move at a fast pace which requires quick iterations to find a path to a repeatable solution. Seek ways to create immediate impact: Be thoughtful and proactive in how you make an impact on your team. Actively look for ways to make a fast, positive impact. Bee the teammate you want to work with: We work as a team, help each other, and encourage each other. Ask questions, answer questions: You can't iterate through solutions if you don't ask the right questions, which is why there is an expectation that questions should be asked. When you know the answer, being a good teammate means chiming in to get others up to speed. Take the time to celebrate wins: It's so easy for a team that is heads down to forget about all the great things they've accomplished. That's why we make it a priority to remind ourselves to create space to celebrate wins, big or small. Job Summary We are seeking a motivated Data Engineer to join our team and help improve our tools, processes, and technical infrastructure. In this role, you will ensure the availability and quality of our data while contributing to the design, implementation, and maintenance of The Helper Bees’ products. You’ll collaborate across teams to create scalable and optimized software systems and play a key role in refining our development processes. This position offers a unique opportunity to learn and leverage cutting-edge AI development tools to enhance coding efficiency and develop advanced data tools and solutions. Supervisory Responsibilities: None Key Responsibilities Data Infrastructure: Design, implement, and maintain data pipelines, ensuring data availability, quality, and scalability. Product Development: Build and enhance products using Python, SQL, and modern technologies. AI Integration: Leverage cutting-edge AI tools, including Cursor, ChatGPT, and Claude to improve development processes, automate workflows, and create innovative data solutions. Collaboration: Communicate across departments to design, build, test, and implement new features and enhancements. Code Excellence: Produce quality, testable, and maintainable code while participating in code reviews. Problem Solving: Debug complex issues, interact with stakeholders, and design viable solutions with clear trade-offs. Process Optimization: Contribute to improving development processes, including deployment, on-call systems, and sprint planning. Team Growth: Collaborate within the development team to help each other grow and continuously learn. Stakeholder Engagement: Partner with analysts, scientists, and IT to ensure alignment and deliver data-driven solutions. Other duties as assigned/necessary Performance Metrics Code Quality: Maintain high coding standards through regular code reviews and adherence to best practices. Development Efficiency: Deliver high-quality features and fixes within efficient timeframes. Bug Resolution Time: Reduce the time taken to identify and resolve issues. System Scalability: Optimize system performance to handle increasing user demands. Collaboration: Foster a collaborative environment that encourages teamwork and knowledge sharing. Customer Satisfaction: Incorporate stakeholder feedback to improve solutions and enhance the customer experience. Continuous Learning: Pursue opportunities for skill development and share knowledge with the team. Requirements: Required Skills & Qualifications Technical Tools: Experience with in Python and/or SQL. Experience with Bash, Shell scripting, Big Query, Airflow, and is a plus. Programming: Cleaning data using code-based approach. AI Proficiency: Interest or experience in using AI tools for coding and development of data solutions. Soft Skills: Problem-solving, cross-team collaboration, data storytelling, and stakeholder engagement. Adaptability: Thrives in a fast-paced startup environment and embraces change. Proactivity: Self-directed, organized, and able to prioritize effectively. Collaboration: Ability to work effectively with cross-functional teams. Education & Experience: A bachelor’s degree is required, and a graduate degree is preferred. Relevant experience in data engineering, software development, STEM, or related fields. Strong experience with SQL and Python is highly desirable. Mindset: A passion for innovation, continuous improvement, and delivering high-quality results from messy data. Preferred Qualifications Familiarity with cloud-based solutions (e.g., Google Cloud Platform, Azure). Experience with ETL processes and tools. Experience building data visualization reports and dashboards Knowledge of modern data storage solutions and database management systems. Exposure to DevOps practices and tools for deployment and monitoring. Why Join Us? Work with a talented, collaborative team dedicated to making a difference. Gain exposure to innovative technologies and opportunities for growth. Learn and utilize cutting-edge AI tools to enhance your development skills and create impactful solutions. Be part of a company that values your contributions and encourages professional development. Join a rapidly expanding health-tech startup (~200 employees and growing) with a state-of-the-art technology office located in Hyde Park, offering a variety of exceptional benefits. Career Progression Timeline In 3 months: Gain a comprehensive understanding of our data infrastructure, technical stacks, and development cycles. Actively participate in team meetings and contribute to the development of new data pipelines. Begin leveraging AI tools, such as Cursor and ChatGPT, to enhance coding efficiency and workflow automation. In 6 months: Contribute to product enhancements and data reporting Collaborate effectively with cross-functional teams, providing insights and solutions for data-related challenges. Demonstrate proficiency in utilizing AI tools for coding and development, actively sharing knowledge with the team. In 12 months: Contribute to data engineering projects, ensuring scalability and performance optimization. Mentor non-technical internal partners to improve company-wide data literacy Contribute to the integration of advanced AI solutions into our development processes, contributing to the company's technological advancement. Physical Requirements: Ability to remain at your designated workstation for the duration of the workday Constantly operates a computer and other office productivity machinery, such as a phone and Voice over Internet Protocol (VoIP). The ability to communicate information and ideas so others will understand. Must be able to exchange accurate information in these situations. The ability to observe details at close range (typically on a computer screen) This position offers the flexibility of remote work at approved locations within the United States. Candidates must have a reliable internet connection and a designated work environment conducive to professional phone calls and sensitive data. Enjoy the convenience and comfort of working remotely while contributing to our team's success. Apply Today If you’re ready to take on challenging problems, contribute to impactful solutions, and grow as a data engineer, we’d love to hear from you. Join us at The Helper Bees and be part of a team that’s making a meaningful difference every day! The Helper Bees is committed to building a workplace where diversity, equity, and inclusion are valued and prioritized. We are an equal opportunity employer that welcomes all qualified applicants without discrimination based on race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or any non-merit based or legally protected grounds. The Helper Bees provides reasonable accommodations to qualified individuals with disabilities during the job application and interview process. To request accommodation, please let your recruiter know. As part of our standard hiring process, selected candidates may be required to undergo a background check and/or drug screen. The Helper Bees adheres to applicable federal, state, and local laws regarding these screenings, and the results will be considered in accordance with applicable regulations. The Helper Bees was recently made aware of a fraudulent entity posing as our organization and requesting personal information. Please be aware of and protect yourself from scams. Visit thehelperbees.com/careers to view all current job openings.",
         "Technical Tools: Experience with in Python and/or SQL. Experience with Bash, Shell scripting, Big Query, Airflow, and is a plus. Programming: Cleaning data using code-based approach. AI Proficiency: Interest or experience in using AI tools for coding and development of data solutions. Soft Skills: Problem-solving, cross-team collaboration, data storytelling, and stakeholder engagement. Adaptability: Thrives in a fast-paced startup environment and embraces change. Proactivity: Self-directed, organized, and able to prioritize effectively. Collaboration: Ability to work effectively with cross-functional teams. Education & Experience: A bachelor’s degree is required, and a graduate degree is preferred. Relevant experience in data engineering, software development, STEM, or related fields. Strong experience with SQL and Python is highly desirable. Mindset: A passion for innovation, continuous improvement, and delivering high-quality results from messy data. Preferred Qualifications Familiarity with cloud-based solutions (e.g., Google Cloud Platform, Azure). Experience with ETL processes and tools. Experience building data visualization reports and dashboards Knowledge of modern data storage solutions and database management systems. Exposure to DevOps practices and tools for deployment and monitoring. Why Join Us? Work with a talented, collaborative team dedicated to making a difference. Gain exposure to innovative technologies and opportunities for growth. Learn and utilize cutting-edge AI tools to enhance your development skills and create impactful solutions. Be part of a company that values your contributions and encourages professional development. Join a rapidly expanding health-tech startup (~200 employees and growing) with a state-of-the-art technology office located in Hyde Park, offering a variety of exceptional benefits. Career Progression Timeline In 3 months: Gain a comprehensive understanding of our data infrastructure, technical stacks, and development cycles. Actively participate in team meetings and contribute to the development of new data pipelines. Begin leveraging AI tools, such as Cursor and ChatGPT, to enhance coding efficiency and workflow automation. In 6 months: Contribute to product enhancements and data reporting Collaborate effectively with cross-functional teams, providing insights and solutions for data-related challenges. Demonstrate proficiency in utilizing AI tools for coding and development, actively sharing knowledge with the team. In 12 months: Contribute to data engineering projects, ensuring scalability and performance optimization. Mentor non-technical internal partners to improve company-wide data literacy Contribute to the integration of advanced AI solutions into our development processes, contributing to the company's technological advancement. Physical Requirements: Ability to remain at your designated workstation for the duration of the workday Constantly operates a computer and other office productivity machinery, such as a phone and Voice over Internet Protocol (VoIP). The ability to communicate information and ideas so others will understand. Must be able to exchange accurate information in these situations. The ability to observe details at close range (typically on a computer screen) This position offers the flexibility of remote work at approved locations within the United States. Candidates must have a reliable internet connection and a designated work environment conducive to professional phone calls and sensitive data. Enjoy the convenience and comfort of working remotely while contributing to our team's success. Apply Today If you’re ready to take on challenging problems, contribute to impactful solutions, and grow as a data engineer, we’d love to hear from you. Join us at The Helper Bees and be part of a team that’s making a meaningful difference every day! The Helper Bees is committed to building a workplace where diversity, equity, and inclusion are valued and prioritized. We are an equal opportunity employer that welcomes all qualified applicants without discrimination based on race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or any non-merit based or legally protected grounds. The Helper Bees provides reasonable accommodations to qualified individuals with disabilities during the job application and interview process. To request accommodation, please let your recruiter know. As part of our standard hiring process, selected candidates may be required to undergo a background check and/or drug screen. The Helper Bees adheres to applicable federal, state, and local laws regarding these screenings, and the results will be considered in accordance with applicable regulations. The Helper Bees was recently made aware of a fraudulent entity posing as our organization and requesting personal information. Please be aware of and protect yourself from scams. Visit thehelperbees.com/careers to view all current job openings.",
         698
        ],
        [
         "Data Engineer",
         "Cella",
         "Index Analytics, LLC, is a rapidly growing, Baltimore-based small business providing health-related consulting services to the federal government. At the center of our company culture is a commitment to instilling a dynamic and employee-friendly place to work. We place a priority on promoting a supportive and collegial team environment and enhancing staff experience through career development and educational opportunities. Position Overview The Data Engineer is responsible for designing, building, and maintaining data pipelines and architectures to support data analytics and reporting needs across the organization. This role involves working closely with data scientists, analysts, and other stakeholders to ensure that data is clean, accessible, and ready for analysis. The Data Engineer will optimize data systems, develop data integration solutions, and ensure data security and governance. Key responsibilities include creating ETL processes, managing databases, and improving data infrastructure performance. The ideal candidate has strong programming and database skills and experience with cloud-based data platforms. Responsibilities Leads design, implementation, and management of data pipelines Develops and executes ETL (extract, transform, load) or ELT code Supports design of robust Data Integration Architecture to support customers Helps monitor and administer the systems and ensures applications and systems are always functioning properly Analyzes the Data Integration and Engineering architecture to identify weaknesses and develops improvements such as enhancing business processes Identifies and analyzes business requirements, functional design, and translation of requirements to technical specifications Performs complex query design, developments, validation routine analysis, and streamlining processes Operates large data sets, delta data sets and querying efficiently Transforms, joins, and normalizes data in service of specific use cases. Employs AWS data pipeline solutions such as Glue, Data Pipeline, Step functions, MWAA to orchestrate data movement Work with DevSecOps engineer to deploy continuous integration and continuous deployment (CI/CD) data pipelines Understand the technical architecture to design, build, optimize, and maintain scalable data solutions in a Big Data environment Work with Product Owners and/or business stakeholders to gather business requirements and translate to detailed technical specifications US citizen or Authorized to Work and lived in the US for 3 of the last 5 years. Must be able to obtain a U.S. Federal government client badge and pass a government Public Trust. Bachelors degree or higher in IT or relevant discipline required 4+ years of IT experience Experience with setting up and operating data pipelines using Python or SQL Experience with Scala and PySpark 3+ years of experience working on AWS, GCP or Azure (AWS Preferred) cloud platforms Hands-on relational DB / NoSQL experience (PostgreSQL or similar) with specific implementation on cloud Experience working with data warehouses such as Redshift to open source and proprietary cloud data pipeline tools such as Airflow, Glue, Data Pipeline, Step functions Experience working with relational databases that handle structured and semi-structured (JSON) datasets Experience with data serialization languages such as JSON, XML, YAML Experience with code management tools (e.g. Git, SVN) and DevOps tools (e.g. Jenkins, Docker, AWS Code Pipeline) Strong analytical problem-solving ability Working experience with Transactional and Dimensional data modeling methodologies (Eg: Normalization, Star Schema, Snowflake Schema) Experience working with a distributed computing environment like AWS EMR or similar. Ability to obtain Public Trust level clearance Ability to demonstrate excellent written and oral communication required Prior experience with Center for Medicare Medicaid Services or other Govt agencies is a plus The salary range provided represents the estimated compensation for new hires in this position, applicable across all locations. Actual offers may vary based on factors such as the candidate's skills, qualifications, experience, and market conditions. Index complements its base salary offering with a competitive package that includes health and retirement benefits, discretionary bonuses, and reimbursement for professional development opportunities. Index Analytics provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training. Attention Candidates We're dedicated to ensuring a safe and transparent recruitment process for all candidates and have implemented robust measures to protect your personal information. Please be aware that all employment-related communications will originate from a secure portal ( NAME@msg.paycomonline.com ) or a corporate email address ( NAME@index-analytics.com ). If you have any concerns, please don't hesitate to reach out to us at recruiting@index-analytics.com",
         "data",
         "Index Analytics, LLC, is a rapidly growing, Baltimore-based small business providing health-related consulting services to the federal government. At the center of our company culture is a commitment to instilling a dynamic and employee-friendly place to work. We place a priority on promoting a supportive and collegial team environment and enhancing staff experience through career development and educational opportunities. Position Overview The Data Engineer is responsible for designing, building, and maintaining data pipelines and architectures to support data analytics and reporting needs across the organization. This role involves working closely with data scientists, analysts, and other stakeholders to ensure that data is clean, accessible, and ready for analysis. The Data Engineer will optimize data systems, develop data integration solutions, and ensure data security and governance. Key responsibilities include creating ETL processes, managing databases, and improving data infrastructure performance. The ideal candidate has strong programming and database skills and experience with cloud-based data platforms. Responsibilities Leads design, implementation, and management of data pipelines Develops and executes ETL (extract, transform, load) or ELT code Supports design of robust Data Integration Architecture to support customers Helps monitor and administer the systems and ensures applications and systems are always functioning properly Analyzes the Data Integration and Engineering architecture to identify weaknesses and develops improvements such as enhancing business processes Identifies and analyzes business requirements, functional design, and translation of requirements to technical specifications Performs complex query design, developments, validation routine analysis, and streamlining processes Operates large data sets, delta data sets and querying efficiently Transforms, joins, and normalizes data in service of specific use cases. Employs AWS data pipeline solutions such as Glue, Data Pipeline, Step functions, MWAA to orchestrate data movement Work with DevSecOps engineer to deploy continuous integration and continuous deployment (CI/CD) data pipelines Understand the technical architecture to design, build, optimize, and maintain scalable data solutions in a Big Data environment Work with Product Owners and/or business stakeholders to gather business requirements and translate to detailed technical specifications US citizen or Authorized to Work and lived in the US for 3 of the last 5 years. Must be able to obtain a U.S. Federal government client badge and pass a government Public Trust. Bachelors degree or higher in IT or relevant discipline required 4+ years of IT experience Experience with setting up and operating data pipelines using Python or SQL Experience with Scala and PySpark 3+ years of experience working on AWS, GCP or Azure (AWS Preferred) cloud platforms Hands-on relational DB / NoSQL experience (PostgreSQL or similar) with specific implementation on cloud Experience working with data warehouses such as Redshift to open source and proprietary cloud data pipeline tools such as Airflow, Glue, Data Pipeline, Step functions Experience working with relational databases that handle structured and semi-structured (JSON) datasets Experience with data serialization languages such as JSON, XML, YAML Experience with code management tools (e.g. Git, SVN) and DevOps tools (e.g. Jenkins, Docker, AWS Code Pipeline) Strong analytical problem-solving ability Working experience with Transactional and Dimensional data modeling methodologies (Eg: Normalization, Star Schema, Snowflake Schema) Experience working with a distributed computing environment like AWS EMR or similar. Ability to obtain Public Trust level clearance Ability to demonstrate excellent written and oral communication required Prior experience with Center for Medicare Medicaid Services or other Govt agencies is a plus The salary range provided represents the estimated compensation for new hires in this position, applicable across all locations. Actual offers may vary based on factors such as the candidate's skills, qualifications, experience, and market conditions. Index complements its base salary offering with a competitive package that includes health and retirement benefits, discretionary bonuses, and reimbursement for professional development opportunities. Index Analytics provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training. Attention Candidates We're dedicated to ensuring a safe and transparent recruitment process for all candidates and have implemented robust measures to protect your personal information. Please be aware that all employment-related communications will originate from a secure portal ( NAME@msg.paycomonline.com ) or a corporate email address ( NAME@index-analytics.com ). If you have any concerns, please don't hesitate to reach out to us at recruiting@index-analytics.com",
         "Index Analytics, LLC, is a rapidly growing, Baltimore-based small business providing health-related consulting services to the federal government. At the center of our company culture is a commitment to instilling a dynamic and employee-friendly place to work. We place a priority on promoting a supportive and collegial team environment and enhancing staff experience through career development and educational opportunities. Position Overview The Data Engineer is responsible for designing, building, and maintaining data pipelines and architectures to support data analytics and reporting needs across the organization. This role involves working closely with data scientists, analysts, and other stakeholders to ensure that data is clean, accessible, and ready for analysis. The Data Engineer will optimize data systems, develop data integration solutions, and ensure data security and governance. Key responsibilities include creating ETL processes, managing databases, and improving data infrastructure performance. The ideal candidate has strong programming and database skills and experience with cloud-based data platforms. Responsibilities Leads design, implementation, and management of data pipelines Develops and executes ETL (extract, transform, load) or ELT code Supports design of robust Data Integration Architecture to support customers Helps monitor and administer the systems and ensures applications and systems are always functioning properly Analyzes the Data Integration and Engineering architecture to identify weaknesses and develops improvements such as enhancing business processes Identifies and analyzes business requirements, functional design, and translation of requirements to technical specifications Performs complex query design, developments, validation routine analysis, and streamlining processes Operates large data sets, delta data sets and querying efficiently Transforms, joins, and normalizes data in service of specific use cases. Employs AWS data pipeline solutions such as Glue, Data Pipeline, Step functions, MWAA to orchestrate data movement Work with DevSecOps engineer to deploy continuous integration and continuous deployment (CI/CD) data pipelines Understand the technical architecture to design, build, optimize, and maintain scalable data solutions in a Big Data environment Work with Product Owners and/or business stakeholders to gather business requirements and translate to detailed technical specifications US citizen or Authorized to Work and lived in the US for 3 of the last 5 years. Must be able to obtain a U.S. Federal government client badge and pass a government Public Trust. Bachelors degree or higher in IT or relevant discipline required 4+ years of IT experience Experience with setting up and operating data pipelines using Python or SQL Experience with Scala and PySpark 3+ years of experience working on AWS, GCP or Azure (AWS Preferred) cloud platforms Hands-on relational DB / NoSQL experience (PostgreSQL or similar) with specific implementation on cloud Experience working with data warehouses such as Redshift to open source and proprietary cloud data pipeline tools such as Airflow, Glue, Data Pipeline, Step functions Experience working with relational databases that handle structured and semi-structured (JSON) datasets Experience with data serialization languages such as JSON, XML, YAML Experience with code management tools (e.g. Git, SVN) and DevOps tools (e.g. Jenkins, Docker, AWS Code Pipeline) Strong analytical problem-solving ability Working experience with Transactional and Dimensional data modeling methodologies (Eg: Normalization, Star Schema, Snowflake Schema) Experience working with a distributed computing environment like AWS EMR or similar. Ability to obtain Public Trust level clearance Ability to demonstrate excellent written and oral communication required Prior experience with Center for Medicare Medicaid Services or other Govt agencies is a plus The salary range provided represents the estimated compensation for new hires in this position, applicable across all locations. Actual offers may vary based on factors such as the candidate's skills, qualifications, experience, and market conditions. Index complements its base salary offering with a competitive package that includes health and retirement benefits, discretionary bonuses, and reimbursement for professional development opportunities. Index Analytics provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training. Attention Candidates We're dedicated to ensuring a safe and transparent recruitment process for all candidates and have implemented robust measures to protect your personal information. Please be aware that all employment-related communications will originate from a secure portal ( NAME@msg.paycomonline.com ) or a corporate email address ( NAME@index-analytics.com ). If you have any concerns, please don't hesitate to reach out to us at recruiting@index-analytics.com",
         "to technical specifications Performs complex query design, developments, validation routine analysis, and streamlining processes Operates large data sets, delta data sets and querying efficiently Transforms, joins, and normalizes data in service of specific use cases. Employs AWS data pipeline solutions such as Glue, Data Pipeline, Step functions, MWAA to orchestrate data movement Work with DevSecOps engineer to deploy continuous integration and continuous deployment (CI/CD) data pipelines Understand the technical architecture to design, build, optimize, and maintain scalable data solutions in a Big Data environment Work with Product Owners and/or business stakeholders to gather business requirements and translate to detailed technical specifications US citizen or Authorized to Work and lived in the US for 3 of the last 5 years. Must be able to obtain a U.S. Federal government client badge and pass a government Public Trust. Bachelors degree or higher in IT or relevant discipline required 4+ years of IT experience Experience with setting up and operating data pipelines using Python or SQL Experience with Scala and PySpark 3+ years of experience working on AWS, GCP or Azure (AWS Preferred) cloud platforms Hands-on relational DB / NoSQL experience (PostgreSQL or similar) with specific implementation on cloud Experience working with data warehouses such as Redshift to open source and proprietary cloud data pipeline tools such as Airflow, Glue, Data Pipeline, Step functions Experience working with relational databases that handle structured and semi-structured (JSON) datasets Experience with data serialization languages such as JSON, XML, YAML Experience with code management tools (e.g. Git, SVN) and DevOps tools (e.g. Jenkins, Docker, AWS Code Pipeline) Strong analytical problem-solving ability Working experience with Transactional and Dimensional data modeling methodologies (Eg: Normalization, Star Schema, Snowflake Schema) Experience working with a distributed computing environment like AWS EMR or similar. Ability to obtain Public Trust level clearance Ability to demonstrate excellent written and oral communication required Prior experience with Center for Medicare Medicaid Services or other Govt agencies is a plus The salary range provided represents the estimated compensation for new hires in this position, applicable across all locations. Actual offers may vary based on factors such as the candidate's skills, qualifications, experience, and market conditions. Index complements its base salary offering with a competitive package that includes health and retirement benefits, discretionary bonuses, and reimbursement for professional development opportunities. Index Analytics provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training. Attention Candidates We're dedicated to ensuring a safe and transparent recruitment process for all candidates and have implemented robust measures to protect your personal information. Please be aware that all employment-related communications will originate from a secure portal ( NAME@msg.paycomonline.com ) or a corporate email address ( NAME@index-analytics.com ). If you have any concerns, please don't hesitate to reach out to us at recruiting@index-analytics.com",
         524
        ],
        [
         "Data Engineer",
         "Intone Networks",
         "About Tixr Tixr's on a mission to transform the ticket buying experience with a modern approach to a legacy business. Born from a fan-focused frame of mind, we empower large-scale events, music venues, and sports properties with modern, innovative solutions to their highly-complex ticketing and e-commerce needs. Our unified commerce platform is built for big, supporting all types of events, from festivals to global arena tours, and an almost limitless suite of commerce offerings beyond admission tickets. The Opportunity As our Data Engineer, you will play a crucial role in building and maintaining scalable, reliable, and secure data platforms to support our growing business. You'll work closely with data scientists, analysts, and engineers to design, develop, and optimize data pipelines and infrastructure. You will be joining a passionate team that continually pushes the boundaries of technology. Work-Life This role is 100% remote with an optional work environment at our Santa Monica office, located on the 3rd Street Promenade. Most teams run West Coast Hours with lots of autonomy. At this time we are only able to hire US Citizens or active US Green Card holders Skills & Qualifications Deep knowledge and experience with architectures for modern data infrastructure including data lakes, data warehouses, ETL pipelines, physical and logical data formats, data processing systems, data reliability, security, governance, and performance Work to improve and migrate existing code to improve performance, making deliberate and thoughtful tradeoffs where necessary. Extensive knowledge of different kinds of data stores (row-oriented, columnar, key/value, document, graph, etc.) and their use cases and tradeoffs Proficiency with various big data technologies including BigQuery, Redshift, Parquet, Spark, AWS Glue, Expertise in Java (Hibernate) Be independently responsible for the entire lifecycle of projects and systems, including design, development, and deployment High standards and expectations for software development, excellent written and verbal communication skills Strive to write elegant and maintainable code; comfortable picking up new technologies. You break down complex projects into simple systems that can be built and maintained by less experienced engineers You are proficient in working with distributed systems and have experience with different distributed processing frameworks that can handle data in batch and real-time Preferred Skills & Qualifications 5+ Years experience as a Software Engineer (Java preferred) with a focus on data 5+ Years experience working with distributed ingestion, processing, storage, and access of big data (bonus points for experience with AI/ML) 5+ Years experience with MySQL, Couchbase, Kafka, SageMaker 7+ Years experience leveraging tools and infrastructure provided by GCP and AWS The Perks Salary Range $130,000 - $180,000 + Bonus + Equity 100% Remote with Hybrid Optional Paid Health Benefits ($0 Premiums) Dental, Vision, Life plans Open Vacation 401k (50% match up to 3%) Paid Equipment Education Stipend Paid Holidays & Birthdays Off Parental Leave Team Offsites / Events Ticket hookups! Tixr is the largest, fastest-growing, privately-held primary ticketing and live event commerce marketplace in the world. We're a California born and bred company that's still founder owned and led to this day, and we support a global client base with staff throughout the US, Canada, and UK. We exclusively power 500 of the most respected live entertainment brands in 40 countries including LIV Golf, Wynn Nightlife, Riot Fest, Acura Grand Prix of Long Beach, Riot Games Arena, Luke Bryan’s Crash My Playa, Sturgis Buffalo Chip, Lightning in a Bottle, Portland Trail Blazers’ New G League Affiliate Rip City Remix, among many others. The pay range for this role is: 130,000 - 180,000 USD per year(Remote - United States) Title: Data Analytics Engineer Company: CardWorks URL: https://www.indeed.com/pagead/clk?mo=r&ad=-6NYlbfkN0BUbgFVVy_VKxKTM2USS09L-3kZv-F7kRpUqr0tB56vVP1i0xMkFj6KFckr2xoFpzjy4zfMSvjzthGntWDePJBN3xFIOUFM_Aoy8lY5wPHJc1SE7LWJshEMPhiobbMYtrxJzOsBUeWF8pdypcGyj4tc_97LJgH4X5Scy0Qpd8ThJnrYJOf9aFnVzfqj1sYm8-WGy_BxHzy0ja_6-B1p9BXqCST3QCLFqoUSNsgcOrg-u8QYnm3qZqNLPCQHA3hHsULSEOjx3XPO4U3YOZ49uBUTDRB8CyRW4Bjj1F_wbIHsQsUmd-vlrRBuHOpP9O3M64YAOyk7G3pgUFjRhX2myyeaGH54TybJ41The_fDTqYCRWkV-tltYwJ2AollXjkzguA0RxKe_2eWI5nX2Z27WXeXc9S1EV8kMD4f-5gRro3serTOAHTb11anERGDT4_2Jg6W15LoaA8wqbVs5iM0u9gMYMF9pwg0rIU7O8HqNBdIABTDb2Kfggyn1MfpaT76RIPIYYDb4BrZ4rD8bdg6JCiKutRMpe3MIpLHPjPxpFn7f9Br6bmGBi65bfHlCNXtwil1eIJk7P7afhZwo23v1UHgW72MhGh5ndqV9MSZCQ7NMmLz0rVbe0SM4W07-mAKYogvYYXeYLpS5Z0zeQeyCNZi&xkcb=SoAJ6_M33zDWevR-pR0LbzkdCdPP&camk=CPChkbYSGj-8rrWl1YViqg==&p=0&fvj=0&vjs=3  Title: Data Engineer Company: The Helper Bees URL: https://www.indeed.com/rc/clk?jk=6253474d1b58f413&bb=1TLRjqutBEYcit1OApAPtg6wY0fc5oBBCTyU7VwylasOUf6nQ8oTqOkXH0dnrnLZAaVB8nFtVNl5Z5kcRtJMk5SkC3U7H-JGc8jJqVcYLoUkDuSkTNrX8bAjfKZMI1yM&xkcb=SoBJ67M33zDWevR-pR0KbzkdCdPP&fccid=8ce618308adea162&vjs=3  Title: Data Analyst Company: Fix-It 24/7 URL: https://www.indeed.com/rc/clk?jk=06050d41e9f16407&bb=1TLRjqutBEYcit1OApAPto3A50Hg4Pzq5qFUF25sU891HTb0FMRKF-y31Tt72Rgj3vRHASDwe2nU2bKOyor677T1mfz6aMuuBmnum2LV6DDSRY1DGNuI6LNVrSB8DuSr&xkcb=SoDU67M33zDWevR-pR0JbzkdCdPP&fccid=61e4e7d2ce056d37&vjs=3  Title: Data Engineer I (R-17233) Company: Dun & Bradstreet URL: https://www.indeed.com/rc/clk?jk=f039623f105630f2&bb=1TLRjqutBEYcit1OApAPtg8D7eDBj8dWOPGrLLp5ZYiX2k5J48QjJ2VDYk8FyyDclWTFw3_uJx_lmIj2ONJMsJ2UUi5nujuLcodWuG6bPgGaBITZV5mfDBbvAF55qLOX&xkcb=SoBg67M33zDWevR-pR0IbzkdCdPP&fccid=fa0ca3b638673d62&vjs=3  Title: Data Analytics Engineer Company: Trolley Hospitality Companies URL: https://www.indeed.com/rc/clk?jk=2ed062ddf827d425&bb=1TLRjqutBEYcit1OApAPtqdISEDoy_d-IplDpybCSSMZpPo35r3cqU4mEJIYXYaDDVs9MrLJl-6gi6-5WFGx_E2KzO8CRErgNgARjPzv2CNuTu45b0AwJm3eCCk7YcVY&xkcb=SoDu67M33zDWevR-pR0PbzkdCdPP&fccid=d7db7b4b8d85f941&vjs=3  Title: Data Engineer Company: KesarWeb URL: https://www.indeed.com/rc/clk?jk=375bf3b4e704091b&bb=1TLRjqutBEYcit1OApAPtrcEczvcHO3wdOyX_7vPvKjueUN9MYpJsgZgF3qHa7uGyTbrxnq9JrcbPXGtFrlnc6K96XPZi_WmLBNMR-dU2giCyAECR-sdKTnVbuTCJ6Kd&xkcb=SoBa67M33zDWevR-pR0ObzkdCdPP&fccid=36a6953a97504177&cmp=KesarWeb&ti=Data+Engineer&vjs=3  Title: Data Analyst Company: TemperaturePro URL: https://www.indeed.com/rc/clk?jk=ce648987ee7515b1&bb=1TLRjqutBEYcit1OApAPtuY7ZI7s4dKP_loSJCdMjyEtPwhqz1EZ1Gv1WMK3EDBIZXPri1wso4SgFqKO0pamkIuqmPFovd77z5lF4obKC8yPJAQqUE0hF7tabRBUWj_z&xkcb=SoDH67M33zDWevR-pR0NbzkdCdPP&fccid=f67b5b2c8fb57889&vjs=3  Title: Data Scientist Company: Syntricate Technologies URL: https://www.indeed.com/rc/clk?jk=3d18d09ef73e17e3&bb=1TLRjqutBEYcit1OApAPtjJZHve0IREZcvimeUf98DreHFPkqvt2hoKQj7jltcOQMUfLQncq9bYhpa1IOZSu2ZOKrpNkE3JXFQl7HLR1kvew9FRZ-p5uYCmAYKypgrLe&xkcb=SoBz67M33zDWevR-pR0MbzkdCdPP&fccid=6a8862eed7fda9a3&cmp=Syntricate-Technologies&ti=Data+Scientist&vjs=3  Title: Data Scientist Company: ABOUT HEALTHCARE INC URL: https://www.indeed.com/rc/clk?jk=90ac2fadb29afe88&bb=1TLRjqutBEYcit1OApAPts7-O6E_jxzVoJOVxo_XYvb4FD_ctlKqGX5nL9lUGv3K0eAAvg-eH6qJq_emQfsWS6f-Wjw9iPsMS8Ybr0ijT61zmQk0UGii7V1s4hsi2x38&xkcb=SoCa67M33zDWevR-pR0DbzkdCdPP&fccid=c5bbd2c6370864bf&vjs=3  Title: Junior Data Engineer Company: American Veterinary Group URL: https://www.indeed.com/rc/clk?jk=b7ccd9fcd1afced7&bb=1TLRjqutBEYcit1OApAPtqrHYylbIkCH-hjMPAlsxl27fhhbmpR2ESoGFPzZ8_yAHfmXJJR-sxCiyJrJbrdNtoLq2VLDYGJB8eFEb_NompMj9I3HutPP1GvnnhForEvK&xkcb=SoAu67M33zDWevR-pR0CbzkdCdPP&fccid=4a4b722c7189c738&vjs=3  Title: Sr. Data Engineer Company: The Krusteaz Company URL: https://www.indeed.com/rc/clk?jk=ce1286f4f8d9c8f3&bb=1TLRjqutBEYcit1OApAPtg8D7eDBj8dWqCWgbfovlBMEYXXX_UJfze6KJ1Rk1HH29XymcqlzaGkV97O3N8iJ-QcsoD1GvtyjT96qcACImA-USRr2d9fMjXrM5az2uskT&xkcb=SoCz67M33zDWevR-pR0BbzkdCdPP&fccid=f5302c51750cf2bd&vjs=3  Title: Royalty Data Analyst - HarbourView Company: People Strata URL: https://www.indeed.com/rc/clk?jk=042c410f50c0faa6&bb=1TLRjqutBEYcit1OApAPtt6B4oNDQ9pvplvzh521n9octR12bdC8X0WPxpzUuEahEqtE5IkoxGLcfct2Fl3E3ERVE0CDNI3ufYlz_WxpqD2cHp3NqHNahE2fQxTMaZ59&xkcb=SoAH67M33zDWevR-pR0AbzkdCdPP&fccid=9e189ac6632e8eb3&vjs=3  Title: Data Engineer Company: Inizio Evoke URL: https://www.indeed.com/rc/clk?jk=9e40be84f9b83316&bb=1TLRjqutBEYcit1OApAPtiwFpIvslSGO7SJE2_6w2_yabPnRswbug_gQ3b7K53wZGRBcqAa66xMWWTgARyrcFowe-VfPsz2pyzNQu_d_4U1sucRRl3FlqEKL7xzWLpfM&xkcb=SoCJ67M33zDWevR-pR0HbzkdCdPP&fccid=9a61e67ffa915534&vjs=3  Title: Data Scientist Company: ENTERPRISE APPLICATIONS CONSULTING URL: https://www.indeed.com/rc/clk?jk=3887882c5612732e&bb=1TLRjqutBEYcit1OApAPtnomAnXe-PSxKGRzCB1zbhwQwhEyhzbWHNr_p7QvcZZj0wVF6Vw3tSd0HBb8Vm7gecKxVcnj_izsPiOGLXV5VBnBRZM8IPobYIIuWcT2KsXE&xkcb=SoA967M33zDWevR-pR0GbzkdCdPP&fccid=dd616958bd9ddc12&vjs=3  Title: Data Engineer II (Remote) Company: HirexHire URL: https://www.indeed.com/rc/clk?jk=4d6537997645be15&bb=1TLRjqutBEYcit1OApAPtsu8U9eiETJtKb46-YumxUjNFKa0IhH3KgXcjvuI5QjlLUeyjv-q0oPm8CDVODYtziLh0ZF2QcruNLh8cUnrQCpO9gqSUhjbq2HX5WTDgkfa&xkcb=SoCg67M33zDWevR-pR0FbzkdCdPP&fccid=97225ff5630ed4a6&vjs=3",
         "data",
         "About Tixr Tixr's on a mission to transform the ticket buying experience with a modern approach to a legacy business. Born from a fan-focused frame of mind, we empower large-scale events, music venues, and sports properties with modern, innovative solutions to their highly-complex ticketing and e-commerce needs. Our unified commerce platform is built for big, supporting all types of events, from festivals to global arena tours, and an almost limitless suite of commerce offerings beyond admission tickets. The Opportunity As our Data Engineer, you will play a crucial role in building and maintaining scalable, reliable, and secure data platforms to support our growing business. You'll work closely with data scientists, analysts, and engineers to design, develop, and optimize data pipelines and infrastructure. You will be joining a passionate team that continually pushes the boundaries of technology. Work-Life This role is 100% remote with an optional work environment at our Santa Monica office, located on the 3rd Street Promenade. Most teams run West Coast Hours with lots of autonomy. At this time we are only able to hire US Citizens or active US Green Card holders Skills & Qualifications Deep knowledge and experience with architectures for modern data infrastructure including data lakes, data warehouses, ETL pipelines, physical and logical data formats, data processing systems, data reliability, security, governance, and performance Work to improve and migrate existing code to improve performance, making deliberate and thoughtful tradeoffs where necessary. Extensive knowledge of different kinds of data stores (row-oriented, columnar, key/value, document, graph, etc.) and their use cases and tradeoffs Proficiency with various big data technologies including BigQuery, Redshift, Parquet, Spark, AWS Glue, Expertise in Java (Hibernate) Be independently responsible for the entire lifecycle of projects and systems, including design, development, and deployment High standards and expectations for software development, excellent written and verbal communication skills Strive to write elegant and maintainable code; comfortable picking up new technologies. You break down complex projects into simple systems that can be built and maintained by less experienced engineers You are proficient in working with distributed systems and have experience with different distributed processing frameworks that can handle data in batch and real-time Preferred Skills & Qualifications 5+ Years experience as a Software Engineer (Java preferred) with a focus on data 5+ Years experience working with distributed ingestion, processing, storage, and access of big data (bonus points for experience with AI/ML) 5+ Years experience with MySQL, Couchbase, Kafka, SageMaker 7+ Years experience leveraging tools and infrastructure provided by GCP and AWS The Perks Salary Range $130,000 - $180,000 + Bonus + Equity 100% Remote with Hybrid Optional Paid Health Benefits ($0 Premiums) Dental, Vision, Life plans Open Vacation 401k (50% match up to 3%) Paid Equipment Education Stipend Paid Holidays & Birthdays Off Parental Leave Team Offsites / Events Ticket hookups! Tixr is the largest, fastest-growing, privately-held primary ticketing and live event commerce marketplace in the world. We're a California born and bred company that's still founder owned and led to this day, and we support a global client base with staff throughout the US, Canada, and UK. We exclusively power 500 of the most respected live entertainment brands in 40 countries including LIV Golf, Wynn Nightlife, Riot Fest, Acura Grand Prix of Long Beach, Riot Games Arena, Luke Bryan’s Crash My Playa, Sturgis Buffalo Chip, Lightning in a Bottle, Portland Trail Blazers’ New G League Affiliate Rip City Remix, among many others. The pay range for this role is: 130,000 - 180,000 USD per year(Remote - United States) Title: Data Analytics Engineer Company: CardWorks URL:   Title: Data Engineer Company: The Helper Bees URL:   Title: Data Analyst Company: Fix-It 24/7 URL:   Title: Data Engineer I (R-17233) Company: Dun & Bradstreet URL:   Title: Data Analytics Engineer Company: Trolley Hospitality Companies URL:   Title: Data Engineer Company: KesarWeb URL:   Title: Data Analyst Company: TemperaturePro URL:   Title: Data Scientist Company: Syntricate Technologies URL:   Title: Data Scientist Company: ABOUT HEALTHCARE INC URL:   Title: Junior Data Engineer Company: American Veterinary Group URL:   Title: Sr. Data Engineer Company: The Krusteaz Company URL:   Title: Royalty Data Analyst - HarbourView Company: People Strata URL:   Title: Data Engineer Company: Inizio Evoke URL:   Title: Data Scientist Company: ENTERPRISE APPLICATIONS CONSULTING URL:   Title: Data Engineer II (Remote) Company: HirexHire URL: ",
         "About Tixr Tixr's on a mission to transform the ticket buying experience with a modern approach to a legacy business. Born from a fan-focused frame of mind, we empower large-scale events, music venues, and sports properties with modern, innovative solutions to their highly-complex ticketing and e-commerce needs. Our unified commerce platform is built for big, supporting all types of events, from festivals to global arena tours, and an almost limitless suite of commerce offerings beyond admission tickets. The Opportunity As our Data Engineer, you will play a crucial role in building and maintaining scalable, reliable, and secure data platforms to support our growing business. You'll work closely with data scientists, analysts, and engineers to design, develop, and optimize data pipelines and infrastructure. You will be joining a passionate team that continually pushes the boundaries of technology. Work-Life This role is 100% remote with an optional work environment at our Santa Monica office, located on the 3rd Street Promenade. Most teams run West Coast Hours with lots of autonomy. At this time we are only able to hire US Citizens or active US Green Card holders Skills & Qualifications Deep knowledge and experience with architectures for modern data infrastructure including data lakes, data warehouses, ETL pipelines, physical and logical data formats, data processing systems, data reliability, security, governance, and performance Work to improve and migrate existing code to improve performance, making deliberate and thoughtful tradeoffs where necessary. Extensive knowledge of different kinds of data stores (row-oriented, columnar, key/value, document, graph, etc.) and their use cases and tradeoffs Proficiency with various big data technologies including BigQuery, Redshift, Parquet, Spark, AWS Glue, Expertise in Java (Hibernate) Be independently responsible for the entire lifecycle of projects and systems, including design, development, and deployment High standards and expectations for software development, excellent written and verbal communication skills Strive to write elegant and maintainable code; comfortable picking up new technologies. You break down complex projects into simple systems that can be built and maintained by less experienced engineers You are proficient in working with distributed systems and have experience with different distributed processing frameworks that can handle data in batch and real-time Preferred Skills & Qualifications 5+ Years experience as a Software Engineer (Java preferred) with a focus on data 5+ Years experience working with distributed ingestion, processing, storage, and access of big data (bonus points for experience with AI/ML) 5+ Years experience with MySQL, Couchbase, Kafka, SageMaker 7+ Years experience leveraging tools and infrastructure provided by GCP and AWS The Perks Salary Range $130,000 - $180,000 + Bonus + Equity 100% Remote with Hybrid Optional Paid Health Benefits ($0 Premiums) Dental, Vision, Life plans Open Vacation 401k (50% match up to 3%) Paid Equipment Education Stipend Paid Holidays & Birthdays Off Parental Leave Team Offsites / Events Ticket hookups! Tixr is the largest, fastest-growing, privately-held primary ticketing and live event commerce marketplace in the world. We're a California born and bred company that's still founder owned and led to this day, and we support a global client base with staff throughout the US, Canada, and UK. We exclusively power 500 of the most respected live entertainment brands in 40 countries including LIV Golf, Wynn Nightlife, Riot Fest, Acura Grand Prix of Long Beach, Riot Games Arena, Luke Bryan’s Crash My Playa, Sturgis Buffalo Chip, Lightning in a Bottle, Portland Trail Blazers’ New G League Affiliate Rip City Remix, among many others. The pay range for this role is: 130,000 - 180,000 USD per year(Remote - United States) Title: Data Analytics Engineer Company: CardWorks URL:   Title: Data Engineer Company: The Helper Bees URL:   Title: Data Analyst Company: Fix-It 24/7 URL:   Title: Data Engineer I (R-17233) Company: Dun & Bradstreet URL:   Title: Data Analytics Engineer Company: Trolley Hospitality Companies URL:   Title: Data Engineer Company: KesarWeb URL:   Title: Data Analyst Company: TemperaturePro URL:   Title: Data Scientist Company: Syntricate Technologies URL:   Title: Data Scientist Company: ABOUT HEALTHCARE INC URL:   Title: Junior Data Engineer Company: American Veterinary Group URL:   Title: Sr. Data Engineer Company: The Krusteaz Company URL:   Title: Royalty Data Analyst - HarbourView Company: People Strata URL:   Title: Data Engineer Company: Inizio Evoke URL:   Title: Data Scientist Company: ENTERPRISE APPLICATIONS CONSULTING URL:   Title: Data Engineer II (Remote) Company: HirexHire URL:",
         "Deep knowledge and experience with architectures for modern data infrastructure including data lakes, data warehouses, ETL pipelines, physical and logical data formats, data processing systems, data reliability, security, governance, and performance Work to improve and migrate existing code to improve performance, making deliberate and thoughtful tradeoffs where necessary. Extensive knowledge of different kinds of data stores (row-oriented, columnar, key/value, document, graph, etc.) and their use cases and tradeoffs Proficiency with various big data technologies including BigQuery, Redshift, Parquet, Spark, AWS Glue, Expertise in Java (Hibernate) Be independently responsible for the entire lifecycle of projects and systems, including design, development, and deployment High standards and expectations for software development, excellent written and verbal communication skills Strive to write elegant and maintainable code; comfortable picking up new technologies. You break down complex projects into simple systems that can be built and maintained by less experienced engineers You are proficient in working with distributed systems and have experience with different distributed processing frameworks that can handle data in batch and real-time Preferred Skills & Qualifications 5+ Years experience as a Software Engineer (Java preferred) with a focus on data 5+ Years experience working with distributed ingestion, processing, storage, and access of big data (bonus points for experience with AI/ML) 5+ Years experience with MySQL, Couchbase, Kafka, SageMaker 7+ Years experience leveraging tools and infrastructure provided by GCP and AWS The Perks Salary Range $130,000 - $180,000 + Bonus + Equity 100% Remote with Hybrid Optional Paid Health Benefits ($0 Premiums) Dental, Vision, Life plans Open Vacation 401k (50% match up to 3%) Paid Equipment Education Stipend Paid Holidays & Birthdays Off Parental Leave Team Offsites / Events Ticket hookups! Tixr is the largest, fastest-growing, privately-held primary ticketing and live event commerce marketplace in the world. We're a California born and bred company that's still founder owned and led to this day, and we support a global client base with staff throughout the US, Canada, and UK. We exclusively power 500 of the most respected live entertainment brands in 40 countries including LIV Golf, Wynn Nightlife, Riot Fest, Acura Grand Prix of Long Beach, Riot Games Arena, Luke Bryan’s Crash My Playa, Sturgis Buffalo Chip, Lightning in a Bottle, Portland Trail Blazers’ New G League Affiliate Rip City Remix, among many others. The pay range for this role is: 130,000 - 180,000 USD per year(Remote - United States) Title: Data Analytics Engineer Company: CardWorks URL:   Title: Data Engineer Company: The Helper Bees URL:   Title: Data Analyst Company: Fix-It 24/7 URL:   Title: Data Engineer I (R-17233) Company: Dun & Bradstreet URL:   Title: Data Analytics Engineer Company: Trolley Hospitality Companies URL:   Title: Data Engineer Company: KesarWeb URL:   Title: Data Analyst Company: TemperaturePro URL:   Title: Data Scientist Company: Syntricate Technologies URL:   Title: Data Scientist Company: ABOUT HEALTHCARE INC URL:   Title: Junior Data Engineer Company: American Veterinary Group URL:   Title: Sr. Data Engineer Company: The Krusteaz Company URL:   Title: Royalty Data Analyst - HarbourView Company: People Strata URL:   Title: Data Engineer Company: Inizio Evoke URL:   Title: Data Scientist Company: ENTERPRISE APPLICATIONS CONSULTING URL:   Title: Data Engineer II (Remote) Company: HirexHire URL:",
         513
        ],
        [
         "Data Analyst",
         "that values your contributions and encourages professional development.",
         "Description: Join our winning team, recently honored as #67 on Forbes’ list of America’s Best Startup Employers for 2024! About The Helper Bees The Helper Bees’ mission is to help people stay home longer through data-driven services that transform both the payer and the care-recipient experience. At The Helper Bees, we are reshaping how care is delivered to aging individuals by leveraging innovative technology and insightful data solutions. We maintain multiple SaaS products and payment solutions through our web applications (internal and external facing), a mobile app, and reporting integrations. As part of our growing Data Engineering team, you’ll iterate quickly, have a high impact, and be challenged to design and implement cutting-edge solutions. At THB, we define our company culture through our Core Values: Quickly iterate through solutions: We move at a fast pace which requires quick iterations to find a path to a repeatable solution. Seek ways to create immediate impact: Be thoughtful and proactive in how you make an impact on your team. Actively look for ways to make a fast, positive impact. Bee the teammate you want to work with: We work as a team, help each other, and encourage each other. Ask questions, answer questions: You can't iterate through solutions if you don't ask the right questions, which is why there is an expectation that questions should be asked. When you know the answer, being a good teammate means chiming in to get others up to speed. Take the time to celebrate wins: It's so easy for a team that is heads down to forget about all the great things they've accomplished. That's why we make it a priority to remind ourselves to create space to celebrate wins, big or small. Job Summary We are seeking a motivated Data Engineer to join our team and help improve our tools, processes, and technical infrastructure. In this role, you will ensure the availability and quality of our data while contributing to the design, implementation, and maintenance of The Helper Bees’ products. You’ll collaborate across teams to create scalable and optimized software systems and play a key role in refining our development processes. This position offers a unique opportunity to learn and leverage cutting-edge AI development tools to enhance coding efficiency and develop advanced data tools and solutions. Supervisory Responsibilities: None Key Responsibilities Data Infrastructure: Design, implement, and maintain data pipelines, ensuring data availability, quality, and scalability. Product Development: Build and enhance products using Python, SQL, and modern technologies. AI Integration: Leverage cutting-edge AI tools, including Cursor, ChatGPT, and Claude to improve development processes, automate workflows, and create innovative data solutions. Collaboration: Communicate across departments to design, build, test, and implement new features and enhancements. Code Excellence: Produce quality, testable, and maintainable code while participating in code reviews. Problem Solving: Debug complex issues, interact with stakeholders, and design viable solutions with clear trade-offs. Process Optimization: Contribute to improving development processes, including deployment, on-call systems, and sprint planning. Team Growth: Collaborate within the development team to help each other grow and continuously learn. Stakeholder Engagement: Partner with analysts, scientists, and IT to ensure alignment and deliver data-driven solutions. Other duties as assigned/necessary Performance Metrics Code Quality: Maintain high coding standards through regular code reviews and adherence to best practices. Development Efficiency: Deliver high-quality features and fixes within efficient timeframes. Bug Resolution Time: Reduce the time taken to identify and resolve issues. System Scalability: Optimize system performance to handle increasing user demands. Collaboration: Foster a collaborative environment that encourages teamwork and knowledge sharing. Customer Satisfaction: Incorporate stakeholder feedback to improve solutions and enhance the customer experience. Continuous Learning: Pursue opportunities for skill development and share knowledge with the team. Requirements: Required Skills & Qualifications Technical Tools: Experience with in Python and/or SQL. Experience with Bash, Shell scripting, Big Query, Airflow, and is a plus. Programming: Cleaning data using code-based approach. AI Proficiency: Interest or experience in using AI tools for coding and development of data solutions. Soft Skills: Problem-solving, cross-team collaboration, data storytelling, and stakeholder engagement. Adaptability: Thrives in a fast-paced startup environment and embraces change. Proactivity: Self-directed, organized, and able to prioritize effectively. Collaboration: Ability to work effectively with cross-functional teams. Education & Experience: A bachelor’s degree is required, and a graduate degree is preferred. Relevant experience in data engineering, software development, STEM, or related fields. Strong experience with SQL and Python is highly desirable. Mindset: A passion for innovation, continuous improvement, and delivering high-quality results from messy data. Preferred Qualifications Familiarity with cloud-based solutions (e.g., Google Cloud Platform, Azure). Experience with ETL processes and tools. Experience building data visualization reports and dashboards Knowledge of modern data storage solutions and database management systems. Exposure to DevOps practices and tools for deployment and monitoring. Why Join Us? Work with a talented, collaborative team dedicated to making a difference. Gain exposure to innovative technologies and opportunities for growth. Learn and utilize cutting-edge AI tools to enhance your development skills and create impactful solutions. Be part of a company that values your contributions and encourages professional development. Join a rapidly expanding health-tech startup (~200 employees and growing) with a state-of-the-art technology office located in Hyde Park, offering a variety of exceptional benefits. Career Progression Timeline In 3 months: Gain a comprehensive understanding of our data infrastructure, technical stacks, and development cycles. Actively participate in team meetings and contribute to the development of new data pipelines. Begin leveraging AI tools, such as Cursor and ChatGPT, to enhance coding efficiency and workflow automation. In 6 months: Contribute to product enhancements and data reporting Collaborate effectively with cross-functional teams, providing insights and solutions for data-related challenges. Demonstrate proficiency in utilizing AI tools for coding and development, actively sharing knowledge with the team. In 12 months: Contribute to data engineering projects, ensuring scalability and performance optimization. Mentor non-technical internal partners to improve company-wide data literacy Contribute to the integration of advanced AI solutions into our development processes, contributing to the company's technological advancement. Physical Requirements: Ability to remain at your designated workstation for the duration of the workday Constantly operates a computer and other office productivity machinery, such as a phone and Voice over Internet Protocol (VoIP). The ability to communicate information and ideas so others will understand. Must be able to exchange accurate information in these situations. The ability to observe details at close range (typically on a computer screen) This position offers the flexibility of remote work at approved locations within the United States. Candidates must have a reliable internet connection and a designated work environment conducive to professional phone calls and sensitive data. Enjoy the convenience and comfort of working remotely while contributing to our team's success. Apply Today If you’re ready to take on challenging problems, contribute to impactful solutions, and grow as a data engineer, we’d love to hear from you. Join us at The Helper Bees and be part of a team that’s making a meaningful difference every day! The Helper Bees is committed to building a workplace where diversity, equity, and inclusion are valued and prioritized. We are an equal opportunity employer that welcomes all qualified applicants without discrimination based on race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or any non-merit based or legally protected grounds. The Helper Bees provides reasonable accommodations to qualified individuals with disabilities during the job application and interview process. To request accommodation, please let your recruiter know. As part of our standard hiring process, selected candidates may be required to undergo a background check and/or drug screen. The Helper Bees adheres to applicable federal, state, and local laws regarding these screenings, and the results will be considered in accordance with applicable regulations. The Helper Bees was recently made aware of a fraudulent entity posing as our organization and requesting personal information. Please be aware of and protect yourself from scams. Visit thehelperbees.com/careers to view all current job openings.",
         "data",
         "Description: Join our winning team, recently honored as #67 on Forbes’ list of America’s Best Startup Employers for 2024! About The Helper Bees The Helper Bees’ mission is to help people stay home longer through data-driven services that transform both the payer and the care-recipient experience. At The Helper Bees, we are reshaping how care is delivered to aging individuals by leveraging innovative technology and insightful data solutions. We maintain multiple SaaS products and payment solutions through our web applications (internal and external facing), a mobile app, and reporting integrations. As part of our growing Data Engineering team, you’ll iterate quickly, have a high impact, and be challenged to design and implement cutting-edge solutions. At THB, we define our company culture through our Core Values: Quickly iterate through solutions: We move at a fast pace which requires quick iterations to find a path to a repeatable solution. Seek ways to create immediate impact: Be thoughtful and proactive in how you make an impact on your team. Actively look for ways to make a fast, positive impact. Bee the teammate you want to work with: We work as a team, help each other, and encourage each other. Ask questions, answer questions: You can't iterate through solutions if you don't ask the right questions, which is why there is an expectation that questions should be asked. When you know the answer, being a good teammate means chiming in to get others up to speed. Take the time to celebrate wins: It's so easy for a team that is heads down to forget about all the great things they've accomplished. That's why we make it a priority to remind ourselves to create space to celebrate wins, big or small. Job Summary We are seeking a motivated Data Engineer to join our team and help improve our tools, processes, and technical infrastructure. In this role, you will ensure the availability and quality of our data while contributing to the design, implementation, and maintenance of The Helper Bees’ products. You’ll collaborate across teams to create scalable and optimized software systems and play a key role in refining our development processes. This position offers a unique opportunity to learn and leverage cutting-edge AI development tools to enhance coding efficiency and develop advanced data tools and solutions. Supervisory Responsibilities: None Key Responsibilities Data Infrastructure: Design, implement, and maintain data pipelines, ensuring data availability, quality, and scalability. Product Development: Build and enhance products using Python, SQL, and modern technologies. AI Integration: Leverage cutting-edge AI tools, including Cursor, ChatGPT, and Claude to improve development processes, automate workflows, and create innovative data solutions. Collaboration: Communicate across departments to design, build, test, and implement new features and enhancements. Code Excellence: Produce quality, testable, and maintainable code while participating in code reviews. Problem Solving: Debug complex issues, interact with stakeholders, and design viable solutions with clear trade-offs. Process Optimization: Contribute to improving development processes, including deployment, on-call systems, and sprint planning. Team Growth: Collaborate within the development team to help each other grow and continuously learn. Stakeholder Engagement: Partner with analysts, scientists, and IT to ensure alignment and deliver data-driven solutions. Other duties as assigned/necessary Performance Metrics Code Quality: Maintain high coding standards through regular code reviews and adherence to best practices. Development Efficiency: Deliver high-quality features and fixes within efficient timeframes. Bug Resolution Time: Reduce the time taken to identify and resolve issues. System Scalability: Optimize system performance to handle increasing user demands. Collaboration: Foster a collaborative environment that encourages teamwork and knowledge sharing. Customer Satisfaction: Incorporate stakeholder feedback to improve solutions and enhance the customer experience. Continuous Learning: Pursue opportunities for skill development and share knowledge with the team. Requirements: Required Skills & Qualifications Technical Tools: Experience with in Python and/or SQL. Experience with Bash, Shell scripting, Big Query, Airflow, and is a plus. Programming: Cleaning data using code-based approach. AI Proficiency: Interest or experience in using AI tools for coding and development of data solutions. Soft Skills: Problem-solving, cross-team collaboration, data storytelling, and stakeholder engagement. Adaptability: Thrives in a fast-paced startup environment and embraces change. Proactivity: Self-directed, organized, and able to prioritize effectively. Collaboration: Ability to work effectively with cross-functional teams. Education & Experience: A bachelor’s degree is required, and a graduate degree is preferred. Relevant experience in data engineering, software development, STEM, or related fields. Strong experience with SQL and Python is highly desirable. Mindset: A passion for innovation, continuous improvement, and delivering high-quality results from messy data. Preferred Qualifications Familiarity with cloud-based solutions (e.g., Google Cloud Platform, Azure). Experience with ETL processes and tools. Experience building data visualization reports and dashboards Knowledge of modern data storage solutions and database management systems. Exposure to DevOps practices and tools for deployment and monitoring. Why Join Us? Work with a talented, collaborative team dedicated to making a difference. Gain exposure to innovative technologies and opportunities for growth. Learn and utilize cutting-edge AI tools to enhance your development skills and create impactful solutions. Be part of a company that values your contributions and encourages professional development. Join a rapidly expanding health-tech startup (~200 employees and growing) with a state-of-the-art technology office located in Hyde Park, offering a variety of exceptional benefits. Career Progression Timeline In 3 months: Gain a comprehensive understanding of our data infrastructure, technical stacks, and development cycles. Actively participate in team meetings and contribute to the development of new data pipelines. Begin leveraging AI tools, such as Cursor and ChatGPT, to enhance coding efficiency and workflow automation. In 6 months: Contribute to product enhancements and data reporting Collaborate effectively with cross-functional teams, providing insights and solutions for data-related challenges. Demonstrate proficiency in utilizing AI tools for coding and development, actively sharing knowledge with the team. In 12 months: Contribute to data engineering projects, ensuring scalability and performance optimization. Mentor non-technical internal partners to improve company-wide data literacy Contribute to the integration of advanced AI solutions into our development processes, contributing to the company's technological advancement. Physical Requirements: Ability to remain at your designated workstation for the duration of the workday Constantly operates a computer and other office productivity machinery, such as a phone and Voice over Internet Protocol (VoIP). The ability to communicate information and ideas so others will understand. Must be able to exchange accurate information in these situations. The ability to observe details at close range (typically on a computer screen) This position offers the flexibility of remote work at approved locations within the United States. Candidates must have a reliable internet connection and a designated work environment conducive to professional phone calls and sensitive data. Enjoy the convenience and comfort of working remotely while contributing to our team's success. Apply Today If you’re ready to take on challenging problems, contribute to impactful solutions, and grow as a data engineer, we’d love to hear from you. Join us at The Helper Bees and be part of a team that’s making a meaningful difference every day! The Helper Bees is committed to building a workplace where diversity, equity, and inclusion are valued and prioritized. We are an equal opportunity employer that welcomes all qualified applicants without discrimination based on race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or any non-merit based or legally protected grounds. The Helper Bees provides reasonable accommodations to qualified individuals with disabilities during the job application and interview process. To request accommodation, please let your recruiter know. As part of our standard hiring process, selected candidates may be required to undergo a background check and/or drug screen. The Helper Bees adheres to applicable federal, state, and local laws regarding these screenings, and the results will be considered in accordance with applicable regulations. The Helper Bees was recently made aware of a fraudulent entity posing as our organization and requesting personal information. Please be aware of and protect yourself from scams. Visit thehelperbees.com/careers to view all current job openings.",
         "Description: Join our winning team, recently honored as #67 on Forbes’ list of America’s Best Startup Employers for 2024! About The Helper Bees The Helper Bees’ mission is to help people stay home longer through data-driven services that transform both the payer and the care-recipient experience. At The Helper Bees, we are reshaping how care is delivered to aging individuals by leveraging innovative technology and insightful data solutions. We maintain multiple SaaS products and payment solutions through our web applications (internal and external facing), a mobile app, and reporting integrations. As part of our growing Data Engineering team, you’ll iterate quickly, have a high impact, and be challenged to design and implement cutting-edge solutions. At THB, we define our company culture through our Core Values: Quickly iterate through solutions: We move at a fast pace which requires quick iterations to find a path to a repeatable solution. Seek ways to create immediate impact: Be thoughtful and proactive in how you make an impact on your team. Actively look for ways to make a fast, positive impact. Bee the teammate you want to work with: We work as a team, help each other, and encourage each other. Ask questions, answer questions: You can't iterate through solutions if you don't ask the right questions, which is why there is an expectation that questions should be asked. When you know the answer, being a good teammate means chiming in to get others up to speed. Take the time to celebrate wins: It's so easy for a team that is heads down to forget about all the great things they've accomplished. That's why we make it a priority to remind ourselves to create space to celebrate wins, big or small. Job Summary We are seeking a motivated Data Engineer to join our team and help improve our tools, processes, and technical infrastructure. In this role, you will ensure the availability and quality of our data while contributing to the design, implementation, and maintenance of The Helper Bees’ products. You’ll collaborate across teams to create scalable and optimized software systems and play a key role in refining our development processes. This position offers a unique opportunity to learn and leverage cutting-edge AI development tools to enhance coding efficiency and develop advanced data tools and solutions. Supervisory Responsibilities: None Key Responsibilities Data Infrastructure: Design, implement, and maintain data pipelines, ensuring data availability, quality, and scalability. Product Development: Build and enhance products using Python, SQL, and modern technologies. AI Integration: Leverage cutting-edge AI tools, including Cursor, ChatGPT, and Claude to improve development processes, automate workflows, and create innovative data solutions. Collaboration: Communicate across departments to design, build, test, and implement new features and enhancements. Code Excellence: Produce quality, testable, and maintainable code while participating in code reviews. Problem Solving: Debug complex issues, interact with stakeholders, and design viable solutions with clear trade-offs. Process Optimization: Contribute to improving development processes, including deployment, on-call systems, and sprint planning. Team Growth: Collaborate within the development team to help each other grow and continuously learn. Stakeholder Engagement: Partner with analysts, scientists, and IT to ensure alignment and deliver data-driven solutions. Other duties as assigned/necessary Performance Metrics Code Quality: Maintain high coding standards through regular code reviews and adherence to best practices. Development Efficiency: Deliver high-quality features and fixes within efficient timeframes. Bug Resolution Time: Reduce the time taken to identify and resolve issues. System Scalability: Optimize system performance to handle increasing user demands. Collaboration: Foster a collaborative environment that encourages teamwork and knowledge sharing. Customer Satisfaction: Incorporate stakeholder feedback to improve solutions and enhance the customer experience. Continuous Learning: Pursue opportunities for skill development and share knowledge with the team. Requirements: Required Skills & Qualifications Technical Tools: Experience with in Python and/or SQL. Experience with Bash, Shell scripting, Big Query, Airflow, and is a plus. Programming: Cleaning data using code-based approach. AI Proficiency: Interest or experience in using AI tools for coding and development of data solutions. Soft Skills: Problem-solving, cross-team collaboration, data storytelling, and stakeholder engagement. Adaptability: Thrives in a fast-paced startup environment and embraces change. Proactivity: Self-directed, organized, and able to prioritize effectively. Collaboration: Ability to work effectively with cross-functional teams. Education & Experience: A bachelor’s degree is required, and a graduate degree is preferred. Relevant experience in data engineering, software development, STEM, or related fields. Strong experience with SQL and Python is highly desirable. Mindset: A passion for innovation, continuous improvement, and delivering high-quality results from messy data. Preferred Qualifications Familiarity with cloud-based solutions (e.g., Google Cloud Platform, Azure). Experience with ETL processes and tools. Experience building data visualization reports and dashboards Knowledge of modern data storage solutions and database management systems. Exposure to DevOps practices and tools for deployment and monitoring. Why Join Us? Work with a talented, collaborative team dedicated to making a difference. Gain exposure to innovative technologies and opportunities for growth. Learn and utilize cutting-edge AI tools to enhance your development skills and create impactful solutions. Be part of a company that values your contributions and encourages professional development. Join a rapidly expanding health-tech startup (~200 employees and growing) with a state-of-the-art technology office located in Hyde Park, offering a variety of exceptional benefits. Career Progression Timeline In 3 months: Gain a comprehensive understanding of our data infrastructure, technical stacks, and development cycles. Actively participate in team meetings and contribute to the development of new data pipelines. Begin leveraging AI tools, such as Cursor and ChatGPT, to enhance coding efficiency and workflow automation. In 6 months: Contribute to product enhancements and data reporting Collaborate effectively with cross-functional teams, providing insights and solutions for data-related challenges. Demonstrate proficiency in utilizing AI tools for coding and development, actively sharing knowledge with the team. In 12 months: Contribute to data engineering projects, ensuring scalability and performance optimization. Mentor non-technical internal partners to improve company-wide data literacy Contribute to the integration of advanced AI solutions into our development processes, contributing to the company's technological advancement. Physical Requirements: Ability to remain at your designated workstation for the duration of the workday Constantly operates a computer and other office productivity machinery, such as a phone and Voice over Internet Protocol (VoIP). The ability to communicate information and ideas so others will understand. Must be able to exchange accurate information in these situations. The ability to observe details at close range (typically on a computer screen) This position offers the flexibility of remote work at approved locations within the United States. Candidates must have a reliable internet connection and a designated work environment conducive to professional phone calls and sensitive data. Enjoy the convenience and comfort of working remotely while contributing to our team's success. Apply Today If you’re ready to take on challenging problems, contribute to impactful solutions, and grow as a data engineer, we’d love to hear from you. Join us at The Helper Bees and be part of a team that’s making a meaningful difference every day! The Helper Bees is committed to building a workplace where diversity, equity, and inclusion are valued and prioritized. We are an equal opportunity employer that welcomes all qualified applicants without discrimination based on race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or any non-merit based or legally protected grounds. The Helper Bees provides reasonable accommodations to qualified individuals with disabilities during the job application and interview process. To request accommodation, please let your recruiter know. As part of our standard hiring process, selected candidates may be required to undergo a background check and/or drug screen. The Helper Bees adheres to applicable federal, state, and local laws regarding these screenings, and the results will be considered in accordance with applicable regulations. The Helper Bees was recently made aware of a fraudulent entity posing as our organization and requesting personal information. Please be aware of and protect yourself from scams. Visit thehelperbees.com/careers to view all current job openings.",
         "Technical Tools: Experience with in Python and/or SQL. Experience with Bash, Shell scripting, Big Query, Airflow, and is a plus. Programming: Cleaning data using code-based approach. AI Proficiency: Interest or experience in using AI tools for coding and development of data solutions. Soft Skills: Problem-solving, cross-team collaboration, data storytelling, and stakeholder engagement. Adaptability: Thrives in a fast-paced startup environment and embraces change. Proactivity: Self-directed, organized, and able to prioritize effectively. Collaboration: Ability to work effectively with cross-functional teams. Education & Experience: A bachelor’s degree is required, and a graduate degree is preferred. Relevant experience in data engineering, software development, STEM, or related fields. Strong experience with SQL and Python is highly desirable. Mindset: A passion for innovation, continuous improvement, and delivering high-quality results from messy data. Preferred Qualifications Familiarity with cloud-based solutions (e.g., Google Cloud Platform, Azure). Experience with ETL processes and tools. Experience building data visualization reports and dashboards Knowledge of modern data storage solutions and database management systems. Exposure to DevOps practices and tools for deployment and monitoring. Why Join Us? Work with a talented, collaborative team dedicated to making a difference. Gain exposure to innovative technologies and opportunities for growth. Learn and utilize cutting-edge AI tools to enhance your development skills and create impactful solutions. Be part of a company that values your contributions and encourages professional development. Join a rapidly expanding health-tech startup (~200 employees and growing) with a state-of-the-art technology office located in Hyde Park, offering a variety of exceptional benefits. Career Progression Timeline In 3 months: Gain a comprehensive understanding of our data infrastructure, technical stacks, and development cycles. Actively participate in team meetings and contribute to the development of new data pipelines. Begin leveraging AI tools, such as Cursor and ChatGPT, to enhance coding efficiency and workflow automation. In 6 months: Contribute to product enhancements and data reporting Collaborate effectively with cross-functional teams, providing insights and solutions for data-related challenges. Demonstrate proficiency in utilizing AI tools for coding and development, actively sharing knowledge with the team. In 12 months: Contribute to data engineering projects, ensuring scalability and performance optimization. Mentor non-technical internal partners to improve company-wide data literacy Contribute to the integration of advanced AI solutions into our development processes, contributing to the company's technological advancement. Physical Requirements: Ability to remain at your designated workstation for the duration of the workday Constantly operates a computer and other office productivity machinery, such as a phone and Voice over Internet Protocol (VoIP). The ability to communicate information and ideas so others will understand. Must be able to exchange accurate information in these situations. The ability to observe details at close range (typically on a computer screen) This position offers the flexibility of remote work at approved locations within the United States. Candidates must have a reliable internet connection and a designated work environment conducive to professional phone calls and sensitive data. Enjoy the convenience and comfort of working remotely while contributing to our team's success. Apply Today If you’re ready to take on challenging problems, contribute to impactful solutions, and grow as a data engineer, we’d love to hear from you. Join us at The Helper Bees and be part of a team that’s making a meaningful difference every day! The Helper Bees is committed to building a workplace where diversity, equity, and inclusion are valued and prioritized. We are an equal opportunity employer that welcomes all qualified applicants without discrimination based on race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or any non-merit based or legally protected grounds. The Helper Bees provides reasonable accommodations to qualified individuals with disabilities during the job application and interview process. To request accommodation, please let your recruiter know. As part of our standard hiring process, selected candidates may be required to undergo a background check and/or drug screen. The Helper Bees adheres to applicable federal, state, and local laws regarding these screenings, and the results will be considered in accordance with applicable regulations. The Helper Bees was recently made aware of a fraudulent entity posing as our organization and requesting personal information. Please be aware of and protect yourself from scams. Visit thehelperbees.com/careers to view all current job openings.",
         698
        ],
        [
         "Data Scientist",
         "'s technological advancement.",
         "Description: Join our winning team, recently honored as #67 on Forbes’ list of America’s Best Startup Employers for 2024! About The Helper Bees The Helper Bees’ mission is to help people stay home longer through data-driven services that transform both the payer and the care-recipient experience. At The Helper Bees, we are reshaping how care is delivered to aging individuals by leveraging innovative technology and insightful data solutions. We maintain multiple SaaS products and payment solutions through our web applications (internal and external facing), a mobile app, and reporting integrations. As part of our growing Data Engineering team, you’ll iterate quickly, have a high impact, and be challenged to design and implement cutting-edge solutions. At THB, we define our company culture through our Core Values: Quickly iterate through solutions: We move at a fast pace which requires quick iterations to find a path to a repeatable solution. Seek ways to create immediate impact: Be thoughtful and proactive in how you make an impact on your team. Actively look for ways to make a fast, positive impact. Bee the teammate you want to work with: We work as a team, help each other, and encourage each other. Ask questions, answer questions: You can't iterate through solutions if you don't ask the right questions, which is why there is an expectation that questions should be asked. When you know the answer, being a good teammate means chiming in to get others up to speed. Take the time to celebrate wins: It's so easy for a team that is heads down to forget about all the great things they've accomplished. That's why we make it a priority to remind ourselves to create space to celebrate wins, big or small. Job Summary We are seeking a motivated Data Engineer to join our team and help improve our tools, processes, and technical infrastructure. In this role, you will ensure the availability and quality of our data while contributing to the design, implementation, and maintenance of The Helper Bees’ products. You’ll collaborate across teams to create scalable and optimized software systems and play a key role in refining our development processes. This position offers a unique opportunity to learn and leverage cutting-edge AI development tools to enhance coding efficiency and develop advanced data tools and solutions. Supervisory Responsibilities: None Key Responsibilities Data Infrastructure: Design, implement, and maintain data pipelines, ensuring data availability, quality, and scalability. Product Development: Build and enhance products using Python, SQL, and modern technologies. AI Integration: Leverage cutting-edge AI tools, including Cursor, ChatGPT, and Claude to improve development processes, automate workflows, and create innovative data solutions. Collaboration: Communicate across departments to design, build, test, and implement new features and enhancements. Code Excellence: Produce quality, testable, and maintainable code while participating in code reviews. Problem Solving: Debug complex issues, interact with stakeholders, and design viable solutions with clear trade-offs. Process Optimization: Contribute to improving development processes, including deployment, on-call systems, and sprint planning. Team Growth: Collaborate within the development team to help each other grow and continuously learn. Stakeholder Engagement: Partner with analysts, scientists, and IT to ensure alignment and deliver data-driven solutions. Other duties as assigned/necessary Performance Metrics Code Quality: Maintain high coding standards through regular code reviews and adherence to best practices. Development Efficiency: Deliver high-quality features and fixes within efficient timeframes. Bug Resolution Time: Reduce the time taken to identify and resolve issues. System Scalability: Optimize system performance to handle increasing user demands. Collaboration: Foster a collaborative environment that encourages teamwork and knowledge sharing. Customer Satisfaction: Incorporate stakeholder feedback to improve solutions and enhance the customer experience. Continuous Learning: Pursue opportunities for skill development and share knowledge with the team. Requirements: Required Skills & Qualifications Technical Tools: Experience with in Python and/or SQL. Experience with Bash, Shell scripting, Big Query, Airflow, and is a plus. Programming: Cleaning data using code-based approach. AI Proficiency: Interest or experience in using AI tools for coding and development of data solutions. Soft Skills: Problem-solving, cross-team collaboration, data storytelling, and stakeholder engagement. Adaptability: Thrives in a fast-paced startup environment and embraces change. Proactivity: Self-directed, organized, and able to prioritize effectively. Collaboration: Ability to work effectively with cross-functional teams. Education & Experience: A bachelor’s degree is required, and a graduate degree is preferred. Relevant experience in data engineering, software development, STEM, or related fields. Strong experience with SQL and Python is highly desirable. Mindset: A passion for innovation, continuous improvement, and delivering high-quality results from messy data. Preferred Qualifications Familiarity with cloud-based solutions (e.g., Google Cloud Platform, Azure). Experience with ETL processes and tools. Experience building data visualization reports and dashboards Knowledge of modern data storage solutions and database management systems. Exposure to DevOps practices and tools for deployment and monitoring. Why Join Us? Work with a talented, collaborative team dedicated to making a difference. Gain exposure to innovative technologies and opportunities for growth. Learn and utilize cutting-edge AI tools to enhance your development skills and create impactful solutions. Be part of a company that values your contributions and encourages professional development. Join a rapidly expanding health-tech startup (~200 employees and growing) with a state-of-the-art technology office located in Hyde Park, offering a variety of exceptional benefits. Career Progression Timeline In 3 months: Gain a comprehensive understanding of our data infrastructure, technical stacks, and development cycles. Actively participate in team meetings and contribute to the development of new data pipelines. Begin leveraging AI tools, such as Cursor and ChatGPT, to enhance coding efficiency and workflow automation. In 6 months: Contribute to product enhancements and data reporting Collaborate effectively with cross-functional teams, providing insights and solutions for data-related challenges. Demonstrate proficiency in utilizing AI tools for coding and development, actively sharing knowledge with the team. In 12 months: Contribute to data engineering projects, ensuring scalability and performance optimization. Mentor non-technical internal partners to improve company-wide data literacy Contribute to the integration of advanced AI solutions into our development processes, contributing to the company's technological advancement. Physical Requirements: Ability to remain at your designated workstation for the duration of the workday Constantly operates a computer and other office productivity machinery, such as a phone and Voice over Internet Protocol (VoIP). The ability to communicate information and ideas so others will understand. Must be able to exchange accurate information in these situations. The ability to observe details at close range (typically on a computer screen) This position offers the flexibility of remote work at approved locations within the United States. Candidates must have a reliable internet connection and a designated work environment conducive to professional phone calls and sensitive data. Enjoy the convenience and comfort of working remotely while contributing to our team's success. Apply Today If you’re ready to take on challenging problems, contribute to impactful solutions, and grow as a data engineer, we’d love to hear from you. Join us at The Helper Bees and be part of a team that’s making a meaningful difference every day! The Helper Bees is committed to building a workplace where diversity, equity, and inclusion are valued and prioritized. We are an equal opportunity employer that welcomes all qualified applicants without discrimination based on race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or any non-merit based or legally protected grounds. The Helper Bees provides reasonable accommodations to qualified individuals with disabilities during the job application and interview process. To request accommodation, please let your recruiter know. As part of our standard hiring process, selected candidates may be required to undergo a background check and/or drug screen. The Helper Bees adheres to applicable federal, state, and local laws regarding these screenings, and the results will be considered in accordance with applicable regulations. The Helper Bees was recently made aware of a fraudulent entity posing as our organization and requesting personal information. Please be aware of and protect yourself from scams. Visit thehelperbees.com/careers to view all current job openings.",
         "data",
         "Description: Join our winning team, recently honored as #67 on Forbes’ list of America’s Best Startup Employers for 2024! About The Helper Bees The Helper Bees’ mission is to help people stay home longer through data-driven services that transform both the payer and the care-recipient experience. At The Helper Bees, we are reshaping how care is delivered to aging individuals by leveraging innovative technology and insightful data solutions. We maintain multiple SaaS products and payment solutions through our web applications (internal and external facing), a mobile app, and reporting integrations. As part of our growing Data Engineering team, you’ll iterate quickly, have a high impact, and be challenged to design and implement cutting-edge solutions. At THB, we define our company culture through our Core Values: Quickly iterate through solutions: We move at a fast pace which requires quick iterations to find a path to a repeatable solution. Seek ways to create immediate impact: Be thoughtful and proactive in how you make an impact on your team. Actively look for ways to make a fast, positive impact. Bee the teammate you want to work with: We work as a team, help each other, and encourage each other. Ask questions, answer questions: You can't iterate through solutions if you don't ask the right questions, which is why there is an expectation that questions should be asked. When you know the answer, being a good teammate means chiming in to get others up to speed. Take the time to celebrate wins: It's so easy for a team that is heads down to forget about all the great things they've accomplished. That's why we make it a priority to remind ourselves to create space to celebrate wins, big or small. Job Summary We are seeking a motivated Data Engineer to join our team and help improve our tools, processes, and technical infrastructure. In this role, you will ensure the availability and quality of our data while contributing to the design, implementation, and maintenance of The Helper Bees’ products. You’ll collaborate across teams to create scalable and optimized software systems and play a key role in refining our development processes. This position offers a unique opportunity to learn and leverage cutting-edge AI development tools to enhance coding efficiency and develop advanced data tools and solutions. Supervisory Responsibilities: None Key Responsibilities Data Infrastructure: Design, implement, and maintain data pipelines, ensuring data availability, quality, and scalability. Product Development: Build and enhance products using Python, SQL, and modern technologies. AI Integration: Leverage cutting-edge AI tools, including Cursor, ChatGPT, and Claude to improve development processes, automate workflows, and create innovative data solutions. Collaboration: Communicate across departments to design, build, test, and implement new features and enhancements. Code Excellence: Produce quality, testable, and maintainable code while participating in code reviews. Problem Solving: Debug complex issues, interact with stakeholders, and design viable solutions with clear trade-offs. Process Optimization: Contribute to improving development processes, including deployment, on-call systems, and sprint planning. Team Growth: Collaborate within the development team to help each other grow and continuously learn. Stakeholder Engagement: Partner with analysts, scientists, and IT to ensure alignment and deliver data-driven solutions. Other duties as assigned/necessary Performance Metrics Code Quality: Maintain high coding standards through regular code reviews and adherence to best practices. Development Efficiency: Deliver high-quality features and fixes within efficient timeframes. Bug Resolution Time: Reduce the time taken to identify and resolve issues. System Scalability: Optimize system performance to handle increasing user demands. Collaboration: Foster a collaborative environment that encourages teamwork and knowledge sharing. Customer Satisfaction: Incorporate stakeholder feedback to improve solutions and enhance the customer experience. Continuous Learning: Pursue opportunities for skill development and share knowledge with the team. Requirements: Required Skills & Qualifications Technical Tools: Experience with in Python and/or SQL. Experience with Bash, Shell scripting, Big Query, Airflow, and is a plus. Programming: Cleaning data using code-based approach. AI Proficiency: Interest or experience in using AI tools for coding and development of data solutions. Soft Skills: Problem-solving, cross-team collaboration, data storytelling, and stakeholder engagement. Adaptability: Thrives in a fast-paced startup environment and embraces change. Proactivity: Self-directed, organized, and able to prioritize effectively. Collaboration: Ability to work effectively with cross-functional teams. Education & Experience: A bachelor’s degree is required, and a graduate degree is preferred. Relevant experience in data engineering, software development, STEM, or related fields. Strong experience with SQL and Python is highly desirable. Mindset: A passion for innovation, continuous improvement, and delivering high-quality results from messy data. Preferred Qualifications Familiarity with cloud-based solutions (e.g., Google Cloud Platform, Azure). Experience with ETL processes and tools. Experience building data visualization reports and dashboards Knowledge of modern data storage solutions and database management systems. Exposure to DevOps practices and tools for deployment and monitoring. Why Join Us? Work with a talented, collaborative team dedicated to making a difference. Gain exposure to innovative technologies and opportunities for growth. Learn and utilize cutting-edge AI tools to enhance your development skills and create impactful solutions. Be part of a company that values your contributions and encourages professional development. Join a rapidly expanding health-tech startup (~200 employees and growing) with a state-of-the-art technology office located in Hyde Park, offering a variety of exceptional benefits. Career Progression Timeline In 3 months: Gain a comprehensive understanding of our data infrastructure, technical stacks, and development cycles. Actively participate in team meetings and contribute to the development of new data pipelines. Begin leveraging AI tools, such as Cursor and ChatGPT, to enhance coding efficiency and workflow automation. In 6 months: Contribute to product enhancements and data reporting Collaborate effectively with cross-functional teams, providing insights and solutions for data-related challenges. Demonstrate proficiency in utilizing AI tools for coding and development, actively sharing knowledge with the team. In 12 months: Contribute to data engineering projects, ensuring scalability and performance optimization. Mentor non-technical internal partners to improve company-wide data literacy Contribute to the integration of advanced AI solutions into our development processes, contributing to the company's technological advancement. Physical Requirements: Ability to remain at your designated workstation for the duration of the workday Constantly operates a computer and other office productivity machinery, such as a phone and Voice over Internet Protocol (VoIP). The ability to communicate information and ideas so others will understand. Must be able to exchange accurate information in these situations. The ability to observe details at close range (typically on a computer screen) This position offers the flexibility of remote work at approved locations within the United States. Candidates must have a reliable internet connection and a designated work environment conducive to professional phone calls and sensitive data. Enjoy the convenience and comfort of working remotely while contributing to our team's success. Apply Today If you’re ready to take on challenging problems, contribute to impactful solutions, and grow as a data engineer, we’d love to hear from you. Join us at The Helper Bees and be part of a team that’s making a meaningful difference every day! The Helper Bees is committed to building a workplace where diversity, equity, and inclusion are valued and prioritized. We are an equal opportunity employer that welcomes all qualified applicants without discrimination based on race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or any non-merit based or legally protected grounds. The Helper Bees provides reasonable accommodations to qualified individuals with disabilities during the job application and interview process. To request accommodation, please let your recruiter know. As part of our standard hiring process, selected candidates may be required to undergo a background check and/or drug screen. The Helper Bees adheres to applicable federal, state, and local laws regarding these screenings, and the results will be considered in accordance with applicable regulations. The Helper Bees was recently made aware of a fraudulent entity posing as our organization and requesting personal information. Please be aware of and protect yourself from scams. Visit thehelperbees.com/careers to view all current job openings.",
         "Description: Join our winning team, recently honored as #67 on Forbes’ list of America’s Best Startup Employers for 2024! About The Helper Bees The Helper Bees’ mission is to help people stay home longer through data-driven services that transform both the payer and the care-recipient experience. At The Helper Bees, we are reshaping how care is delivered to aging individuals by leveraging innovative technology and insightful data solutions. We maintain multiple SaaS products and payment solutions through our web applications (internal and external facing), a mobile app, and reporting integrations. As part of our growing Data Engineering team, you’ll iterate quickly, have a high impact, and be challenged to design and implement cutting-edge solutions. At THB, we define our company culture through our Core Values: Quickly iterate through solutions: We move at a fast pace which requires quick iterations to find a path to a repeatable solution. Seek ways to create immediate impact: Be thoughtful and proactive in how you make an impact on your team. Actively look for ways to make a fast, positive impact. Bee the teammate you want to work with: We work as a team, help each other, and encourage each other. Ask questions, answer questions: You can't iterate through solutions if you don't ask the right questions, which is why there is an expectation that questions should be asked. When you know the answer, being a good teammate means chiming in to get others up to speed. Take the time to celebrate wins: It's so easy for a team that is heads down to forget about all the great things they've accomplished. That's why we make it a priority to remind ourselves to create space to celebrate wins, big or small. Job Summary We are seeking a motivated Data Engineer to join our team and help improve our tools, processes, and technical infrastructure. In this role, you will ensure the availability and quality of our data while contributing to the design, implementation, and maintenance of The Helper Bees’ products. You’ll collaborate across teams to create scalable and optimized software systems and play a key role in refining our development processes. This position offers a unique opportunity to learn and leverage cutting-edge AI development tools to enhance coding efficiency and develop advanced data tools and solutions. Supervisory Responsibilities: None Key Responsibilities Data Infrastructure: Design, implement, and maintain data pipelines, ensuring data availability, quality, and scalability. Product Development: Build and enhance products using Python, SQL, and modern technologies. AI Integration: Leverage cutting-edge AI tools, including Cursor, ChatGPT, and Claude to improve development processes, automate workflows, and create innovative data solutions. Collaboration: Communicate across departments to design, build, test, and implement new features and enhancements. Code Excellence: Produce quality, testable, and maintainable code while participating in code reviews. Problem Solving: Debug complex issues, interact with stakeholders, and design viable solutions with clear trade-offs. Process Optimization: Contribute to improving development processes, including deployment, on-call systems, and sprint planning. Team Growth: Collaborate within the development team to help each other grow and continuously learn. Stakeholder Engagement: Partner with analysts, scientists, and IT to ensure alignment and deliver data-driven solutions. Other duties as assigned/necessary Performance Metrics Code Quality: Maintain high coding standards through regular code reviews and adherence to best practices. Development Efficiency: Deliver high-quality features and fixes within efficient timeframes. Bug Resolution Time: Reduce the time taken to identify and resolve issues. System Scalability: Optimize system performance to handle increasing user demands. Collaboration: Foster a collaborative environment that encourages teamwork and knowledge sharing. Customer Satisfaction: Incorporate stakeholder feedback to improve solutions and enhance the customer experience. Continuous Learning: Pursue opportunities for skill development and share knowledge with the team. Requirements: Required Skills & Qualifications Technical Tools: Experience with in Python and/or SQL. Experience with Bash, Shell scripting, Big Query, Airflow, and is a plus. Programming: Cleaning data using code-based approach. AI Proficiency: Interest or experience in using AI tools for coding and development of data solutions. Soft Skills: Problem-solving, cross-team collaboration, data storytelling, and stakeholder engagement. Adaptability: Thrives in a fast-paced startup environment and embraces change. Proactivity: Self-directed, organized, and able to prioritize effectively. Collaboration: Ability to work effectively with cross-functional teams. Education & Experience: A bachelor’s degree is required, and a graduate degree is preferred. Relevant experience in data engineering, software development, STEM, or related fields. Strong experience with SQL and Python is highly desirable. Mindset: A passion for innovation, continuous improvement, and delivering high-quality results from messy data. Preferred Qualifications Familiarity with cloud-based solutions (e.g., Google Cloud Platform, Azure). Experience with ETL processes and tools. Experience building data visualization reports and dashboards Knowledge of modern data storage solutions and database management systems. Exposure to DevOps practices and tools for deployment and monitoring. Why Join Us? Work with a talented, collaborative team dedicated to making a difference. Gain exposure to innovative technologies and opportunities for growth. Learn and utilize cutting-edge AI tools to enhance your development skills and create impactful solutions. Be part of a company that values your contributions and encourages professional development. Join a rapidly expanding health-tech startup (~200 employees and growing) with a state-of-the-art technology office located in Hyde Park, offering a variety of exceptional benefits. Career Progression Timeline In 3 months: Gain a comprehensive understanding of our data infrastructure, technical stacks, and development cycles. Actively participate in team meetings and contribute to the development of new data pipelines. Begin leveraging AI tools, such as Cursor and ChatGPT, to enhance coding efficiency and workflow automation. In 6 months: Contribute to product enhancements and data reporting Collaborate effectively with cross-functional teams, providing insights and solutions for data-related challenges. Demonstrate proficiency in utilizing AI tools for coding and development, actively sharing knowledge with the team. In 12 months: Contribute to data engineering projects, ensuring scalability and performance optimization. Mentor non-technical internal partners to improve company-wide data literacy Contribute to the integration of advanced AI solutions into our development processes, contributing to the company's technological advancement. Physical Requirements: Ability to remain at your designated workstation for the duration of the workday Constantly operates a computer and other office productivity machinery, such as a phone and Voice over Internet Protocol (VoIP). The ability to communicate information and ideas so others will understand. Must be able to exchange accurate information in these situations. The ability to observe details at close range (typically on a computer screen) This position offers the flexibility of remote work at approved locations within the United States. Candidates must have a reliable internet connection and a designated work environment conducive to professional phone calls and sensitive data. Enjoy the convenience and comfort of working remotely while contributing to our team's success. Apply Today If you’re ready to take on challenging problems, contribute to impactful solutions, and grow as a data engineer, we’d love to hear from you. Join us at The Helper Bees and be part of a team that’s making a meaningful difference every day! The Helper Bees is committed to building a workplace where diversity, equity, and inclusion are valued and prioritized. We are an equal opportunity employer that welcomes all qualified applicants without discrimination based on race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or any non-merit based or legally protected grounds. The Helper Bees provides reasonable accommodations to qualified individuals with disabilities during the job application and interview process. To request accommodation, please let your recruiter know. As part of our standard hiring process, selected candidates may be required to undergo a background check and/or drug screen. The Helper Bees adheres to applicable federal, state, and local laws regarding these screenings, and the results will be considered in accordance with applicable regulations. The Helper Bees was recently made aware of a fraudulent entity posing as our organization and requesting personal information. Please be aware of and protect yourself from scams. Visit thehelperbees.com/careers to view all current job openings.",
         "Technical Tools: Experience with in Python and/or SQL. Experience with Bash, Shell scripting, Big Query, Airflow, and is a plus. Programming: Cleaning data using code-based approach. AI Proficiency: Interest or experience in using AI tools for coding and development of data solutions. Soft Skills: Problem-solving, cross-team collaboration, data storytelling, and stakeholder engagement. Adaptability: Thrives in a fast-paced startup environment and embraces change. Proactivity: Self-directed, organized, and able to prioritize effectively. Collaboration: Ability to work effectively with cross-functional teams. Education & Experience: A bachelor’s degree is required, and a graduate degree is preferred. Relevant experience in data engineering, software development, STEM, or related fields. Strong experience with SQL and Python is highly desirable. Mindset: A passion for innovation, continuous improvement, and delivering high-quality results from messy data. Preferred Qualifications Familiarity with cloud-based solutions (e.g., Google Cloud Platform, Azure). Experience with ETL processes and tools. Experience building data visualization reports and dashboards Knowledge of modern data storage solutions and database management systems. Exposure to DevOps practices and tools for deployment and monitoring. Why Join Us? Work with a talented, collaborative team dedicated to making a difference. Gain exposure to innovative technologies and opportunities for growth. Learn and utilize cutting-edge AI tools to enhance your development skills and create impactful solutions. Be part of a company that values your contributions and encourages professional development. Join a rapidly expanding health-tech startup (~200 employees and growing) with a state-of-the-art technology office located in Hyde Park, offering a variety of exceptional benefits. Career Progression Timeline In 3 months: Gain a comprehensive understanding of our data infrastructure, technical stacks, and development cycles. Actively participate in team meetings and contribute to the development of new data pipelines. Begin leveraging AI tools, such as Cursor and ChatGPT, to enhance coding efficiency and workflow automation. In 6 months: Contribute to product enhancements and data reporting Collaborate effectively with cross-functional teams, providing insights and solutions for data-related challenges. Demonstrate proficiency in utilizing AI tools for coding and development, actively sharing knowledge with the team. In 12 months: Contribute to data engineering projects, ensuring scalability and performance optimization. Mentor non-technical internal partners to improve company-wide data literacy Contribute to the integration of advanced AI solutions into our development processes, contributing to the company's technological advancement. Physical Requirements: Ability to remain at your designated workstation for the duration of the workday Constantly operates a computer and other office productivity machinery, such as a phone and Voice over Internet Protocol (VoIP). The ability to communicate information and ideas so others will understand. Must be able to exchange accurate information in these situations. The ability to observe details at close range (typically on a computer screen) This position offers the flexibility of remote work at approved locations within the United States. Candidates must have a reliable internet connection and a designated work environment conducive to professional phone calls and sensitive data. Enjoy the convenience and comfort of working remotely while contributing to our team's success. Apply Today If you’re ready to take on challenging problems, contribute to impactful solutions, and grow as a data engineer, we’d love to hear from you. Join us at The Helper Bees and be part of a team that’s making a meaningful difference every day! The Helper Bees is committed to building a workplace where diversity, equity, and inclusion are valued and prioritized. We are an equal opportunity employer that welcomes all qualified applicants without discrimination based on race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or any non-merit based or legally protected grounds. The Helper Bees provides reasonable accommodations to qualified individuals with disabilities during the job application and interview process. To request accommodation, please let your recruiter know. As part of our standard hiring process, selected candidates may be required to undergo a background check and/or drug screen. The Helper Bees adheres to applicable federal, state, and local laws regarding these screenings, and the results will be considered in accordance with applicable regulations. The Helper Bees was recently made aware of a fraudulent entity posing as our organization and requesting personal information. Please be aware of and protect yourself from scams. Visit thehelperbees.com/careers to view all current job openings.",
         698
        ],
        [
         "Data Engineer II (Remote)",
         ", we welcome people of all abilities and want to ensure that our hiring and interview process meets the needs of all applicants. If you require a reasonable accommodation to make your application or interview experience a great one, please contact HRsupport@randstadusa.com.",
         "Index Analytics, LLC, is a rapidly growing, Baltimore-based small business providing health-related consulting services to the federal government. At the center of our company culture is a commitment to instilling a dynamic and employee-friendly place to work. We place a priority on promoting a supportive and collegial team environment and enhancing staff experience through career development and educational opportunities. Position Overview The Data Engineer is responsible for designing, building, and maintaining data pipelines and architectures to support data analytics and reporting needs across the organization. This role involves working closely with data scientists, analysts, and other stakeholders to ensure that data is clean, accessible, and ready for analysis. The Data Engineer will optimize data systems, develop data integration solutions, and ensure data security and governance. Key responsibilities include creating ETL processes, managing databases, and improving data infrastructure performance. The ideal candidate has strong programming and database skills and experience with cloud-based data platforms. Responsibilities Leads design, implementation, and management of data pipelines Develops and executes ETL (extract, transform, load) or ELT code Supports design of robust Data Integration Architecture to support customers Helps monitor and administer the systems and ensures applications and systems are always functioning properly Analyzes the Data Integration and Engineering architecture to identify weaknesses and develops improvements such as enhancing business processes Identifies and analyzes business requirements, functional design, and translation of requirements to technical specifications Performs complex query design, developments, validation routine analysis, and streamlining processes Operates large data sets, delta data sets and querying efficiently Transforms, joins, and normalizes data in service of specific use cases. Employs AWS data pipeline solutions such as Glue, Data Pipeline, Step functions, MWAA to orchestrate data movement Work with DevSecOps engineer to deploy continuous integration and continuous deployment (CI/CD) data pipelines Understand the technical architecture to design, build, optimize, and maintain scalable data solutions in a Big Data environment Work with Product Owners and/or business stakeholders to gather business requirements and translate to detailed technical specifications US citizen or Authorized to Work and lived in the US for 3 of the last 5 years. Must be able to obtain a U.S. Federal government client badge and pass a government Public Trust. Bachelors degree or higher in IT or relevant discipline required 4+ years of IT experience Experience with setting up and operating data pipelines using Python or SQL Experience with Scala and PySpark 3+ years of experience working on AWS, GCP or Azure (AWS Preferred) cloud platforms Hands-on relational DB / NoSQL experience (PostgreSQL or similar) with specific implementation on cloud Experience working with data warehouses such as Redshift to open source and proprietary cloud data pipeline tools such as Airflow, Glue, Data Pipeline, Step functions Experience working with relational databases that handle structured and semi-structured (JSON) datasets Experience with data serialization languages such as JSON, XML, YAML Experience with code management tools (e.g. Git, SVN) and DevOps tools (e.g. Jenkins, Docker, AWS Code Pipeline) Strong analytical problem-solving ability Working experience with Transactional and Dimensional data modeling methodologies (Eg: Normalization, Star Schema, Snowflake Schema) Experience working with a distributed computing environment like AWS EMR or similar. Ability to obtain Public Trust level clearance Ability to demonstrate excellent written and oral communication required Prior experience with Center for Medicare Medicaid Services or other Govt agencies is a plus The salary range provided represents the estimated compensation for new hires in this position, applicable across all locations. Actual offers may vary based on factors such as the candidate's skills, qualifications, experience, and market conditions. Index complements its base salary offering with a competitive package that includes health and retirement benefits, discretionary bonuses, and reimbursement for professional development opportunities. Index Analytics provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training. Attention Candidates We're dedicated to ensuring a safe and transparent recruitment process for all candidates and have implemented robust measures to protect your personal information. Please be aware that all employment-related communications will originate from a secure portal ( NAME@msg.paycomonline.com ) or a corporate email address ( NAME@index-analytics.com ). If you have any concerns, please don't hesitate to reach out to us at recruiting@index-analytics.com",
         "data",
         "Index Analytics, LLC, is a rapidly growing, Baltimore-based small business providing health-related consulting services to the federal government. At the center of our company culture is a commitment to instilling a dynamic and employee-friendly place to work. We place a priority on promoting a supportive and collegial team environment and enhancing staff experience through career development and educational opportunities. Position Overview The Data Engineer is responsible for designing, building, and maintaining data pipelines and architectures to support data analytics and reporting needs across the organization. This role involves working closely with data scientists, analysts, and other stakeholders to ensure that data is clean, accessible, and ready for analysis. The Data Engineer will optimize data systems, develop data integration solutions, and ensure data security and governance. Key responsibilities include creating ETL processes, managing databases, and improving data infrastructure performance. The ideal candidate has strong programming and database skills and experience with cloud-based data platforms. Responsibilities Leads design, implementation, and management of data pipelines Develops and executes ETL (extract, transform, load) or ELT code Supports design of robust Data Integration Architecture to support customers Helps monitor and administer the systems and ensures applications and systems are always functioning properly Analyzes the Data Integration and Engineering architecture to identify weaknesses and develops improvements such as enhancing business processes Identifies and analyzes business requirements, functional design, and translation of requirements to technical specifications Performs complex query design, developments, validation routine analysis, and streamlining processes Operates large data sets, delta data sets and querying efficiently Transforms, joins, and normalizes data in service of specific use cases. Employs AWS data pipeline solutions such as Glue, Data Pipeline, Step functions, MWAA to orchestrate data movement Work with DevSecOps engineer to deploy continuous integration and continuous deployment (CI/CD) data pipelines Understand the technical architecture to design, build, optimize, and maintain scalable data solutions in a Big Data environment Work with Product Owners and/or business stakeholders to gather business requirements and translate to detailed technical specifications US citizen or Authorized to Work and lived in the US for 3 of the last 5 years. Must be able to obtain a U.S. Federal government client badge and pass a government Public Trust. Bachelors degree or higher in IT or relevant discipline required 4+ years of IT experience Experience with setting up and operating data pipelines using Python or SQL Experience with Scala and PySpark 3+ years of experience working on AWS, GCP or Azure (AWS Preferred) cloud platforms Hands-on relational DB / NoSQL experience (PostgreSQL or similar) with specific implementation on cloud Experience working with data warehouses such as Redshift to open source and proprietary cloud data pipeline tools such as Airflow, Glue, Data Pipeline, Step functions Experience working with relational databases that handle structured and semi-structured (JSON) datasets Experience with data serialization languages such as JSON, XML, YAML Experience with code management tools (e.g. Git, SVN) and DevOps tools (e.g. Jenkins, Docker, AWS Code Pipeline) Strong analytical problem-solving ability Working experience with Transactional and Dimensional data modeling methodologies (Eg: Normalization, Star Schema, Snowflake Schema) Experience working with a distributed computing environment like AWS EMR or similar. Ability to obtain Public Trust level clearance Ability to demonstrate excellent written and oral communication required Prior experience with Center for Medicare Medicaid Services or other Govt agencies is a plus The salary range provided represents the estimated compensation for new hires in this position, applicable across all locations. Actual offers may vary based on factors such as the candidate's skills, qualifications, experience, and market conditions. Index complements its base salary offering with a competitive package that includes health and retirement benefits, discretionary bonuses, and reimbursement for professional development opportunities. Index Analytics provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training. Attention Candidates We're dedicated to ensuring a safe and transparent recruitment process for all candidates and have implemented robust measures to protect your personal information. Please be aware that all employment-related communications will originate from a secure portal ( NAME@msg.paycomonline.com ) or a corporate email address ( NAME@index-analytics.com ). If you have any concerns, please don't hesitate to reach out to us at recruiting@index-analytics.com",
         "Index Analytics, LLC, is a rapidly growing, Baltimore-based small business providing health-related consulting services to the federal government. At the center of our company culture is a commitment to instilling a dynamic and employee-friendly place to work. We place a priority on promoting a supportive and collegial team environment and enhancing staff experience through career development and educational opportunities. Position Overview The Data Engineer is responsible for designing, building, and maintaining data pipelines and architectures to support data analytics and reporting needs across the organization. This role involves working closely with data scientists, analysts, and other stakeholders to ensure that data is clean, accessible, and ready for analysis. The Data Engineer will optimize data systems, develop data integration solutions, and ensure data security and governance. Key responsibilities include creating ETL processes, managing databases, and improving data infrastructure performance. The ideal candidate has strong programming and database skills and experience with cloud-based data platforms. Responsibilities Leads design, implementation, and management of data pipelines Develops and executes ETL (extract, transform, load) or ELT code Supports design of robust Data Integration Architecture to support customers Helps monitor and administer the systems and ensures applications and systems are always functioning properly Analyzes the Data Integration and Engineering architecture to identify weaknesses and develops improvements such as enhancing business processes Identifies and analyzes business requirements, functional design, and translation of requirements to technical specifications Performs complex query design, developments, validation routine analysis, and streamlining processes Operates large data sets, delta data sets and querying efficiently Transforms, joins, and normalizes data in service of specific use cases. Employs AWS data pipeline solutions such as Glue, Data Pipeline, Step functions, MWAA to orchestrate data movement Work with DevSecOps engineer to deploy continuous integration and continuous deployment (CI/CD) data pipelines Understand the technical architecture to design, build, optimize, and maintain scalable data solutions in a Big Data environment Work with Product Owners and/or business stakeholders to gather business requirements and translate to detailed technical specifications US citizen or Authorized to Work and lived in the US for 3 of the last 5 years. Must be able to obtain a U.S. Federal government client badge and pass a government Public Trust. Bachelors degree or higher in IT or relevant discipline required 4+ years of IT experience Experience with setting up and operating data pipelines using Python or SQL Experience with Scala and PySpark 3+ years of experience working on AWS, GCP or Azure (AWS Preferred) cloud platforms Hands-on relational DB / NoSQL experience (PostgreSQL or similar) with specific implementation on cloud Experience working with data warehouses such as Redshift to open source and proprietary cloud data pipeline tools such as Airflow, Glue, Data Pipeline, Step functions Experience working with relational databases that handle structured and semi-structured (JSON) datasets Experience with data serialization languages such as JSON, XML, YAML Experience with code management tools (e.g. Git, SVN) and DevOps tools (e.g. Jenkins, Docker, AWS Code Pipeline) Strong analytical problem-solving ability Working experience with Transactional and Dimensional data modeling methodologies (Eg: Normalization, Star Schema, Snowflake Schema) Experience working with a distributed computing environment like AWS EMR or similar. Ability to obtain Public Trust level clearance Ability to demonstrate excellent written and oral communication required Prior experience with Center for Medicare Medicaid Services or other Govt agencies is a plus The salary range provided represents the estimated compensation for new hires in this position, applicable across all locations. Actual offers may vary based on factors such as the candidate's skills, qualifications, experience, and market conditions. Index complements its base salary offering with a competitive package that includes health and retirement benefits, discretionary bonuses, and reimbursement for professional development opportunities. Index Analytics provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training. Attention Candidates We're dedicated to ensuring a safe and transparent recruitment process for all candidates and have implemented robust measures to protect your personal information. Please be aware that all employment-related communications will originate from a secure portal ( NAME@msg.paycomonline.com ) or a corporate email address ( NAME@index-analytics.com ). If you have any concerns, please don't hesitate to reach out to us at recruiting@index-analytics.com",
         "to technical specifications Performs complex query design, developments, validation routine analysis, and streamlining processes Operates large data sets, delta data sets and querying efficiently Transforms, joins, and normalizes data in service of specific use cases. Employs AWS data pipeline solutions such as Glue, Data Pipeline, Step functions, MWAA to orchestrate data movement Work with DevSecOps engineer to deploy continuous integration and continuous deployment (CI/CD) data pipelines Understand the technical architecture to design, build, optimize, and maintain scalable data solutions in a Big Data environment Work with Product Owners and/or business stakeholders to gather business requirements and translate to detailed technical specifications US citizen or Authorized to Work and lived in the US for 3 of the last 5 years. Must be able to obtain a U.S. Federal government client badge and pass a government Public Trust. Bachelors degree or higher in IT or relevant discipline required 4+ years of IT experience Experience with setting up and operating data pipelines using Python or SQL Experience with Scala and PySpark 3+ years of experience working on AWS, GCP or Azure (AWS Preferred) cloud platforms Hands-on relational DB / NoSQL experience (PostgreSQL or similar) with specific implementation on cloud Experience working with data warehouses such as Redshift to open source and proprietary cloud data pipeline tools such as Airflow, Glue, Data Pipeline, Step functions Experience working with relational databases that handle structured and semi-structured (JSON) datasets Experience with data serialization languages such as JSON, XML, YAML Experience with code management tools (e.g. Git, SVN) and DevOps tools (e.g. Jenkins, Docker, AWS Code Pipeline) Strong analytical problem-solving ability Working experience with Transactional and Dimensional data modeling methodologies (Eg: Normalization, Star Schema, Snowflake Schema) Experience working with a distributed computing environment like AWS EMR or similar. Ability to obtain Public Trust level clearance Ability to demonstrate excellent written and oral communication required Prior experience with Center for Medicare Medicaid Services or other Govt agencies is a plus The salary range provided represents the estimated compensation for new hires in this position, applicable across all locations. Actual offers may vary based on factors such as the candidate's skills, qualifications, experience, and market conditions. Index complements its base salary offering with a competitive package that includes health and retirement benefits, discretionary bonuses, and reimbursement for professional development opportunities. Index Analytics provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training. Attention Candidates We're dedicated to ensuring a safe and transparent recruitment process for all candidates and have implemented robust measures to protect your personal information. Please be aware that all employment-related communications will originate from a secure portal ( NAME@msg.paycomonline.com ) or a corporate email address ( NAME@index-analytics.com ). If you have any concerns, please don't hesitate to reach out to us at recruiting@index-analytics.com",
         524
        ],
        [
         null,
         "The Helper Bees",
         "Description: Join our winning team, recently honored as #67 on Forbes’ list of America’s Best Startup Employers for 2024! About The Helper Bees The Helper Bees’ mission is to help people stay home longer through data-driven services that transform both the payer and the care-recipient experience. At The Helper Bees, we are reshaping how care is delivered to aging individuals by leveraging innovative technology and insightful data solutions. We maintain multiple SaaS products and payment solutions through our web applications (internal and external facing), a mobile app, and reporting integrations. As part of our growing Data Engineering team, you’ll iterate quickly, have a high impact, and be challenged to design and implement cutting-edge solutions. At THB, we define our company culture through our Core Values: Quickly iterate through solutions: We move at a fast pace which requires quick iterations to find a path to a repeatable solution. Seek ways to create immediate impact: Be thoughtful and proactive in how you make an impact on your team. Actively look for ways to make a fast, positive impact. Bee the teammate you want to work with: We work as a team, help each other, and encourage each other. Ask questions, answer questions: You can't iterate through solutions if you don't ask the right questions, which is why there is an expectation that questions should be asked. When you know the answer, being a good teammate means chiming in to get others up to speed. Take the time to celebrate wins: It's so easy for a team that is heads down to forget about all the great things they've accomplished. That's why we make it a priority to remind ourselves to create space to celebrate wins, big or small. Job Summary We are seeking a motivated Data Engineer to join our team and help improve our tools, processes, and technical infrastructure. In this role, you will ensure the availability and quality of our data while contributing to the design, implementation, and maintenance of The Helper Bees’ products. You’ll collaborate across teams to create scalable and optimized software systems and play a key role in refining our development processes. This position offers a unique opportunity to learn and leverage cutting-edge AI development tools to enhance coding efficiency and develop advanced data tools and solutions. Supervisory Responsibilities: None Key Responsibilities Data Infrastructure: Design, implement, and maintain data pipelines, ensuring data availability, quality, and scalability. Product Development: Build and enhance products using Python, SQL, and modern technologies. AI Integration: Leverage cutting-edge AI tools, including Cursor, ChatGPT, and Claude to improve development processes, automate workflows, and create innovative data solutions. Collaboration: Communicate across departments to design, build, test, and implement new features and enhancements. Code Excellence: Produce quality, testable, and maintainable code while participating in code reviews. Problem Solving: Debug complex issues, interact with stakeholders, and design viable solutions with clear trade-offs. Process Optimization: Contribute to improving development processes, including deployment, on-call systems, and sprint planning. Team Growth: Collaborate within the development team to help each other grow and continuously learn. Stakeholder Engagement: Partner with analysts, scientists, and IT to ensure alignment and deliver data-driven solutions. Other duties as assigned/necessary Performance Metrics Code Quality: Maintain high coding standards through regular code reviews and adherence to best practices. Development Efficiency: Deliver high-quality features and fixes within efficient timeframes. Bug Resolution Time: Reduce the time taken to identify and resolve issues. System Scalability: Optimize system performance to handle increasing user demands. Collaboration: Foster a collaborative environment that encourages teamwork and knowledge sharing. Customer Satisfaction: Incorporate stakeholder feedback to improve solutions and enhance the customer experience. Continuous Learning: Pursue opportunities for skill development and share knowledge with the team. Requirements: Required Skills & Qualifications Technical Tools: Experience with in Python and/or SQL. Experience with Bash, Shell scripting, Big Query, Airflow, and is a plus. Programming: Cleaning data using code-based approach. AI Proficiency: Interest or experience in using AI tools for coding and development of data solutions. Soft Skills: Problem-solving, cross-team collaboration, data storytelling, and stakeholder engagement. Adaptability: Thrives in a fast-paced startup environment and embraces change. Proactivity: Self-directed, organized, and able to prioritize effectively. Collaboration: Ability to work effectively with cross-functional teams. Education & Experience: A bachelor’s degree is required, and a graduate degree is preferred. Relevant experience in data engineering, software development, STEM, or related fields. Strong experience with SQL and Python is highly desirable. Mindset: A passion for innovation, continuous improvement, and delivering high-quality results from messy data. Preferred Qualifications Familiarity with cloud-based solutions (e.g., Google Cloud Platform, Azure). Experience with ETL processes and tools. Experience building data visualization reports and dashboards Knowledge of modern data storage solutions and database management systems. Exposure to DevOps practices and tools for deployment and monitoring. Why Join Us? Work with a talented, collaborative team dedicated to making a difference. Gain exposure to innovative technologies and opportunities for growth. Learn and utilize cutting-edge AI tools to enhance your development skills and create impactful solutions. Be part of a company that values your contributions and encourages professional development. Join a rapidly expanding health-tech startup (~200 employees and growing) with a state-of-the-art technology office located in Hyde Park, offering a variety of exceptional benefits. Career Progression Timeline In 3 months: Gain a comprehensive understanding of our data infrastructure, technical stacks, and development cycles. Actively participate in team meetings and contribute to the development of new data pipelines. Begin leveraging AI tools, such as Cursor and ChatGPT, to enhance coding efficiency and workflow automation. In 6 months: Contribute to product enhancements and data reporting Collaborate effectively with cross-functional teams, providing insights and solutions for data-related challenges. Demonstrate proficiency in utilizing AI tools for coding and development, actively sharing knowledge with the team. In 12 months: Contribute to data engineering projects, ensuring scalability and performance optimization. Mentor non-technical internal partners to improve company-wide data literacy Contribute to the integration of advanced AI solutions into our development processes, contributing to the company's technological advancement. Physical Requirements: Ability to remain at your designated workstation for the duration of the workday Constantly operates a computer and other office productivity machinery, such as a phone and Voice over Internet Protocol (VoIP). The ability to communicate information and ideas so others will understand. Must be able to exchange accurate information in these situations. The ability to observe details at close range (typically on a computer screen) This position offers the flexibility of remote work at approved locations within the United States. Candidates must have a reliable internet connection and a designated work environment conducive to professional phone calls and sensitive data. Enjoy the convenience and comfort of working remotely while contributing to our team's success. Apply Today If you’re ready to take on challenging problems, contribute to impactful solutions, and grow as a data engineer, we’d love to hear from you. Join us at The Helper Bees and be part of a team that’s making a meaningful difference every day! The Helper Bees is committed to building a workplace where diversity, equity, and inclusion are valued and prioritized. We are an equal opportunity employer that welcomes all qualified applicants without discrimination based on race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or any non-merit based or legally protected grounds. The Helper Bees provides reasonable accommodations to qualified individuals with disabilities during the job application and interview process. To request accommodation, please let your recruiter know. As part of our standard hiring process, selected candidates may be required to undergo a background check and/or drug screen. The Helper Bees adheres to applicable federal, state, and local laws regarding these screenings, and the results will be considered in accordance with applicable regulations. The Helper Bees was recently made aware of a fraudulent entity posing as our organization and requesting personal information. Please be aware of and protect yourself from scams. Visit thehelperbees.com/careers to view all current job openings. Opened URL: https://www.indeed.com/rc/clk?jk=06050d41e9f16407&bb=1TLRjqutBEYcit1OApAPto3A50Hg4Pzq5qFUF25sU891HTb0FMRKF-y31Tt72Rgj3vRHASDwe2nU2bKOyor677T1mfz6aMuuBmnum2LV6DDSRY1DGNuI6LNVrSB8DuSr&xkcb=SoDU67M33zDWevR-pR0JbzkdCdPP&fccid=61e4e7d2ce056d37&vjs=3",
         "data",
         "Description: Join our winning team, recently honored as #67 on Forbes’ list of America’s Best Startup Employers for 2024! About The Helper Bees The Helper Bees’ mission is to help people stay home longer through data-driven services that transform both the payer and the care-recipient experience. At The Helper Bees, we are reshaping how care is delivered to aging individuals by leveraging innovative technology and insightful data solutions. We maintain multiple SaaS products and payment solutions through our web applications (internal and external facing), a mobile app, and reporting integrations. As part of our growing Data Engineering team, you’ll iterate quickly, have a high impact, and be challenged to design and implement cutting-edge solutions. At THB, we define our company culture through our Core Values: Quickly iterate through solutions: We move at a fast pace which requires quick iterations to find a path to a repeatable solution. Seek ways to create immediate impact: Be thoughtful and proactive in how you make an impact on your team. Actively look for ways to make a fast, positive impact. Bee the teammate you want to work with: We work as a team, help each other, and encourage each other. Ask questions, answer questions: You can't iterate through solutions if you don't ask the right questions, which is why there is an expectation that questions should be asked. When you know the answer, being a good teammate means chiming in to get others up to speed. Take the time to celebrate wins: It's so easy for a team that is heads down to forget about all the great things they've accomplished. That's why we make it a priority to remind ourselves to create space to celebrate wins, big or small. Job Summary We are seeking a motivated Data Engineer to join our team and help improve our tools, processes, and technical infrastructure. In this role, you will ensure the availability and quality of our data while contributing to the design, implementation, and maintenance of The Helper Bees’ products. You’ll collaborate across teams to create scalable and optimized software systems and play a key role in refining our development processes. This position offers a unique opportunity to learn and leverage cutting-edge AI development tools to enhance coding efficiency and develop advanced data tools and solutions. Supervisory Responsibilities: None Key Responsibilities Data Infrastructure: Design, implement, and maintain data pipelines, ensuring data availability, quality, and scalability. Product Development: Build and enhance products using Python, SQL, and modern technologies. AI Integration: Leverage cutting-edge AI tools, including Cursor, ChatGPT, and Claude to improve development processes, automate workflows, and create innovative data solutions. Collaboration: Communicate across departments to design, build, test, and implement new features and enhancements. Code Excellence: Produce quality, testable, and maintainable code while participating in code reviews. Problem Solving: Debug complex issues, interact with stakeholders, and design viable solutions with clear trade-offs. Process Optimization: Contribute to improving development processes, including deployment, on-call systems, and sprint planning. Team Growth: Collaborate within the development team to help each other grow and continuously learn. Stakeholder Engagement: Partner with analysts, scientists, and IT to ensure alignment and deliver data-driven solutions. Other duties as assigned/necessary Performance Metrics Code Quality: Maintain high coding standards through regular code reviews and adherence to best practices. Development Efficiency: Deliver high-quality features and fixes within efficient timeframes. Bug Resolution Time: Reduce the time taken to identify and resolve issues. System Scalability: Optimize system performance to handle increasing user demands. Collaboration: Foster a collaborative environment that encourages teamwork and knowledge sharing. Customer Satisfaction: Incorporate stakeholder feedback to improve solutions and enhance the customer experience. Continuous Learning: Pursue opportunities for skill development and share knowledge with the team. Requirements: Required Skills & Qualifications Technical Tools: Experience with in Python and/or SQL. Experience with Bash, Shell scripting, Big Query, Airflow, and is a plus. Programming: Cleaning data using code-based approach. AI Proficiency: Interest or experience in using AI tools for coding and development of data solutions. Soft Skills: Problem-solving, cross-team collaboration, data storytelling, and stakeholder engagement. Adaptability: Thrives in a fast-paced startup environment and embraces change. Proactivity: Self-directed, organized, and able to prioritize effectively. Collaboration: Ability to work effectively with cross-functional teams. Education & Experience: A bachelor’s degree is required, and a graduate degree is preferred. Relevant experience in data engineering, software development, STEM, or related fields. Strong experience with SQL and Python is highly desirable. Mindset: A passion for innovation, continuous improvement, and delivering high-quality results from messy data. Preferred Qualifications Familiarity with cloud-based solutions (e.g., Google Cloud Platform, Azure). Experience with ETL processes and tools. Experience building data visualization reports and dashboards Knowledge of modern data storage solutions and database management systems. Exposure to DevOps practices and tools for deployment and monitoring. Why Join Us? Work with a talented, collaborative team dedicated to making a difference. Gain exposure to innovative technologies and opportunities for growth. Learn and utilize cutting-edge AI tools to enhance your development skills and create impactful solutions. Be part of a company that values your contributions and encourages professional development. Join a rapidly expanding health-tech startup (~200 employees and growing) with a state-of-the-art technology office located in Hyde Park, offering a variety of exceptional benefits. Career Progression Timeline In 3 months: Gain a comprehensive understanding of our data infrastructure, technical stacks, and development cycles. Actively participate in team meetings and contribute to the development of new data pipelines. Begin leveraging AI tools, such as Cursor and ChatGPT, to enhance coding efficiency and workflow automation. In 6 months: Contribute to product enhancements and data reporting Collaborate effectively with cross-functional teams, providing insights and solutions for data-related challenges. Demonstrate proficiency in utilizing AI tools for coding and development, actively sharing knowledge with the team. In 12 months: Contribute to data engineering projects, ensuring scalability and performance optimization. Mentor non-technical internal partners to improve company-wide data literacy Contribute to the integration of advanced AI solutions into our development processes, contributing to the company's technological advancement. Physical Requirements: Ability to remain at your designated workstation for the duration of the workday Constantly operates a computer and other office productivity machinery, such as a phone and Voice over Internet Protocol (VoIP). The ability to communicate information and ideas so others will understand. Must be able to exchange accurate information in these situations. The ability to observe details at close range (typically on a computer screen) This position offers the flexibility of remote work at approved locations within the United States. Candidates must have a reliable internet connection and a designated work environment conducive to professional phone calls and sensitive data. Enjoy the convenience and comfort of working remotely while contributing to our team's success. Apply Today If you’re ready to take on challenging problems, contribute to impactful solutions, and grow as a data engineer, we’d love to hear from you. Join us at The Helper Bees and be part of a team that’s making a meaningful difference every day! The Helper Bees is committed to building a workplace where diversity, equity, and inclusion are valued and prioritized. We are an equal opportunity employer that welcomes all qualified applicants without discrimination based on race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or any non-merit based or legally protected grounds. The Helper Bees provides reasonable accommodations to qualified individuals with disabilities during the job application and interview process. To request accommodation, please let your recruiter know. As part of our standard hiring process, selected candidates may be required to undergo a background check and/or drug screen. The Helper Bees adheres to applicable federal, state, and local laws regarding these screenings, and the results will be considered in accordance with applicable regulations. The Helper Bees was recently made aware of a fraudulent entity posing as our organization and requesting personal information. Please be aware of and protect yourself from scams. Visit thehelperbees.com/careers to view all current job openings.",
         "Description: Join our winning team, recently honored as #67 on Forbes’ list of America’s Best Startup Employers for 2024! About The Helper Bees The Helper Bees’ mission is to help people stay home longer through data-driven services that transform both the payer and the care-recipient experience. At The Helper Bees, we are reshaping how care is delivered to aging individuals by leveraging innovative technology and insightful data solutions. We maintain multiple SaaS products and payment solutions through our web applications (internal and external facing), a mobile app, and reporting integrations. As part of our growing Data Engineering team, you’ll iterate quickly, have a high impact, and be challenged to design and implement cutting-edge solutions. At THB, we define our company culture through our Core Values: Quickly iterate through solutions: We move at a fast pace which requires quick iterations to find a path to a repeatable solution. Seek ways to create immediate impact: Be thoughtful and proactive in how you make an impact on your team. Actively look for ways to make a fast, positive impact. Bee the teammate you want to work with: We work as a team, help each other, and encourage each other. Ask questions, answer questions: You can't iterate through solutions if you don't ask the right questions, which is why there is an expectation that questions should be asked. When you know the answer, being a good teammate means chiming in to get others up to speed. Take the time to celebrate wins: It's so easy for a team that is heads down to forget about all the great things they've accomplished. That's why we make it a priority to remind ourselves to create space to celebrate wins, big or small. Job Summary We are seeking a motivated Data Engineer to join our team and help improve our tools, processes, and technical infrastructure. In this role, you will ensure the availability and quality of our data while contributing to the design, implementation, and maintenance of The Helper Bees’ products. You’ll collaborate across teams to create scalable and optimized software systems and play a key role in refining our development processes. This position offers a unique opportunity to learn and leverage cutting-edge AI development tools to enhance coding efficiency and develop advanced data tools and solutions. Supervisory Responsibilities: None Key Responsibilities Data Infrastructure: Design, implement, and maintain data pipelines, ensuring data availability, quality, and scalability. Product Development: Build and enhance products using Python, SQL, and modern technologies. AI Integration: Leverage cutting-edge AI tools, including Cursor, ChatGPT, and Claude to improve development processes, automate workflows, and create innovative data solutions. Collaboration: Communicate across departments to design, build, test, and implement new features and enhancements. Code Excellence: Produce quality, testable, and maintainable code while participating in code reviews. Problem Solving: Debug complex issues, interact with stakeholders, and design viable solutions with clear trade-offs. Process Optimization: Contribute to improving development processes, including deployment, on-call systems, and sprint planning. Team Growth: Collaborate within the development team to help each other grow and continuously learn. Stakeholder Engagement: Partner with analysts, scientists, and IT to ensure alignment and deliver data-driven solutions. Other duties as assigned/necessary Performance Metrics Code Quality: Maintain high coding standards through regular code reviews and adherence to best practices. Development Efficiency: Deliver high-quality features and fixes within efficient timeframes. Bug Resolution Time: Reduce the time taken to identify and resolve issues. System Scalability: Optimize system performance to handle increasing user demands. Collaboration: Foster a collaborative environment that encourages teamwork and knowledge sharing. Customer Satisfaction: Incorporate stakeholder feedback to improve solutions and enhance the customer experience. Continuous Learning: Pursue opportunities for skill development and share knowledge with the team. Requirements: Required Skills & Qualifications Technical Tools: Experience with in Python and/or SQL. Experience with Bash, Shell scripting, Big Query, Airflow, and is a plus. Programming: Cleaning data using code-based approach. AI Proficiency: Interest or experience in using AI tools for coding and development of data solutions. Soft Skills: Problem-solving, cross-team collaboration, data storytelling, and stakeholder engagement. Adaptability: Thrives in a fast-paced startup environment and embraces change. Proactivity: Self-directed, organized, and able to prioritize effectively. Collaboration: Ability to work effectively with cross-functional teams. Education & Experience: A bachelor’s degree is required, and a graduate degree is preferred. Relevant experience in data engineering, software development, STEM, or related fields. Strong experience with SQL and Python is highly desirable. Mindset: A passion for innovation, continuous improvement, and delivering high-quality results from messy data. Preferred Qualifications Familiarity with cloud-based solutions (e.g., Google Cloud Platform, Azure). Experience with ETL processes and tools. Experience building data visualization reports and dashboards Knowledge of modern data storage solutions and database management systems. Exposure to DevOps practices and tools for deployment and monitoring. Why Join Us? Work with a talented, collaborative team dedicated to making a difference. Gain exposure to innovative technologies and opportunities for growth. Learn and utilize cutting-edge AI tools to enhance your development skills and create impactful solutions. Be part of a company that values your contributions and encourages professional development. Join a rapidly expanding health-tech startup (~200 employees and growing) with a state-of-the-art technology office located in Hyde Park, offering a variety of exceptional benefits. Career Progression Timeline In 3 months: Gain a comprehensive understanding of our data infrastructure, technical stacks, and development cycles. Actively participate in team meetings and contribute to the development of new data pipelines. Begin leveraging AI tools, such as Cursor and ChatGPT, to enhance coding efficiency and workflow automation. In 6 months: Contribute to product enhancements and data reporting Collaborate effectively with cross-functional teams, providing insights and solutions for data-related challenges. Demonstrate proficiency in utilizing AI tools for coding and development, actively sharing knowledge with the team. In 12 months: Contribute to data engineering projects, ensuring scalability and performance optimization. Mentor non-technical internal partners to improve company-wide data literacy Contribute to the integration of advanced AI solutions into our development processes, contributing to the company's technological advancement. Physical Requirements: Ability to remain at your designated workstation for the duration of the workday Constantly operates a computer and other office productivity machinery, such as a phone and Voice over Internet Protocol (VoIP). The ability to communicate information and ideas so others will understand. Must be able to exchange accurate information in these situations. The ability to observe details at close range (typically on a computer screen) This position offers the flexibility of remote work at approved locations within the United States. Candidates must have a reliable internet connection and a designated work environment conducive to professional phone calls and sensitive data. Enjoy the convenience and comfort of working remotely while contributing to our team's success. Apply Today If you’re ready to take on challenging problems, contribute to impactful solutions, and grow as a data engineer, we’d love to hear from you. Join us at The Helper Bees and be part of a team that’s making a meaningful difference every day! The Helper Bees is committed to building a workplace where diversity, equity, and inclusion are valued and prioritized. We are an equal opportunity employer that welcomes all qualified applicants without discrimination based on race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or any non-merit based or legally protected grounds. The Helper Bees provides reasonable accommodations to qualified individuals with disabilities during the job application and interview process. To request accommodation, please let your recruiter know. As part of our standard hiring process, selected candidates may be required to undergo a background check and/or drug screen. The Helper Bees adheres to applicable federal, state, and local laws regarding these screenings, and the results will be considered in accordance with applicable regulations. The Helper Bees was recently made aware of a fraudulent entity posing as our organization and requesting personal information. Please be aware of and protect yourself from scams. Visit thehelperbees.com/careers to view all current job openings.",
         "Technical Tools: Experience with in Python and/or SQL. Experience with Bash, Shell scripting, Big Query, Airflow, and is a plus. Programming: Cleaning data using code-based approach. AI Proficiency: Interest or experience in using AI tools for coding and development of data solutions. Soft Skills: Problem-solving, cross-team collaboration, data storytelling, and stakeholder engagement. Adaptability: Thrives in a fast-paced startup environment and embraces change. Proactivity: Self-directed, organized, and able to prioritize effectively. Collaboration: Ability to work effectively with cross-functional teams. Education & Experience: A bachelor’s degree is required, and a graduate degree is preferred. Relevant experience in data engineering, software development, STEM, or related fields. Strong experience with SQL and Python is highly desirable. Mindset: A passion for innovation, continuous improvement, and delivering high-quality results from messy data. Preferred Qualifications Familiarity with cloud-based solutions (e.g., Google Cloud Platform, Azure). Experience with ETL processes and tools. Experience building data visualization reports and dashboards Knowledge of modern data storage solutions and database management systems. Exposure to DevOps practices and tools for deployment and monitoring. Why Join Us? Work with a talented, collaborative team dedicated to making a difference. Gain exposure to innovative technologies and opportunities for growth. Learn and utilize cutting-edge AI tools to enhance your development skills and create impactful solutions. Be part of a company that values your contributions and encourages professional development. Join a rapidly expanding health-tech startup (~200 employees and growing) with a state-of-the-art technology office located in Hyde Park, offering a variety of exceptional benefits. Career Progression Timeline In 3 months: Gain a comprehensive understanding of our data infrastructure, technical stacks, and development cycles. Actively participate in team meetings and contribute to the development of new data pipelines. Begin leveraging AI tools, such as Cursor and ChatGPT, to enhance coding efficiency and workflow automation. In 6 months: Contribute to product enhancements and data reporting Collaborate effectively with cross-functional teams, providing insights and solutions for data-related challenges. Demonstrate proficiency in utilizing AI tools for coding and development, actively sharing knowledge with the team. In 12 months: Contribute to data engineering projects, ensuring scalability and performance optimization. Mentor non-technical internal partners to improve company-wide data literacy Contribute to the integration of advanced AI solutions into our development processes, contributing to the company's technological advancement. Physical Requirements: Ability to remain at your designated workstation for the duration of the workday Constantly operates a computer and other office productivity machinery, such as a phone and Voice over Internet Protocol (VoIP). The ability to communicate information and ideas so others will understand. Must be able to exchange accurate information in these situations. The ability to observe details at close range (typically on a computer screen) This position offers the flexibility of remote work at approved locations within the United States. Candidates must have a reliable internet connection and a designated work environment conducive to professional phone calls and sensitive data. Enjoy the convenience and comfort of working remotely while contributing to our team's success. Apply Today If you’re ready to take on challenging problems, contribute to impactful solutions, and grow as a data engineer, we’d love to hear from you. Join us at The Helper Bees and be part of a team that’s making a meaningful difference every day! The Helper Bees is committed to building a workplace where diversity, equity, and inclusion are valued and prioritized. We are an equal opportunity employer that welcomes all qualified applicants without discrimination based on race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or any non-merit based or legally protected grounds. The Helper Bees provides reasonable accommodations to qualified individuals with disabilities during the job application and interview process. To request accommodation, please let your recruiter know. As part of our standard hiring process, selected candidates may be required to undergo a background check and/or drug screen. The Helper Bees adheres to applicable federal, state, and local laws regarding these screenings, and the results will be considered in accordance with applicable regulations. The Helper Bees was recently made aware of a fraudulent entity posing as our organization and requesting personal information. Please be aware of and protect yourself from scams. Visit thehelperbees.com/careers to view all current job openings.",
         698
        ],
        [
         null,
         "ABOUT HEALTHCARE INC",
         "SUMMARY: ABOUT Healthcare is seeking a skilled and innovative Data Scientist to help expand our predictive analytics capabilities and advance our mission to revolutionize hospital operations. This role will work at the intersection of AI/ML, healthcare, and operations to develop and scale machine learning models that deliver actionable insights to hospitals. ESSENTIAL FUNCTIONS : This class specification lists the major duties and requirements of the job and is not all-inclusive. Incumbent(s) may be expected to perform job-related duties other than those contained in this document and may be required to have specific job-related knowledge and skills. Predictive Analytics Development : Build and refine machine learning models for hourly discharge forecasting, aggregate hospital admission/discharge predictions, and patient-level progress tracking. Data Exploration : Analyze complex healthcare datasets to identify trends, challenges, and actionable opportunities. Model Deployment : Collaborate with engineers to deploy AI/ML solutions into production, ensuring reliability and scalability. Collaboration : Partner with product managers, operations teams, and customers to define and implement data-driven features and metrics. Feature Engineering : Work with AWS infrastructure (S3, Glue, Athena, Timestream, Bedrock, Nova, SageMaker) to standardize data pipelines and enrich machine learning models. Continuous Improvement : Optimize model accuracy and efficiency through testing, monitoring, and iteration. Documentation and Communication : Present technical findings and recommendations to stakeholders in an easily understandable way. LLMs: Demonstrate experience and depth in building products through applying LLMs or other AI domains like NLP, ML or deep learning. Full Stack: Capable as a full-stack engineer, seeing LLM implementations from concept to production. Perform other duties as assigned. QUALIFICATIONS: To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The requirements listed below are representative of the knowledge, skill, and/or ability required. Need to Have: Bachelor’s in data science, Computer Science, Statistics, or related field (or equivalent experience). 1+ years of experience developing and deploying machine learning models in production. Proficiency in Python (or R), SQL, and common ML libraries (e.g., Scikit-learn, TensorFlow, PyTorch). Experience working with cloud technologies, particularly AWS (e.g., S3, Glue, Timestream, Bedrock, Nova, sageMaker). Strong analytical skills and ability to interpret complex datasets. Knowledge of ETL processes, feature engineering, and real-time forecasting methods. Excellent communication skills with the ability to present technical concepts to non-technical stakeholders. Nice to Have: Experience in healthcare data analytics or hospital operations. Familiarity with EHR/EMR data or healthcare interoperability standards. Knowledge of time-series modeling and ensemble methods. Exposure to data visualization tools (e.g., Tableau, Power BI). Understanding of Agile methodologies and collaborative software development. Required Knowledge and Skills Required Knowledge: Correct business English, including spelling, grammar and punctuation. Medical Terminology Health system operating and working models Business planning and development Required Skills: Using initiative and independent judgment within established department guidelines. Contributing effectively to the accomplishment of team or work unit goals, objectives and activities. Establishing and maintaining effective working relationships with a variety of individuals. PHYSICAL/MENTAL REQUIREMENTS: The physical demands described herein are representative of those that must be met by an employee to successfully perform the essential functions of the job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions. Mobility to work in an office setting, use standard office equipment and stamina to sit for extended periods of time; strength to lift and carry up to 10 pounds; vision to read printed materials and computer screens; and hearing and speech to communicate in person or over the telephone. Travel as needed to support company and customer initiatives. Work on Site at our St Paul office may be required and ABOUT reserves the right to change the location of the role at any time. This role may involve work on federal government contracts that require additional federal background investigations, training, and federal badging. As such, you may be required to submit personal information to the government and be fingerprinted and photographed at your local Department of Veteran Affairs Medical Center. ABOUT is also an Equal Employment Opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, age, national origin, protected veteran status, disability status, sexual orientation, gender identity or expression, marital status, genetic information, or any other characteristic protected by law. ABOUT offers a flexible, purpose-built solution that empowers hospitals and health systems to operate as one connected network of care. We enable easy access for clinicians to move patients into and out of the acute care setting - getting them to the next, best care setting faster and easier. Complemented by our clinical experts and best practices, we provide health systems the necessary controls and insights to grow with resilience, drive clinician effectiveness, and improve patient outcomes. __________________________________________________________________________________________________________________________________ Opened URL: https://www.indeed.com/rc/clk?jk=b7ccd9fcd1afced7&bb=1TLRjqutBEYcit1OApAPtqrHYylbIkCH-hjMPAlsxl27fhhbmpR2ESoGFPzZ8_yAHfmXJJR-sxCiyJrJbrdNtoLq2VLDYGJB8eFEb_NompMj9I3HutPP1GvnnhForEvK&xkcb=SoAu67M33zDWevR-pR0CbzkdCdPP&fccid=4a4b722c7189c738&vjs=3",
         "data",
         "SUMMARY: ABOUT Healthcare is seeking a skilled and innovative Data Scientist to help expand our predictive analytics capabilities and advance our mission to revolutionize hospital operations. This role will work at the intersection of AI/ML, healthcare, and operations to develop and scale machine learning models that deliver actionable insights to hospitals. ESSENTIAL FUNCTIONS : This class specification lists the major duties and requirements of the job and is not all-inclusive. Incumbent(s) may be expected to perform job-related duties other than those contained in this document and may be required to have specific job-related knowledge and skills. Predictive Analytics Development : Build and refine machine learning models for hourly discharge forecasting, aggregate hospital admission/discharge predictions, and patient-level progress tracking. Data Exploration : Analyze complex healthcare datasets to identify trends, challenges, and actionable opportunities. Model Deployment : Collaborate with engineers to deploy AI/ML solutions into production, ensuring reliability and scalability. Collaboration : Partner with product managers, operations teams, and customers to define and implement data-driven features and metrics. Feature Engineering : Work with AWS infrastructure (S3, Glue, Athena, Timestream, Bedrock, Nova, SageMaker) to standardize data pipelines and enrich machine learning models. Continuous Improvement : Optimize model accuracy and efficiency through testing, monitoring, and iteration. Documentation and Communication : Present technical findings and recommendations to stakeholders in an easily understandable way. LLMs: Demonstrate experience and depth in building products through applying LLMs or other AI domains like NLP, ML or deep learning. Full Stack: Capable as a full-stack engineer, seeing LLM implementations from concept to production. Perform other duties as assigned. QUALIFICATIONS: To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The requirements listed below are representative of the knowledge, skill, and/or ability required. Need to Have: Bachelor’s in data science, Computer Science, Statistics, or related field (or equivalent experience). 1+ years of experience developing and deploying machine learning models in production. Proficiency in Python (or R), SQL, and common ML libraries (e.g., Scikit-learn, TensorFlow, PyTorch). Experience working with cloud technologies, particularly AWS (e.g., S3, Glue, Timestream, Bedrock, Nova, sageMaker). Strong analytical skills and ability to interpret complex datasets. Knowledge of ETL processes, feature engineering, and real-time forecasting methods. Excellent communication skills with the ability to present technical concepts to non-technical stakeholders. Nice to Have: Experience in healthcare data analytics or hospital operations. Familiarity with EHR/EMR data or healthcare interoperability standards. Knowledge of time-series modeling and ensemble methods. Exposure to data visualization tools (e.g., Tableau, Power BI). Understanding of Agile methodologies and collaborative software development. Required Knowledge and Skills Required Knowledge: Correct business English, including spelling, grammar and punctuation. Medical Terminology Health system operating and working models Business planning and development Required Skills: Using initiative and independent judgment within established department guidelines. Contributing effectively to the accomplishment of team or work unit goals, objectives and activities. Establishing and maintaining effective working relationships with a variety of individuals. PHYSICAL/MENTAL REQUIREMENTS: The physical demands described herein are representative of those that must be met by an employee to successfully perform the essential functions of the job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions. Mobility to work in an office setting, use standard office equipment and stamina to sit for extended periods of time; strength to lift and carry up to 10 pounds; vision to read printed materials and computer screens; and hearing and speech to communicate in person or over the telephone. Travel as needed to support company and customer initiatives. Work on Site at our St Paul office may be required and ABOUT reserves the right to change the location of the role at any time. This role may involve work on federal government contracts that require additional federal background investigations, training, and federal badging. As such, you may be required to submit personal information to the government and be fingerprinted and photographed at your local Department of Veteran Affairs Medical Center. ABOUT is also an Equal Employment Opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, age, national origin, protected veteran status, disability status, sexual orientation, gender identity or expression, marital status, genetic information, or any other characteristic protected by law. ABOUT offers a flexible, purpose-built solution that empowers hospitals and health systems to operate as one connected network of care. We enable easy access for clinicians to move patients into and out of the acute care setting - getting them to the next, best care setting faster and easier. Complemented by our clinical experts and best practices, we provide health systems the necessary controls and insights to grow with resilience, drive clinician effectiveness, and improve patient outcomes. __________________________________________________________________________________________________________________________________",
         "SUMMARY: ABOUT Healthcare is seeking a skilled and innovative Data Scientist to help expand our predictive analytics capabilities and advance our mission to revolutionize hospital operations. This role will work at the intersection of AI/ML, healthcare, and operations to develop and scale machine learning models that deliver actionable insights to hospitals. ESSENTIAL FUNCTIONS : This class specification lists the major duties and requirements of the job and is not all-inclusive. Incumbent(s) may be expected to perform job-related duties other than those contained in this document and may be required to have specific job-related knowledge and skills. Predictive Analytics Development : Build and refine machine learning models for hourly discharge forecasting, aggregate hospital admission/discharge predictions, and patient-level progress tracking. Data Exploration : Analyze complex healthcare datasets to identify trends, challenges, and actionable opportunities. Model Deployment : Collaborate with engineers to deploy AI/ML solutions into production, ensuring reliability and scalability. Collaboration : Partner with product managers, operations teams, and customers to define and implement data-driven features and metrics. Feature Engineering : Work with AWS infrastructure (S3, Glue, Athena, Timestream, Bedrock, Nova, SageMaker) to standardize data pipelines and enrich machine learning models. Continuous Improvement : Optimize model accuracy and efficiency through testing, monitoring, and iteration. Documentation and Communication : Present technical findings and recommendations to stakeholders in an easily understandable way. LLMs: Demonstrate experience and depth in building products through applying LLMs or other AI domains like NLP, ML or deep learning. Full Stack: Capable as a full-stack engineer, seeing LLM implementations from concept to production. Perform other duties as assigned. QUALIFICATIONS: To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The requirements listed below are representative of the knowledge, skill, and/or ability required. Need to Have: Bachelor’s in data science, Computer Science, Statistics, or related field (or equivalent experience). 1+ years of experience developing and deploying machine learning models in production. Proficiency in Python (or R), SQL, and common ML libraries (e.g., Scikit-learn, TensorFlow, PyTorch). Experience working with cloud technologies, particularly AWS (e.g., S3, Glue, Timestream, Bedrock, Nova, sageMaker). Strong analytical skills and ability to interpret complex datasets. Knowledge of ETL processes, feature engineering, and real-time forecasting methods. Excellent communication skills with the ability to present technical concepts to non-technical stakeholders. Nice to Have: Experience in healthcare data analytics or hospital operations. Familiarity with EHR/EMR data or healthcare interoperability standards. Knowledge of time-series modeling and ensemble methods. Exposure to data visualization tools (e.g., Tableau, Power BI). Understanding of Agile methodologies and collaborative software development. Required Knowledge and Skills Required Knowledge: Correct business English, including spelling, grammar and punctuation. Medical Terminology Health system operating and working models Business planning and development Required Skills: Using initiative and independent judgment within established department guidelines. Contributing effectively to the accomplishment of team or work unit goals, objectives and activities. Establishing and maintaining effective working relationships with a variety of individuals. PHYSICAL/MENTAL REQUIREMENTS: The physical demands described herein are representative of those that must be met by an employee to successfully perform the essential functions of the job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions. Mobility to work in an office setting, use standard office equipment and stamina to sit for extended periods of time; strength to lift and carry up to 10 pounds; vision to read printed materials and computer screens; and hearing and speech to communicate in person or over the telephone. Travel as needed to support company and customer initiatives. Work on Site at our St Paul office may be required and ABOUT reserves the right to change the location of the role at any time. This role may involve work on federal government contracts that require additional federal background investigations, training, and federal badging. As such, you may be required to submit personal information to the government and be fingerprinted and photographed at your local Department of Veteran Affairs Medical Center. ABOUT is also an Equal Employment Opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, age, national origin, protected veteran status, disability status, sexual orientation, gender identity or expression, marital status, genetic information, or any other characteristic protected by law. ABOUT offers a flexible, purpose-built solution that empowers hospitals and health systems to operate as one connected network of care. We enable easy access for clinicians to move patients into and out of the acute care setting - getting them to the next, best care setting faster and easier. Complemented by our clinical experts and best practices, we provide health systems the necessary controls and insights to grow with resilience, drive clinician effectiveness, and improve patient outcomes. __________________________________________________________________________________________________________________________________",
         "To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The requirements listed below are representative of the knowledge, skill, and/or ability required. Need to Have: Bachelor’s in data science, Computer Science, Statistics, or related field (or equivalent experience). 1+ years of experience developing and deploying machine learning models in production. Proficiency in Python (or R), SQL, and common ML libraries (e.g., Scikit-learn, TensorFlow, PyTorch). Experience working with cloud technologies, particularly AWS (e.g., S3, Glue, Timestream, Bedrock, Nova, sageMaker). Strong analytical skills and ability to interpret complex datasets. Knowledge of ETL processes, feature engineering, and real-time forecasting methods. Excellent communication skills with the ability to present technical concepts to non-technical stakeholders. Nice to Have: Experience in healthcare data analytics or hospital operations. Familiarity with EHR/EMR data or healthcare interoperability standards. Knowledge of time-series modeling and ensemble methods. Exposure to data visualization tools (e.g., Tableau, Power BI). Understanding of Agile methodologies and collaborative software development. Required Knowledge and Skills Required Knowledge: Correct business English, including spelling, grammar and punctuation. Medical Terminology Health system operating and working models Business planning and development Required Skills: Using initiative and independent judgment within established department guidelines. Contributing effectively to the accomplishment of team or work unit goals, objectives and activities. Establishing and maintaining effective working relationships with a variety of individuals. PHYSICAL/MENTAL REQUIREMENTS: The physical demands described herein are representative of those that must be met by an employee to successfully perform the essential functions of the job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions. Mobility to work in an office setting, use standard office equipment and stamina to sit for extended periods of time; strength to lift and carry up to 10 pounds; vision to read printed materials and computer screens; and hearing and speech to communicate in person or over the telephone. Travel as needed to support company and customer initiatives. Work on Site at our St Paul office may be required and ABOUT reserves the right to change the location of the role at any time. This role may involve work on federal government contracts that require additional federal background investigations, training, and federal badging. As such, you may be required to submit personal information to the government and be fingerprinted and photographed at your local Department of Veteran Affairs Medical Center. ABOUT is also an Equal Employment Opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, age, national origin, protected veteran status, disability status, sexual orientation, gender identity or expression, marital status, genetic information, or any other characteristic protected by law. ABOUT offers a flexible, purpose-built solution that empowers hospitals and health systems to operate as one connected network of care. We enable easy access for clinicians to move patients into and out of the acute care setting - getting them to the next, best care setting faster and easier. Complemented by our clinical experts and best practices, we provide health systems the necessary controls and insights to grow with resilience, drive clinician effectiveness, and improve patient outcomes. __________________________________________________________________________________________________________________________________",
         521
        ],
        [
         null,
         "The Krusteaz Company",
         "The Krusteaz Company is seeking a Senior Data Engineer to lead the architecture and development of our enterprise data strategy. Reporting to the Director of Enterprise Applications and Data Management, this role will play a key role in design, delivery, and management of our enterprise data strategy and solution(s). As a key contributor to our digital transformation, this role will take the lead in designing data structure, design, and ingestion, reporting processes and standards for the organization working across both the IT development, infrastructure, and analyst teams. As a senior member of the IT team, this role will be instrumental in promoting agility, scalability, and operational excellence. This role will also be a key contributor in our business transformation, working closely with our IT Business Analysts to understand the challenges facing our business partners and developing scalable and repeatable data solutions to meet their needs. This role will be a trusted partner to your peers within the IT team, demonstrating the ability to provide both conceptual and technical mentorship. Essential Functions : Other duties, responsibilities, and activities may change or be assigned at any time. Maintain and build on our data warehouse and analytics environment. Design, implement, test, deploy, and maintain stable, secure, and scalable data engineering solutions and pipelines. Build reports and data visualizations, using data from the data warehouse and other sources. Produce scalable, replicable code and engineering solutions that help automate repetitive data management tasks. Implement and monitor best in class security measures in our data warehouse and analytics environment. Provide direct input on the IT technology roadmap, helping ensure we make appropriate investments in build vs. buy decisions. Define and document best practices and strategies. Keep apprised of trends, identifies best-in class capabilities, opportunities and technology that may benefit The Krusteaz Company. Provide guidance, thought leadership, and mentorship to development and infrastructure teams to build EDW and development competencies. Position Requirements To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The requirements listed below are representative of the knowledge, skill, and/or ability required. Reasonable accommodations may be made to enable individuals qualified with disabilities to perform the essential functions. Proven success in developing technical solutions with a ‘cloud first’ mindset. Deep understanding of cloud data warehousing and ETL best practices, including system reliability and scalability. Ensuring data quality and consistency across various sources. Ability to function effectively as a change agent and problem solver within your team and across IT and the business. Excellent written, verbal, communication, and presentation skills with the ability to think critically, problem solve, and articulate new ideas and concepts to technical and non-technical audiences. Education and/or Experience: Bachelor’s degree in computer science, information technology, mathematics, or progressive relevant work experience. 8+ years of development experience required. 5+ years’ experience working with public cloud providers (Azure, Oracle Cloud, etc.). 5+ years’ experience in data pipeline development, including languages such as Python and R, and tools such as Airflow and SSIS. 5+ years Data Warehousing and ETL experience, preferably with large transactional datasets. Familiarity working in both Windows and Linux environments. Direct experience working with both traditional and agile methodologies required. Experience within the manufacturing industry, including knowledge in supply chain, procurement, and logistics is preferred but not required. Physical Demands and Work Environment: While performing the duties of this job, the employee is regularly required to stand, sit, talk, hear, and use hands and fingers to operate a computer and telephone along with reaching. Specific vision abilities include close vision requirements due to computer work. Moderate noise, ability to work in a confined area, and ability to sit at a computer for an extended period of time are also included. The policy of The Krusteaz Company is to hire, train, and promote all persons in all job groups in accordance with law, without regard to race, color, religion, sex, sexual orientation, age, marital or military status, national origin, gender identity, the presence of any sensory, mental or physical disability, genetic information, or any other status or characteristic protected by local, state, or federal law. Get to know us: A people-focused company that cares: We're a 90-year-old company with the entrepreneurial spirit of a startup and a focused eye on the future. As a midsized, privately held company with a portfolio of beloved food and beverage brands, our people are the most important ingredient in our success. A valued and supported workforce : We place tremendous value in our employees and provide competitive pay and comprehensive benefits to ensure our employees can create the best life for themselves. Benefits include a top tier health insurance plan with lower-than-average employee cost share, generous PTO, 401(k) match, and more. An engaged and energized culture: At The Krusteaz Company, collaboration and ingenuity drive our fierce commitment to creating extraordinary product experiences that people love. A place to grow and make a difference: An entrepreneurial spirit has been at the core of our company since the beginning, attracting self-starters who are curious and love to learn and to share ideas. Hybrid Work Model: At The Krusteaz Company, we have in-office \"core days\" of Tuesdays and Wednesdays where all corporate employees are expected to be onsite. Mondays, Thursdays, and Fridays are flexible remote days to allow for work/life balance. You may be asked to come in outside of a core day from time to time, based on business needs. We have found aligning our scheduled in-office days provides opportunity for employees to build connections and collaborate together. Benefits: We are proud to offer generous benefits including comprehensive medical, dental, and vision insurance (starting at $50/month for employee only coverage on the PPO Plan or starting at $25/month for employee only coverage on the HDHP), 401(K) matching, 3 weeks of paid vacation, 10 paid holidays, company provided life insurance and disability insurance, flexible spending account, healthcare saving account, voluntary accident insurance, voluntary critical illness insurance, and tuition reimbursement. Salary Information: An employee in this position can expect a salary range between $126,101 and $208,055. We typically pay out between $142,000 and $180,000. The actual salary offered will carefully consider a wide range of factors, including internal equity, experience, education, certification, training, and location. All positions are eligible for additional incentives based on business performance. We hope you'll take the time to get to know us! The Krusteaz Company is not sponsoring new applicant employment authorization at this time and please, no third-party recruiters. Opened URL: https://www.indeed.com/rc/clk?jk=042c410f50c0faa6&bb=1TLRjqutBEYcit1OApAPtt6B4oNDQ9pvplvzh521n9octR12bdC8X0WPxpzUuEahEqtE5IkoxGLcfct2Fl3E3ERVE0CDNI3ufYlz_WxpqD2cHp3NqHNahE2fQxTMaZ59&xkcb=SoAH67M33zDWevR-pR0AbzkdCdPP&fccid=9e189ac6632e8eb3&vjs=3",
         "data",
         "The Krusteaz Company is seeking a Senior Data Engineer to lead the architecture and development of our enterprise data strategy. Reporting to the Director of Enterprise Applications and Data Management, this role will play a key role in design, delivery, and management of our enterprise data strategy and solution(s). As a key contributor to our digital transformation, this role will take the lead in designing data structure, design, and ingestion, reporting processes and standards for the organization working across both the IT development, infrastructure, and analyst teams. As a senior member of the IT team, this role will be instrumental in promoting agility, scalability, and operational excellence. This role will also be a key contributor in our business transformation, working closely with our IT Business Analysts to understand the challenges facing our business partners and developing scalable and repeatable data solutions to meet their needs. This role will be a trusted partner to your peers within the IT team, demonstrating the ability to provide both conceptual and technical mentorship. Essential Functions : Other duties, responsibilities, and activities may change or be assigned at any time. Maintain and build on our data warehouse and analytics environment. Design, implement, test, deploy, and maintain stable, secure, and scalable data engineering solutions and pipelines. Build reports and data visualizations, using data from the data warehouse and other sources. Produce scalable, replicable code and engineering solutions that help automate repetitive data management tasks. Implement and monitor best in class security measures in our data warehouse and analytics environment. Provide direct input on the IT technology roadmap, helping ensure we make appropriate investments in build vs. buy decisions. Define and document best practices and strategies. Keep apprised of trends, identifies best-in class capabilities, opportunities and technology that may benefit The Krusteaz Company. Provide guidance, thought leadership, and mentorship to development and infrastructure teams to build EDW and development competencies. Position Requirements To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The requirements listed below are representative of the knowledge, skill, and/or ability required. Reasonable accommodations may be made to enable individuals qualified with disabilities to perform the essential functions. Proven success in developing technical solutions with a ‘cloud first’ mindset. Deep understanding of cloud data warehousing and ETL best practices, including system reliability and scalability. Ensuring data quality and consistency across various sources. Ability to function effectively as a change agent and problem solver within your team and across IT and the business. Excellent written, verbal, communication, and presentation skills with the ability to think critically, problem solve, and articulate new ideas and concepts to technical and non-technical audiences. Education and/or Experience: Bachelor’s degree in computer science, information technology, mathematics, or progressive relevant work experience. 8+ years of development experience required. 5+ years’ experience working with public cloud providers (Azure, Oracle Cloud, etc.). 5+ years’ experience in data pipeline development, including languages such as Python and R, and tools such as Airflow and SSIS. 5+ years Data Warehousing and ETL experience, preferably with large transactional datasets. Familiarity working in both Windows and Linux environments. Direct experience working with both traditional and agile methodologies required. Experience within the manufacturing industry, including knowledge in supply chain, procurement, and logistics is preferred but not required. Physical Demands and Work Environment: While performing the duties of this job, the employee is regularly required to stand, sit, talk, hear, and use hands and fingers to operate a computer and telephone along with reaching. Specific vision abilities include close vision requirements due to computer work. Moderate noise, ability to work in a confined area, and ability to sit at a computer for an extended period of time are also included. The policy of The Krusteaz Company is to hire, train, and promote all persons in all job groups in accordance with law, without regard to race, color, religion, sex, sexual orientation, age, marital or military status, national origin, gender identity, the presence of any sensory, mental or physical disability, genetic information, or any other status or characteristic protected by local, state, or federal law. Get to know us: A people-focused company that cares: We're a 90-year-old company with the entrepreneurial spirit of a startup and a focused eye on the future. As a midsized, privately held company with a portfolio of beloved food and beverage brands, our people are the most important ingredient in our success. A valued and supported workforce : We place tremendous value in our employees and provide competitive pay and comprehensive benefits to ensure our employees can create the best life for themselves. Benefits include a top tier health insurance plan with lower-than-average employee cost share, generous PTO, 401(k) match, and more. An engaged and energized culture: At The Krusteaz Company, collaboration and ingenuity drive our fierce commitment to creating extraordinary product experiences that people love. A place to grow and make a difference: An entrepreneurial spirit has been at the core of our company since the beginning, attracting self-starters who are curious and love to learn and to share ideas. Hybrid Work Model: At The Krusteaz Company, we have in-office \"core days\" of Tuesdays and Wednesdays where all corporate employees are expected to be onsite. Mondays, Thursdays, and Fridays are flexible remote days to allow for work/life balance. You may be asked to come in outside of a core day from time to time, based on business needs. We have found aligning our scheduled in-office days provides opportunity for employees to build connections and collaborate together. Benefits: We are proud to offer generous benefits including comprehensive medical, dental, and vision insurance (starting at $50/month for employee only coverage on the PPO Plan or starting at $25/month for employee only coverage on the HDHP), 401(K) matching, 3 weeks of paid vacation, 10 paid holidays, company provided life insurance and disability insurance, flexible spending account, healthcare saving account, voluntary accident insurance, voluntary critical illness insurance, and tuition reimbursement. Salary Information: An employee in this position can expect a salary range between $126,101 and $208,055. We typically pay out between $142,000 and $180,000. The actual salary offered will carefully consider a wide range of factors, including internal equity, experience, education, certification, training, and location. All positions are eligible for additional incentives based on business performance. We hope you'll take the time to get to know us! The Krusteaz Company is not sponsoring new applicant employment authorization at this time and please, no third-party recruiters.",
         "The Krusteaz Company is seeking a Senior Data Engineer to lead the architecture and development of our enterprise data strategy. Reporting to the Director of Enterprise Applications and Data Management, this role will play a key role in design, delivery, and management of our enterprise data strategy and solution(s). As a key contributor to our digital transformation, this role will take the lead in designing data structure, design, and ingestion, reporting processes and standards for the organization working across both the IT development, infrastructure, and analyst teams. As a senior member of the IT team, this role will be instrumental in promoting agility, scalability, and operational excellence. This role will also be a key contributor in our business transformation, working closely with our IT Business Analysts to understand the challenges facing our business partners and developing scalable and repeatable data solutions to meet their needs. This role will be a trusted partner to your peers within the IT team, demonstrating the ability to provide both conceptual and technical mentorship. Essential Functions : Other duties, responsibilities, and activities may change or be assigned at any time. Maintain and build on our data warehouse and analytics environment. Design, implement, test, deploy, and maintain stable, secure, and scalable data engineering solutions and pipelines. Build reports and data visualizations, using data from the data warehouse and other sources. Produce scalable, replicable code and engineering solutions that help automate repetitive data management tasks. Implement and monitor best in class security measures in our data warehouse and analytics environment. Provide direct input on the IT technology roadmap, helping ensure we make appropriate investments in build vs. buy decisions. Define and document best practices and strategies. Keep apprised of trends, identifies best-in class capabilities, opportunities and technology that may benefit The Krusteaz Company. Provide guidance, thought leadership, and mentorship to development and infrastructure teams to build EDW and development competencies. Position Requirements To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The requirements listed below are representative of the knowledge, skill, and/or ability required. Reasonable accommodations may be made to enable individuals qualified with disabilities to perform the essential functions. Proven success in developing technical solutions with a ‘cloud first’ mindset. Deep understanding of cloud data warehousing and ETL best practices, including system reliability and scalability. Ensuring data quality and consistency across various sources. Ability to function effectively as a change agent and problem solver within your team and across IT and the business. Excellent written, verbal, communication, and presentation skills with the ability to think critically, problem solve, and articulate new ideas and concepts to technical and non-technical audiences. Education and/or Experience: Bachelor’s degree in computer science, information technology, mathematics, or progressive relevant work experience. 8+ years of development experience required. 5+ years’ experience working with public cloud providers (Azure, Oracle Cloud, etc.). 5+ years’ experience in data pipeline development, including languages such as Python and R, and tools such as Airflow and SSIS. 5+ years Data Warehousing and ETL experience, preferably with large transactional datasets. Familiarity working in both Windows and Linux environments. Direct experience working with both traditional and agile methodologies required. Experience within the manufacturing industry, including knowledge in supply chain, procurement, and logistics is preferred but not required. Physical Demands and Work Environment: While performing the duties of this job, the employee is regularly required to stand, sit, talk, hear, and use hands and fingers to operate a computer and telephone along with reaching. Specific vision abilities include close vision requirements due to computer work. Moderate noise, ability to work in a confined area, and ability to sit at a computer for an extended period of time are also included. The policy of The Krusteaz Company is to hire, train, and promote all persons in all job groups in accordance with law, without regard to race, color, religion, sex, sexual orientation, age, marital or military status, national origin, gender identity, the presence of any sensory, mental or physical disability, genetic information, or any other status or characteristic protected by local, state, or federal law. Get to know us: A people-focused company that cares: We're a 90-year-old company with the entrepreneurial spirit of a startup and a focused eye on the future. As a midsized, privately held company with a portfolio of beloved food and beverage brands, our people are the most important ingredient in our success. A valued and supported workforce : We place tremendous value in our employees and provide competitive pay and comprehensive benefits to ensure our employees can create the best life for themselves. Benefits include a top tier health insurance plan with lower-than-average employee cost share, generous PTO, 401(k) match, and more. An engaged and energized culture: At The Krusteaz Company, collaboration and ingenuity drive our fierce commitment to creating extraordinary product experiences that people love. A place to grow and make a difference: An entrepreneurial spirit has been at the core of our company since the beginning, attracting self-starters who are curious and love to learn and to share ideas. Hybrid Work Model: At The Krusteaz Company, we have in-office \"core days\" of Tuesdays and Wednesdays where all corporate employees are expected to be onsite. Mondays, Thursdays, and Fridays are flexible remote days to allow for work/life balance. You may be asked to come in outside of a core day from time to time, based on business needs. We have found aligning our scheduled in-office days provides opportunity for employees to build connections and collaborate together. Benefits: We are proud to offer generous benefits including comprehensive medical, dental, and vision insurance (starting at $50/month for employee only coverage on the PPO Plan or starting at $25/month for employee only coverage on the HDHP), 401(K) matching, 3 weeks of paid vacation, 10 paid holidays, company provided life insurance and disability insurance, flexible spending account, healthcare saving account, voluntary accident insurance, voluntary critical illness insurance, and tuition reimbursement. Salary Information: An employee in this position can expect a salary range between $126,101 and $208,055. We typically pay out between $142,000 and $180,000. The actual salary offered will carefully consider a wide range of factors, including internal equity, experience, education, certification, training, and location. All positions are eligible for additional incentives based on business performance. We hope you'll take the time to get to know us! The Krusteaz Company is not sponsoring new applicant employment authorization at this time and please, no third-party recruiters.",
         "To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The requirements listed below are representative of the knowledge, skill, and/or ability required. Reasonable accommodations may be made to enable individuals qualified with disabilities to perform the essential functions. Proven success in developing technical solutions with a ‘cloud first’ mindset. Deep understanding of cloud data warehousing and ETL best practices, including system reliability and scalability. Ensuring data quality and consistency across various sources. Ability to function effectively as a change agent and problem solver within your team and across IT and the business. Excellent written, verbal, communication, and presentation skills with the ability to think critically, problem solve, and articulate new ideas and concepts to technical and non-technical audiences. Education and/or Experience: Bachelor’s degree in computer science, information technology, mathematics, or progressive relevant work experience. 8+ years of development experience required. 5+ years’ experience working with public cloud providers (Azure, Oracle Cloud, etc.). 5+ years’ experience in data pipeline development, including languages such as Python and R, and tools such as Airflow and SSIS. 5+ years Data Warehousing and ETL experience, preferably with large transactional datasets. Familiarity working in both Windows and Linux environments. Direct experience working with both traditional and agile methodologies required. Experience within the manufacturing industry, including knowledge in supply chain, procurement, and logistics is preferred but not required. Physical Demands and Work Environment: While performing the duties of this job, the employee is regularly required to stand, sit, talk, hear, and use hands and fingers to operate a computer and telephone along with reaching. Specific vision abilities include close vision requirements due to computer work. Moderate noise, ability to work in a confined area, and ability to sit at a computer for an extended period of time are also included. The policy of The Krusteaz Company is to hire, train, and promote all persons in all job groups in accordance with law, without regard to race, color, religion, sex, sexual orientation, age, marital or military status, national origin, gender identity, the presence of any sensory, mental or physical disability, genetic information, or any other status or characteristic protected by local, state, or federal law. Get to know us: A people-focused company that cares: We're a 90-year-old company with the entrepreneurial spirit of a startup and a focused eye on the future. As a midsized, privately held company with a portfolio of beloved food and beverage brands, our people are the most important ingredient in our success. A valued and supported workforce : We place tremendous value in our employees and provide competitive pay and comprehensive benefits to ensure our employees can create the best life for themselves. Benefits include a top tier health insurance plan with lower-than-average employee cost share, generous PTO, 401(k) match, and more. An engaged and energized culture: At The Krusteaz Company, collaboration and ingenuity drive our fierce commitment to creating extraordinary product experiences that people love. A place to grow and make a difference: An entrepreneurial spirit has been at the core of our company since the beginning, attracting self-starters who are curious and love to learn and to share ideas. Hybrid Work Model: At The Krusteaz Company, we have in-office \"core days\" of Tuesdays and Wednesdays where all corporate employees are expected to be onsite. Mondays, Thursdays, and Fridays are flexible remote days to allow for work/life balance. You may be asked to come in outside of a core day from time to time, based on business needs. We have found aligning our scheduled in-office days provides opportunity for employees to build connections and collaborate together. Benefits: We are proud to offer generous benefits including comprehensive medical, dental, and vision insurance (starting at $50/month for employee only coverage on the PPO Plan or starting at $25/month for employee only coverage on the HDHP), 401(K) matching, 3 weeks of paid vacation, 10 paid holidays, company provided life insurance and disability insurance, flexible spending account, healthcare saving account, voluntary accident insurance, voluntary critical illness insurance, and tuition reimbursement. Salary Information: An employee in this position can expect a salary range between $126,101 and $208,055. We typically pay out between $142,000 and $180,000. The actual salary offered will carefully consider a wide range of factors, including internal equity, experience, education, certification, training, and location. All positions are eligible for additional incentives based on business performance. We hope you'll take the time to get to know us! The Krusteaz Company is not sponsoring new applicant employment authorization at this time and please, no third-party recruiters.",
         756
        ],
        [
         null,
         "#NAME?",
         "Description: Join our winning team, recently honored as #67 on Forbes’ list of America’s Best Startup Employers for 2024! About The Helper Bees The Helper Bees’ mission is to help people stay home longer through data-driven services that transform both the payer and the care-recipient experience. At The Helper Bees, we are reshaping how care is delivered to aging individuals by leveraging innovative technology and insightful data solutions. We maintain multiple SaaS products and payment solutions through our web applications (internal and external facing), a mobile app, and reporting integrations. As part of our growing Data Engineering team, you’ll iterate quickly, have a high impact, and be challenged to design and implement cutting-edge solutions. At THB, we define our company culture through our Core Values: Quickly iterate through solutions: We move at a fast pace which requires quick iterations to find a path to a repeatable solution. Seek ways to create immediate impact: Be thoughtful and proactive in how you make an impact on your team. Actively look for ways to make a fast, positive impact. Bee the teammate you want to work with: We work as a team, help each other, and encourage each other. Ask questions, answer questions: You can't iterate through solutions if you don't ask the right questions, which is why there is an expectation that questions should be asked. When you know the answer, being a good teammate means chiming in to get others up to speed. Take the time to celebrate wins: It's so easy for a team that is heads down to forget about all the great things they've accomplished. That's why we make it a priority to remind ourselves to create space to celebrate wins, big or small. Job Summary We are seeking a motivated Data Engineer to join our team and help improve our tools, processes, and technical infrastructure. In this role, you will ensure the availability and quality of our data while contributing to the design, implementation, and maintenance of The Helper Bees’ products. You’ll collaborate across teams to create scalable and optimized software systems and play a key role in refining our development processes. This position offers a unique opportunity to learn and leverage cutting-edge AI development tools to enhance coding efficiency and develop advanced data tools and solutions. Supervisory Responsibilities: None Key Responsibilities Data Infrastructure: Design, implement, and maintain data pipelines, ensuring data availability, quality, and scalability. Product Development: Build and enhance products using Python, SQL, and modern technologies. AI Integration: Leverage cutting-edge AI tools, including Cursor, ChatGPT, and Claude to improve development processes, automate workflows, and create innovative data solutions. Collaboration: Communicate across departments to design, build, test, and implement new features and enhancements. Code Excellence: Produce quality, testable, and maintainable code while participating in code reviews. Problem Solving: Debug complex issues, interact with stakeholders, and design viable solutions with clear trade-offs. Process Optimization: Contribute to improving development processes, including deployment, on-call systems, and sprint planning. Team Growth: Collaborate within the development team to help each other grow and continuously learn. Stakeholder Engagement: Partner with analysts, scientists, and IT to ensure alignment and deliver data-driven solutions. Other duties as assigned/necessary Performance Metrics Code Quality: Maintain high coding standards through regular code reviews and adherence to best practices. Development Efficiency: Deliver high-quality features and fixes within efficient timeframes. Bug Resolution Time: Reduce the time taken to identify and resolve issues. System Scalability: Optimize system performance to handle increasing user demands. Collaboration: Foster a collaborative environment that encourages teamwork and knowledge sharing. Customer Satisfaction: Incorporate stakeholder feedback to improve solutions and enhance the customer experience. Continuous Learning: Pursue opportunities for skill development and share knowledge with the team. Requirements: Required Skills & Qualifications Technical Tools: Experience with in Python and/or SQL. Experience with Bash, Shell scripting, Big Query, Airflow, and is a plus. Programming: Cleaning data using code-based approach. AI Proficiency: Interest or experience in using AI tools for coding and development of data solutions. Soft Skills: Problem-solving, cross-team collaboration, data storytelling, and stakeholder engagement. Adaptability: Thrives in a fast-paced startup environment and embraces change. Proactivity: Self-directed, organized, and able to prioritize effectively. Collaboration: Ability to work effectively with cross-functional teams. Education & Experience: A bachelor’s degree is required, and a graduate degree is preferred. Relevant experience in data engineering, software development, STEM, or related fields. Strong experience with SQL and Python is highly desirable. Mindset: A passion for innovation, continuous improvement, and delivering high-quality results from messy data. Preferred Qualifications Familiarity with cloud-based solutions (e.g., Google Cloud Platform, Azure). Experience with ETL processes and tools. Experience building data visualization reports and dashboards Knowledge of modern data storage solutions and database management systems. Exposure to DevOps practices and tools for deployment and monitoring. Why Join Us? Work with a talented, collaborative team dedicated to making a difference. Gain exposure to innovative technologies and opportunities for growth. Learn and utilize cutting-edge AI tools to enhance your development skills and create impactful solutions. Be part of a company that values your contributions and encourages professional development. Join a rapidly expanding health-tech startup (~200 employees and growing) with a state-of-the-art technology office located in Hyde Park, offering a variety of exceptional benefits. Career Progression Timeline In 3 months: Gain a comprehensive understanding of our data infrastructure, technical stacks, and development cycles. Actively participate in team meetings and contribute to the development of new data pipelines. Begin leveraging AI tools, such as Cursor and ChatGPT, to enhance coding efficiency and workflow automation. In 6 months: Contribute to product enhancements and data reporting Collaborate effectively with cross-functional teams, providing insights and solutions for data-related challenges. Demonstrate proficiency in utilizing AI tools for coding and development, actively sharing knowledge with the team. In 12 months: Contribute to data engineering projects, ensuring scalability and performance optimization. Mentor non-technical internal partners to improve company-wide data literacy Contribute to the integration of advanced AI solutions into our development processes, contributing to the company's technological advancement. Physical Requirements: Ability to remain at your designated workstation for the duration of the workday Constantly operates a computer and other office productivity machinery, such as a phone and Voice over Internet Protocol (VoIP). The ability to communicate information and ideas so others will understand. Must be able to exchange accurate information in these situations. The ability to observe details at close range (typically on a computer screen) This position offers the flexibility of remote work at approved locations within the United States. Candidates must have a reliable internet connection and a designated work environment conducive to professional phone calls and sensitive data. Enjoy the convenience and comfort of working remotely while contributing to our team's success. Apply Today If you’re ready to take on challenging problems, contribute to impactful solutions, and grow as a data engineer, we’d love to hear from you. Join us at The Helper Bees and be part of a team that’s making a meaningful difference every day! The Helper Bees is committed to building a workplace where diversity, equity, and inclusion are valued and prioritized. We are an equal opportunity employer that welcomes all qualified applicants without discrimination based on race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or any non-merit based or legally protected grounds. The Helper Bees provides reasonable accommodations to qualified individuals with disabilities during the job application and interview process. To request accommodation, please let your recruiter know. As part of our standard hiring process, selected candidates may be required to undergo a background check and/or drug screen. The Helper Bees adheres to applicable federal, state, and local laws regarding these screenings, and the results will be considered in accordance with applicable regulations. The Helper Bees was recently made aware of a fraudulent entity posing as our organization and requesting personal information. Please be aware of and protect yourself from scams. Visit thehelperbees.com/careers to view all current job openings.",
         "data",
         "Description: Join our winning team, recently honored as #67 on Forbes’ list of America’s Best Startup Employers for 2024! About The Helper Bees The Helper Bees’ mission is to help people stay home longer through data-driven services that transform both the payer and the care-recipient experience. At The Helper Bees, we are reshaping how care is delivered to aging individuals by leveraging innovative technology and insightful data solutions. We maintain multiple SaaS products and payment solutions through our web applications (internal and external facing), a mobile app, and reporting integrations. As part of our growing Data Engineering team, you’ll iterate quickly, have a high impact, and be challenged to design and implement cutting-edge solutions. At THB, we define our company culture through our Core Values: Quickly iterate through solutions: We move at a fast pace which requires quick iterations to find a path to a repeatable solution. Seek ways to create immediate impact: Be thoughtful and proactive in how you make an impact on your team. Actively look for ways to make a fast, positive impact. Bee the teammate you want to work with: We work as a team, help each other, and encourage each other. Ask questions, answer questions: You can't iterate through solutions if you don't ask the right questions, which is why there is an expectation that questions should be asked. When you know the answer, being a good teammate means chiming in to get others up to speed. Take the time to celebrate wins: It's so easy for a team that is heads down to forget about all the great things they've accomplished. That's why we make it a priority to remind ourselves to create space to celebrate wins, big or small. Job Summary We are seeking a motivated Data Engineer to join our team and help improve our tools, processes, and technical infrastructure. In this role, you will ensure the availability and quality of our data while contributing to the design, implementation, and maintenance of The Helper Bees’ products. You’ll collaborate across teams to create scalable and optimized software systems and play a key role in refining our development processes. This position offers a unique opportunity to learn and leverage cutting-edge AI development tools to enhance coding efficiency and develop advanced data tools and solutions. Supervisory Responsibilities: None Key Responsibilities Data Infrastructure: Design, implement, and maintain data pipelines, ensuring data availability, quality, and scalability. Product Development: Build and enhance products using Python, SQL, and modern technologies. AI Integration: Leverage cutting-edge AI tools, including Cursor, ChatGPT, and Claude to improve development processes, automate workflows, and create innovative data solutions. Collaboration: Communicate across departments to design, build, test, and implement new features and enhancements. Code Excellence: Produce quality, testable, and maintainable code while participating in code reviews. Problem Solving: Debug complex issues, interact with stakeholders, and design viable solutions with clear trade-offs. Process Optimization: Contribute to improving development processes, including deployment, on-call systems, and sprint planning. Team Growth: Collaborate within the development team to help each other grow and continuously learn. Stakeholder Engagement: Partner with analysts, scientists, and IT to ensure alignment and deliver data-driven solutions. Other duties as assigned/necessary Performance Metrics Code Quality: Maintain high coding standards through regular code reviews and adherence to best practices. Development Efficiency: Deliver high-quality features and fixes within efficient timeframes. Bug Resolution Time: Reduce the time taken to identify and resolve issues. System Scalability: Optimize system performance to handle increasing user demands. Collaboration: Foster a collaborative environment that encourages teamwork and knowledge sharing. Customer Satisfaction: Incorporate stakeholder feedback to improve solutions and enhance the customer experience. Continuous Learning: Pursue opportunities for skill development and share knowledge with the team. Requirements: Required Skills & Qualifications Technical Tools: Experience with in Python and/or SQL. Experience with Bash, Shell scripting, Big Query, Airflow, and is a plus. Programming: Cleaning data using code-based approach. AI Proficiency: Interest or experience in using AI tools for coding and development of data solutions. Soft Skills: Problem-solving, cross-team collaboration, data storytelling, and stakeholder engagement. Adaptability: Thrives in a fast-paced startup environment and embraces change. Proactivity: Self-directed, organized, and able to prioritize effectively. Collaboration: Ability to work effectively with cross-functional teams. Education & Experience: A bachelor’s degree is required, and a graduate degree is preferred. Relevant experience in data engineering, software development, STEM, or related fields. Strong experience with SQL and Python is highly desirable. Mindset: A passion for innovation, continuous improvement, and delivering high-quality results from messy data. Preferred Qualifications Familiarity with cloud-based solutions (e.g., Google Cloud Platform, Azure). Experience with ETL processes and tools. Experience building data visualization reports and dashboards Knowledge of modern data storage solutions and database management systems. Exposure to DevOps practices and tools for deployment and monitoring. Why Join Us? Work with a talented, collaborative team dedicated to making a difference. Gain exposure to innovative technologies and opportunities for growth. Learn and utilize cutting-edge AI tools to enhance your development skills and create impactful solutions. Be part of a company that values your contributions and encourages professional development. Join a rapidly expanding health-tech startup (~200 employees and growing) with a state-of-the-art technology office located in Hyde Park, offering a variety of exceptional benefits. Career Progression Timeline In 3 months: Gain a comprehensive understanding of our data infrastructure, technical stacks, and development cycles. Actively participate in team meetings and contribute to the development of new data pipelines. Begin leveraging AI tools, such as Cursor and ChatGPT, to enhance coding efficiency and workflow automation. In 6 months: Contribute to product enhancements and data reporting Collaborate effectively with cross-functional teams, providing insights and solutions for data-related challenges. Demonstrate proficiency in utilizing AI tools for coding and development, actively sharing knowledge with the team. In 12 months: Contribute to data engineering projects, ensuring scalability and performance optimization. Mentor non-technical internal partners to improve company-wide data literacy Contribute to the integration of advanced AI solutions into our development processes, contributing to the company's technological advancement. Physical Requirements: Ability to remain at your designated workstation for the duration of the workday Constantly operates a computer and other office productivity machinery, such as a phone and Voice over Internet Protocol (VoIP). The ability to communicate information and ideas so others will understand. Must be able to exchange accurate information in these situations. The ability to observe details at close range (typically on a computer screen) This position offers the flexibility of remote work at approved locations within the United States. Candidates must have a reliable internet connection and a designated work environment conducive to professional phone calls and sensitive data. Enjoy the convenience and comfort of working remotely while contributing to our team's success. Apply Today If you’re ready to take on challenging problems, contribute to impactful solutions, and grow as a data engineer, we’d love to hear from you. Join us at The Helper Bees and be part of a team that’s making a meaningful difference every day! The Helper Bees is committed to building a workplace where diversity, equity, and inclusion are valued and prioritized. We are an equal opportunity employer that welcomes all qualified applicants without discrimination based on race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or any non-merit based or legally protected grounds. The Helper Bees provides reasonable accommodations to qualified individuals with disabilities during the job application and interview process. To request accommodation, please let your recruiter know. As part of our standard hiring process, selected candidates may be required to undergo a background check and/or drug screen. The Helper Bees adheres to applicable federal, state, and local laws regarding these screenings, and the results will be considered in accordance with applicable regulations. The Helper Bees was recently made aware of a fraudulent entity posing as our organization and requesting personal information. Please be aware of and protect yourself from scams. Visit thehelperbees.com/careers to view all current job openings.",
         "Description: Join our winning team, recently honored as #67 on Forbes’ list of America’s Best Startup Employers for 2024! About The Helper Bees The Helper Bees’ mission is to help people stay home longer through data-driven services that transform both the payer and the care-recipient experience. At The Helper Bees, we are reshaping how care is delivered to aging individuals by leveraging innovative technology and insightful data solutions. We maintain multiple SaaS products and payment solutions through our web applications (internal and external facing), a mobile app, and reporting integrations. As part of our growing Data Engineering team, you’ll iterate quickly, have a high impact, and be challenged to design and implement cutting-edge solutions. At THB, we define our company culture through our Core Values: Quickly iterate through solutions: We move at a fast pace which requires quick iterations to find a path to a repeatable solution. Seek ways to create immediate impact: Be thoughtful and proactive in how you make an impact on your team. Actively look for ways to make a fast, positive impact. Bee the teammate you want to work with: We work as a team, help each other, and encourage each other. Ask questions, answer questions: You can't iterate through solutions if you don't ask the right questions, which is why there is an expectation that questions should be asked. When you know the answer, being a good teammate means chiming in to get others up to speed. Take the time to celebrate wins: It's so easy for a team that is heads down to forget about all the great things they've accomplished. That's why we make it a priority to remind ourselves to create space to celebrate wins, big or small. Job Summary We are seeking a motivated Data Engineer to join our team and help improve our tools, processes, and technical infrastructure. In this role, you will ensure the availability and quality of our data while contributing to the design, implementation, and maintenance of The Helper Bees’ products. You’ll collaborate across teams to create scalable and optimized software systems and play a key role in refining our development processes. This position offers a unique opportunity to learn and leverage cutting-edge AI development tools to enhance coding efficiency and develop advanced data tools and solutions. Supervisory Responsibilities: None Key Responsibilities Data Infrastructure: Design, implement, and maintain data pipelines, ensuring data availability, quality, and scalability. Product Development: Build and enhance products using Python, SQL, and modern technologies. AI Integration: Leverage cutting-edge AI tools, including Cursor, ChatGPT, and Claude to improve development processes, automate workflows, and create innovative data solutions. Collaboration: Communicate across departments to design, build, test, and implement new features and enhancements. Code Excellence: Produce quality, testable, and maintainable code while participating in code reviews. Problem Solving: Debug complex issues, interact with stakeholders, and design viable solutions with clear trade-offs. Process Optimization: Contribute to improving development processes, including deployment, on-call systems, and sprint planning. Team Growth: Collaborate within the development team to help each other grow and continuously learn. Stakeholder Engagement: Partner with analysts, scientists, and IT to ensure alignment and deliver data-driven solutions. Other duties as assigned/necessary Performance Metrics Code Quality: Maintain high coding standards through regular code reviews and adherence to best practices. Development Efficiency: Deliver high-quality features and fixes within efficient timeframes. Bug Resolution Time: Reduce the time taken to identify and resolve issues. System Scalability: Optimize system performance to handle increasing user demands. Collaboration: Foster a collaborative environment that encourages teamwork and knowledge sharing. Customer Satisfaction: Incorporate stakeholder feedback to improve solutions and enhance the customer experience. Continuous Learning: Pursue opportunities for skill development and share knowledge with the team. Requirements: Required Skills & Qualifications Technical Tools: Experience with in Python and/or SQL. Experience with Bash, Shell scripting, Big Query, Airflow, and is a plus. Programming: Cleaning data using code-based approach. AI Proficiency: Interest or experience in using AI tools for coding and development of data solutions. Soft Skills: Problem-solving, cross-team collaboration, data storytelling, and stakeholder engagement. Adaptability: Thrives in a fast-paced startup environment and embraces change. Proactivity: Self-directed, organized, and able to prioritize effectively. Collaboration: Ability to work effectively with cross-functional teams. Education & Experience: A bachelor’s degree is required, and a graduate degree is preferred. Relevant experience in data engineering, software development, STEM, or related fields. Strong experience with SQL and Python is highly desirable. Mindset: A passion for innovation, continuous improvement, and delivering high-quality results from messy data. Preferred Qualifications Familiarity with cloud-based solutions (e.g., Google Cloud Platform, Azure). Experience with ETL processes and tools. Experience building data visualization reports and dashboards Knowledge of modern data storage solutions and database management systems. Exposure to DevOps practices and tools for deployment and monitoring. Why Join Us? Work with a talented, collaborative team dedicated to making a difference. Gain exposure to innovative technologies and opportunities for growth. Learn and utilize cutting-edge AI tools to enhance your development skills and create impactful solutions. Be part of a company that values your contributions and encourages professional development. Join a rapidly expanding health-tech startup (~200 employees and growing) with a state-of-the-art technology office located in Hyde Park, offering a variety of exceptional benefits. Career Progression Timeline In 3 months: Gain a comprehensive understanding of our data infrastructure, technical stacks, and development cycles. Actively participate in team meetings and contribute to the development of new data pipelines. Begin leveraging AI tools, such as Cursor and ChatGPT, to enhance coding efficiency and workflow automation. In 6 months: Contribute to product enhancements and data reporting Collaborate effectively with cross-functional teams, providing insights and solutions for data-related challenges. Demonstrate proficiency in utilizing AI tools for coding and development, actively sharing knowledge with the team. In 12 months: Contribute to data engineering projects, ensuring scalability and performance optimization. Mentor non-technical internal partners to improve company-wide data literacy Contribute to the integration of advanced AI solutions into our development processes, contributing to the company's technological advancement. Physical Requirements: Ability to remain at your designated workstation for the duration of the workday Constantly operates a computer and other office productivity machinery, such as a phone and Voice over Internet Protocol (VoIP). The ability to communicate information and ideas so others will understand. Must be able to exchange accurate information in these situations. The ability to observe details at close range (typically on a computer screen) This position offers the flexibility of remote work at approved locations within the United States. Candidates must have a reliable internet connection and a designated work environment conducive to professional phone calls and sensitive data. Enjoy the convenience and comfort of working remotely while contributing to our team's success. Apply Today If you’re ready to take on challenging problems, contribute to impactful solutions, and grow as a data engineer, we’d love to hear from you. Join us at The Helper Bees and be part of a team that’s making a meaningful difference every day! The Helper Bees is committed to building a workplace where diversity, equity, and inclusion are valued and prioritized. We are an equal opportunity employer that welcomes all qualified applicants without discrimination based on race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or any non-merit based or legally protected grounds. The Helper Bees provides reasonable accommodations to qualified individuals with disabilities during the job application and interview process. To request accommodation, please let your recruiter know. As part of our standard hiring process, selected candidates may be required to undergo a background check and/or drug screen. The Helper Bees adheres to applicable federal, state, and local laws regarding these screenings, and the results will be considered in accordance with applicable regulations. The Helper Bees was recently made aware of a fraudulent entity posing as our organization and requesting personal information. Please be aware of and protect yourself from scams. Visit thehelperbees.com/careers to view all current job openings.",
         "Technical Tools: Experience with in Python and/or SQL. Experience with Bash, Shell scripting, Big Query, Airflow, and is a plus. Programming: Cleaning data using code-based approach. AI Proficiency: Interest or experience in using AI tools for coding and development of data solutions. Soft Skills: Problem-solving, cross-team collaboration, data storytelling, and stakeholder engagement. Adaptability: Thrives in a fast-paced startup environment and embraces change. Proactivity: Self-directed, organized, and able to prioritize effectively. Collaboration: Ability to work effectively with cross-functional teams. Education & Experience: A bachelor’s degree is required, and a graduate degree is preferred. Relevant experience in data engineering, software development, STEM, or related fields. Strong experience with SQL and Python is highly desirable. Mindset: A passion for innovation, continuous improvement, and delivering high-quality results from messy data. Preferred Qualifications Familiarity with cloud-based solutions (e.g., Google Cloud Platform, Azure). Experience with ETL processes and tools. Experience building data visualization reports and dashboards Knowledge of modern data storage solutions and database management systems. Exposure to DevOps practices and tools for deployment and monitoring. Why Join Us? Work with a talented, collaborative team dedicated to making a difference. Gain exposure to innovative technologies and opportunities for growth. Learn and utilize cutting-edge AI tools to enhance your development skills and create impactful solutions. Be part of a company that values your contributions and encourages professional development. Join a rapidly expanding health-tech startup (~200 employees and growing) with a state-of-the-art technology office located in Hyde Park, offering a variety of exceptional benefits. Career Progression Timeline In 3 months: Gain a comprehensive understanding of our data infrastructure, technical stacks, and development cycles. Actively participate in team meetings and contribute to the development of new data pipelines. Begin leveraging AI tools, such as Cursor and ChatGPT, to enhance coding efficiency and workflow automation. In 6 months: Contribute to product enhancements and data reporting Collaborate effectively with cross-functional teams, providing insights and solutions for data-related challenges. Demonstrate proficiency in utilizing AI tools for coding and development, actively sharing knowledge with the team. In 12 months: Contribute to data engineering projects, ensuring scalability and performance optimization. Mentor non-technical internal partners to improve company-wide data literacy Contribute to the integration of advanced AI solutions into our development processes, contributing to the company's technological advancement. Physical Requirements: Ability to remain at your designated workstation for the duration of the workday Constantly operates a computer and other office productivity machinery, such as a phone and Voice over Internet Protocol (VoIP). The ability to communicate information and ideas so others will understand. Must be able to exchange accurate information in these situations. The ability to observe details at close range (typically on a computer screen) This position offers the flexibility of remote work at approved locations within the United States. Candidates must have a reliable internet connection and a designated work environment conducive to professional phone calls and sensitive data. Enjoy the convenience and comfort of working remotely while contributing to our team's success. Apply Today If you’re ready to take on challenging problems, contribute to impactful solutions, and grow as a data engineer, we’d love to hear from you. Join us at The Helper Bees and be part of a team that’s making a meaningful difference every day! The Helper Bees is committed to building a workplace where diversity, equity, and inclusion are valued and prioritized. We are an equal opportunity employer that welcomes all qualified applicants without discrimination based on race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or any non-merit based or legally protected grounds. The Helper Bees provides reasonable accommodations to qualified individuals with disabilities during the job application and interview process. To request accommodation, please let your recruiter know. As part of our standard hiring process, selected candidates may be required to undergo a background check and/or drug screen. The Helper Bees adheres to applicable federal, state, and local laws regarding these screenings, and the results will be considered in accordance with applicable regulations. The Helper Bees was recently made aware of a fraudulent entity posing as our organization and requesting personal information. Please be aware of and protect yourself from scams. Visit thehelperbees.com/careers to view all current job openings.",
         698
        ],
        [
         null,
         "culture through our Core Values:",
         "Description: Join our winning team, recently honored as #67 on Forbes’ list of America’s Best Startup Employers for 2024! About The Helper Bees The Helper Bees’ mission is to help people stay home longer through data-driven services that transform both the payer and the care-recipient experience. At The Helper Bees, we are reshaping how care is delivered to aging individuals by leveraging innovative technology and insightful data solutions. We maintain multiple SaaS products and payment solutions through our web applications (internal and external facing), a mobile app, and reporting integrations. As part of our growing Data Engineering team, you’ll iterate quickly, have a high impact, and be challenged to design and implement cutting-edge solutions. At THB, we define our company culture through our Core Values: Quickly iterate through solutions: We move at a fast pace which requires quick iterations to find a path to a repeatable solution. Seek ways to create immediate impact: Be thoughtful and proactive in how you make an impact on your team. Actively look for ways to make a fast, positive impact. Bee the teammate you want to work with: We work as a team, help each other, and encourage each other. Ask questions, answer questions: You can't iterate through solutions if you don't ask the right questions, which is why there is an expectation that questions should be asked. When you know the answer, being a good teammate means chiming in to get others up to speed. Take the time to celebrate wins: It's so easy for a team that is heads down to forget about all the great things they've accomplished. That's why we make it a priority to remind ourselves to create space to celebrate wins, big or small. Job Summary We are seeking a motivated Data Engineer to join our team and help improve our tools, processes, and technical infrastructure. In this role, you will ensure the availability and quality of our data while contributing to the design, implementation, and maintenance of The Helper Bees’ products. You’ll collaborate across teams to create scalable and optimized software systems and play a key role in refining our development processes. This position offers a unique opportunity to learn and leverage cutting-edge AI development tools to enhance coding efficiency and develop advanced data tools and solutions. Supervisory Responsibilities: None Key Responsibilities Data Infrastructure: Design, implement, and maintain data pipelines, ensuring data availability, quality, and scalability. Product Development: Build and enhance products using Python, SQL, and modern technologies. AI Integration: Leverage cutting-edge AI tools, including Cursor, ChatGPT, and Claude to improve development processes, automate workflows, and create innovative data solutions. Collaboration: Communicate across departments to design, build, test, and implement new features and enhancements. Code Excellence: Produce quality, testable, and maintainable code while participating in code reviews. Problem Solving: Debug complex issues, interact with stakeholders, and design viable solutions with clear trade-offs. Process Optimization: Contribute to improving development processes, including deployment, on-call systems, and sprint planning. Team Growth: Collaborate within the development team to help each other grow and continuously learn. Stakeholder Engagement: Partner with analysts, scientists, and IT to ensure alignment and deliver data-driven solutions. Other duties as assigned/necessary Performance Metrics Code Quality: Maintain high coding standards through regular code reviews and adherence to best practices. Development Efficiency: Deliver high-quality features and fixes within efficient timeframes. Bug Resolution Time: Reduce the time taken to identify and resolve issues. System Scalability: Optimize system performance to handle increasing user demands. Collaboration: Foster a collaborative environment that encourages teamwork and knowledge sharing. Customer Satisfaction: Incorporate stakeholder feedback to improve solutions and enhance the customer experience. Continuous Learning: Pursue opportunities for skill development and share knowledge with the team. Requirements: Required Skills & Qualifications Technical Tools: Experience with in Python and/or SQL. Experience with Bash, Shell scripting, Big Query, Airflow, and is a plus. Programming: Cleaning data using code-based approach. AI Proficiency: Interest or experience in using AI tools for coding and development of data solutions. Soft Skills: Problem-solving, cross-team collaboration, data storytelling, and stakeholder engagement. Adaptability: Thrives in a fast-paced startup environment and embraces change. Proactivity: Self-directed, organized, and able to prioritize effectively. Collaboration: Ability to work effectively with cross-functional teams. Education & Experience: A bachelor’s degree is required, and a graduate degree is preferred. Relevant experience in data engineering, software development, STEM, or related fields. Strong experience with SQL and Python is highly desirable. Mindset: A passion for innovation, continuous improvement, and delivering high-quality results from messy data. Preferred Qualifications Familiarity with cloud-based solutions (e.g., Google Cloud Platform, Azure). Experience with ETL processes and tools. Experience building data visualization reports and dashboards Knowledge of modern data storage solutions and database management systems. Exposure to DevOps practices and tools for deployment and monitoring. Why Join Us? Work with a talented, collaborative team dedicated to making a difference. Gain exposure to innovative technologies and opportunities for growth. Learn and utilize cutting-edge AI tools to enhance your development skills and create impactful solutions. Be part of a company that values your contributions and encourages professional development. Join a rapidly expanding health-tech startup (~200 employees and growing) with a state-of-the-art technology office located in Hyde Park, offering a variety of exceptional benefits. Career Progression Timeline In 3 months: Gain a comprehensive understanding of our data infrastructure, technical stacks, and development cycles. Actively participate in team meetings and contribute to the development of new data pipelines. Begin leveraging AI tools, such as Cursor and ChatGPT, to enhance coding efficiency and workflow automation. In 6 months: Contribute to product enhancements and data reporting Collaborate effectively with cross-functional teams, providing insights and solutions for data-related challenges. Demonstrate proficiency in utilizing AI tools for coding and development, actively sharing knowledge with the team. In 12 months: Contribute to data engineering projects, ensuring scalability and performance optimization. Mentor non-technical internal partners to improve company-wide data literacy Contribute to the integration of advanced AI solutions into our development processes, contributing to the company's technological advancement. Physical Requirements: Ability to remain at your designated workstation for the duration of the workday Constantly operates a computer and other office productivity machinery, such as a phone and Voice over Internet Protocol (VoIP). The ability to communicate information and ideas so others will understand. Must be able to exchange accurate information in these situations. The ability to observe details at close range (typically on a computer screen) This position offers the flexibility of remote work at approved locations within the United States. Candidates must have a reliable internet connection and a designated work environment conducive to professional phone calls and sensitive data. Enjoy the convenience and comfort of working remotely while contributing to our team's success. Apply Today If you’re ready to take on challenging problems, contribute to impactful solutions, and grow as a data engineer, we’d love to hear from you. Join us at The Helper Bees and be part of a team that’s making a meaningful difference every day! The Helper Bees is committed to building a workplace where diversity, equity, and inclusion are valued and prioritized. We are an equal opportunity employer that welcomes all qualified applicants without discrimination based on race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or any non-merit based or legally protected grounds. The Helper Bees provides reasonable accommodations to qualified individuals with disabilities during the job application and interview process. To request accommodation, please let your recruiter know. As part of our standard hiring process, selected candidates may be required to undergo a background check and/or drug screen. The Helper Bees adheres to applicable federal, state, and local laws regarding these screenings, and the results will be considered in accordance with applicable regulations. The Helper Bees was recently made aware of a fraudulent entity posing as our organization and requesting personal information. Please be aware of and protect yourself from scams. Visit thehelperbees.com/careers to view all current job openings.",
         "data",
         "Description: Join our winning team, recently honored as #67 on Forbes’ list of America’s Best Startup Employers for 2024! About The Helper Bees The Helper Bees’ mission is to help people stay home longer through data-driven services that transform both the payer and the care-recipient experience. At The Helper Bees, we are reshaping how care is delivered to aging individuals by leveraging innovative technology and insightful data solutions. We maintain multiple SaaS products and payment solutions through our web applications (internal and external facing), a mobile app, and reporting integrations. As part of our growing Data Engineering team, you’ll iterate quickly, have a high impact, and be challenged to design and implement cutting-edge solutions. At THB, we define our company culture through our Core Values: Quickly iterate through solutions: We move at a fast pace which requires quick iterations to find a path to a repeatable solution. Seek ways to create immediate impact: Be thoughtful and proactive in how you make an impact on your team. Actively look for ways to make a fast, positive impact. Bee the teammate you want to work with: We work as a team, help each other, and encourage each other. Ask questions, answer questions: You can't iterate through solutions if you don't ask the right questions, which is why there is an expectation that questions should be asked. When you know the answer, being a good teammate means chiming in to get others up to speed. Take the time to celebrate wins: It's so easy for a team that is heads down to forget about all the great things they've accomplished. That's why we make it a priority to remind ourselves to create space to celebrate wins, big or small. Job Summary We are seeking a motivated Data Engineer to join our team and help improve our tools, processes, and technical infrastructure. In this role, you will ensure the availability and quality of our data while contributing to the design, implementation, and maintenance of The Helper Bees’ products. You’ll collaborate across teams to create scalable and optimized software systems and play a key role in refining our development processes. This position offers a unique opportunity to learn and leverage cutting-edge AI development tools to enhance coding efficiency and develop advanced data tools and solutions. Supervisory Responsibilities: None Key Responsibilities Data Infrastructure: Design, implement, and maintain data pipelines, ensuring data availability, quality, and scalability. Product Development: Build and enhance products using Python, SQL, and modern technologies. AI Integration: Leverage cutting-edge AI tools, including Cursor, ChatGPT, and Claude to improve development processes, automate workflows, and create innovative data solutions. Collaboration: Communicate across departments to design, build, test, and implement new features and enhancements. Code Excellence: Produce quality, testable, and maintainable code while participating in code reviews. Problem Solving: Debug complex issues, interact with stakeholders, and design viable solutions with clear trade-offs. Process Optimization: Contribute to improving development processes, including deployment, on-call systems, and sprint planning. Team Growth: Collaborate within the development team to help each other grow and continuously learn. Stakeholder Engagement: Partner with analysts, scientists, and IT to ensure alignment and deliver data-driven solutions. Other duties as assigned/necessary Performance Metrics Code Quality: Maintain high coding standards through regular code reviews and adherence to best practices. Development Efficiency: Deliver high-quality features and fixes within efficient timeframes. Bug Resolution Time: Reduce the time taken to identify and resolve issues. System Scalability: Optimize system performance to handle increasing user demands. Collaboration: Foster a collaborative environment that encourages teamwork and knowledge sharing. Customer Satisfaction: Incorporate stakeholder feedback to improve solutions and enhance the customer experience. Continuous Learning: Pursue opportunities for skill development and share knowledge with the team. Requirements: Required Skills & Qualifications Technical Tools: Experience with in Python and/or SQL. Experience with Bash, Shell scripting, Big Query, Airflow, and is a plus. Programming: Cleaning data using code-based approach. AI Proficiency: Interest or experience in using AI tools for coding and development of data solutions. Soft Skills: Problem-solving, cross-team collaboration, data storytelling, and stakeholder engagement. Adaptability: Thrives in a fast-paced startup environment and embraces change. Proactivity: Self-directed, organized, and able to prioritize effectively. Collaboration: Ability to work effectively with cross-functional teams. Education & Experience: A bachelor’s degree is required, and a graduate degree is preferred. Relevant experience in data engineering, software development, STEM, or related fields. Strong experience with SQL and Python is highly desirable. Mindset: A passion for innovation, continuous improvement, and delivering high-quality results from messy data. Preferred Qualifications Familiarity with cloud-based solutions (e.g., Google Cloud Platform, Azure). Experience with ETL processes and tools. Experience building data visualization reports and dashboards Knowledge of modern data storage solutions and database management systems. Exposure to DevOps practices and tools for deployment and monitoring. Why Join Us? Work with a talented, collaborative team dedicated to making a difference. Gain exposure to innovative technologies and opportunities for growth. Learn and utilize cutting-edge AI tools to enhance your development skills and create impactful solutions. Be part of a company that values your contributions and encourages professional development. Join a rapidly expanding health-tech startup (~200 employees and growing) with a state-of-the-art technology office located in Hyde Park, offering a variety of exceptional benefits. Career Progression Timeline In 3 months: Gain a comprehensive understanding of our data infrastructure, technical stacks, and development cycles. Actively participate in team meetings and contribute to the development of new data pipelines. Begin leveraging AI tools, such as Cursor and ChatGPT, to enhance coding efficiency and workflow automation. In 6 months: Contribute to product enhancements and data reporting Collaborate effectively with cross-functional teams, providing insights and solutions for data-related challenges. Demonstrate proficiency in utilizing AI tools for coding and development, actively sharing knowledge with the team. In 12 months: Contribute to data engineering projects, ensuring scalability and performance optimization. Mentor non-technical internal partners to improve company-wide data literacy Contribute to the integration of advanced AI solutions into our development processes, contributing to the company's technological advancement. Physical Requirements: Ability to remain at your designated workstation for the duration of the workday Constantly operates a computer and other office productivity machinery, such as a phone and Voice over Internet Protocol (VoIP). The ability to communicate information and ideas so others will understand. Must be able to exchange accurate information in these situations. The ability to observe details at close range (typically on a computer screen) This position offers the flexibility of remote work at approved locations within the United States. Candidates must have a reliable internet connection and a designated work environment conducive to professional phone calls and sensitive data. Enjoy the convenience and comfort of working remotely while contributing to our team's success. Apply Today If you’re ready to take on challenging problems, contribute to impactful solutions, and grow as a data engineer, we’d love to hear from you. Join us at The Helper Bees and be part of a team that’s making a meaningful difference every day! The Helper Bees is committed to building a workplace where diversity, equity, and inclusion are valued and prioritized. We are an equal opportunity employer that welcomes all qualified applicants without discrimination based on race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or any non-merit based or legally protected grounds. The Helper Bees provides reasonable accommodations to qualified individuals with disabilities during the job application and interview process. To request accommodation, please let your recruiter know. As part of our standard hiring process, selected candidates may be required to undergo a background check and/or drug screen. The Helper Bees adheres to applicable federal, state, and local laws regarding these screenings, and the results will be considered in accordance with applicable regulations. The Helper Bees was recently made aware of a fraudulent entity posing as our organization and requesting personal information. Please be aware of and protect yourself from scams. Visit thehelperbees.com/careers to view all current job openings.",
         "Description: Join our winning team, recently honored as #67 on Forbes’ list of America’s Best Startup Employers for 2024! About The Helper Bees The Helper Bees’ mission is to help people stay home longer through data-driven services that transform both the payer and the care-recipient experience. At The Helper Bees, we are reshaping how care is delivered to aging individuals by leveraging innovative technology and insightful data solutions. We maintain multiple SaaS products and payment solutions through our web applications (internal and external facing), a mobile app, and reporting integrations. As part of our growing Data Engineering team, you’ll iterate quickly, have a high impact, and be challenged to design and implement cutting-edge solutions. At THB, we define our company culture through our Core Values: Quickly iterate through solutions: We move at a fast pace which requires quick iterations to find a path to a repeatable solution. Seek ways to create immediate impact: Be thoughtful and proactive in how you make an impact on your team. Actively look for ways to make a fast, positive impact. Bee the teammate you want to work with: We work as a team, help each other, and encourage each other. Ask questions, answer questions: You can't iterate through solutions if you don't ask the right questions, which is why there is an expectation that questions should be asked. When you know the answer, being a good teammate means chiming in to get others up to speed. Take the time to celebrate wins: It's so easy for a team that is heads down to forget about all the great things they've accomplished. That's why we make it a priority to remind ourselves to create space to celebrate wins, big or small. Job Summary We are seeking a motivated Data Engineer to join our team and help improve our tools, processes, and technical infrastructure. In this role, you will ensure the availability and quality of our data while contributing to the design, implementation, and maintenance of The Helper Bees’ products. You’ll collaborate across teams to create scalable and optimized software systems and play a key role in refining our development processes. This position offers a unique opportunity to learn and leverage cutting-edge AI development tools to enhance coding efficiency and develop advanced data tools and solutions. Supervisory Responsibilities: None Key Responsibilities Data Infrastructure: Design, implement, and maintain data pipelines, ensuring data availability, quality, and scalability. Product Development: Build and enhance products using Python, SQL, and modern technologies. AI Integration: Leverage cutting-edge AI tools, including Cursor, ChatGPT, and Claude to improve development processes, automate workflows, and create innovative data solutions. Collaboration: Communicate across departments to design, build, test, and implement new features and enhancements. Code Excellence: Produce quality, testable, and maintainable code while participating in code reviews. Problem Solving: Debug complex issues, interact with stakeholders, and design viable solutions with clear trade-offs. Process Optimization: Contribute to improving development processes, including deployment, on-call systems, and sprint planning. Team Growth: Collaborate within the development team to help each other grow and continuously learn. Stakeholder Engagement: Partner with analysts, scientists, and IT to ensure alignment and deliver data-driven solutions. Other duties as assigned/necessary Performance Metrics Code Quality: Maintain high coding standards through regular code reviews and adherence to best practices. Development Efficiency: Deliver high-quality features and fixes within efficient timeframes. Bug Resolution Time: Reduce the time taken to identify and resolve issues. System Scalability: Optimize system performance to handle increasing user demands. Collaboration: Foster a collaborative environment that encourages teamwork and knowledge sharing. Customer Satisfaction: Incorporate stakeholder feedback to improve solutions and enhance the customer experience. Continuous Learning: Pursue opportunities for skill development and share knowledge with the team. Requirements: Required Skills & Qualifications Technical Tools: Experience with in Python and/or SQL. Experience with Bash, Shell scripting, Big Query, Airflow, and is a plus. Programming: Cleaning data using code-based approach. AI Proficiency: Interest or experience in using AI tools for coding and development of data solutions. Soft Skills: Problem-solving, cross-team collaboration, data storytelling, and stakeholder engagement. Adaptability: Thrives in a fast-paced startup environment and embraces change. Proactivity: Self-directed, organized, and able to prioritize effectively. Collaboration: Ability to work effectively with cross-functional teams. Education & Experience: A bachelor’s degree is required, and a graduate degree is preferred. Relevant experience in data engineering, software development, STEM, or related fields. Strong experience with SQL and Python is highly desirable. Mindset: A passion for innovation, continuous improvement, and delivering high-quality results from messy data. Preferred Qualifications Familiarity with cloud-based solutions (e.g., Google Cloud Platform, Azure). Experience with ETL processes and tools. Experience building data visualization reports and dashboards Knowledge of modern data storage solutions and database management systems. Exposure to DevOps practices and tools for deployment and monitoring. Why Join Us? Work with a talented, collaborative team dedicated to making a difference. Gain exposure to innovative technologies and opportunities for growth. Learn and utilize cutting-edge AI tools to enhance your development skills and create impactful solutions. Be part of a company that values your contributions and encourages professional development. Join a rapidly expanding health-tech startup (~200 employees and growing) with a state-of-the-art technology office located in Hyde Park, offering a variety of exceptional benefits. Career Progression Timeline In 3 months: Gain a comprehensive understanding of our data infrastructure, technical stacks, and development cycles. Actively participate in team meetings and contribute to the development of new data pipelines. Begin leveraging AI tools, such as Cursor and ChatGPT, to enhance coding efficiency and workflow automation. In 6 months: Contribute to product enhancements and data reporting Collaborate effectively with cross-functional teams, providing insights and solutions for data-related challenges. Demonstrate proficiency in utilizing AI tools for coding and development, actively sharing knowledge with the team. In 12 months: Contribute to data engineering projects, ensuring scalability and performance optimization. Mentor non-technical internal partners to improve company-wide data literacy Contribute to the integration of advanced AI solutions into our development processes, contributing to the company's technological advancement. Physical Requirements: Ability to remain at your designated workstation for the duration of the workday Constantly operates a computer and other office productivity machinery, such as a phone and Voice over Internet Protocol (VoIP). The ability to communicate information and ideas so others will understand. Must be able to exchange accurate information in these situations. The ability to observe details at close range (typically on a computer screen) This position offers the flexibility of remote work at approved locations within the United States. Candidates must have a reliable internet connection and a designated work environment conducive to professional phone calls and sensitive data. Enjoy the convenience and comfort of working remotely while contributing to our team's success. Apply Today If you’re ready to take on challenging problems, contribute to impactful solutions, and grow as a data engineer, we’d love to hear from you. Join us at The Helper Bees and be part of a team that’s making a meaningful difference every day! The Helper Bees is committed to building a workplace where diversity, equity, and inclusion are valued and prioritized. We are an equal opportunity employer that welcomes all qualified applicants without discrimination based on race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or any non-merit based or legally protected grounds. The Helper Bees provides reasonable accommodations to qualified individuals with disabilities during the job application and interview process. To request accommodation, please let your recruiter know. As part of our standard hiring process, selected candidates may be required to undergo a background check and/or drug screen. The Helper Bees adheres to applicable federal, state, and local laws regarding these screenings, and the results will be considered in accordance with applicable regulations. The Helper Bees was recently made aware of a fraudulent entity posing as our organization and requesting personal information. Please be aware of and protect yourself from scams. Visit thehelperbees.com/careers to view all current job openings.",
         "Technical Tools: Experience with in Python and/or SQL. Experience with Bash, Shell scripting, Big Query, Airflow, and is a plus. Programming: Cleaning data using code-based approach. AI Proficiency: Interest or experience in using AI tools for coding and development of data solutions. Soft Skills: Problem-solving, cross-team collaboration, data storytelling, and stakeholder engagement. Adaptability: Thrives in a fast-paced startup environment and embraces change. Proactivity: Self-directed, organized, and able to prioritize effectively. Collaboration: Ability to work effectively with cross-functional teams. Education & Experience: A bachelor’s degree is required, and a graduate degree is preferred. Relevant experience in data engineering, software development, STEM, or related fields. Strong experience with SQL and Python is highly desirable. Mindset: A passion for innovation, continuous improvement, and delivering high-quality results from messy data. Preferred Qualifications Familiarity with cloud-based solutions (e.g., Google Cloud Platform, Azure). Experience with ETL processes and tools. Experience building data visualization reports and dashboards Knowledge of modern data storage solutions and database management systems. Exposure to DevOps practices and tools for deployment and monitoring. Why Join Us? Work with a talented, collaborative team dedicated to making a difference. Gain exposure to innovative technologies and opportunities for growth. Learn and utilize cutting-edge AI tools to enhance your development skills and create impactful solutions. Be part of a company that values your contributions and encourages professional development. Join a rapidly expanding health-tech startup (~200 employees and growing) with a state-of-the-art technology office located in Hyde Park, offering a variety of exceptional benefits. Career Progression Timeline In 3 months: Gain a comprehensive understanding of our data infrastructure, technical stacks, and development cycles. Actively participate in team meetings and contribute to the development of new data pipelines. Begin leveraging AI tools, such as Cursor and ChatGPT, to enhance coding efficiency and workflow automation. In 6 months: Contribute to product enhancements and data reporting Collaborate effectively with cross-functional teams, providing insights and solutions for data-related challenges. Demonstrate proficiency in utilizing AI tools for coding and development, actively sharing knowledge with the team. In 12 months: Contribute to data engineering projects, ensuring scalability and performance optimization. Mentor non-technical internal partners to improve company-wide data literacy Contribute to the integration of advanced AI solutions into our development processes, contributing to the company's technological advancement. Physical Requirements: Ability to remain at your designated workstation for the duration of the workday Constantly operates a computer and other office productivity machinery, such as a phone and Voice over Internet Protocol (VoIP). The ability to communicate information and ideas so others will understand. Must be able to exchange accurate information in these situations. The ability to observe details at close range (typically on a computer screen) This position offers the flexibility of remote work at approved locations within the United States. Candidates must have a reliable internet connection and a designated work environment conducive to professional phone calls and sensitive data. Enjoy the convenience and comfort of working remotely while contributing to our team's success. Apply Today If you’re ready to take on challenging problems, contribute to impactful solutions, and grow as a data engineer, we’d love to hear from you. Join us at The Helper Bees and be part of a team that’s making a meaningful difference every day! The Helper Bees is committed to building a workplace where diversity, equity, and inclusion are valued and prioritized. We are an equal opportunity employer that welcomes all qualified applicants without discrimination based on race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or any non-merit based or legally protected grounds. The Helper Bees provides reasonable accommodations to qualified individuals with disabilities during the job application and interview process. To request accommodation, please let your recruiter know. As part of our standard hiring process, selected candidates may be required to undergo a background check and/or drug screen. The Helper Bees adheres to applicable federal, state, and local laws regarding these screenings, and the results will be considered in accordance with applicable regulations. The Helper Bees was recently made aware of a fraudulent entity posing as our organization and requesting personal information. Please be aware of and protect yourself from scams. Visit thehelperbees.com/careers to view all current job openings.",
         698
        ],
        [
         null,
         "culture is a commitment to instilling a dynamic and employee-friendly place to work. We place a priority on promoting a supportive and collegial team environment and enhancing staff experience through career development and educational opportunities.",
         "Index Analytics, LLC, is a rapidly growing, Baltimore-based small business providing health-related consulting services to the federal government. At the center of our company culture is a commitment to instilling a dynamic and employee-friendly place to work. We place a priority on promoting a supportive and collegial team environment and enhancing staff experience through career development and educational opportunities. Position Overview The Data Engineer is responsible for designing, building, and maintaining data pipelines and architectures to support data analytics and reporting needs across the organization. This role involves working closely with data scientists, analysts, and other stakeholders to ensure that data is clean, accessible, and ready for analysis. The Data Engineer will optimize data systems, develop data integration solutions, and ensure data security and governance. Key responsibilities include creating ETL processes, managing databases, and improving data infrastructure performance. The ideal candidate has strong programming and database skills and experience with cloud-based data platforms. Responsibilities Leads design, implementation, and management of data pipelines Develops and executes ETL (extract, transform, load) or ELT code Supports design of robust Data Integration Architecture to support customers Helps monitor and administer the systems and ensures applications and systems are always functioning properly Analyzes the Data Integration and Engineering architecture to identify weaknesses and develops improvements such as enhancing business processes Identifies and analyzes business requirements, functional design, and translation of requirements to technical specifications Performs complex query design, developments, validation routine analysis, and streamlining processes Operates large data sets, delta data sets and querying efficiently Transforms, joins, and normalizes data in service of specific use cases. Employs AWS data pipeline solutions such as Glue, Data Pipeline, Step functions, MWAA to orchestrate data movement Work with DevSecOps engineer to deploy continuous integration and continuous deployment (CI/CD) data pipelines Understand the technical architecture to design, build, optimize, and maintain scalable data solutions in a Big Data environment Work with Product Owners and/or business stakeholders to gather business requirements and translate to detailed technical specifications US citizen or Authorized to Work and lived in the US for 3 of the last 5 years. Must be able to obtain a U.S. Federal government client badge and pass a government Public Trust. Bachelors degree or higher in IT or relevant discipline required 4+ years of IT experience Experience with setting up and operating data pipelines using Python or SQL Experience with Scala and PySpark 3+ years of experience working on AWS, GCP or Azure (AWS Preferred) cloud platforms Hands-on relational DB / NoSQL experience (PostgreSQL or similar) with specific implementation on cloud Experience working with data warehouses such as Redshift to open source and proprietary cloud data pipeline tools such as Airflow, Glue, Data Pipeline, Step functions Experience working with relational databases that handle structured and semi-structured (JSON) datasets Experience with data serialization languages such as JSON, XML, YAML Experience with code management tools (e.g. Git, SVN) and DevOps tools (e.g. Jenkins, Docker, AWS Code Pipeline) Strong analytical problem-solving ability Working experience with Transactional and Dimensional data modeling methodologies (Eg: Normalization, Star Schema, Snowflake Schema) Experience working with a distributed computing environment like AWS EMR or similar. Ability to obtain Public Trust level clearance Ability to demonstrate excellent written and oral communication required Prior experience with Center for Medicare Medicaid Services or other Govt agencies is a plus The salary range provided represents the estimated compensation for new hires in this position, applicable across all locations. Actual offers may vary based on factors such as the candidate's skills, qualifications, experience, and market conditions. Index complements its base salary offering with a competitive package that includes health and retirement benefits, discretionary bonuses, and reimbursement for professional development opportunities. Index Analytics provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training. Attention Candidates We're dedicated to ensuring a safe and transparent recruitment process for all candidates and have implemented robust measures to protect your personal information. Please be aware that all employment-related communications will originate from a secure portal ( NAME@msg.paycomonline.com ) or a corporate email address ( NAME@index-analytics.com ). If you have any concerns, please don't hesitate to reach out to us at recruiting@index-analytics.com",
         "data",
         "Index Analytics, LLC, is a rapidly growing, Baltimore-based small business providing health-related consulting services to the federal government. At the center of our company culture is a commitment to instilling a dynamic and employee-friendly place to work. We place a priority on promoting a supportive and collegial team environment and enhancing staff experience through career development and educational opportunities. Position Overview The Data Engineer is responsible for designing, building, and maintaining data pipelines and architectures to support data analytics and reporting needs across the organization. This role involves working closely with data scientists, analysts, and other stakeholders to ensure that data is clean, accessible, and ready for analysis. The Data Engineer will optimize data systems, develop data integration solutions, and ensure data security and governance. Key responsibilities include creating ETL processes, managing databases, and improving data infrastructure performance. The ideal candidate has strong programming and database skills and experience with cloud-based data platforms. Responsibilities Leads design, implementation, and management of data pipelines Develops and executes ETL (extract, transform, load) or ELT code Supports design of robust Data Integration Architecture to support customers Helps monitor and administer the systems and ensures applications and systems are always functioning properly Analyzes the Data Integration and Engineering architecture to identify weaknesses and develops improvements such as enhancing business processes Identifies and analyzes business requirements, functional design, and translation of requirements to technical specifications Performs complex query design, developments, validation routine analysis, and streamlining processes Operates large data sets, delta data sets and querying efficiently Transforms, joins, and normalizes data in service of specific use cases. Employs AWS data pipeline solutions such as Glue, Data Pipeline, Step functions, MWAA to orchestrate data movement Work with DevSecOps engineer to deploy continuous integration and continuous deployment (CI/CD) data pipelines Understand the technical architecture to design, build, optimize, and maintain scalable data solutions in a Big Data environment Work with Product Owners and/or business stakeholders to gather business requirements and translate to detailed technical specifications US citizen or Authorized to Work and lived in the US for 3 of the last 5 years. Must be able to obtain a U.S. Federal government client badge and pass a government Public Trust. Bachelors degree or higher in IT or relevant discipline required 4+ years of IT experience Experience with setting up and operating data pipelines using Python or SQL Experience with Scala and PySpark 3+ years of experience working on AWS, GCP or Azure (AWS Preferred) cloud platforms Hands-on relational DB / NoSQL experience (PostgreSQL or similar) with specific implementation on cloud Experience working with data warehouses such as Redshift to open source and proprietary cloud data pipeline tools such as Airflow, Glue, Data Pipeline, Step functions Experience working with relational databases that handle structured and semi-structured (JSON) datasets Experience with data serialization languages such as JSON, XML, YAML Experience with code management tools (e.g. Git, SVN) and DevOps tools (e.g. Jenkins, Docker, AWS Code Pipeline) Strong analytical problem-solving ability Working experience with Transactional and Dimensional data modeling methodologies (Eg: Normalization, Star Schema, Snowflake Schema) Experience working with a distributed computing environment like AWS EMR or similar. Ability to obtain Public Trust level clearance Ability to demonstrate excellent written and oral communication required Prior experience with Center for Medicare Medicaid Services or other Govt agencies is a plus The salary range provided represents the estimated compensation for new hires in this position, applicable across all locations. Actual offers may vary based on factors such as the candidate's skills, qualifications, experience, and market conditions. Index complements its base salary offering with a competitive package that includes health and retirement benefits, discretionary bonuses, and reimbursement for professional development opportunities. Index Analytics provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training. Attention Candidates We're dedicated to ensuring a safe and transparent recruitment process for all candidates and have implemented robust measures to protect your personal information. Please be aware that all employment-related communications will originate from a secure portal ( NAME@msg.paycomonline.com ) or a corporate email address ( NAME@index-analytics.com ). If you have any concerns, please don't hesitate to reach out to us at recruiting@index-analytics.com",
         "Index Analytics, LLC, is a rapidly growing, Baltimore-based small business providing health-related consulting services to the federal government. At the center of our company culture is a commitment to instilling a dynamic and employee-friendly place to work. We place a priority on promoting a supportive and collegial team environment and enhancing staff experience through career development and educational opportunities. Position Overview The Data Engineer is responsible for designing, building, and maintaining data pipelines and architectures to support data analytics and reporting needs across the organization. This role involves working closely with data scientists, analysts, and other stakeholders to ensure that data is clean, accessible, and ready for analysis. The Data Engineer will optimize data systems, develop data integration solutions, and ensure data security and governance. Key responsibilities include creating ETL processes, managing databases, and improving data infrastructure performance. The ideal candidate has strong programming and database skills and experience with cloud-based data platforms. Responsibilities Leads design, implementation, and management of data pipelines Develops and executes ETL (extract, transform, load) or ELT code Supports design of robust Data Integration Architecture to support customers Helps monitor and administer the systems and ensures applications and systems are always functioning properly Analyzes the Data Integration and Engineering architecture to identify weaknesses and develops improvements such as enhancing business processes Identifies and analyzes business requirements, functional design, and translation of requirements to technical specifications Performs complex query design, developments, validation routine analysis, and streamlining processes Operates large data sets, delta data sets and querying efficiently Transforms, joins, and normalizes data in service of specific use cases. Employs AWS data pipeline solutions such as Glue, Data Pipeline, Step functions, MWAA to orchestrate data movement Work with DevSecOps engineer to deploy continuous integration and continuous deployment (CI/CD) data pipelines Understand the technical architecture to design, build, optimize, and maintain scalable data solutions in a Big Data environment Work with Product Owners and/or business stakeholders to gather business requirements and translate to detailed technical specifications US citizen or Authorized to Work and lived in the US for 3 of the last 5 years. Must be able to obtain a U.S. Federal government client badge and pass a government Public Trust. Bachelors degree or higher in IT or relevant discipline required 4+ years of IT experience Experience with setting up and operating data pipelines using Python or SQL Experience with Scala and PySpark 3+ years of experience working on AWS, GCP or Azure (AWS Preferred) cloud platforms Hands-on relational DB / NoSQL experience (PostgreSQL or similar) with specific implementation on cloud Experience working with data warehouses such as Redshift to open source and proprietary cloud data pipeline tools such as Airflow, Glue, Data Pipeline, Step functions Experience working with relational databases that handle structured and semi-structured (JSON) datasets Experience with data serialization languages such as JSON, XML, YAML Experience with code management tools (e.g. Git, SVN) and DevOps tools (e.g. Jenkins, Docker, AWS Code Pipeline) Strong analytical problem-solving ability Working experience with Transactional and Dimensional data modeling methodologies (Eg: Normalization, Star Schema, Snowflake Schema) Experience working with a distributed computing environment like AWS EMR or similar. Ability to obtain Public Trust level clearance Ability to demonstrate excellent written and oral communication required Prior experience with Center for Medicare Medicaid Services or other Govt agencies is a plus The salary range provided represents the estimated compensation for new hires in this position, applicable across all locations. Actual offers may vary based on factors such as the candidate's skills, qualifications, experience, and market conditions. Index complements its base salary offering with a competitive package that includes health and retirement benefits, discretionary bonuses, and reimbursement for professional development opportunities. Index Analytics provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training. Attention Candidates We're dedicated to ensuring a safe and transparent recruitment process for all candidates and have implemented robust measures to protect your personal information. Please be aware that all employment-related communications will originate from a secure portal ( NAME@msg.paycomonline.com ) or a corporate email address ( NAME@index-analytics.com ). If you have any concerns, please don't hesitate to reach out to us at recruiting@index-analytics.com",
         "to technical specifications Performs complex query design, developments, validation routine analysis, and streamlining processes Operates large data sets, delta data sets and querying efficiently Transforms, joins, and normalizes data in service of specific use cases. Employs AWS data pipeline solutions such as Glue, Data Pipeline, Step functions, MWAA to orchestrate data movement Work with DevSecOps engineer to deploy continuous integration and continuous deployment (CI/CD) data pipelines Understand the technical architecture to design, build, optimize, and maintain scalable data solutions in a Big Data environment Work with Product Owners and/or business stakeholders to gather business requirements and translate to detailed technical specifications US citizen or Authorized to Work and lived in the US for 3 of the last 5 years. Must be able to obtain a U.S. Federal government client badge and pass a government Public Trust. Bachelors degree or higher in IT or relevant discipline required 4+ years of IT experience Experience with setting up and operating data pipelines using Python or SQL Experience with Scala and PySpark 3+ years of experience working on AWS, GCP or Azure (AWS Preferred) cloud platforms Hands-on relational DB / NoSQL experience (PostgreSQL or similar) with specific implementation on cloud Experience working with data warehouses such as Redshift to open source and proprietary cloud data pipeline tools such as Airflow, Glue, Data Pipeline, Step functions Experience working with relational databases that handle structured and semi-structured (JSON) datasets Experience with data serialization languages such as JSON, XML, YAML Experience with code management tools (e.g. Git, SVN) and DevOps tools (e.g. Jenkins, Docker, AWS Code Pipeline) Strong analytical problem-solving ability Working experience with Transactional and Dimensional data modeling methodologies (Eg: Normalization, Star Schema, Snowflake Schema) Experience working with a distributed computing environment like AWS EMR or similar. Ability to obtain Public Trust level clearance Ability to demonstrate excellent written and oral communication required Prior experience with Center for Medicare Medicaid Services or other Govt agencies is a plus The salary range provided represents the estimated compensation for new hires in this position, applicable across all locations. Actual offers may vary based on factors such as the candidate's skills, qualifications, experience, and market conditions. Index complements its base salary offering with a competitive package that includes health and retirement benefits, discretionary bonuses, and reimbursement for professional development opportunities. Index Analytics provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training. Attention Candidates We're dedicated to ensuring a safe and transparent recruitment process for all candidates and have implemented robust measures to protect your personal information. Please be aware that all employment-related communications will originate from a secure portal ( NAME@msg.paycomonline.com ) or a corporate email address ( NAME@index-analytics.com ). If you have any concerns, please don't hesitate to reach out to us at recruiting@index-analytics.com",
         524
        ],
        [
         null,
         "#NAME?",
         "Description: Join our winning team, recently honored as #67 on Forbes’ list of America’s Best Startup Employers for 2024! About The Helper Bees The Helper Bees’ mission is to help people stay home longer through data-driven services that transform both the payer and the care-recipient experience. At The Helper Bees, we are reshaping how care is delivered to aging individuals by leveraging innovative technology and insightful data solutions. We maintain multiple SaaS products and payment solutions through our web applications (internal and external facing), a mobile app, and reporting integrations. As part of our growing Data Engineering team, you’ll iterate quickly, have a high impact, and be challenged to design and implement cutting-edge solutions. At THB, we define our company culture through our Core Values: Quickly iterate through solutions: We move at a fast pace which requires quick iterations to find a path to a repeatable solution. Seek ways to create immediate impact: Be thoughtful and proactive in how you make an impact on your team. Actively look for ways to make a fast, positive impact. Bee the teammate you want to work with: We work as a team, help each other, and encourage each other. Ask questions, answer questions: You can't iterate through solutions if you don't ask the right questions, which is why there is an expectation that questions should be asked. When you know the answer, being a good teammate means chiming in to get others up to speed. Take the time to celebrate wins: It's so easy for a team that is heads down to forget about all the great things they've accomplished. That's why we make it a priority to remind ourselves to create space to celebrate wins, big or small. Job Summary We are seeking a motivated Data Engineer to join our team and help improve our tools, processes, and technical infrastructure. In this role, you will ensure the availability and quality of our data while contributing to the design, implementation, and maintenance of The Helper Bees’ products. You’ll collaborate across teams to create scalable and optimized software systems and play a key role in refining our development processes. This position offers a unique opportunity to learn and leverage cutting-edge AI development tools to enhance coding efficiency and develop advanced data tools and solutions. Supervisory Responsibilities: None Key Responsibilities Data Infrastructure: Design, implement, and maintain data pipelines, ensuring data availability, quality, and scalability. Product Development: Build and enhance products using Python, SQL, and modern technologies. AI Integration: Leverage cutting-edge AI tools, including Cursor, ChatGPT, and Claude to improve development processes, automate workflows, and create innovative data solutions. Collaboration: Communicate across departments to design, build, test, and implement new features and enhancements. Code Excellence: Produce quality, testable, and maintainable code while participating in code reviews. Problem Solving: Debug complex issues, interact with stakeholders, and design viable solutions with clear trade-offs. Process Optimization: Contribute to improving development processes, including deployment, on-call systems, and sprint planning. Team Growth: Collaborate within the development team to help each other grow and continuously learn. Stakeholder Engagement: Partner with analysts, scientists, and IT to ensure alignment and deliver data-driven solutions. Other duties as assigned/necessary Performance Metrics Code Quality: Maintain high coding standards through regular code reviews and adherence to best practices. Development Efficiency: Deliver high-quality features and fixes within efficient timeframes. Bug Resolution Time: Reduce the time taken to identify and resolve issues. System Scalability: Optimize system performance to handle increasing user demands. Collaboration: Foster a collaborative environment that encourages teamwork and knowledge sharing. Customer Satisfaction: Incorporate stakeholder feedback to improve solutions and enhance the customer experience. Continuous Learning: Pursue opportunities for skill development and share knowledge with the team. Requirements: Required Skills & Qualifications Technical Tools: Experience with in Python and/or SQL. Experience with Bash, Shell scripting, Big Query, Airflow, and is a plus. Programming: Cleaning data using code-based approach. AI Proficiency: Interest or experience in using AI tools for coding and development of data solutions. Soft Skills: Problem-solving, cross-team collaboration, data storytelling, and stakeholder engagement. Adaptability: Thrives in a fast-paced startup environment and embraces change. Proactivity: Self-directed, organized, and able to prioritize effectively. Collaboration: Ability to work effectively with cross-functional teams. Education & Experience: A bachelor’s degree is required, and a graduate degree is preferred. Relevant experience in data engineering, software development, STEM, or related fields. Strong experience with SQL and Python is highly desirable. Mindset: A passion for innovation, continuous improvement, and delivering high-quality results from messy data. Preferred Qualifications Familiarity with cloud-based solutions (e.g., Google Cloud Platform, Azure). Experience with ETL processes and tools. Experience building data visualization reports and dashboards Knowledge of modern data storage solutions and database management systems. Exposure to DevOps practices and tools for deployment and monitoring. Why Join Us? Work with a talented, collaborative team dedicated to making a difference. Gain exposure to innovative technologies and opportunities for growth. Learn and utilize cutting-edge AI tools to enhance your development skills and create impactful solutions. Be part of a company that values your contributions and encourages professional development. Join a rapidly expanding health-tech startup (~200 employees and growing) with a state-of-the-art technology office located in Hyde Park, offering a variety of exceptional benefits. Career Progression Timeline In 3 months: Gain a comprehensive understanding of our data infrastructure, technical stacks, and development cycles. Actively participate in team meetings and contribute to the development of new data pipelines. Begin leveraging AI tools, such as Cursor and ChatGPT, to enhance coding efficiency and workflow automation. In 6 months: Contribute to product enhancements and data reporting Collaborate effectively with cross-functional teams, providing insights and solutions for data-related challenges. Demonstrate proficiency in utilizing AI tools for coding and development, actively sharing knowledge with the team. In 12 months: Contribute to data engineering projects, ensuring scalability and performance optimization. Mentor non-technical internal partners to improve company-wide data literacy Contribute to the integration of advanced AI solutions into our development processes, contributing to the company's technological advancement. Physical Requirements: Ability to remain at your designated workstation for the duration of the workday Constantly operates a computer and other office productivity machinery, such as a phone and Voice over Internet Protocol (VoIP). The ability to communicate information and ideas so others will understand. Must be able to exchange accurate information in these situations. The ability to observe details at close range (typically on a computer screen) This position offers the flexibility of remote work at approved locations within the United States. Candidates must have a reliable internet connection and a designated work environment conducive to professional phone calls and sensitive data. Enjoy the convenience and comfort of working remotely while contributing to our team's success. Apply Today If you’re ready to take on challenging problems, contribute to impactful solutions, and grow as a data engineer, we’d love to hear from you. Join us at The Helper Bees and be part of a team that’s making a meaningful difference every day! The Helper Bees is committed to building a workplace where diversity, equity, and inclusion are valued and prioritized. We are an equal opportunity employer that welcomes all qualified applicants without discrimination based on race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or any non-merit based or legally protected grounds. The Helper Bees provides reasonable accommodations to qualified individuals with disabilities during the job application and interview process. To request accommodation, please let your recruiter know. As part of our standard hiring process, selected candidates may be required to undergo a background check and/or drug screen. The Helper Bees adheres to applicable federal, state, and local laws regarding these screenings, and the results will be considered in accordance with applicable regulations. The Helper Bees was recently made aware of a fraudulent entity posing as our organization and requesting personal information. Please be aware of and protect yourself from scams. Visit thehelperbees.com/careers to view all current job openings. Opened URL: https://www.indeed.com/rc/clk?jk=06050d41e9f16407&bb=1TLRjqutBEYcit1OApAPto3A50Hg4Pzq5qFUF25sU891HTb0FMRKF-y31Tt72Rgj3vRHASDwe2nU2bKOyor677T1mfz6aMuuBmnum2LV6DDSRY1DGNuI6LNVrSB8DuSr&xkcb=SoDU67M33zDWevR-pR0JbzkdCdPP&fccid=61e4e7d2ce056d37&vjs=3",
         "data",
         "Description: Join our winning team, recently honored as #67 on Forbes’ list of America’s Best Startup Employers for 2024! About The Helper Bees The Helper Bees’ mission is to help people stay home longer through data-driven services that transform both the payer and the care-recipient experience. At The Helper Bees, we are reshaping how care is delivered to aging individuals by leveraging innovative technology and insightful data solutions. We maintain multiple SaaS products and payment solutions through our web applications (internal and external facing), a mobile app, and reporting integrations. As part of our growing Data Engineering team, you’ll iterate quickly, have a high impact, and be challenged to design and implement cutting-edge solutions. At THB, we define our company culture through our Core Values: Quickly iterate through solutions: We move at a fast pace which requires quick iterations to find a path to a repeatable solution. Seek ways to create immediate impact: Be thoughtful and proactive in how you make an impact on your team. Actively look for ways to make a fast, positive impact. Bee the teammate you want to work with: We work as a team, help each other, and encourage each other. Ask questions, answer questions: You can't iterate through solutions if you don't ask the right questions, which is why there is an expectation that questions should be asked. When you know the answer, being a good teammate means chiming in to get others up to speed. Take the time to celebrate wins: It's so easy for a team that is heads down to forget about all the great things they've accomplished. That's why we make it a priority to remind ourselves to create space to celebrate wins, big or small. Job Summary We are seeking a motivated Data Engineer to join our team and help improve our tools, processes, and technical infrastructure. In this role, you will ensure the availability and quality of our data while contributing to the design, implementation, and maintenance of The Helper Bees’ products. You’ll collaborate across teams to create scalable and optimized software systems and play a key role in refining our development processes. This position offers a unique opportunity to learn and leverage cutting-edge AI development tools to enhance coding efficiency and develop advanced data tools and solutions. Supervisory Responsibilities: None Key Responsibilities Data Infrastructure: Design, implement, and maintain data pipelines, ensuring data availability, quality, and scalability. Product Development: Build and enhance products using Python, SQL, and modern technologies. AI Integration: Leverage cutting-edge AI tools, including Cursor, ChatGPT, and Claude to improve development processes, automate workflows, and create innovative data solutions. Collaboration: Communicate across departments to design, build, test, and implement new features and enhancements. Code Excellence: Produce quality, testable, and maintainable code while participating in code reviews. Problem Solving: Debug complex issues, interact with stakeholders, and design viable solutions with clear trade-offs. Process Optimization: Contribute to improving development processes, including deployment, on-call systems, and sprint planning. Team Growth: Collaborate within the development team to help each other grow and continuously learn. Stakeholder Engagement: Partner with analysts, scientists, and IT to ensure alignment and deliver data-driven solutions. Other duties as assigned/necessary Performance Metrics Code Quality: Maintain high coding standards through regular code reviews and adherence to best practices. Development Efficiency: Deliver high-quality features and fixes within efficient timeframes. Bug Resolution Time: Reduce the time taken to identify and resolve issues. System Scalability: Optimize system performance to handle increasing user demands. Collaboration: Foster a collaborative environment that encourages teamwork and knowledge sharing. Customer Satisfaction: Incorporate stakeholder feedback to improve solutions and enhance the customer experience. Continuous Learning: Pursue opportunities for skill development and share knowledge with the team. Requirements: Required Skills & Qualifications Technical Tools: Experience with in Python and/or SQL. Experience with Bash, Shell scripting, Big Query, Airflow, and is a plus. Programming: Cleaning data using code-based approach. AI Proficiency: Interest or experience in using AI tools for coding and development of data solutions. Soft Skills: Problem-solving, cross-team collaboration, data storytelling, and stakeholder engagement. Adaptability: Thrives in a fast-paced startup environment and embraces change. Proactivity: Self-directed, organized, and able to prioritize effectively. Collaboration: Ability to work effectively with cross-functional teams. Education & Experience: A bachelor’s degree is required, and a graduate degree is preferred. Relevant experience in data engineering, software development, STEM, or related fields. Strong experience with SQL and Python is highly desirable. Mindset: A passion for innovation, continuous improvement, and delivering high-quality results from messy data. Preferred Qualifications Familiarity with cloud-based solutions (e.g., Google Cloud Platform, Azure). Experience with ETL processes and tools. Experience building data visualization reports and dashboards Knowledge of modern data storage solutions and database management systems. Exposure to DevOps practices and tools for deployment and monitoring. Why Join Us? Work with a talented, collaborative team dedicated to making a difference. Gain exposure to innovative technologies and opportunities for growth. Learn and utilize cutting-edge AI tools to enhance your development skills and create impactful solutions. Be part of a company that values your contributions and encourages professional development. Join a rapidly expanding health-tech startup (~200 employees and growing) with a state-of-the-art technology office located in Hyde Park, offering a variety of exceptional benefits. Career Progression Timeline In 3 months: Gain a comprehensive understanding of our data infrastructure, technical stacks, and development cycles. Actively participate in team meetings and contribute to the development of new data pipelines. Begin leveraging AI tools, such as Cursor and ChatGPT, to enhance coding efficiency and workflow automation. In 6 months: Contribute to product enhancements and data reporting Collaborate effectively with cross-functional teams, providing insights and solutions for data-related challenges. Demonstrate proficiency in utilizing AI tools for coding and development, actively sharing knowledge with the team. In 12 months: Contribute to data engineering projects, ensuring scalability and performance optimization. Mentor non-technical internal partners to improve company-wide data literacy Contribute to the integration of advanced AI solutions into our development processes, contributing to the company's technological advancement. Physical Requirements: Ability to remain at your designated workstation for the duration of the workday Constantly operates a computer and other office productivity machinery, such as a phone and Voice over Internet Protocol (VoIP). The ability to communicate information and ideas so others will understand. Must be able to exchange accurate information in these situations. The ability to observe details at close range (typically on a computer screen) This position offers the flexibility of remote work at approved locations within the United States. Candidates must have a reliable internet connection and a designated work environment conducive to professional phone calls and sensitive data. Enjoy the convenience and comfort of working remotely while contributing to our team's success. Apply Today If you’re ready to take on challenging problems, contribute to impactful solutions, and grow as a data engineer, we’d love to hear from you. Join us at The Helper Bees and be part of a team that’s making a meaningful difference every day! The Helper Bees is committed to building a workplace where diversity, equity, and inclusion are valued and prioritized. We are an equal opportunity employer that welcomes all qualified applicants without discrimination based on race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or any non-merit based or legally protected grounds. The Helper Bees provides reasonable accommodations to qualified individuals with disabilities during the job application and interview process. To request accommodation, please let your recruiter know. As part of our standard hiring process, selected candidates may be required to undergo a background check and/or drug screen. The Helper Bees adheres to applicable federal, state, and local laws regarding these screenings, and the results will be considered in accordance with applicable regulations. The Helper Bees was recently made aware of a fraudulent entity posing as our organization and requesting personal information. Please be aware of and protect yourself from scams. Visit thehelperbees.com/careers to view all current job openings.",
         "Description: Join our winning team, recently honored as #67 on Forbes’ list of America’s Best Startup Employers for 2024! About The Helper Bees The Helper Bees’ mission is to help people stay home longer through data-driven services that transform both the payer and the care-recipient experience. At The Helper Bees, we are reshaping how care is delivered to aging individuals by leveraging innovative technology and insightful data solutions. We maintain multiple SaaS products and payment solutions through our web applications (internal and external facing), a mobile app, and reporting integrations. As part of our growing Data Engineering team, you’ll iterate quickly, have a high impact, and be challenged to design and implement cutting-edge solutions. At THB, we define our company culture through our Core Values: Quickly iterate through solutions: We move at a fast pace which requires quick iterations to find a path to a repeatable solution. Seek ways to create immediate impact: Be thoughtful and proactive in how you make an impact on your team. Actively look for ways to make a fast, positive impact. Bee the teammate you want to work with: We work as a team, help each other, and encourage each other. Ask questions, answer questions: You can't iterate through solutions if you don't ask the right questions, which is why there is an expectation that questions should be asked. When you know the answer, being a good teammate means chiming in to get others up to speed. Take the time to celebrate wins: It's so easy for a team that is heads down to forget about all the great things they've accomplished. That's why we make it a priority to remind ourselves to create space to celebrate wins, big or small. Job Summary We are seeking a motivated Data Engineer to join our team and help improve our tools, processes, and technical infrastructure. In this role, you will ensure the availability and quality of our data while contributing to the design, implementation, and maintenance of The Helper Bees’ products. You’ll collaborate across teams to create scalable and optimized software systems and play a key role in refining our development processes. This position offers a unique opportunity to learn and leverage cutting-edge AI development tools to enhance coding efficiency and develop advanced data tools and solutions. Supervisory Responsibilities: None Key Responsibilities Data Infrastructure: Design, implement, and maintain data pipelines, ensuring data availability, quality, and scalability. Product Development: Build and enhance products using Python, SQL, and modern technologies. AI Integration: Leverage cutting-edge AI tools, including Cursor, ChatGPT, and Claude to improve development processes, automate workflows, and create innovative data solutions. Collaboration: Communicate across departments to design, build, test, and implement new features and enhancements. Code Excellence: Produce quality, testable, and maintainable code while participating in code reviews. Problem Solving: Debug complex issues, interact with stakeholders, and design viable solutions with clear trade-offs. Process Optimization: Contribute to improving development processes, including deployment, on-call systems, and sprint planning. Team Growth: Collaborate within the development team to help each other grow and continuously learn. Stakeholder Engagement: Partner with analysts, scientists, and IT to ensure alignment and deliver data-driven solutions. Other duties as assigned/necessary Performance Metrics Code Quality: Maintain high coding standards through regular code reviews and adherence to best practices. Development Efficiency: Deliver high-quality features and fixes within efficient timeframes. Bug Resolution Time: Reduce the time taken to identify and resolve issues. System Scalability: Optimize system performance to handle increasing user demands. Collaboration: Foster a collaborative environment that encourages teamwork and knowledge sharing. Customer Satisfaction: Incorporate stakeholder feedback to improve solutions and enhance the customer experience. Continuous Learning: Pursue opportunities for skill development and share knowledge with the team. Requirements: Required Skills & Qualifications Technical Tools: Experience with in Python and/or SQL. Experience with Bash, Shell scripting, Big Query, Airflow, and is a plus. Programming: Cleaning data using code-based approach. AI Proficiency: Interest or experience in using AI tools for coding and development of data solutions. Soft Skills: Problem-solving, cross-team collaboration, data storytelling, and stakeholder engagement. Adaptability: Thrives in a fast-paced startup environment and embraces change. Proactivity: Self-directed, organized, and able to prioritize effectively. Collaboration: Ability to work effectively with cross-functional teams. Education & Experience: A bachelor’s degree is required, and a graduate degree is preferred. Relevant experience in data engineering, software development, STEM, or related fields. Strong experience with SQL and Python is highly desirable. Mindset: A passion for innovation, continuous improvement, and delivering high-quality results from messy data. Preferred Qualifications Familiarity with cloud-based solutions (e.g., Google Cloud Platform, Azure). Experience with ETL processes and tools. Experience building data visualization reports and dashboards Knowledge of modern data storage solutions and database management systems. Exposure to DevOps practices and tools for deployment and monitoring. Why Join Us? Work with a talented, collaborative team dedicated to making a difference. Gain exposure to innovative technologies and opportunities for growth. Learn and utilize cutting-edge AI tools to enhance your development skills and create impactful solutions. Be part of a company that values your contributions and encourages professional development. Join a rapidly expanding health-tech startup (~200 employees and growing) with a state-of-the-art technology office located in Hyde Park, offering a variety of exceptional benefits. Career Progression Timeline In 3 months: Gain a comprehensive understanding of our data infrastructure, technical stacks, and development cycles. Actively participate in team meetings and contribute to the development of new data pipelines. Begin leveraging AI tools, such as Cursor and ChatGPT, to enhance coding efficiency and workflow automation. In 6 months: Contribute to product enhancements and data reporting Collaborate effectively with cross-functional teams, providing insights and solutions for data-related challenges. Demonstrate proficiency in utilizing AI tools for coding and development, actively sharing knowledge with the team. In 12 months: Contribute to data engineering projects, ensuring scalability and performance optimization. Mentor non-technical internal partners to improve company-wide data literacy Contribute to the integration of advanced AI solutions into our development processes, contributing to the company's technological advancement. Physical Requirements: Ability to remain at your designated workstation for the duration of the workday Constantly operates a computer and other office productivity machinery, such as a phone and Voice over Internet Protocol (VoIP). The ability to communicate information and ideas so others will understand. Must be able to exchange accurate information in these situations. The ability to observe details at close range (typically on a computer screen) This position offers the flexibility of remote work at approved locations within the United States. Candidates must have a reliable internet connection and a designated work environment conducive to professional phone calls and sensitive data. Enjoy the convenience and comfort of working remotely while contributing to our team's success. Apply Today If you’re ready to take on challenging problems, contribute to impactful solutions, and grow as a data engineer, we’d love to hear from you. Join us at The Helper Bees and be part of a team that’s making a meaningful difference every day! The Helper Bees is committed to building a workplace where diversity, equity, and inclusion are valued and prioritized. We are an equal opportunity employer that welcomes all qualified applicants without discrimination based on race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or any non-merit based or legally protected grounds. The Helper Bees provides reasonable accommodations to qualified individuals with disabilities during the job application and interview process. To request accommodation, please let your recruiter know. As part of our standard hiring process, selected candidates may be required to undergo a background check and/or drug screen. The Helper Bees adheres to applicable federal, state, and local laws regarding these screenings, and the results will be considered in accordance with applicable regulations. The Helper Bees was recently made aware of a fraudulent entity posing as our organization and requesting personal information. Please be aware of and protect yourself from scams. Visit thehelperbees.com/careers to view all current job openings.",
         "Technical Tools: Experience with in Python and/or SQL. Experience with Bash, Shell scripting, Big Query, Airflow, and is a plus. Programming: Cleaning data using code-based approach. AI Proficiency: Interest or experience in using AI tools for coding and development of data solutions. Soft Skills: Problem-solving, cross-team collaboration, data storytelling, and stakeholder engagement. Adaptability: Thrives in a fast-paced startup environment and embraces change. Proactivity: Self-directed, organized, and able to prioritize effectively. Collaboration: Ability to work effectively with cross-functional teams. Education & Experience: A bachelor’s degree is required, and a graduate degree is preferred. Relevant experience in data engineering, software development, STEM, or related fields. Strong experience with SQL and Python is highly desirable. Mindset: A passion for innovation, continuous improvement, and delivering high-quality results from messy data. Preferred Qualifications Familiarity with cloud-based solutions (e.g., Google Cloud Platform, Azure). Experience with ETL processes and tools. Experience building data visualization reports and dashboards Knowledge of modern data storage solutions and database management systems. Exposure to DevOps practices and tools for deployment and monitoring. Why Join Us? Work with a talented, collaborative team dedicated to making a difference. Gain exposure to innovative technologies and opportunities for growth. Learn and utilize cutting-edge AI tools to enhance your development skills and create impactful solutions. Be part of a company that values your contributions and encourages professional development. Join a rapidly expanding health-tech startup (~200 employees and growing) with a state-of-the-art technology office located in Hyde Park, offering a variety of exceptional benefits. Career Progression Timeline In 3 months: Gain a comprehensive understanding of our data infrastructure, technical stacks, and development cycles. Actively participate in team meetings and contribute to the development of new data pipelines. Begin leveraging AI tools, such as Cursor and ChatGPT, to enhance coding efficiency and workflow automation. In 6 months: Contribute to product enhancements and data reporting Collaborate effectively with cross-functional teams, providing insights and solutions for data-related challenges. Demonstrate proficiency in utilizing AI tools for coding and development, actively sharing knowledge with the team. In 12 months: Contribute to data engineering projects, ensuring scalability and performance optimization. Mentor non-technical internal partners to improve company-wide data literacy Contribute to the integration of advanced AI solutions into our development processes, contributing to the company's technological advancement. Physical Requirements: Ability to remain at your designated workstation for the duration of the workday Constantly operates a computer and other office productivity machinery, such as a phone and Voice over Internet Protocol (VoIP). The ability to communicate information and ideas so others will understand. Must be able to exchange accurate information in these situations. The ability to observe details at close range (typically on a computer screen) This position offers the flexibility of remote work at approved locations within the United States. Candidates must have a reliable internet connection and a designated work environment conducive to professional phone calls and sensitive data. Enjoy the convenience and comfort of working remotely while contributing to our team's success. Apply Today If you’re ready to take on challenging problems, contribute to impactful solutions, and grow as a data engineer, we’d love to hear from you. Join us at The Helper Bees and be part of a team that’s making a meaningful difference every day! The Helper Bees is committed to building a workplace where diversity, equity, and inclusion are valued and prioritized. We are an equal opportunity employer that welcomes all qualified applicants without discrimination based on race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or any non-merit based or legally protected grounds. The Helper Bees provides reasonable accommodations to qualified individuals with disabilities during the job application and interview process. To request accommodation, please let your recruiter know. As part of our standard hiring process, selected candidates may be required to undergo a background check and/or drug screen. The Helper Bees adheres to applicable federal, state, and local laws regarding these screenings, and the results will be considered in accordance with applicable regulations. The Helper Bees was recently made aware of a fraudulent entity posing as our organization and requesting personal information. Please be aware of and protect yourself from scams. Visit thehelperbees.com/careers to view all current job openings.",
         698
        ],
        [
         null,
         "experience",
         "SUMMARY: ABOUT Healthcare is seeking a skilled and innovative Data Scientist to help expand our predictive analytics capabilities and advance our mission to revolutionize hospital operations. This role will work at the intersection of AI/ML, healthcare, and operations to develop and scale machine learning models that deliver actionable insights to hospitals. ESSENTIAL FUNCTIONS : This class specification lists the major duties and requirements of the job and is not all-inclusive. Incumbent(s) may be expected to perform job-related duties other than those contained in this document and may be required to have specific job-related knowledge and skills. Predictive Analytics Development : Build and refine machine learning models for hourly discharge forecasting, aggregate hospital admission/discharge predictions, and patient-level progress tracking. Data Exploration : Analyze complex healthcare datasets to identify trends, challenges, and actionable opportunities. Model Deployment : Collaborate with engineers to deploy AI/ML solutions into production, ensuring reliability and scalability. Collaboration : Partner with product managers, operations teams, and customers to define and implement data-driven features and metrics. Feature Engineering : Work with AWS infrastructure (S3, Glue, Athena, Timestream, Bedrock, Nova, SageMaker) to standardize data pipelines and enrich machine learning models. Continuous Improvement : Optimize model accuracy and efficiency through testing, monitoring, and iteration. Documentation and Communication : Present technical findings and recommendations to stakeholders in an easily understandable way. LLMs: Demonstrate experience and depth in building products through applying LLMs or other AI domains like NLP, ML or deep learning. Full Stack: Capable as a full-stack engineer, seeing LLM implementations from concept to production. Perform other duties as assigned. QUALIFICATIONS: To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The requirements listed below are representative of the knowledge, skill, and/or ability required. Need to Have: Bachelor’s in data science, Computer Science, Statistics, or related field (or equivalent experience). 1+ years of experience developing and deploying machine learning models in production. Proficiency in Python (or R), SQL, and common ML libraries (e.g., Scikit-learn, TensorFlow, PyTorch). Experience working with cloud technologies, particularly AWS (e.g., S3, Glue, Timestream, Bedrock, Nova, sageMaker). Strong analytical skills and ability to interpret complex datasets. Knowledge of ETL processes, feature engineering, and real-time forecasting methods. Excellent communication skills with the ability to present technical concepts to non-technical stakeholders. Nice to Have: Experience in healthcare data analytics or hospital operations. Familiarity with EHR/EMR data or healthcare interoperability standards. Knowledge of time-series modeling and ensemble methods. Exposure to data visualization tools (e.g., Tableau, Power BI). Understanding of Agile methodologies and collaborative software development. Required Knowledge and Skills Required Knowledge: Correct business English, including spelling, grammar and punctuation. Medical Terminology Health system operating and working models Business planning and development Required Skills: Using initiative and independent judgment within established department guidelines. Contributing effectively to the accomplishment of team or work unit goals, objectives and activities. Establishing and maintaining effective working relationships with a variety of individuals. PHYSICAL/MENTAL REQUIREMENTS: The physical demands described herein are representative of those that must be met by an employee to successfully perform the essential functions of the job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions. Mobility to work in an office setting, use standard office equipment and stamina to sit for extended periods of time; strength to lift and carry up to 10 pounds; vision to read printed materials and computer screens; and hearing and speech to communicate in person or over the telephone. Travel as needed to support company and customer initiatives. Work on Site at our St Paul office may be required and ABOUT reserves the right to change the location of the role at any time. This role may involve work on federal government contracts that require additional federal background investigations, training, and federal badging. As such, you may be required to submit personal information to the government and be fingerprinted and photographed at your local Department of Veteran Affairs Medical Center. ABOUT is also an Equal Employment Opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, age, national origin, protected veteran status, disability status, sexual orientation, gender identity or expression, marital status, genetic information, or any other characteristic protected by law. ABOUT offers a flexible, purpose-built solution that empowers hospitals and health systems to operate as one connected network of care. We enable easy access for clinicians to move patients into and out of the acute care setting - getting them to the next, best care setting faster and easier. Complemented by our clinical experts and best practices, we provide health systems the necessary controls and insights to grow with resilience, drive clinician effectiveness, and improve patient outcomes. __________________________________________________________________________________________________________________________________ Opened URL: https://www.indeed.com/rc/clk?jk=b7ccd9fcd1afced7&bb=1TLRjqutBEYcit1OApAPtqrHYylbIkCH-hjMPAlsxl27fhhbmpR2ESoGFPzZ8_yAHfmXJJR-sxCiyJrJbrdNtoLq2VLDYGJB8eFEb_NompMj9I3HutPP1GvnnhForEvK&xkcb=SoAu67M33zDWevR-pR0CbzkdCdPP&fccid=4a4b722c7189c738&vjs=3",
         "data",
         "SUMMARY: ABOUT Healthcare is seeking a skilled and innovative Data Scientist to help expand our predictive analytics capabilities and advance our mission to revolutionize hospital operations. This role will work at the intersection of AI/ML, healthcare, and operations to develop and scale machine learning models that deliver actionable insights to hospitals. ESSENTIAL FUNCTIONS : This class specification lists the major duties and requirements of the job and is not all-inclusive. Incumbent(s) may be expected to perform job-related duties other than those contained in this document and may be required to have specific job-related knowledge and skills. Predictive Analytics Development : Build and refine machine learning models for hourly discharge forecasting, aggregate hospital admission/discharge predictions, and patient-level progress tracking. Data Exploration : Analyze complex healthcare datasets to identify trends, challenges, and actionable opportunities. Model Deployment : Collaborate with engineers to deploy AI/ML solutions into production, ensuring reliability and scalability. Collaboration : Partner with product managers, operations teams, and customers to define and implement data-driven features and metrics. Feature Engineering : Work with AWS infrastructure (S3, Glue, Athena, Timestream, Bedrock, Nova, SageMaker) to standardize data pipelines and enrich machine learning models. Continuous Improvement : Optimize model accuracy and efficiency through testing, monitoring, and iteration. Documentation and Communication : Present technical findings and recommendations to stakeholders in an easily understandable way. LLMs: Demonstrate experience and depth in building products through applying LLMs or other AI domains like NLP, ML or deep learning. Full Stack: Capable as a full-stack engineer, seeing LLM implementations from concept to production. Perform other duties as assigned. QUALIFICATIONS: To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The requirements listed below are representative of the knowledge, skill, and/or ability required. Need to Have: Bachelor’s in data science, Computer Science, Statistics, or related field (or equivalent experience). 1+ years of experience developing and deploying machine learning models in production. Proficiency in Python (or R), SQL, and common ML libraries (e.g., Scikit-learn, TensorFlow, PyTorch). Experience working with cloud technologies, particularly AWS (e.g., S3, Glue, Timestream, Bedrock, Nova, sageMaker). Strong analytical skills and ability to interpret complex datasets. Knowledge of ETL processes, feature engineering, and real-time forecasting methods. Excellent communication skills with the ability to present technical concepts to non-technical stakeholders. Nice to Have: Experience in healthcare data analytics or hospital operations. Familiarity with EHR/EMR data or healthcare interoperability standards. Knowledge of time-series modeling and ensemble methods. Exposure to data visualization tools (e.g., Tableau, Power BI). Understanding of Agile methodologies and collaborative software development. Required Knowledge and Skills Required Knowledge: Correct business English, including spelling, grammar and punctuation. Medical Terminology Health system operating and working models Business planning and development Required Skills: Using initiative and independent judgment within established department guidelines. Contributing effectively to the accomplishment of team or work unit goals, objectives and activities. Establishing and maintaining effective working relationships with a variety of individuals. PHYSICAL/MENTAL REQUIREMENTS: The physical demands described herein are representative of those that must be met by an employee to successfully perform the essential functions of the job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions. Mobility to work in an office setting, use standard office equipment and stamina to sit for extended periods of time; strength to lift and carry up to 10 pounds; vision to read printed materials and computer screens; and hearing and speech to communicate in person or over the telephone. Travel as needed to support company and customer initiatives. Work on Site at our St Paul office may be required and ABOUT reserves the right to change the location of the role at any time. This role may involve work on federal government contracts that require additional federal background investigations, training, and federal badging. As such, you may be required to submit personal information to the government and be fingerprinted and photographed at your local Department of Veteran Affairs Medical Center. ABOUT is also an Equal Employment Opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, age, national origin, protected veteran status, disability status, sexual orientation, gender identity or expression, marital status, genetic information, or any other characteristic protected by law. ABOUT offers a flexible, purpose-built solution that empowers hospitals and health systems to operate as one connected network of care. We enable easy access for clinicians to move patients into and out of the acute care setting - getting them to the next, best care setting faster and easier. Complemented by our clinical experts and best practices, we provide health systems the necessary controls and insights to grow with resilience, drive clinician effectiveness, and improve patient outcomes. __________________________________________________________________________________________________________________________________",
         "SUMMARY: ABOUT Healthcare is seeking a skilled and innovative Data Scientist to help expand our predictive analytics capabilities and advance our mission to revolutionize hospital operations. This role will work at the intersection of AI/ML, healthcare, and operations to develop and scale machine learning models that deliver actionable insights to hospitals. ESSENTIAL FUNCTIONS : This class specification lists the major duties and requirements of the job and is not all-inclusive. Incumbent(s) may be expected to perform job-related duties other than those contained in this document and may be required to have specific job-related knowledge and skills. Predictive Analytics Development : Build and refine machine learning models for hourly discharge forecasting, aggregate hospital admission/discharge predictions, and patient-level progress tracking. Data Exploration : Analyze complex healthcare datasets to identify trends, challenges, and actionable opportunities. Model Deployment : Collaborate with engineers to deploy AI/ML solutions into production, ensuring reliability and scalability. Collaboration : Partner with product managers, operations teams, and customers to define and implement data-driven features and metrics. Feature Engineering : Work with AWS infrastructure (S3, Glue, Athena, Timestream, Bedrock, Nova, SageMaker) to standardize data pipelines and enrich machine learning models. Continuous Improvement : Optimize model accuracy and efficiency through testing, monitoring, and iteration. Documentation and Communication : Present technical findings and recommendations to stakeholders in an easily understandable way. LLMs: Demonstrate experience and depth in building products through applying LLMs or other AI domains like NLP, ML or deep learning. Full Stack: Capable as a full-stack engineer, seeing LLM implementations from concept to production. Perform other duties as assigned. QUALIFICATIONS: To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The requirements listed below are representative of the knowledge, skill, and/or ability required. Need to Have: Bachelor’s in data science, Computer Science, Statistics, or related field (or equivalent experience). 1+ years of experience developing and deploying machine learning models in production. Proficiency in Python (or R), SQL, and common ML libraries (e.g., Scikit-learn, TensorFlow, PyTorch). Experience working with cloud technologies, particularly AWS (e.g., S3, Glue, Timestream, Bedrock, Nova, sageMaker). Strong analytical skills and ability to interpret complex datasets. Knowledge of ETL processes, feature engineering, and real-time forecasting methods. Excellent communication skills with the ability to present technical concepts to non-technical stakeholders. Nice to Have: Experience in healthcare data analytics or hospital operations. Familiarity with EHR/EMR data or healthcare interoperability standards. Knowledge of time-series modeling and ensemble methods. Exposure to data visualization tools (e.g., Tableau, Power BI). Understanding of Agile methodologies and collaborative software development. Required Knowledge and Skills Required Knowledge: Correct business English, including spelling, grammar and punctuation. Medical Terminology Health system operating and working models Business planning and development Required Skills: Using initiative and independent judgment within established department guidelines. Contributing effectively to the accomplishment of team or work unit goals, objectives and activities. Establishing and maintaining effective working relationships with a variety of individuals. PHYSICAL/MENTAL REQUIREMENTS: The physical demands described herein are representative of those that must be met by an employee to successfully perform the essential functions of the job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions. Mobility to work in an office setting, use standard office equipment and stamina to sit for extended periods of time; strength to lift and carry up to 10 pounds; vision to read printed materials and computer screens; and hearing and speech to communicate in person or over the telephone. Travel as needed to support company and customer initiatives. Work on Site at our St Paul office may be required and ABOUT reserves the right to change the location of the role at any time. This role may involve work on federal government contracts that require additional federal background investigations, training, and federal badging. As such, you may be required to submit personal information to the government and be fingerprinted and photographed at your local Department of Veteran Affairs Medical Center. ABOUT is also an Equal Employment Opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, age, national origin, protected veteran status, disability status, sexual orientation, gender identity or expression, marital status, genetic information, or any other characteristic protected by law. ABOUT offers a flexible, purpose-built solution that empowers hospitals and health systems to operate as one connected network of care. We enable easy access for clinicians to move patients into and out of the acute care setting - getting them to the next, best care setting faster and easier. Complemented by our clinical experts and best practices, we provide health systems the necessary controls and insights to grow with resilience, drive clinician effectiveness, and improve patient outcomes. __________________________________________________________________________________________________________________________________",
         "To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The requirements listed below are representative of the knowledge, skill, and/or ability required. Need to Have: Bachelor’s in data science, Computer Science, Statistics, or related field (or equivalent experience). 1+ years of experience developing and deploying machine learning models in production. Proficiency in Python (or R), SQL, and common ML libraries (e.g., Scikit-learn, TensorFlow, PyTorch). Experience working with cloud technologies, particularly AWS (e.g., S3, Glue, Timestream, Bedrock, Nova, sageMaker). Strong analytical skills and ability to interpret complex datasets. Knowledge of ETL processes, feature engineering, and real-time forecasting methods. Excellent communication skills with the ability to present technical concepts to non-technical stakeholders. Nice to Have: Experience in healthcare data analytics or hospital operations. Familiarity with EHR/EMR data or healthcare interoperability standards. Knowledge of time-series modeling and ensemble methods. Exposure to data visualization tools (e.g., Tableau, Power BI). Understanding of Agile methodologies and collaborative software development. Required Knowledge and Skills Required Knowledge: Correct business English, including spelling, grammar and punctuation. Medical Terminology Health system operating and working models Business planning and development Required Skills: Using initiative and independent judgment within established department guidelines. Contributing effectively to the accomplishment of team or work unit goals, objectives and activities. Establishing and maintaining effective working relationships with a variety of individuals. PHYSICAL/MENTAL REQUIREMENTS: The physical demands described herein are representative of those that must be met by an employee to successfully perform the essential functions of the job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions. Mobility to work in an office setting, use standard office equipment and stamina to sit for extended periods of time; strength to lift and carry up to 10 pounds; vision to read printed materials and computer screens; and hearing and speech to communicate in person or over the telephone. Travel as needed to support company and customer initiatives. Work on Site at our St Paul office may be required and ABOUT reserves the right to change the location of the role at any time. This role may involve work on federal government contracts that require additional federal background investigations, training, and federal badging. As such, you may be required to submit personal information to the government and be fingerprinted and photographed at your local Department of Veteran Affairs Medical Center. ABOUT is also an Equal Employment Opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, age, national origin, protected veteran status, disability status, sexual orientation, gender identity or expression, marital status, genetic information, or any other characteristic protected by law. ABOUT offers a flexible, purpose-built solution that empowers hospitals and health systems to operate as one connected network of care. We enable easy access for clinicians to move patients into and out of the acute care setting - getting them to the next, best care setting faster and easier. Complemented by our clinical experts and best practices, we provide health systems the necessary controls and insights to grow with resilience, drive clinician effectiveness, and improve patient outcomes. __________________________________________________________________________________________________________________________________",
         521
        ],
        [
         null,
         ".",
         "The Krusteaz Company is seeking a Senior Data Engineer to lead the architecture and development of our enterprise data strategy. Reporting to the Director of Enterprise Applications and Data Management, this role will play a key role in design, delivery, and management of our enterprise data strategy and solution(s). As a key contributor to our digital transformation, this role will take the lead in designing data structure, design, and ingestion, reporting processes and standards for the organization working across both the IT development, infrastructure, and analyst teams. As a senior member of the IT team, this role will be instrumental in promoting agility, scalability, and operational excellence. This role will also be a key contributor in our business transformation, working closely with our IT Business Analysts to understand the challenges facing our business partners and developing scalable and repeatable data solutions to meet their needs. This role will be a trusted partner to your peers within the IT team, demonstrating the ability to provide both conceptual and technical mentorship. Essential Functions : Other duties, responsibilities, and activities may change or be assigned at any time. Maintain and build on our data warehouse and analytics environment. Design, implement, test, deploy, and maintain stable, secure, and scalable data engineering solutions and pipelines. Build reports and data visualizations, using data from the data warehouse and other sources. Produce scalable, replicable code and engineering solutions that help automate repetitive data management tasks. Implement and monitor best in class security measures in our data warehouse and analytics environment. Provide direct input on the IT technology roadmap, helping ensure we make appropriate investments in build vs. buy decisions. Define and document best practices and strategies. Keep apprised of trends, identifies best-in class capabilities, opportunities and technology that may benefit The Krusteaz Company. Provide guidance, thought leadership, and mentorship to development and infrastructure teams to build EDW and development competencies. Position Requirements To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The requirements listed below are representative of the knowledge, skill, and/or ability required. Reasonable accommodations may be made to enable individuals qualified with disabilities to perform the essential functions. Proven success in developing technical solutions with a ‘cloud first’ mindset. Deep understanding of cloud data warehousing and ETL best practices, including system reliability and scalability. Ensuring data quality and consistency across various sources. Ability to function effectively as a change agent and problem solver within your team and across IT and the business. Excellent written, verbal, communication, and presentation skills with the ability to think critically, problem solve, and articulate new ideas and concepts to technical and non-technical audiences. Education and/or Experience: Bachelor’s degree in computer science, information technology, mathematics, or progressive relevant work experience. 8+ years of development experience required. 5+ years’ experience working with public cloud providers (Azure, Oracle Cloud, etc.). 5+ years’ experience in data pipeline development, including languages such as Python and R, and tools such as Airflow and SSIS. 5+ years Data Warehousing and ETL experience, preferably with large transactional datasets. Familiarity working in both Windows and Linux environments. Direct experience working with both traditional and agile methodologies required. Experience within the manufacturing industry, including knowledge in supply chain, procurement, and logistics is preferred but not required. Physical Demands and Work Environment: While performing the duties of this job, the employee is regularly required to stand, sit, talk, hear, and use hands and fingers to operate a computer and telephone along with reaching. Specific vision abilities include close vision requirements due to computer work. Moderate noise, ability to work in a confined area, and ability to sit at a computer for an extended period of time are also included. The policy of The Krusteaz Company is to hire, train, and promote all persons in all job groups in accordance with law, without regard to race, color, religion, sex, sexual orientation, age, marital or military status, national origin, gender identity, the presence of any sensory, mental or physical disability, genetic information, or any other status or characteristic protected by local, state, or federal law. Get to know us: A people-focused company that cares: We're a 90-year-old company with the entrepreneurial spirit of a startup and a focused eye on the future. As a midsized, privately held company with a portfolio of beloved food and beverage brands, our people are the most important ingredient in our success. A valued and supported workforce : We place tremendous value in our employees and provide competitive pay and comprehensive benefits to ensure our employees can create the best life for themselves. Benefits include a top tier health insurance plan with lower-than-average employee cost share, generous PTO, 401(k) match, and more. An engaged and energized culture: At The Krusteaz Company, collaboration and ingenuity drive our fierce commitment to creating extraordinary product experiences that people love. A place to grow and make a difference: An entrepreneurial spirit has been at the core of our company since the beginning, attracting self-starters who are curious and love to learn and to share ideas. Hybrid Work Model: At The Krusteaz Company, we have in-office \"core days\" of Tuesdays and Wednesdays where all corporate employees are expected to be onsite. Mondays, Thursdays, and Fridays are flexible remote days to allow for work/life balance. You may be asked to come in outside of a core day from time to time, based on business needs. We have found aligning our scheduled in-office days provides opportunity for employees to build connections and collaborate together. Benefits: We are proud to offer generous benefits including comprehensive medical, dental, and vision insurance (starting at $50/month for employee only coverage on the PPO Plan or starting at $25/month for employee only coverage on the HDHP), 401(K) matching, 3 weeks of paid vacation, 10 paid holidays, company provided life insurance and disability insurance, flexible spending account, healthcare saving account, voluntary accident insurance, voluntary critical illness insurance, and tuition reimbursement. Salary Information: An employee in this position can expect a salary range between $126,101 and $208,055. We typically pay out between $142,000 and $180,000. The actual salary offered will carefully consider a wide range of factors, including internal equity, experience, education, certification, training, and location. All positions are eligible for additional incentives based on business performance. We hope you'll take the time to get to know us! The Krusteaz Company is not sponsoring new applicant employment authorization at this time and please, no third-party recruiters. Opened URL: https://www.indeed.com/rc/clk?jk=042c410f50c0faa6&bb=1TLRjqutBEYcit1OApAPtt6B4oNDQ9pvplvzh521n9octR12bdC8X0WPxpzUuEahEqtE5IkoxGLcfct2Fl3E3ERVE0CDNI3ufYlz_WxpqD2cHp3NqHNahE2fQxTMaZ59&xkcb=SoAH67M33zDWevR-pR0AbzkdCdPP&fccid=9e189ac6632e8eb3&vjs=3",
         "data",
         "The Krusteaz Company is seeking a Senior Data Engineer to lead the architecture and development of our enterprise data strategy. Reporting to the Director of Enterprise Applications and Data Management, this role will play a key role in design, delivery, and management of our enterprise data strategy and solution(s). As a key contributor to our digital transformation, this role will take the lead in designing data structure, design, and ingestion, reporting processes and standards for the organization working across both the IT development, infrastructure, and analyst teams. As a senior member of the IT team, this role will be instrumental in promoting agility, scalability, and operational excellence. This role will also be a key contributor in our business transformation, working closely with our IT Business Analysts to understand the challenges facing our business partners and developing scalable and repeatable data solutions to meet their needs. This role will be a trusted partner to your peers within the IT team, demonstrating the ability to provide both conceptual and technical mentorship. Essential Functions : Other duties, responsibilities, and activities may change or be assigned at any time. Maintain and build on our data warehouse and analytics environment. Design, implement, test, deploy, and maintain stable, secure, and scalable data engineering solutions and pipelines. Build reports and data visualizations, using data from the data warehouse and other sources. Produce scalable, replicable code and engineering solutions that help automate repetitive data management tasks. Implement and monitor best in class security measures in our data warehouse and analytics environment. Provide direct input on the IT technology roadmap, helping ensure we make appropriate investments in build vs. buy decisions. Define and document best practices and strategies. Keep apprised of trends, identifies best-in class capabilities, opportunities and technology that may benefit The Krusteaz Company. Provide guidance, thought leadership, and mentorship to development and infrastructure teams to build EDW and development competencies. Position Requirements To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The requirements listed below are representative of the knowledge, skill, and/or ability required. Reasonable accommodations may be made to enable individuals qualified with disabilities to perform the essential functions. Proven success in developing technical solutions with a ‘cloud first’ mindset. Deep understanding of cloud data warehousing and ETL best practices, including system reliability and scalability. Ensuring data quality and consistency across various sources. Ability to function effectively as a change agent and problem solver within your team and across IT and the business. Excellent written, verbal, communication, and presentation skills with the ability to think critically, problem solve, and articulate new ideas and concepts to technical and non-technical audiences. Education and/or Experience: Bachelor’s degree in computer science, information technology, mathematics, or progressive relevant work experience. 8+ years of development experience required. 5+ years’ experience working with public cloud providers (Azure, Oracle Cloud, etc.). 5+ years’ experience in data pipeline development, including languages such as Python and R, and tools such as Airflow and SSIS. 5+ years Data Warehousing and ETL experience, preferably with large transactional datasets. Familiarity working in both Windows and Linux environments. Direct experience working with both traditional and agile methodologies required. Experience within the manufacturing industry, including knowledge in supply chain, procurement, and logistics is preferred but not required. Physical Demands and Work Environment: While performing the duties of this job, the employee is regularly required to stand, sit, talk, hear, and use hands and fingers to operate a computer and telephone along with reaching. Specific vision abilities include close vision requirements due to computer work. Moderate noise, ability to work in a confined area, and ability to sit at a computer for an extended period of time are also included. The policy of The Krusteaz Company is to hire, train, and promote all persons in all job groups in accordance with law, without regard to race, color, religion, sex, sexual orientation, age, marital or military status, national origin, gender identity, the presence of any sensory, mental or physical disability, genetic information, or any other status or characteristic protected by local, state, or federal law. Get to know us: A people-focused company that cares: We're a 90-year-old company with the entrepreneurial spirit of a startup and a focused eye on the future. As a midsized, privately held company with a portfolio of beloved food and beverage brands, our people are the most important ingredient in our success. A valued and supported workforce : We place tremendous value in our employees and provide competitive pay and comprehensive benefits to ensure our employees can create the best life for themselves. Benefits include a top tier health insurance plan with lower-than-average employee cost share, generous PTO, 401(k) match, and more. An engaged and energized culture: At The Krusteaz Company, collaboration and ingenuity drive our fierce commitment to creating extraordinary product experiences that people love. A place to grow and make a difference: An entrepreneurial spirit has been at the core of our company since the beginning, attracting self-starters who are curious and love to learn and to share ideas. Hybrid Work Model: At The Krusteaz Company, we have in-office \"core days\" of Tuesdays and Wednesdays where all corporate employees are expected to be onsite. Mondays, Thursdays, and Fridays are flexible remote days to allow for work/life balance. You may be asked to come in outside of a core day from time to time, based on business needs. We have found aligning our scheduled in-office days provides opportunity for employees to build connections and collaborate together. Benefits: We are proud to offer generous benefits including comprehensive medical, dental, and vision insurance (starting at $50/month for employee only coverage on the PPO Plan or starting at $25/month for employee only coverage on the HDHP), 401(K) matching, 3 weeks of paid vacation, 10 paid holidays, company provided life insurance and disability insurance, flexible spending account, healthcare saving account, voluntary accident insurance, voluntary critical illness insurance, and tuition reimbursement. Salary Information: An employee in this position can expect a salary range between $126,101 and $208,055. We typically pay out between $142,000 and $180,000. The actual salary offered will carefully consider a wide range of factors, including internal equity, experience, education, certification, training, and location. All positions are eligible for additional incentives based on business performance. We hope you'll take the time to get to know us! The Krusteaz Company is not sponsoring new applicant employment authorization at this time and please, no third-party recruiters.",
         "The Krusteaz Company is seeking a Senior Data Engineer to lead the architecture and development of our enterprise data strategy. Reporting to the Director of Enterprise Applications and Data Management, this role will play a key role in design, delivery, and management of our enterprise data strategy and solution(s). As a key contributor to our digital transformation, this role will take the lead in designing data structure, design, and ingestion, reporting processes and standards for the organization working across both the IT development, infrastructure, and analyst teams. As a senior member of the IT team, this role will be instrumental in promoting agility, scalability, and operational excellence. This role will also be a key contributor in our business transformation, working closely with our IT Business Analysts to understand the challenges facing our business partners and developing scalable and repeatable data solutions to meet their needs. This role will be a trusted partner to your peers within the IT team, demonstrating the ability to provide both conceptual and technical mentorship. Essential Functions : Other duties, responsibilities, and activities may change or be assigned at any time. Maintain and build on our data warehouse and analytics environment. Design, implement, test, deploy, and maintain stable, secure, and scalable data engineering solutions and pipelines. Build reports and data visualizations, using data from the data warehouse and other sources. Produce scalable, replicable code and engineering solutions that help automate repetitive data management tasks. Implement and monitor best in class security measures in our data warehouse and analytics environment. Provide direct input on the IT technology roadmap, helping ensure we make appropriate investments in build vs. buy decisions. Define and document best practices and strategies. Keep apprised of trends, identifies best-in class capabilities, opportunities and technology that may benefit The Krusteaz Company. Provide guidance, thought leadership, and mentorship to development and infrastructure teams to build EDW and development competencies. Position Requirements To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The requirements listed below are representative of the knowledge, skill, and/or ability required. Reasonable accommodations may be made to enable individuals qualified with disabilities to perform the essential functions. Proven success in developing technical solutions with a ‘cloud first’ mindset. Deep understanding of cloud data warehousing and ETL best practices, including system reliability and scalability. Ensuring data quality and consistency across various sources. Ability to function effectively as a change agent and problem solver within your team and across IT and the business. Excellent written, verbal, communication, and presentation skills with the ability to think critically, problem solve, and articulate new ideas and concepts to technical and non-technical audiences. Education and/or Experience: Bachelor’s degree in computer science, information technology, mathematics, or progressive relevant work experience. 8+ years of development experience required. 5+ years’ experience working with public cloud providers (Azure, Oracle Cloud, etc.). 5+ years’ experience in data pipeline development, including languages such as Python and R, and tools such as Airflow and SSIS. 5+ years Data Warehousing and ETL experience, preferably with large transactional datasets. Familiarity working in both Windows and Linux environments. Direct experience working with both traditional and agile methodologies required. Experience within the manufacturing industry, including knowledge in supply chain, procurement, and logistics is preferred but not required. Physical Demands and Work Environment: While performing the duties of this job, the employee is regularly required to stand, sit, talk, hear, and use hands and fingers to operate a computer and telephone along with reaching. Specific vision abilities include close vision requirements due to computer work. Moderate noise, ability to work in a confined area, and ability to sit at a computer for an extended period of time are also included. The policy of The Krusteaz Company is to hire, train, and promote all persons in all job groups in accordance with law, without regard to race, color, religion, sex, sexual orientation, age, marital or military status, national origin, gender identity, the presence of any sensory, mental or physical disability, genetic information, or any other status or characteristic protected by local, state, or federal law. Get to know us: A people-focused company that cares: We're a 90-year-old company with the entrepreneurial spirit of a startup and a focused eye on the future. As a midsized, privately held company with a portfolio of beloved food and beverage brands, our people are the most important ingredient in our success. A valued and supported workforce : We place tremendous value in our employees and provide competitive pay and comprehensive benefits to ensure our employees can create the best life for themselves. Benefits include a top tier health insurance plan with lower-than-average employee cost share, generous PTO, 401(k) match, and more. An engaged and energized culture: At The Krusteaz Company, collaboration and ingenuity drive our fierce commitment to creating extraordinary product experiences that people love. A place to grow and make a difference: An entrepreneurial spirit has been at the core of our company since the beginning, attracting self-starters who are curious and love to learn and to share ideas. Hybrid Work Model: At The Krusteaz Company, we have in-office \"core days\" of Tuesdays and Wednesdays where all corporate employees are expected to be onsite. Mondays, Thursdays, and Fridays are flexible remote days to allow for work/life balance. You may be asked to come in outside of a core day from time to time, based on business needs. We have found aligning our scheduled in-office days provides opportunity for employees to build connections and collaborate together. Benefits: We are proud to offer generous benefits including comprehensive medical, dental, and vision insurance (starting at $50/month for employee only coverage on the PPO Plan or starting at $25/month for employee only coverage on the HDHP), 401(K) matching, 3 weeks of paid vacation, 10 paid holidays, company provided life insurance and disability insurance, flexible spending account, healthcare saving account, voluntary accident insurance, voluntary critical illness insurance, and tuition reimbursement. Salary Information: An employee in this position can expect a salary range between $126,101 and $208,055. We typically pay out between $142,000 and $180,000. The actual salary offered will carefully consider a wide range of factors, including internal equity, experience, education, certification, training, and location. All positions are eligible for additional incentives based on business performance. We hope you'll take the time to get to know us! The Krusteaz Company is not sponsoring new applicant employment authorization at this time and please, no third-party recruiters.",
         "To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The requirements listed below are representative of the knowledge, skill, and/or ability required. Reasonable accommodations may be made to enable individuals qualified with disabilities to perform the essential functions. Proven success in developing technical solutions with a ‘cloud first’ mindset. Deep understanding of cloud data warehousing and ETL best practices, including system reliability and scalability. Ensuring data quality and consistency across various sources. Ability to function effectively as a change agent and problem solver within your team and across IT and the business. Excellent written, verbal, communication, and presentation skills with the ability to think critically, problem solve, and articulate new ideas and concepts to technical and non-technical audiences. Education and/or Experience: Bachelor’s degree in computer science, information technology, mathematics, or progressive relevant work experience. 8+ years of development experience required. 5+ years’ experience working with public cloud providers (Azure, Oracle Cloud, etc.). 5+ years’ experience in data pipeline development, including languages such as Python and R, and tools such as Airflow and SSIS. 5+ years Data Warehousing and ETL experience, preferably with large transactional datasets. Familiarity working in both Windows and Linux environments. Direct experience working with both traditional and agile methodologies required. Experience within the manufacturing industry, including knowledge in supply chain, procurement, and logistics is preferred but not required. Physical Demands and Work Environment: While performing the duties of this job, the employee is regularly required to stand, sit, talk, hear, and use hands and fingers to operate a computer and telephone along with reaching. Specific vision abilities include close vision requirements due to computer work. Moderate noise, ability to work in a confined area, and ability to sit at a computer for an extended period of time are also included. The policy of The Krusteaz Company is to hire, train, and promote all persons in all job groups in accordance with law, without regard to race, color, religion, sex, sexual orientation, age, marital or military status, national origin, gender identity, the presence of any sensory, mental or physical disability, genetic information, or any other status or characteristic protected by local, state, or federal law. Get to know us: A people-focused company that cares: We're a 90-year-old company with the entrepreneurial spirit of a startup and a focused eye on the future. As a midsized, privately held company with a portfolio of beloved food and beverage brands, our people are the most important ingredient in our success. A valued and supported workforce : We place tremendous value in our employees and provide competitive pay and comprehensive benefits to ensure our employees can create the best life for themselves. Benefits include a top tier health insurance plan with lower-than-average employee cost share, generous PTO, 401(k) match, and more. An engaged and energized culture: At The Krusteaz Company, collaboration and ingenuity drive our fierce commitment to creating extraordinary product experiences that people love. A place to grow and make a difference: An entrepreneurial spirit has been at the core of our company since the beginning, attracting self-starters who are curious and love to learn and to share ideas. Hybrid Work Model: At The Krusteaz Company, we have in-office \"core days\" of Tuesdays and Wednesdays where all corporate employees are expected to be onsite. Mondays, Thursdays, and Fridays are flexible remote days to allow for work/life balance. You may be asked to come in outside of a core day from time to time, based on business needs. We have found aligning our scheduled in-office days provides opportunity for employees to build connections and collaborate together. Benefits: We are proud to offer generous benefits including comprehensive medical, dental, and vision insurance (starting at $50/month for employee only coverage on the PPO Plan or starting at $25/month for employee only coverage on the HDHP), 401(K) matching, 3 weeks of paid vacation, 10 paid holidays, company provided life insurance and disability insurance, flexible spending account, healthcare saving account, voluntary accident insurance, voluntary critical illness insurance, and tuition reimbursement. Salary Information: An employee in this position can expect a salary range between $126,101 and $208,055. We typically pay out between $142,000 and $180,000. The actual salary offered will carefully consider a wide range of factors, including internal equity, experience, education, certification, training, and location. All positions are eligible for additional incentives based on business performance. We hope you'll take the time to get to know us! The Krusteaz Company is not sponsoring new applicant employment authorization at this time and please, no third-party recruiters.",
         756
        ],
        [
         null,
         "provided life insurance and disability insurance, flexible spending account, healthcare saving account, voluntary accident insurance, voluntary critical illness insurance, and tuition reimbursement.",
         "Description: Join our winning team, recently honored as #67 on Forbes’ list of America’s Best Startup Employers for 2024! About The Helper Bees The Helper Bees’ mission is to help people stay home longer through data-driven services that transform both the payer and the care-recipient experience. At The Helper Bees, we are reshaping how care is delivered to aging individuals by leveraging innovative technology and insightful data solutions. We maintain multiple SaaS products and payment solutions through our web applications (internal and external facing), a mobile app, and reporting integrations. As part of our growing Data Engineering team, you’ll iterate quickly, have a high impact, and be challenged to design and implement cutting-edge solutions. At THB, we define our company culture through our Core Values: Quickly iterate through solutions: We move at a fast pace which requires quick iterations to find a path to a repeatable solution. Seek ways to create immediate impact: Be thoughtful and proactive in how you make an impact on your team. Actively look for ways to make a fast, positive impact. Bee the teammate you want to work with: We work as a team, help each other, and encourage each other. Ask questions, answer questions: You can't iterate through solutions if you don't ask the right questions, which is why there is an expectation that questions should be asked. When you know the answer, being a good teammate means chiming in to get others up to speed. Take the time to celebrate wins: It's so easy for a team that is heads down to forget about all the great things they've accomplished. That's why we make it a priority to remind ourselves to create space to celebrate wins, big or small. Job Summary We are seeking a motivated Data Engineer to join our team and help improve our tools, processes, and technical infrastructure. In this role, you will ensure the availability and quality of our data while contributing to the design, implementation, and maintenance of The Helper Bees’ products. You’ll collaborate across teams to create scalable and optimized software systems and play a key role in refining our development processes. This position offers a unique opportunity to learn and leverage cutting-edge AI development tools to enhance coding efficiency and develop advanced data tools and solutions. Supervisory Responsibilities: None Key Responsibilities Data Infrastructure: Design, implement, and maintain data pipelines, ensuring data availability, quality, and scalability. Product Development: Build and enhance products using Python, SQL, and modern technologies. AI Integration: Leverage cutting-edge AI tools, including Cursor, ChatGPT, and Claude to improve development processes, automate workflows, and create innovative data solutions. Collaboration: Communicate across departments to design, build, test, and implement new features and enhancements. Code Excellence: Produce quality, testable, and maintainable code while participating in code reviews. Problem Solving: Debug complex issues, interact with stakeholders, and design viable solutions with clear trade-offs. Process Optimization: Contribute to improving development processes, including deployment, on-call systems, and sprint planning. Team Growth: Collaborate within the development team to help each other grow and continuously learn. Stakeholder Engagement: Partner with analysts, scientists, and IT to ensure alignment and deliver data-driven solutions. Other duties as assigned/necessary Performance Metrics Code Quality: Maintain high coding standards through regular code reviews and adherence to best practices. Development Efficiency: Deliver high-quality features and fixes within efficient timeframes. Bug Resolution Time: Reduce the time taken to identify and resolve issues. System Scalability: Optimize system performance to handle increasing user demands. Collaboration: Foster a collaborative environment that encourages teamwork and knowledge sharing. Customer Satisfaction: Incorporate stakeholder feedback to improve solutions and enhance the customer experience. Continuous Learning: Pursue opportunities for skill development and share knowledge with the team. Requirements: Required Skills & Qualifications Technical Tools: Experience with in Python and/or SQL. Experience with Bash, Shell scripting, Big Query, Airflow, and is a plus. Programming: Cleaning data using code-based approach. AI Proficiency: Interest or experience in using AI tools for coding and development of data solutions. Soft Skills: Problem-solving, cross-team collaboration, data storytelling, and stakeholder engagement. Adaptability: Thrives in a fast-paced startup environment and embraces change. Proactivity: Self-directed, organized, and able to prioritize effectively. Collaboration: Ability to work effectively with cross-functional teams. Education & Experience: A bachelor’s degree is required, and a graduate degree is preferred. Relevant experience in data engineering, software development, STEM, or related fields. Strong experience with SQL and Python is highly desirable. Mindset: A passion for innovation, continuous improvement, and delivering high-quality results from messy data. Preferred Qualifications Familiarity with cloud-based solutions (e.g., Google Cloud Platform, Azure). Experience with ETL processes and tools. Experience building data visualization reports and dashboards Knowledge of modern data storage solutions and database management systems. Exposure to DevOps practices and tools for deployment and monitoring. Why Join Us? Work with a talented, collaborative team dedicated to making a difference. Gain exposure to innovative technologies and opportunities for growth. Learn and utilize cutting-edge AI tools to enhance your development skills and create impactful solutions. Be part of a company that values your contributions and encourages professional development. Join a rapidly expanding health-tech startup (~200 employees and growing) with a state-of-the-art technology office located in Hyde Park, offering a variety of exceptional benefits. Career Progression Timeline In 3 months: Gain a comprehensive understanding of our data infrastructure, technical stacks, and development cycles. Actively participate in team meetings and contribute to the development of new data pipelines. Begin leveraging AI tools, such as Cursor and ChatGPT, to enhance coding efficiency and workflow automation. In 6 months: Contribute to product enhancements and data reporting Collaborate effectively with cross-functional teams, providing insights and solutions for data-related challenges. Demonstrate proficiency in utilizing AI tools for coding and development, actively sharing knowledge with the team. In 12 months: Contribute to data engineering projects, ensuring scalability and performance optimization. Mentor non-technical internal partners to improve company-wide data literacy Contribute to the integration of advanced AI solutions into our development processes, contributing to the company's technological advancement. Physical Requirements: Ability to remain at your designated workstation for the duration of the workday Constantly operates a computer and other office productivity machinery, such as a phone and Voice over Internet Protocol (VoIP). The ability to communicate information and ideas so others will understand. Must be able to exchange accurate information in these situations. The ability to observe details at close range (typically on a computer screen) This position offers the flexibility of remote work at approved locations within the United States. Candidates must have a reliable internet connection and a designated work environment conducive to professional phone calls and sensitive data. Enjoy the convenience and comfort of working remotely while contributing to our team's success. Apply Today If you’re ready to take on challenging problems, contribute to impactful solutions, and grow as a data engineer, we’d love to hear from you. Join us at The Helper Bees and be part of a team that’s making a meaningful difference every day! The Helper Bees is committed to building a workplace where diversity, equity, and inclusion are valued and prioritized. We are an equal opportunity employer that welcomes all qualified applicants without discrimination based on race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or any non-merit based or legally protected grounds. The Helper Bees provides reasonable accommodations to qualified individuals with disabilities during the job application and interview process. To request accommodation, please let your recruiter know. As part of our standard hiring process, selected candidates may be required to undergo a background check and/or drug screen. The Helper Bees adheres to applicable federal, state, and local laws regarding these screenings, and the results will be considered in accordance with applicable regulations. The Helper Bees was recently made aware of a fraudulent entity posing as our organization and requesting personal information. Please be aware of and protect yourself from scams. Visit thehelperbees.com/careers to view all current job openings. Opened URL: https://www.indeed.com/rc/clk?jk=06050d41e9f16407&bb=nVjcBhNqHzp8_NHgm7Pt9q7Srq7WJc3laX3t3bfzY84KBRoVLSzYwQg5Id0CB1on-KM_yMleDsx7wPr33UW8XbqBO4oQrHGnF3Ow3KdqYHbSXJt-uTwunph9tFWLP-yb&xkcb=SoDC67M33zEiEHSkNJ0IbzkdCdPP&fccid=61e4e7d2ce056d37&vjs=3",
         "data",
         "Description: Join our winning team, recently honored as #67 on Forbes’ list of America’s Best Startup Employers for 2024! About The Helper Bees The Helper Bees’ mission is to help people stay home longer through data-driven services that transform both the payer and the care-recipient experience. At The Helper Bees, we are reshaping how care is delivered to aging individuals by leveraging innovative technology and insightful data solutions. We maintain multiple SaaS products and payment solutions through our web applications (internal and external facing), a mobile app, and reporting integrations. As part of our growing Data Engineering team, you’ll iterate quickly, have a high impact, and be challenged to design and implement cutting-edge solutions. At THB, we define our company culture through our Core Values: Quickly iterate through solutions: We move at a fast pace which requires quick iterations to find a path to a repeatable solution. Seek ways to create immediate impact: Be thoughtful and proactive in how you make an impact on your team. Actively look for ways to make a fast, positive impact. Bee the teammate you want to work with: We work as a team, help each other, and encourage each other. Ask questions, answer questions: You can't iterate through solutions if you don't ask the right questions, which is why there is an expectation that questions should be asked. When you know the answer, being a good teammate means chiming in to get others up to speed. Take the time to celebrate wins: It's so easy for a team that is heads down to forget about all the great things they've accomplished. That's why we make it a priority to remind ourselves to create space to celebrate wins, big or small. Job Summary We are seeking a motivated Data Engineer to join our team and help improve our tools, processes, and technical infrastructure. In this role, you will ensure the availability and quality of our data while contributing to the design, implementation, and maintenance of The Helper Bees’ products. You’ll collaborate across teams to create scalable and optimized software systems and play a key role in refining our development processes. This position offers a unique opportunity to learn and leverage cutting-edge AI development tools to enhance coding efficiency and develop advanced data tools and solutions. Supervisory Responsibilities: None Key Responsibilities Data Infrastructure: Design, implement, and maintain data pipelines, ensuring data availability, quality, and scalability. Product Development: Build and enhance products using Python, SQL, and modern technologies. AI Integration: Leverage cutting-edge AI tools, including Cursor, ChatGPT, and Claude to improve development processes, automate workflows, and create innovative data solutions. Collaboration: Communicate across departments to design, build, test, and implement new features and enhancements. Code Excellence: Produce quality, testable, and maintainable code while participating in code reviews. Problem Solving: Debug complex issues, interact with stakeholders, and design viable solutions with clear trade-offs. Process Optimization: Contribute to improving development processes, including deployment, on-call systems, and sprint planning. Team Growth: Collaborate within the development team to help each other grow and continuously learn. Stakeholder Engagement: Partner with analysts, scientists, and IT to ensure alignment and deliver data-driven solutions. Other duties as assigned/necessary Performance Metrics Code Quality: Maintain high coding standards through regular code reviews and adherence to best practices. Development Efficiency: Deliver high-quality features and fixes within efficient timeframes. Bug Resolution Time: Reduce the time taken to identify and resolve issues. System Scalability: Optimize system performance to handle increasing user demands. Collaboration: Foster a collaborative environment that encourages teamwork and knowledge sharing. Customer Satisfaction: Incorporate stakeholder feedback to improve solutions and enhance the customer experience. Continuous Learning: Pursue opportunities for skill development and share knowledge with the team. Requirements: Required Skills & Qualifications Technical Tools: Experience with in Python and/or SQL. Experience with Bash, Shell scripting, Big Query, Airflow, and is a plus. Programming: Cleaning data using code-based approach. AI Proficiency: Interest or experience in using AI tools for coding and development of data solutions. Soft Skills: Problem-solving, cross-team collaboration, data storytelling, and stakeholder engagement. Adaptability: Thrives in a fast-paced startup environment and embraces change. Proactivity: Self-directed, organized, and able to prioritize effectively. Collaboration: Ability to work effectively with cross-functional teams. Education & Experience: A bachelor’s degree is required, and a graduate degree is preferred. Relevant experience in data engineering, software development, STEM, or related fields. Strong experience with SQL and Python is highly desirable. Mindset: A passion for innovation, continuous improvement, and delivering high-quality results from messy data. Preferred Qualifications Familiarity with cloud-based solutions (e.g., Google Cloud Platform, Azure). Experience with ETL processes and tools. Experience building data visualization reports and dashboards Knowledge of modern data storage solutions and database management systems. Exposure to DevOps practices and tools for deployment and monitoring. Why Join Us? Work with a talented, collaborative team dedicated to making a difference. Gain exposure to innovative technologies and opportunities for growth. Learn and utilize cutting-edge AI tools to enhance your development skills and create impactful solutions. Be part of a company that values your contributions and encourages professional development. Join a rapidly expanding health-tech startup (~200 employees and growing) with a state-of-the-art technology office located in Hyde Park, offering a variety of exceptional benefits. Career Progression Timeline In 3 months: Gain a comprehensive understanding of our data infrastructure, technical stacks, and development cycles. Actively participate in team meetings and contribute to the development of new data pipelines. Begin leveraging AI tools, such as Cursor and ChatGPT, to enhance coding efficiency and workflow automation. In 6 months: Contribute to product enhancements and data reporting Collaborate effectively with cross-functional teams, providing insights and solutions for data-related challenges. Demonstrate proficiency in utilizing AI tools for coding and development, actively sharing knowledge with the team. In 12 months: Contribute to data engineering projects, ensuring scalability and performance optimization. Mentor non-technical internal partners to improve company-wide data literacy Contribute to the integration of advanced AI solutions into our development processes, contributing to the company's technological advancement. Physical Requirements: Ability to remain at your designated workstation for the duration of the workday Constantly operates a computer and other office productivity machinery, such as a phone and Voice over Internet Protocol (VoIP). The ability to communicate information and ideas so others will understand. Must be able to exchange accurate information in these situations. The ability to observe details at close range (typically on a computer screen) This position offers the flexibility of remote work at approved locations within the United States. Candidates must have a reliable internet connection and a designated work environment conducive to professional phone calls and sensitive data. Enjoy the convenience and comfort of working remotely while contributing to our team's success. Apply Today If you’re ready to take on challenging problems, contribute to impactful solutions, and grow as a data engineer, we’d love to hear from you. Join us at The Helper Bees and be part of a team that’s making a meaningful difference every day! The Helper Bees is committed to building a workplace where diversity, equity, and inclusion are valued and prioritized. We are an equal opportunity employer that welcomes all qualified applicants without discrimination based on race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or any non-merit based or legally protected grounds. The Helper Bees provides reasonable accommodations to qualified individuals with disabilities during the job application and interview process. To request accommodation, please let your recruiter know. As part of our standard hiring process, selected candidates may be required to undergo a background check and/or drug screen. The Helper Bees adheres to applicable federal, state, and local laws regarding these screenings, and the results will be considered in accordance with applicable regulations. The Helper Bees was recently made aware of a fraudulent entity posing as our organization and requesting personal information. Please be aware of and protect yourself from scams. Visit thehelperbees.com/careers to view all current job openings.",
         "Description: Join our winning team, recently honored as #67 on Forbes’ list of America’s Best Startup Employers for 2024! About The Helper Bees The Helper Bees’ mission is to help people stay home longer through data-driven services that transform both the payer and the care-recipient experience. At The Helper Bees, we are reshaping how care is delivered to aging individuals by leveraging innovative technology and insightful data solutions. We maintain multiple SaaS products and payment solutions through our web applications (internal and external facing), a mobile app, and reporting integrations. As part of our growing Data Engineering team, you’ll iterate quickly, have a high impact, and be challenged to design and implement cutting-edge solutions. At THB, we define our company culture through our Core Values: Quickly iterate through solutions: We move at a fast pace which requires quick iterations to find a path to a repeatable solution. Seek ways to create immediate impact: Be thoughtful and proactive in how you make an impact on your team. Actively look for ways to make a fast, positive impact. Bee the teammate you want to work with: We work as a team, help each other, and encourage each other. Ask questions, answer questions: You can't iterate through solutions if you don't ask the right questions, which is why there is an expectation that questions should be asked. When you know the answer, being a good teammate means chiming in to get others up to speed. Take the time to celebrate wins: It's so easy for a team that is heads down to forget about all the great things they've accomplished. That's why we make it a priority to remind ourselves to create space to celebrate wins, big or small. Job Summary We are seeking a motivated Data Engineer to join our team and help improve our tools, processes, and technical infrastructure. In this role, you will ensure the availability and quality of our data while contributing to the design, implementation, and maintenance of The Helper Bees’ products. You’ll collaborate across teams to create scalable and optimized software systems and play a key role in refining our development processes. This position offers a unique opportunity to learn and leverage cutting-edge AI development tools to enhance coding efficiency and develop advanced data tools and solutions. Supervisory Responsibilities: None Key Responsibilities Data Infrastructure: Design, implement, and maintain data pipelines, ensuring data availability, quality, and scalability. Product Development: Build and enhance products using Python, SQL, and modern technologies. AI Integration: Leverage cutting-edge AI tools, including Cursor, ChatGPT, and Claude to improve development processes, automate workflows, and create innovative data solutions. Collaboration: Communicate across departments to design, build, test, and implement new features and enhancements. Code Excellence: Produce quality, testable, and maintainable code while participating in code reviews. Problem Solving: Debug complex issues, interact with stakeholders, and design viable solutions with clear trade-offs. Process Optimization: Contribute to improving development processes, including deployment, on-call systems, and sprint planning. Team Growth: Collaborate within the development team to help each other grow and continuously learn. Stakeholder Engagement: Partner with analysts, scientists, and IT to ensure alignment and deliver data-driven solutions. Other duties as assigned/necessary Performance Metrics Code Quality: Maintain high coding standards through regular code reviews and adherence to best practices. Development Efficiency: Deliver high-quality features and fixes within efficient timeframes. Bug Resolution Time: Reduce the time taken to identify and resolve issues. System Scalability: Optimize system performance to handle increasing user demands. Collaboration: Foster a collaborative environment that encourages teamwork and knowledge sharing. Customer Satisfaction: Incorporate stakeholder feedback to improve solutions and enhance the customer experience. Continuous Learning: Pursue opportunities for skill development and share knowledge with the team. Requirements: Required Skills & Qualifications Technical Tools: Experience with in Python and/or SQL. Experience with Bash, Shell scripting, Big Query, Airflow, and is a plus. Programming: Cleaning data using code-based approach. AI Proficiency: Interest or experience in using AI tools for coding and development of data solutions. Soft Skills: Problem-solving, cross-team collaboration, data storytelling, and stakeholder engagement. Adaptability: Thrives in a fast-paced startup environment and embraces change. Proactivity: Self-directed, organized, and able to prioritize effectively. Collaboration: Ability to work effectively with cross-functional teams. Education & Experience: A bachelor’s degree is required, and a graduate degree is preferred. Relevant experience in data engineering, software development, STEM, or related fields. Strong experience with SQL and Python is highly desirable. Mindset: A passion for innovation, continuous improvement, and delivering high-quality results from messy data. Preferred Qualifications Familiarity with cloud-based solutions (e.g., Google Cloud Platform, Azure). Experience with ETL processes and tools. Experience building data visualization reports and dashboards Knowledge of modern data storage solutions and database management systems. Exposure to DevOps practices and tools for deployment and monitoring. Why Join Us? Work with a talented, collaborative team dedicated to making a difference. Gain exposure to innovative technologies and opportunities for growth. Learn and utilize cutting-edge AI tools to enhance your development skills and create impactful solutions. Be part of a company that values your contributions and encourages professional development. Join a rapidly expanding health-tech startup (~200 employees and growing) with a state-of-the-art technology office located in Hyde Park, offering a variety of exceptional benefits. Career Progression Timeline In 3 months: Gain a comprehensive understanding of our data infrastructure, technical stacks, and development cycles. Actively participate in team meetings and contribute to the development of new data pipelines. Begin leveraging AI tools, such as Cursor and ChatGPT, to enhance coding efficiency and workflow automation. In 6 months: Contribute to product enhancements and data reporting Collaborate effectively with cross-functional teams, providing insights and solutions for data-related challenges. Demonstrate proficiency in utilizing AI tools for coding and development, actively sharing knowledge with the team. In 12 months: Contribute to data engineering projects, ensuring scalability and performance optimization. Mentor non-technical internal partners to improve company-wide data literacy Contribute to the integration of advanced AI solutions into our development processes, contributing to the company's technological advancement. Physical Requirements: Ability to remain at your designated workstation for the duration of the workday Constantly operates a computer and other office productivity machinery, such as a phone and Voice over Internet Protocol (VoIP). The ability to communicate information and ideas so others will understand. Must be able to exchange accurate information in these situations. The ability to observe details at close range (typically on a computer screen) This position offers the flexibility of remote work at approved locations within the United States. Candidates must have a reliable internet connection and a designated work environment conducive to professional phone calls and sensitive data. Enjoy the convenience and comfort of working remotely while contributing to our team's success. Apply Today If you’re ready to take on challenging problems, contribute to impactful solutions, and grow as a data engineer, we’d love to hear from you. Join us at The Helper Bees and be part of a team that’s making a meaningful difference every day! The Helper Bees is committed to building a workplace where diversity, equity, and inclusion are valued and prioritized. We are an equal opportunity employer that welcomes all qualified applicants without discrimination based on race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or any non-merit based or legally protected grounds. The Helper Bees provides reasonable accommodations to qualified individuals with disabilities during the job application and interview process. To request accommodation, please let your recruiter know. As part of our standard hiring process, selected candidates may be required to undergo a background check and/or drug screen. The Helper Bees adheres to applicable federal, state, and local laws regarding these screenings, and the results will be considered in accordance with applicable regulations. The Helper Bees was recently made aware of a fraudulent entity posing as our organization and requesting personal information. Please be aware of and protect yourself from scams. Visit thehelperbees.com/careers to view all current job openings.",
         "Technical Tools: Experience with in Python and/or SQL. Experience with Bash, Shell scripting, Big Query, Airflow, and is a plus. Programming: Cleaning data using code-based approach. AI Proficiency: Interest or experience in using AI tools for coding and development of data solutions. Soft Skills: Problem-solving, cross-team collaboration, data storytelling, and stakeholder engagement. Adaptability: Thrives in a fast-paced startup environment and embraces change. Proactivity: Self-directed, organized, and able to prioritize effectively. Collaboration: Ability to work effectively with cross-functional teams. Education & Experience: A bachelor’s degree is required, and a graduate degree is preferred. Relevant experience in data engineering, software development, STEM, or related fields. Strong experience with SQL and Python is highly desirable. Mindset: A passion for innovation, continuous improvement, and delivering high-quality results from messy data. Preferred Qualifications Familiarity with cloud-based solutions (e.g., Google Cloud Platform, Azure). Experience with ETL processes and tools. Experience building data visualization reports and dashboards Knowledge of modern data storage solutions and database management systems. Exposure to DevOps practices and tools for deployment and monitoring. Why Join Us? Work with a talented, collaborative team dedicated to making a difference. Gain exposure to innovative technologies and opportunities for growth. Learn and utilize cutting-edge AI tools to enhance your development skills and create impactful solutions. Be part of a company that values your contributions and encourages professional development. Join a rapidly expanding health-tech startup (~200 employees and growing) with a state-of-the-art technology office located in Hyde Park, offering a variety of exceptional benefits. Career Progression Timeline In 3 months: Gain a comprehensive understanding of our data infrastructure, technical stacks, and development cycles. Actively participate in team meetings and contribute to the development of new data pipelines. Begin leveraging AI tools, such as Cursor and ChatGPT, to enhance coding efficiency and workflow automation. In 6 months: Contribute to product enhancements and data reporting Collaborate effectively with cross-functional teams, providing insights and solutions for data-related challenges. Demonstrate proficiency in utilizing AI tools for coding and development, actively sharing knowledge with the team. In 12 months: Contribute to data engineering projects, ensuring scalability and performance optimization. Mentor non-technical internal partners to improve company-wide data literacy Contribute to the integration of advanced AI solutions into our development processes, contributing to the company's technological advancement. Physical Requirements: Ability to remain at your designated workstation for the duration of the workday Constantly operates a computer and other office productivity machinery, such as a phone and Voice over Internet Protocol (VoIP). The ability to communicate information and ideas so others will understand. Must be able to exchange accurate information in these situations. The ability to observe details at close range (typically on a computer screen) This position offers the flexibility of remote work at approved locations within the United States. Candidates must have a reliable internet connection and a designated work environment conducive to professional phone calls and sensitive data. Enjoy the convenience and comfort of working remotely while contributing to our team's success. Apply Today If you’re ready to take on challenging problems, contribute to impactful solutions, and grow as a data engineer, we’d love to hear from you. Join us at The Helper Bees and be part of a team that’s making a meaningful difference every day! The Helper Bees is committed to building a workplace where diversity, equity, and inclusion are valued and prioritized. We are an equal opportunity employer that welcomes all qualified applicants without discrimination based on race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or any non-merit based or legally protected grounds. The Helper Bees provides reasonable accommodations to qualified individuals with disabilities during the job application and interview process. To request accommodation, please let your recruiter know. As part of our standard hiring process, selected candidates may be required to undergo a background check and/or drug screen. The Helper Bees adheres to applicable federal, state, and local laws regarding these screenings, and the results will be considered in accordance with applicable regulations. The Helper Bees was recently made aware of a fraudulent entity posing as our organization and requesting personal information. Please be aware of and protect yourself from scams. Visit thehelperbees.com/careers to view all current job openings.",
         698
        ],
        [
         "Instructional Designer, Content Developer",
         "Boston Scientific Corporation",
         "Work mode: Hybrid Onsite Location(s): Maple Grove, MN, US, 55311 Additional Location(s): US-MN-Maple Grove Diversity - Innovation - Caring - Global Collaboration - Winning Spirit - High Performance At Boston Scientific, we’ll give you the opportunity to harness all that’s within you by working in teams of diverse and high-performing employees, tackling some of the most important health industry challenges. With access to the latest tools, information and training, we’ll help you in advancing your skills and career. Here, you’ll be supported in progressing – whatever your ambitions. The Instructional Designer Content Developer (Cardiology Training) works closely with business partners, subject matter experts (SMEs), and other key stakeholders to plan and develop high-quality learning experiences to support business goals. This individual is responsible for the development of content, which may include interactive, multimedia, instructor led. This position reports to the Cardiology Training Operations Manager. Candidates will provide work portfolio as part of the application process. The interview will include a portfolio review and discussion. Your responsibilities will include: Partnering with subject matter experts and other stakeholders to analyze the learning needs. Planning, organizing, and developing learning solutions using a variety of modalities. Synthesizing and translating technical information into clear, effective, and engaging learning. Ensuring a consistent approach to the learning experience. Being proficient with a wide variety of learning tools, including but not limited to Storyline, RISE, game-based learning, videos, InDesign. Managing multiple projects with frequent priority shifts, working with high attention to accuracy and detail, and delivering within expected timelines. Being familiar with Learning Management Systems, as it relates to ensuring content works appropriately. Managing and organizing content in a centralized repository to ensure accuracy of material. Minimum Qualifications: Bachelor’s degree and/or equivalent of industry experience Four years of Instructional Design and content creation Innovative, curious mindset and ability to work independently to meet deadlines Excellent written and verbal communication skills Experience editing content for clarity and accuracy Experience using Microsoft 365 tools Experience using Articulate 360 software Experience using video editing software Experience using software to create animated characters Experience using Adobe InDesign Preferred Qualifications: Experience working within an FDA regulated environment Experience using Sales and Learning Enablement Platforms, (such as Showpad, Allego, SmartWinnr, etc) Requisition ID: 598020 Minimum Salary: $ 99100 Maximum Salary: $ 188300 Compensation for non-exempt (hourly), non-sales roles may also include variable compensation from time to time (e.g., any overtime and shift differential) and annual bonus target (subject to plan eligibility and other requirements). Compensation for exempt, non-sales roles may also include variable compensation, i.e., annual bonus target and long-term incentives (subject to plan eligibility and other requirements. For MA positions: It is unlawful to require or administer a lie detector test for employment. Violators are subject to criminal penalties and civil liability. As a leader in medical science for more than 40 years, we are committed to solving the challenges that matter most – united by a deep caring for human life. Our mission to advance science for life is about transforming lives through innovative medical solutions that improve patient lives, create value for our customers, and support our employees and the communities in which we operate. Now more than ever, we have a responsibility to apply those values to everything we do – as a global business and as a global corporate citizen. So, choosing a career with Boston Scientific (NYSE: BSX) isn’t just business, it’s personal. And if you’re a natural problem-solver with the imagination, determination, and spirit to make a meaningful difference to people worldwide, we encourage you to apply and look forward to connecting with you! At Boston Scientific, we recognize that nurturing a diverse and inclusive workplace helps us be more innovative and it is important in our work of advancing science for life and improving patient health. That is why we stand for inclusion, equality, and opportunity for all. By embracing the richness of our unique backgrounds and perspectives, we create a better, more rewarding place for our employees to work and reflect the patients, customers, and communities we serve. Boston Scientific Corporation has been and will continue to be an equal opportunity employer. To ensure full implementation of its equal employment policy, the Company will continue to take steps to assure that recruitment, hiring, assignment, promotion, compensation, and all other personnel decisions are made and administered without regard to race, religion, color, national origin, citizenship, sex, sexual orientation, gender identify, gender expression, veteran status, age, mental or physical disability, genetic information or any other protected class. Please be advised that certain US based positions, including without limitation field sales and service positions that call on hospitals and/or health care centers, require acceptable proof of COVID-19 vaccination status. Candidates will be notified during the interview and selection process if the role(s) for which they have applied require proof of vaccination as a condition of employment. Boston Scientific continues to evaluate its policies and protocols regarding the COVID-19 vaccine and will comply with all applicable state and federal law and healthcare credentialing requirements. As employees of the Company, you will be expected to meet the ongoing requirements for your roles, including any new requirements, should the Company’s policies or protocols change with regard to COVID-19 vaccination. Nearest Major Market: Minneapolis Job Segment: Learning, Testing, Developer, Programmer, Information Technology, Human Resources, Technology Title: Software Engineer Company: Specialty Capital URL: https://www.indeed.com/pagead/clk?mo=r&ad=-6NYlbfkN0DzX7PQAKaiJCZnVFs2Ov8U9Q9S3K6neGnvbuf6n2zC9_Pkj_sXND7Qk4-xgBEMNM9-p4oZMWw5vmAUGkwUkI9i3Ndwit9RWbFDI0MuTROa2LZyH6BjeGUt6QkYQYyZ8HsEoA330tU-H53xVOdfKCqwBoM5_UZDYqq1CxoJHxdDaOZie-n2VGzRKb_eCti_lL9JVg2C1G-CfGJR2cl7RKHDse4BDFvttFpqWGZ8aUq_6_OKvwXw2Ze6Cc1O43BHduYrcEvYRgzw6bTD9sVNVQQ_eomhM1YQp-dOZU8bveYJanIRmabafxJKZE9P6fWJWDrIB61yygA7A38kNlO7xt5eOOgZN5bTYctOMLBsk3QBr0RyODVF4AzvhkVs8p5pi33aqy71uyL3awFy5c56HCxs-uORyqrUU5i_CsBNa0CuJlrOtXV6sCJYldh2kqBTHgVHr5fBDF6LpwdO4N4-ONAkNY7OHwPrrJ9r-Pyola0xAFcCFbduFrlQh-obJ4eLHqhlmciGaVffzsiEkHW6y-D0ueZfR82sxCA3N-Z7Xez2gzWZZ9NeHh_AxWvT5x4_yKcSortfOhNv4PjrIne_L3DdeEFsqYbakOorH7_pJOK67ChBMizMRoOGTqApz9qFfMk=&xkcb=SoCB6_M331x-WqyLNB0NbzkdCdPP&camk=ethIe0s0hefEWJEBjQdxdQ==&p=0&fvj=0&vjs=3  Title: Software Safety Engineer Company: Entegee URL: https://www.indeed.com/pagead/clk?mo=r&ad=-6NYlbfkN0D6OzZjpD_hbicRkMZwNNvvxSeL23iIfvaC4EytleQ8zJPuRiz-GFjENB8tAhgtYfTeju-esYvHP6v3vTW71M2A9oDC-Rz_h3qInRx1oYz3a_7E2sB53Poa4HuP1onGqi-iFt9RtQ9x3FWdLUgr0ghWui8odQO5a_Vl_2K4vZF7404wVXbKwnYB5G9OOSBVRoOmF48k5GxxSO8PvnaFd-vPFWIPZ_yWWAjzz5hLdVJ7o3FvnsE4CHtoP0BHCdTIyxBKo2mhafJpQOqzZYD2xbk6X9z6QhLguv3jsuTJ1pOXRrV9qXXEYgX_tuG6M_n8k-SOXcDFR1TpbMUTGXXV80IGQsoCh06uFkvyKo8nvn6QpbUZjsi4bLFn_PDWHBj_bPoOdtmF2PEYmehJ1OtZEKiVSSdrdgXnH76L22Yp-M8S_N_ZfkocAKHoZOsf0WmxMswoUmoW1Nh-au3_x4m9bhBvbruvgXcW4oMPl2EZC75pSUtCW49VlJICi3q1tHFbYiEFzM2pshSnoS3G3ElG1CAyh6trxA9ypALsD00krIGdBJt-ErPgTwcOrlNDKQWDFWcyyCTkowAqjbHM0xaf0JeLQHOUhcNpva6MsKNjTwP1QecHJ0numx-7tSMC2AAHHJD8pNb475puno5WcxV8ePqp&xkcb=SoA16_M331x-WqyLNB0MbzkdCdPP&camk=f416UQcMBpBqMpW9kmClkg==&p=1&fvj=0&vjs=3  Title: Entry Level Java Developer Company: Hemma Systems Inc. URL: https://www.indeed.com/rc/clk?jk=13be2d2d47d5bc48&bb=14wI_Ylq6Fgk36O9dVMYwGCSiX5dUUZ6ZcLUyF8Lnifo7lCAQ8ryGR5Hw4N6d1Yuvb_6inOxZYooY1OKQs2qtqBShclWxJtNU1uAAyJxdD-2UaeZCHpi9p9QwiPCXlb1&xkcb=SoAo67M331x-WqyLNB0DbzkdCdPP&fccid=64a01098c675b9d4&cmp=Hemma-Systems-Inc.&ti=Entry+Level+Java+Developer&vjs=3  Title: Software Engineer II - C# (Remote) Company: McDonald's Corporation URL: https://www.indeed.com/rc/clk?jk=5dac47dc41cceea1&bb=14wI_Ylq6Fgk36O9dVMYwBSJVfCXzEqIyC-WhjXcttxXHxDnU9v0QjYpB9Hq6dme1Zz5WbxUtzH_O7Oycpt1rjC0IUor_CIh2qFhwzfg0gy9qQhOGEiacQlpTE-yDMkF&xkcb=SoCc67M331x-WqyLNB0CbzkdCdPP&fccid=f753bb1a40104d82&vjs=3  Title: Manager, Software Engineering Company: Balboa Digital Inc URL: https://www.indeed.com/pagead/clk?mo=r&ad=-6NYlbfkN0Adku816-OBHubz4afTLzY4YO-X5PKDkiA3EF33z0Xey0tXEaTJb6iSYB1WEb4VoejiXbG82ebcqQTNEagchcMMGjElXLUihuNMRNIycqyMLEEIa-mdPyDc0shVNtvLxr6-FiYpbmg00VPhBY0RwCNRphNJ_JoMDk9Es2bNn9qoUxXRo7o0XmsJtE-xQq4O8RGEAD7qVQFpKzx_yfWcIfES-3vSgoZTuffuIEDODy2ASoTtegCgz3LLu2Qg5tCLm28BN2LqiRbYn-nL1XYLmc4lroy9eahPTT41y2b5yc5-JOi22MchoJQsFJBh-tVehiVQ9S2tii9o-A-Px-eh8x3B6Aeqcfz4Y9htEMWn8bXj0A622DQpQdAq_u_x7l8dLmaFbd9bDGYxNj2U5I-wZWmfMi-Hkcn94QLWLqaqKD32lePGwc_6BErXZSr51dKcJjAYWdc4cvZuhtrIDHsDR79BvyaCnanI00sRePtT28l2d8kgqRCRO0SeEo1ceblYDAupXHB1vML1R30XoNjyR0U1nuRk_UfMMSAC-G6DZKAMDcmJEuALTfy22tyZhykynqfmqRPl9jNHsk6yFN0ZAj2pNTYUMTOIbmzW8YWK5yFGv_kDljaaegI1lfOj6NJO708=&xkcb=SoD16_M331x-WqyLNB0BbzkdCdPP&camk=ethIe0s0hedh9yg7E_9g5A==&p=4&fvj=0&vjs=3  Title: Associate Software Developer Company: Aspen Technology URL: https://www.indeed.com/rc/clk?jk=7756b67b5792632f&bb=14wI_Ylq6Fgk36O9dVMYwBeTYi-61Wkb7sWVkrwAyiBStf9NK9vbSPUrNYj0ThY9zJUOjtd-9YX3H_wey0FTAIagHJhHHEaFrWxnvtYgL5t5701wFAdbqQ%3D%3D&xkcb=SoC167M331x-WqyLNB0AbzkdCdPP&fccid=aa61d43e9b452410&vjs=3  Title: Experienced Software Engineer across a wide array of tech stacks Company: Infinity Software Development, Inc URL: https://www.indeed.com/pagead/clk?mo=r&ad=-6NYlbfkN0DXKDYI_yepg0NlIxbNRNpLYk6-xAUlLi5O8UrMeMQSh13NFas3aZcKUoDmffy5epMXeY-zhdbmUkRqvRX4t3icq8DjhhYQs_LwSZn2GVwbjRGidLxi3Sof_2aBeoQD6wYD6m_HuwHaiCyhiBReEuf3nRDx0TjXj-fZp9pfU46PUpQdwUNRUDQJT0pa-nM770SIdJOBVOwl5BJBozcMBPyssDgmqoBbSQg_WDZAvrqw0fvHcFfG-NxdLqjMzmP6cv4mS5ouACuJXWz1yhSlIzhJQpjEvdHHbHFL-dH3SNETQUuig-pGnygaN4hzJn9oPOZgbJV2VB74xCG9U7R7NRZXnH88Oi9W20HtdpArO8z4cagQWXIO6JeyN1AEiqWJ8-ilQXPCQmEo0LXeAXf8vpRnwt8A12E3B9v5cj_bNDt9j-owai9Fms794YXGeJyFDSfJUXyTCVu_wzoASkNE40LY2HLivwdqplfYd_YhKtMZGdcHB0gJV9AzgJlFzXCgNLnZNFeTpJfV-Y0UHg1it7Ehe1GGAnjlFRVp2sAgvFd5HiNEaNnQjZPI5MQP6H1iCPOjG1FNPvmxcDA3ZKOC6d0UuAw0CMhN0qWt9AgKWzGuAdLHDvsxKWJK380yzCo2HR-7l8TbHN55nJrJKwxwT0-jhkkVBjZr3Ug-OBek1mmW20VaW7C-Whs_8746rIWADRk=&xkcb=SoDP6_M331x-WqyLNB0HbzkdCdPP&camk=ethIe0s0hed6QKoT7ElUpg==&p=6&fvj=0&vjs=3  Title: Sr Developer/Full Stack (Remote - Hybrid: Twin Cities/St Peter) Company: Scholarship America URL: https://www.indeed.com/rc/clk?jk=74febd0647bc821a&bb=14wI_Ylq6Fgk36O9dVMYwFwi45UQKQtqk4WZZMmpsiiUz8j4x0zJyLmZC7WZhxfcycZV8yRObikAWhHhoeHagZUjKLiCKo4Bw4YwyZ9erBKg_wUj4oItwQ_aO61CXJ3A&xkcb=SoCP67M331x-WqyLNB0GbzkdCdPP&fccid=cce1c4ec59975253&vjs=3  Title: Junior Front End Engineer Company: minware URL: https://www.indeed.com/rc/clk?jk=1726df0b08d5cb30&bb=14wI_Ylq6Fgk36O9dVMYwIJGuhxgMnyLiRtdAXs1WpMSx4pmjP1NCF6rXmhjL9kmk0VFjkhx2NjKWYuHHI9UT0nJis7mlxKdUe9rQr2MlSVJXTQKjDC84fz4WniMlOTK&xkcb=SoAS67M331x-WqyLNB0FbzkdCdPP&fccid=01b27327b9e5d576&vjs=3  Title: Website Programmer Front End - Entry Level Company: Trib Total Media URL: https://www.indeed.com/rc/clk?jk=0eb7983c4faf698d&bb=14wI_Ylq6Fgk36O9dVMYwNIjrG7D-mlEl58-pC9B-d25tD4J7CygSnkKmUpIzuZa8LaCK7pRibpBYCgeao7FdIrnOYAyyZBS1VAb5vAognOaHjfzzKIRl4H6CFkJ3Wda&xkcb=SoCm67M331x-WqyLNB0EbzkdCdPP&fccid=bfe81a77e3f1c572&vjs=3  Title: Full Stack Java Software Engineer - Remote Company: Kunz, Leigh & Associates URL: https://www.indeed.com/pagead/clk?mo=r&ad=-6NYlbfkN0CG0MOFnlYlPQ1Ern0f6lCNr2JCUFSORbPgdH34SplLNydtjSZB1rlqGTh485AdjPSqq2mha0KhGUAFe_iVnt7WAxoq5oy5SzhnieRSG7F-bqhL2z7e-e0EELbybjnN-nt9yxVpskkxcmIH3RG8CiGEjmqW8QZ-0XsdQHhf81y2draoyxPcj-dWZwJuaZa7WW7jWZtwBxQeslg97BeQYjRKHuu60pedz06vZ6OZDeOaAQUkm6fHNTSO4URZXI60op_5an3tRDVhrAY-YR0231Kyd7F4SrUa3RtD1W6DRYWWCdJ9mEXi6Cbm9pbZll9MbAc5OPCAUSsQRBcZ_JCZqum-1ANE7GxBO8GJgqRUTSuWdK8H1SVoHkytBllgBM8WzXq902wqKpW6oc2WLo_1mXJijpKOj01JybvWbLQPWlwkifDCk81gKvs8vWOg0G8dVtjgqSXSh6iCHPYjJoeRZ6uc0naz8ORpgzOfjtfjG_C7EaFWFs712D9uhTPU0rDmoO1SDsMeedz_Tk29C0r0Y-PUM515B-QtV746k0adcRUs6U_h15g1JCCHCdnP7iyLp2siK8BomkQxFrrbyQvviKSjcnyPgoDvDkePQcAzMwOVXHC_5QCwQwJwXYwaIELtu-VkD6UZyQp2kQ1om-LgprZp8KbfSQsim6jevJMCU3n03a7dxbfabgAuxrdJarQe7HQ=&xkcb=SoB16_M331x-WqyLNB0bbzkdCdPP&camk=ethIe0s0heckLFYoCs5mAw==&p=10&fvj=0&vjs=3  Title: Automation Controls Engineer Company: Actalent URL: https://www.indeed.com/pagead/clk?mo=r&ad=-6NYlbfkN0ChYVx_I3yfZ_JDY3EFoivtqvi_stwnZ_kRt8Dowt_l_TGXG89DEg1MfkawasLJpdJGA_HZgfzeZTJl34XGhVdaz_Cs1jcd2oL_83p86XeBHyQt1xpcm0QBZ1ewavzDCOSeWMhihqthB5aqwE_YTSaqQ073Kj_AkRRU_BJ-fa6aUiUurCeiSnyngWnjm2Z7vIdFA0T7Gfogg9RZcSwG9kI28M5L-AUMSPHjxgKNlD-Eef9hXB_zYfIjzdc7BWtWzFJVxv61AJ_b5JeMmmYOgfS0TN5GZVpAbVZrPSnJKKTMOF20nV-tNuoy5uRoPetrubKqPh2Yz5K8Fpn-c4H3AJ5P8mdVTKR0FdRlLB2YJlC6lN8HBFFaQlc_5vhETCpfZsEjV8xt13C2PkDlAbHlsi2_bc0gwWiY2S2dLVSwFqHdwPPxUgVQU8o8p2bfAampuX1DDnL7uUph4-djTn_r18LatyrvGoTXP0gyr7c9563kGTJs6qM0kp6zTvnn9dY-OwRiZKW9SsbRDKSv5PsAoDwQEsedEFRpbceJ68Tf5s2NfyE-t-Ct5vWUPhDGrQfgDMEOBamhXDSwLSllQva-lUv1eXctYfma69BMDN-cGHNikOyYeIkJMXsGIYAesGxqxiGJgvJtKnaT-Bggz1YksF97HT4dAg3IWLLnw0HIDQ8iaE3tLWz7BEFXJkaw5x0Ex_Qa_lA8lZiPf1u1bGHA4V7OrqmOxAyhWLbiuD6pRdDKs0x6bGVo2jsrG_jOelfxDlhudRGmRHUfcDkYn4HM9KHCkwjVyqM2lUhUtwFiDGfkYR6dLCt9puGalVDfeDDWzQYxz0Mbbhlydk5TiWnEGWKwXDvEkT-7HH_fv6fYVlfrZQ7tl6rVES4ZmtjndPPuNHxUB-fIfNMiAyjBFwR9gC5U-Mn9pggoHd91V_tRyNkU0F0eZR_OII-i-9JTv5hHK7mzS1U97rGeQWHxJdAcmndx9_-aV93etsG0aXzud823Lp8N_hy-yuzaqrKw8wRJtywQvjVM87L0rDKC6ywEPD2SHH2bkYEjbvwqb4JUuWmRix5M9C-cKyGsue0zLU1gwkj3xpvQkFWglW_56Ax1k_AAdEg6nbWKEAwLF9k18ed3CZTCNLx-jXs9Af67AL0sNjWaYM7nK8v2RcVgi7KEDuFZ8PPBlz6QAng=&xkcb=SoDB6_M331x-WqyLNB0abzkdCdPP&camk=ethIe0s0heet03p6ceh7aQ==&p=11&fvj=0&vjs=3  Title: Web Developer Company: Advanced Textiles Association URL: https://www.indeed.com/rc/clk?jk=35d6a1e7d41883c6&bb=14wI_Ylq6Fgk36O9dVMYwPYbJSJTPsz6pBat02VgYD4oAvO1twXWUcA3662iAcbLG9uukrWxckyX1E8I1nooh6VIe5XjWZKCxy1TZUS_Y6KUHX_i9lXEiw5iaWsINs70&xkcb=SoCo67M331x-WqyLNB0ZbzkdCdPP&fccid=bff9bd06a5dfd66c&vjs=3  Title: Front End Developer (contract) Company: BNY Mellon URL: https://www.indeed.com/rc/clk?jk=c9d611112809b2fc&bb=14wI_Ylq6Fgk36O9dVMYwAZBeK7bWdQp88iaoLc3uCoEfOWYIbz6digX5Y2vnsZ_MWfcliQa-OVC8Z2ksf9sUg9iN8BB-oud8IOHDpD0WvCJPqx7a9D_dDEG7VVDJ8WR&xkcb=SoAc67M331x-WqyLNB0YbzkdCdPP&fccid=b4048be2884af072&vjs=3  Title: Junior Software Engineer Company: SureCost URL: https://www.indeed.com/rc/clk?jk=68417c24846ae606&bb=14wI_Ylq6Fgk36O9dVMYwNZPbDmcwIHLTyhI5wapbEJJ4fmF07f-RZK7D0eEsTOiAVa2A30ososwTraie2VAdHTCovYglcdfNEMxRU1iNX3HnctGTkrAsLSEz4015svk&xkcb=SoCS67M331x-WqyLNB0fbzkdCdPP&fccid=dd616958bd9ddc12&vjs=3",
         "developer",
         "Work mode: Hybrid Onsite Location(s): Maple Grove, MN, US, 55311 Additional Location(s): US-MN-Maple Grove Diversity - Innovation - Caring - Global Collaboration - Winning Spirit - High Performance At Boston Scientific, we’ll give you the opportunity to harness all that’s within you by working in teams of diverse and high-performing employees, tackling some of the most important health industry challenges. With access to the latest tools, information and training, we’ll help you in advancing your skills and career. Here, you’ll be supported in progressing – whatever your ambitions. The Instructional Designer Content Developer (Cardiology Training) works closely with business partners, subject matter experts (SMEs), and other key stakeholders to plan and develop high-quality learning experiences to support business goals. This individual is responsible for the development of content, which may include interactive, multimedia, instructor led. This position reports to the Cardiology Training Operations Manager. Candidates will provide work portfolio as part of the application process. The interview will include a portfolio review and discussion. Your responsibilities will include: Partnering with subject matter experts and other stakeholders to analyze the learning needs. Planning, organizing, and developing learning solutions using a variety of modalities. Synthesizing and translating technical information into clear, effective, and engaging learning. Ensuring a consistent approach to the learning experience. Being proficient with a wide variety of learning tools, including but not limited to Storyline, RISE, game-based learning, videos, InDesign. Managing multiple projects with frequent priority shifts, working with high attention to accuracy and detail, and delivering within expected timelines. Being familiar with Learning Management Systems, as it relates to ensuring content works appropriately. Managing and organizing content in a centralized repository to ensure accuracy of material. Minimum Qualifications: Bachelor’s degree and/or equivalent of industry experience Four years of Instructional Design and content creation Innovative, curious mindset and ability to work independently to meet deadlines Excellent written and verbal communication skills Experience editing content for clarity and accuracy Experience using Microsoft 365 tools Experience using Articulate 360 software Experience using video editing software Experience using software to create animated characters Experience using Adobe InDesign Preferred Qualifications: Experience working within an FDA regulated environment Experience using Sales and Learning Enablement Platforms, (such as Showpad, Allego, SmartWinnr, etc) Requisition ID: 598020 Minimum Salary: $ 99100 Maximum Salary: $ 188300 Compensation for non-exempt (hourly), non-sales roles may also include variable compensation from time to time (e.g., any overtime and shift differential) and annual bonus target (subject to plan eligibility and other requirements). Compensation for exempt, non-sales roles may also include variable compensation, i.e., annual bonus target and long-term incentives (subject to plan eligibility and other requirements. For MA positions: It is unlawful to require or administer a lie detector test for employment. Violators are subject to criminal penalties and civil liability. As a leader in medical science for more than 40 years, we are committed to solving the challenges that matter most – united by a deep caring for human life. Our mission to advance science for life is about transforming lives through innovative medical solutions that improve patient lives, create value for our customers, and support our employees and the communities in which we operate. Now more than ever, we have a responsibility to apply those values to everything we do – as a global business and as a global corporate citizen. So, choosing a career with Boston Scientific (NYSE: BSX) isn’t just business, it’s personal. And if you’re a natural problem-solver with the imagination, determination, and spirit to make a meaningful difference to people worldwide, we encourage you to apply and look forward to connecting with you! At Boston Scientific, we recognize that nurturing a diverse and inclusive workplace helps us be more innovative and it is important in our work of advancing science for life and improving patient health. That is why we stand for inclusion, equality, and opportunity for all. By embracing the richness of our unique backgrounds and perspectives, we create a better, more rewarding place for our employees to work and reflect the patients, customers, and communities we serve. Boston Scientific Corporation has been and will continue to be an equal opportunity employer. To ensure full implementation of its equal employment policy, the Company will continue to take steps to assure that recruitment, hiring, assignment, promotion, compensation, and all other personnel decisions are made and administered without regard to race, religion, color, national origin, citizenship, sex, sexual orientation, gender identify, gender expression, veteran status, age, mental or physical disability, genetic information or any other protected class. Please be advised that certain US based positions, including without limitation field sales and service positions that call on hospitals and/or health care centers, require acceptable proof of COVID-19 vaccination status. Candidates will be notified during the interview and selection process if the role(s) for which they have applied require proof of vaccination as a condition of employment. Boston Scientific continues to evaluate its policies and protocols regarding the COVID-19 vaccine and will comply with all applicable state and federal law and healthcare credentialing requirements. As employees of the Company, you will be expected to meet the ongoing requirements for your roles, including any new requirements, should the Company’s policies or protocols change with regard to COVID-19 vaccination. Nearest Major Market: Minneapolis Job Segment: Learning, Testing, Developer, Programmer, Information Technology, Human Resources, Technology Title: Software Engineer Company: Specialty Capital URL:   Title: Software Safety Engineer Company: Entegee URL:   Title: Entry Level Java Developer Company: Hemma Systems Inc. URL:   Title: Software Engineer II - C# (Remote) Company: McDonald's Corporation URL:   Title: Manager, Software Engineering Company: Balboa Digital Inc URL:   Title: Associate Software Developer Company: Aspen Technology URL:   Title: Experienced Software Engineer across a wide array of tech stacks Company: Infinity Software Development, Inc URL:   Title: Sr Developer/Full Stack (Remote - Hybrid: Twin Cities/St Peter) Company: Scholarship America URL:   Title: Junior Front End Engineer Company: minware URL:   Title: Website Programmer Front End - Entry Level Company: Trib Total Media URL:   Title: Full Stack Java Software Engineer - Remote Company: Kunz, Leigh & Associates URL:   Title: Automation Controls Engineer Company: Actalent URL:   Title: Web Developer Company: Advanced Textiles Association URL:   Title: Front End Developer (contract) Company: BNY Mellon URL:   Title: Junior Software Engineer Company: SureCost URL: ",
         "Work mode: Hybrid Onsite Location(s): Maple Grove, MN, US, 55311 Additional Location(s): US-MN-Maple Grove Diversity - Innovation - Caring - Global Collaboration - Winning Spirit - High Performance At Boston Scientific, we’ll give you the opportunity to harness all that’s within you by working in teams of diverse and high-performing employees, tackling some of the most important health industry challenges. With access to the latest tools, information and training, we’ll help you in advancing your skills and career. Here, you’ll be supported in progressing – whatever your ambitions. The Instructional Designer Content Developer (Cardiology Training) works closely with business partners, subject matter experts (SMEs), and other key stakeholders to plan and develop high-quality learning experiences to support business goals. This individual is responsible for the development of content, which may include interactive, multimedia, instructor led. This position reports to the Cardiology Training Operations Manager. Candidates will provide work portfolio as part of the application process. The interview will include a portfolio review and discussion. Your responsibilities will include: Partnering with subject matter experts and other stakeholders to analyze the learning needs. Planning, organizing, and developing learning solutions using a variety of modalities. Synthesizing and translating technical information into clear, effective, and engaging learning. Ensuring a consistent approach to the learning experience. Being proficient with a wide variety of learning tools, including but not limited to Storyline, RISE, game-based learning, videos, InDesign. Managing multiple projects with frequent priority shifts, working with high attention to accuracy and detail, and delivering within expected timelines. Being familiar with Learning Management Systems, as it relates to ensuring content works appropriately. Managing and organizing content in a centralized repository to ensure accuracy of material. Minimum Qualifications: Bachelor’s degree and/or equivalent of industry experience Four years of Instructional Design and content creation Innovative, curious mindset and ability to work independently to meet deadlines Excellent written and verbal communication skills Experience editing content for clarity and accuracy Experience using Microsoft 365 tools Experience using Articulate 360 software Experience using video editing software Experience using software to create animated characters Experience using Adobe InDesign Preferred Qualifications: Experience working within an FDA regulated environment Experience using Sales and Learning Enablement Platforms, (such as Showpad, Allego, SmartWinnr, etc) Requisition ID: 598020 Minimum Salary: $ 99100 Maximum Salary: $ 188300 Compensation for non-exempt (hourly), non-sales roles may also include variable compensation from time to time (e.g., any overtime and shift differential) and annual bonus target (subject to plan eligibility and other requirements). Compensation for exempt, non-sales roles may also include variable compensation, i.e., annual bonus target and long-term incentives (subject to plan eligibility and other requirements. For MA positions: It is unlawful to require or administer a lie detector test for employment. Violators are subject to criminal penalties and civil liability. As a leader in medical science for more than 40 years, we are committed to solving the challenges that matter most – united by a deep caring for human life. Our mission to advance science for life is about transforming lives through innovative medical solutions that improve patient lives, create value for our customers, and support our employees and the communities in which we operate. Now more than ever, we have a responsibility to apply those values to everything we do – as a global business and as a global corporate citizen. So, choosing a career with Boston Scientific (NYSE: BSX) isn’t just business, it’s personal. And if you’re a natural problem-solver with the imagination, determination, and spirit to make a meaningful difference to people worldwide, we encourage you to apply and look forward to connecting with you! At Boston Scientific, we recognize that nurturing a diverse and inclusive workplace helps us be more innovative and it is important in our work of advancing science for life and improving patient health. That is why we stand for inclusion, equality, and opportunity for all. By embracing the richness of our unique backgrounds and perspectives, we create a better, more rewarding place for our employees to work and reflect the patients, customers, and communities we serve. Boston Scientific Corporation has been and will continue to be an equal opportunity employer. To ensure full implementation of its equal employment policy, the Company will continue to take steps to assure that recruitment, hiring, assignment, promotion, compensation, and all other personnel decisions are made and administered without regard to race, religion, color, national origin, citizenship, sex, sexual orientation, gender identify, gender expression, veteran status, age, mental or physical disability, genetic information or any other protected class. Please be advised that certain US based positions, including without limitation field sales and service positions that call on hospitals and/or health care centers, require acceptable proof of COVID-19 vaccination status. Candidates will be notified during the interview and selection process if the role(s) for which they have applied require proof of vaccination as a condition of employment. Boston Scientific continues to evaluate its policies and protocols regarding the COVID-19 vaccine and will comply with all applicable state and federal law and healthcare credentialing requirements. As employees of the Company, you will be expected to meet the ongoing requirements for your roles, including any new requirements, should the Company’s policies or protocols change with regard to COVID-19 vaccination. Nearest Major Market: Minneapolis Job Segment: Learning, Testing, Developer, Programmer, Information Technology, Human Resources, Technology Title: Software Engineer Company: Specialty Capital URL:   Title: Software Safety Engineer Company: Entegee URL:   Title: Entry Level Java Developer Company: Hemma Systems Inc. URL:   Title: Software Engineer II - C# (Remote) Company: McDonald's Corporation URL:   Title: Manager, Software Engineering Company: Balboa Digital Inc URL:   Title: Associate Software Developer Company: Aspen Technology URL:   Title: Experienced Software Engineer across a wide array of tech stacks Company: Infinity Software Development, Inc URL:   Title: Sr Developer/Full Stack (Remote - Hybrid: Twin Cities/St Peter) Company: Scholarship America URL:   Title: Junior Front End Engineer Company: minware URL:   Title: Website Programmer Front End - Entry Level Company: Trib Total Media URL:   Title: Full Stack Java Software Engineer - Remote Company: Kunz, Leigh & Associates URL:   Title: Automation Controls Engineer Company: Actalent URL:   Title: Web Developer Company: Advanced Textiles Association URL:   Title: Front End Developer (contract) Company: BNY Mellon URL:   Title: Junior Software Engineer Company: SureCost URL: ",
         "Bachelor’s degree and/or equivalent of industry experience Four years of Instructional Design and content creation Innovative, curious mindset and ability to work independently to meet deadlines Excellent written and verbal communication skills Experience editing content for clarity and accuracy Experience using Microsoft 365 tools Experience using Articulate 360 software Experience using video editing software Experience using software to create animated characters Experience using Adobe InDesign Preferred Qualifications: Experience working within an FDA regulated environment Experience using Sales and Learning Enablement Platforms, (such as Showpad, Allego, SmartWinnr, etc) Requisition ID: 598020 Minimum Salary: $ 99100 Maximum Salary: $ 188300 Compensation for non-exempt (hourly), non-sales roles may also include variable compensation from time to time (e.g., any overtime and shift differential) and annual bonus target (subject to plan eligibility and other requirements). Compensation for exempt, non-sales roles may also include variable compensation, i.e., annual bonus target and long-term incentives (subject to plan eligibility and other requirements. For MA positions: It is unlawful to require or administer a lie detector test for employment. Violators are subject to criminal penalties and civil liability. As a leader in medical science for more than 40 years, we are committed to solving the challenges that matter most – united by a deep caring for human life. Our mission to advance science for life is about transforming lives through innovative medical solutions that improve patient lives, create value for our customers, and support our employees and the communities in which we operate. Now more than ever, we have a responsibility to apply those values to everything we do – as a global business and as a global corporate citizen. So, choosing a career with Boston Scientific (NYSE: BSX) isn’t just business, it’s personal. And if you’re a natural problem-solver with the imagination, determination, and spirit to make a meaningful difference to people worldwide, we encourage you to apply and look forward to connecting with you! At Boston Scientific, we recognize that nurturing a diverse and inclusive workplace helps us be more innovative and it is important in our work of advancing science for life and improving patient health. That is why we stand for inclusion, equality, and opportunity for all. By embracing the richness of our unique backgrounds and perspectives, we create a better, more rewarding place for our employees to work and reflect the patients, customers, and communities we serve. Boston Scientific Corporation has been and will continue to be an equal opportunity employer. To ensure full implementation of its equal employment policy, the Company will continue to take steps to assure that recruitment, hiring, assignment, promotion, compensation, and all other personnel decisions are made and administered without regard to race, religion, color, national origin, citizenship, sex, sexual orientation, gender identify, gender expression, veteran status, age, mental or physical disability, genetic information or any other protected class. Please be advised that certain US based positions, including without limitation field sales and service positions that call on hospitals and/or health care centers, require acceptable proof of COVID-19 vaccination status. Candidates will be notified during the interview and selection process if the role(s) for which they have applied require proof of vaccination as a condition of employment. Boston Scientific continues to evaluate its policies and protocols regarding the COVID-19 vaccine and will comply with all applicable state and federal law and healthcare credentialing requirements. As employees of the Company, you will be expected to meet the ongoing requirements for your roles, including any new requirements, should the Company’s policies or protocols change with regard to COVID-19 vaccination. Nearest Major Market: Minneapolis Job Segment: Learning, Testing, Developer, Programmer, Information Technology, Human Resources, Technology Title: Software Engineer Company: Specialty Capital URL:   Title: Software Safety Engineer Company: Entegee URL:   Title: Entry Level Java Developer Company: Hemma Systems Inc. URL:   Title: Software Engineer II - C# (Remote) Company: McDonald's Corporation URL:   Title: Manager, Software Engineering Company: Balboa Digital Inc URL:   Title: Associate Software Developer Company: Aspen Technology URL:   Title: Experienced Software Engineer across a wide array of tech stacks Company: Infinity Software Development, Inc URL:   Title: Sr Developer/Full Stack (Remote - Hybrid: Twin Cities/St Peter) Company: Scholarship America URL:   Title: Junior Front End Engineer Company: minware URL:   Title: Website Programmer Front End - Entry Level Company: Trib Total Media URL:   Title: Full Stack Java Software Engineer - Remote Company: Kunz, Leigh & Associates URL:   Title: Automation Controls Engineer Company: Actalent URL:   Title: Web Developer Company: Advanced Textiles Association URL:   Title: Front End Developer (contract) Company: BNY Mellon URL:   Title: Junior Software Engineer Company: SureCost URL:",
         752
        ],
        [
         "Junior Software Engineer",
         "Scholarship America",
         "Work mode: Hybrid Onsite Location(s): Maple Grove, MN, US, 55311 Additional Location(s): US-MN-Maple Grove Diversity - Innovation - Caring - Global Collaboration - Winning Spirit - High Performance At Boston Scientific, we’ll give you the opportunity to harness all that’s within you by working in teams of diverse and high-performing employees, tackling some of the most important health industry challenges. With access to the latest tools, information and training, we’ll help you in advancing your skills and career. Here, you’ll be supported in progressing – whatever your ambitions. The Instructional Designer Content Developer (Cardiology Training) works closely with business partners, subject matter experts (SMEs), and other key stakeholders to plan and develop high-quality learning experiences to support business goals. This individual is responsible for the development of content, which may include interactive, multimedia, instructor led. This position reports to the Cardiology Training Operations Manager. Candidates will provide work portfolio as part of the application process. The interview will include a portfolio review and discussion. Your responsibilities will include: Partnering with subject matter experts and other stakeholders to analyze the learning needs. Planning, organizing, and developing learning solutions using a variety of modalities. Synthesizing and translating technical information into clear, effective, and engaging learning. Ensuring a consistent approach to the learning experience. Being proficient with a wide variety of learning tools, including but not limited to Storyline, RISE, game-based learning, videos, InDesign. Managing multiple projects with frequent priority shifts, working with high attention to accuracy and detail, and delivering within expected timelines. Being familiar with Learning Management Systems, as it relates to ensuring content works appropriately. Managing and organizing content in a centralized repository to ensure accuracy of material. Minimum Qualifications: Bachelor’s degree and/or equivalent of industry experience Four years of Instructional Design and content creation Innovative, curious mindset and ability to work independently to meet deadlines Excellent written and verbal communication skills Experience editing content for clarity and accuracy Experience using Microsoft 365 tools Experience using Articulate 360 software Experience using video editing software Experience using software to create animated characters Experience using Adobe InDesign Preferred Qualifications: Experience working within an FDA regulated environment Experience using Sales and Learning Enablement Platforms, (such as Showpad, Allego, SmartWinnr, etc) Requisition ID: 598020 Minimum Salary: $ 99100 Maximum Salary: $ 188300 Compensation for non-exempt (hourly), non-sales roles may also include variable compensation from time to time (e.g., any overtime and shift differential) and annual bonus target (subject to plan eligibility and other requirements). Compensation for exempt, non-sales roles may also include variable compensation, i.e., annual bonus target and long-term incentives (subject to plan eligibility and other requirements. For MA positions: It is unlawful to require or administer a lie detector test for employment. Violators are subject to criminal penalties and civil liability. As a leader in medical science for more than 40 years, we are committed to solving the challenges that matter most – united by a deep caring for human life. Our mission to advance science for life is about transforming lives through innovative medical solutions that improve patient lives, create value for our customers, and support our employees and the communities in which we operate. Now more than ever, we have a responsibility to apply those values to everything we do – as a global business and as a global corporate citizen. So, choosing a career with Boston Scientific (NYSE: BSX) isn’t just business, it’s personal. And if you’re a natural problem-solver with the imagination, determination, and spirit to make a meaningful difference to people worldwide, we encourage you to apply and look forward to connecting with you! At Boston Scientific, we recognize that nurturing a diverse and inclusive workplace helps us be more innovative and it is important in our work of advancing science for life and improving patient health. That is why we stand for inclusion, equality, and opportunity for all. By embracing the richness of our unique backgrounds and perspectives, we create a better, more rewarding place for our employees to work and reflect the patients, customers, and communities we serve. Boston Scientific Corporation has been and will continue to be an equal opportunity employer. To ensure full implementation of its equal employment policy, the Company will continue to take steps to assure that recruitment, hiring, assignment, promotion, compensation, and all other personnel decisions are made and administered without regard to race, religion, color, national origin, citizenship, sex, sexual orientation, gender identify, gender expression, veteran status, age, mental or physical disability, genetic information or any other protected class. Please be advised that certain US based positions, including without limitation field sales and service positions that call on hospitals and/or health care centers, require acceptable proof of COVID-19 vaccination status. Candidates will be notified during the interview and selection process if the role(s) for which they have applied require proof of vaccination as a condition of employment. Boston Scientific continues to evaluate its policies and protocols regarding the COVID-19 vaccine and will comply with all applicable state and federal law and healthcare credentialing requirements. As employees of the Company, you will be expected to meet the ongoing requirements for your roles, including any new requirements, should the Company’s policies or protocols change with regard to COVID-19 vaccination. Nearest Major Market: Minneapolis Job Segment: Learning, Testing, Developer, Programmer, Information Technology, Human Resources, Technology",
         "developer",
         "Work mode: Hybrid Onsite Location(s): Maple Grove, MN, US, 55311 Additional Location(s): US-MN-Maple Grove Diversity - Innovation - Caring - Global Collaboration - Winning Spirit - High Performance At Boston Scientific, we’ll give you the opportunity to harness all that’s within you by working in teams of diverse and high-performing employees, tackling some of the most important health industry challenges. With access to the latest tools, information and training, we’ll help you in advancing your skills and career. Here, you’ll be supported in progressing – whatever your ambitions. The Instructional Designer Content Developer (Cardiology Training) works closely with business partners, subject matter experts (SMEs), and other key stakeholders to plan and develop high-quality learning experiences to support business goals. This individual is responsible for the development of content, which may include interactive, multimedia, instructor led. This position reports to the Cardiology Training Operations Manager. Candidates will provide work portfolio as part of the application process. The interview will include a portfolio review and discussion. Your responsibilities will include: Partnering with subject matter experts and other stakeholders to analyze the learning needs. Planning, organizing, and developing learning solutions using a variety of modalities. Synthesizing and translating technical information into clear, effective, and engaging learning. Ensuring a consistent approach to the learning experience. Being proficient with a wide variety of learning tools, including but not limited to Storyline, RISE, game-based learning, videos, InDesign. Managing multiple projects with frequent priority shifts, working with high attention to accuracy and detail, and delivering within expected timelines. Being familiar with Learning Management Systems, as it relates to ensuring content works appropriately. Managing and organizing content in a centralized repository to ensure accuracy of material. Minimum Qualifications: Bachelor’s degree and/or equivalent of industry experience Four years of Instructional Design and content creation Innovative, curious mindset and ability to work independently to meet deadlines Excellent written and verbal communication skills Experience editing content for clarity and accuracy Experience using Microsoft 365 tools Experience using Articulate 360 software Experience using video editing software Experience using software to create animated characters Experience using Adobe InDesign Preferred Qualifications: Experience working within an FDA regulated environment Experience using Sales and Learning Enablement Platforms, (such as Showpad, Allego, SmartWinnr, etc) Requisition ID: 598020 Minimum Salary: $ 99100 Maximum Salary: $ 188300 Compensation for non-exempt (hourly), non-sales roles may also include variable compensation from time to time (e.g., any overtime and shift differential) and annual bonus target (subject to plan eligibility and other requirements). Compensation for exempt, non-sales roles may also include variable compensation, i.e., annual bonus target and long-term incentives (subject to plan eligibility and other requirements. For MA positions: It is unlawful to require or administer a lie detector test for employment. Violators are subject to criminal penalties and civil liability. As a leader in medical science for more than 40 years, we are committed to solving the challenges that matter most – united by a deep caring for human life. Our mission to advance science for life is about transforming lives through innovative medical solutions that improve patient lives, create value for our customers, and support our employees and the communities in which we operate. Now more than ever, we have a responsibility to apply those values to everything we do – as a global business and as a global corporate citizen. So, choosing a career with Boston Scientific (NYSE: BSX) isn’t just business, it’s personal. And if you’re a natural problem-solver with the imagination, determination, and spirit to make a meaningful difference to people worldwide, we encourage you to apply and look forward to connecting with you! At Boston Scientific, we recognize that nurturing a diverse and inclusive workplace helps us be more innovative and it is important in our work of advancing science for life and improving patient health. That is why we stand for inclusion, equality, and opportunity for all. By embracing the richness of our unique backgrounds and perspectives, we create a better, more rewarding place for our employees to work and reflect the patients, customers, and communities we serve. Boston Scientific Corporation has been and will continue to be an equal opportunity employer. To ensure full implementation of its equal employment policy, the Company will continue to take steps to assure that recruitment, hiring, assignment, promotion, compensation, and all other personnel decisions are made and administered without regard to race, religion, color, national origin, citizenship, sex, sexual orientation, gender identify, gender expression, veteran status, age, mental or physical disability, genetic information or any other protected class. Please be advised that certain US based positions, including without limitation field sales and service positions that call on hospitals and/or health care centers, require acceptable proof of COVID-19 vaccination status. Candidates will be notified during the interview and selection process if the role(s) for which they have applied require proof of vaccination as a condition of employment. Boston Scientific continues to evaluate its policies and protocols regarding the COVID-19 vaccine and will comply with all applicable state and federal law and healthcare credentialing requirements. As employees of the Company, you will be expected to meet the ongoing requirements for your roles, including any new requirements, should the Company’s policies or protocols change with regard to COVID-19 vaccination. Nearest Major Market: Minneapolis Job Segment: Learning, Testing, Developer, Programmer, Information Technology, Human Resources, Technology",
         "Work mode: Hybrid Onsite Location(s): Maple Grove, MN, US, 55311 Additional Location(s): US-MN-Maple Grove Diversity - Innovation - Caring - Global Collaboration - Winning Spirit - High Performance At Boston Scientific, we’ll give you the opportunity to harness all that’s within you by working in teams of diverse and high-performing employees, tackling some of the most important health industry challenges. With access to the latest tools, information and training, we’ll help you in advancing your skills and career. Here, you’ll be supported in progressing – whatever your ambitions. The Instructional Designer Content Developer (Cardiology Training) works closely with business partners, subject matter experts (SMEs), and other key stakeholders to plan and develop high-quality learning experiences to support business goals. This individual is responsible for the development of content, which may include interactive, multimedia, instructor led. This position reports to the Cardiology Training Operations Manager. Candidates will provide work portfolio as part of the application process. The interview will include a portfolio review and discussion. Your responsibilities will include: Partnering with subject matter experts and other stakeholders to analyze the learning needs. Planning, organizing, and developing learning solutions using a variety of modalities. Synthesizing and translating technical information into clear, effective, and engaging learning. Ensuring a consistent approach to the learning experience. Being proficient with a wide variety of learning tools, including but not limited to Storyline, RISE, game-based learning, videos, InDesign. Managing multiple projects with frequent priority shifts, working with high attention to accuracy and detail, and delivering within expected timelines. Being familiar with Learning Management Systems, as it relates to ensuring content works appropriately. Managing and organizing content in a centralized repository to ensure accuracy of material. Minimum Qualifications: Bachelor’s degree and/or equivalent of industry experience Four years of Instructional Design and content creation Innovative, curious mindset and ability to work independently to meet deadlines Excellent written and verbal communication skills Experience editing content for clarity and accuracy Experience using Microsoft 365 tools Experience using Articulate 360 software Experience using video editing software Experience using software to create animated characters Experience using Adobe InDesign Preferred Qualifications: Experience working within an FDA regulated environment Experience using Sales and Learning Enablement Platforms, (such as Showpad, Allego, SmartWinnr, etc) Requisition ID: 598020 Minimum Salary: $ 99100 Maximum Salary: $ 188300 Compensation for non-exempt (hourly), non-sales roles may also include variable compensation from time to time (e.g., any overtime and shift differential) and annual bonus target (subject to plan eligibility and other requirements). Compensation for exempt, non-sales roles may also include variable compensation, i.e., annual bonus target and long-term incentives (subject to plan eligibility and other requirements. For MA positions: It is unlawful to require or administer a lie detector test for employment. Violators are subject to criminal penalties and civil liability. As a leader in medical science for more than 40 years, we are committed to solving the challenges that matter most – united by a deep caring for human life. Our mission to advance science for life is about transforming lives through innovative medical solutions that improve patient lives, create value for our customers, and support our employees and the communities in which we operate. Now more than ever, we have a responsibility to apply those values to everything we do – as a global business and as a global corporate citizen. So, choosing a career with Boston Scientific (NYSE: BSX) isn’t just business, it’s personal. And if you’re a natural problem-solver with the imagination, determination, and spirit to make a meaningful difference to people worldwide, we encourage you to apply and look forward to connecting with you! At Boston Scientific, we recognize that nurturing a diverse and inclusive workplace helps us be more innovative and it is important in our work of advancing science for life and improving patient health. That is why we stand for inclusion, equality, and opportunity for all. By embracing the richness of our unique backgrounds and perspectives, we create a better, more rewarding place for our employees to work and reflect the patients, customers, and communities we serve. Boston Scientific Corporation has been and will continue to be an equal opportunity employer. To ensure full implementation of its equal employment policy, the Company will continue to take steps to assure that recruitment, hiring, assignment, promotion, compensation, and all other personnel decisions are made and administered without regard to race, religion, color, national origin, citizenship, sex, sexual orientation, gender identify, gender expression, veteran status, age, mental or physical disability, genetic information or any other protected class. Please be advised that certain US based positions, including without limitation field sales and service positions that call on hospitals and/or health care centers, require acceptable proof of COVID-19 vaccination status. Candidates will be notified during the interview and selection process if the role(s) for which they have applied require proof of vaccination as a condition of employment. Boston Scientific continues to evaluate its policies and protocols regarding the COVID-19 vaccine and will comply with all applicable state and federal law and healthcare credentialing requirements. As employees of the Company, you will be expected to meet the ongoing requirements for your roles, including any new requirements, should the Company’s policies or protocols change with regard to COVID-19 vaccination. Nearest Major Market: Minneapolis Job Segment: Learning, Testing, Developer, Programmer, Information Technology, Human Resources, Technology",
         "Bachelor’s degree and/or equivalent of industry experience Four years of Instructional Design and content creation Innovative, curious mindset and ability to work independently to meet deadlines Excellent written and verbal communication skills Experience editing content for clarity and accuracy Experience using Microsoft 365 tools Experience using Articulate 360 software Experience using video editing software Experience using software to create animated characters Experience using Adobe InDesign Preferred Qualifications: Experience working within an FDA regulated environment Experience using Sales and Learning Enablement Platforms, (such as Showpad, Allego, SmartWinnr, etc) Requisition ID: 598020 Minimum Salary: $ 99100 Maximum Salary: $ 188300 Compensation for non-exempt (hourly), non-sales roles may also include variable compensation from time to time (e.g., any overtime and shift differential) and annual bonus target (subject to plan eligibility and other requirements). Compensation for exempt, non-sales roles may also include variable compensation, i.e., annual bonus target and long-term incentives (subject to plan eligibility and other requirements. For MA positions: It is unlawful to require or administer a lie detector test for employment. Violators are subject to criminal penalties and civil liability. As a leader in medical science for more than 40 years, we are committed to solving the challenges that matter most – united by a deep caring for human life. Our mission to advance science for life is about transforming lives through innovative medical solutions that improve patient lives, create value for our customers, and support our employees and the communities in which we operate. Now more than ever, we have a responsibility to apply those values to everything we do – as a global business and as a global corporate citizen. So, choosing a career with Boston Scientific (NYSE: BSX) isn’t just business, it’s personal. And if you’re a natural problem-solver with the imagination, determination, and spirit to make a meaningful difference to people worldwide, we encourage you to apply and look forward to connecting with you! At Boston Scientific, we recognize that nurturing a diverse and inclusive workplace helps us be more innovative and it is important in our work of advancing science for life and improving patient health. That is why we stand for inclusion, equality, and opportunity for all. By embracing the richness of our unique backgrounds and perspectives, we create a better, more rewarding place for our employees to work and reflect the patients, customers, and communities we serve. Boston Scientific Corporation has been and will continue to be an equal opportunity employer. To ensure full implementation of its equal employment policy, the Company will continue to take steps to assure that recruitment, hiring, assignment, promotion, compensation, and all other personnel decisions are made and administered without regard to race, religion, color, national origin, citizenship, sex, sexual orientation, gender identify, gender expression, veteran status, age, mental or physical disability, genetic information or any other protected class. Please be advised that certain US based positions, including without limitation field sales and service positions that call on hospitals and/or health care centers, require acceptable proof of COVID-19 vaccination status. Candidates will be notified during the interview and selection process if the role(s) for which they have applied require proof of vaccination as a condition of employment. Boston Scientific continues to evaluate its policies and protocols regarding the COVID-19 vaccine and will comply with all applicable state and federal law and healthcare credentialing requirements. As employees of the Company, you will be expected to meet the ongoing requirements for your roles, including any new requirements, should the Company’s policies or protocols change with regard to COVID-19 vaccination. Nearest Major Market: Minneapolis Job Segment: Learning, Testing, Developer, Programmer, Information Technology, Human Resources, Technology",
         603
        ],
        [
         "Software Engineer, Backend",
         "CyberBalance, LLC",
         "Work mode: Hybrid Onsite Location(s): Maple Grove, MN, US, 55311 Additional Location(s): US-MN-Maple Grove Diversity - Innovation - Caring - Global Collaboration - Winning Spirit - High Performance At Boston Scientific, we’ll give you the opportunity to harness all that’s within you by working in teams of diverse and high-performing employees, tackling some of the most important health industry challenges. With access to the latest tools, information and training, we’ll help you in advancing your skills and career. Here, you’ll be supported in progressing – whatever your ambitions. The Instructional Designer Content Developer (Cardiology Training) works closely with business partners, subject matter experts (SMEs), and other key stakeholders to plan and develop high-quality learning experiences to support business goals. This individual is responsible for the development of content, which may include interactive, multimedia, instructor led. This position reports to the Cardiology Training Operations Manager. Candidates will provide work portfolio as part of the application process. The interview will include a portfolio review and discussion. Your responsibilities will include: Partnering with subject matter experts and other stakeholders to analyze the learning needs. Planning, organizing, and developing learning solutions using a variety of modalities. Synthesizing and translating technical information into clear, effective, and engaging learning. Ensuring a consistent approach to the learning experience. Being proficient with a wide variety of learning tools, including but not limited to Storyline, RISE, game-based learning, videos, InDesign. Managing multiple projects with frequent priority shifts, working with high attention to accuracy and detail, and delivering within expected timelines. Being familiar with Learning Management Systems, as it relates to ensuring content works appropriately. Managing and organizing content in a centralized repository to ensure accuracy of material. Minimum Qualifications: Bachelor’s degree and/or equivalent of industry experience Four years of Instructional Design and content creation Innovative, curious mindset and ability to work independently to meet deadlines Excellent written and verbal communication skills Experience editing content for clarity and accuracy Experience using Microsoft 365 tools Experience using Articulate 360 software Experience using video editing software Experience using software to create animated characters Experience using Adobe InDesign Preferred Qualifications: Experience working within an FDA regulated environment Experience using Sales and Learning Enablement Platforms, (such as Showpad, Allego, SmartWinnr, etc) Requisition ID: 598020 Minimum Salary: $ 99100 Maximum Salary: $ 188300 Compensation for non-exempt (hourly), non-sales roles may also include variable compensation from time to time (e.g., any overtime and shift differential) and annual bonus target (subject to plan eligibility and other requirements). Compensation for exempt, non-sales roles may also include variable compensation, i.e., annual bonus target and long-term incentives (subject to plan eligibility and other requirements. For MA positions: It is unlawful to require or administer a lie detector test for employment. Violators are subject to criminal penalties and civil liability. As a leader in medical science for more than 40 years, we are committed to solving the challenges that matter most – united by a deep caring for human life. Our mission to advance science for life is about transforming lives through innovative medical solutions that improve patient lives, create value for our customers, and support our employees and the communities in which we operate. Now more than ever, we have a responsibility to apply those values to everything we do – as a global business and as a global corporate citizen. So, choosing a career with Boston Scientific (NYSE: BSX) isn’t just business, it’s personal. And if you’re a natural problem-solver with the imagination, determination, and spirit to make a meaningful difference to people worldwide, we encourage you to apply and look forward to connecting with you! At Boston Scientific, we recognize that nurturing a diverse and inclusive workplace helps us be more innovative and it is important in our work of advancing science for life and improving patient health. That is why we stand for inclusion, equality, and opportunity for all. By embracing the richness of our unique backgrounds and perspectives, we create a better, more rewarding place for our employees to work and reflect the patients, customers, and communities we serve. Boston Scientific Corporation has been and will continue to be an equal opportunity employer. To ensure full implementation of its equal employment policy, the Company will continue to take steps to assure that recruitment, hiring, assignment, promotion, compensation, and all other personnel decisions are made and administered without regard to race, religion, color, national origin, citizenship, sex, sexual orientation, gender identify, gender expression, veteran status, age, mental or physical disability, genetic information or any other protected class. Please be advised that certain US based positions, including without limitation field sales and service positions that call on hospitals and/or health care centers, require acceptable proof of COVID-19 vaccination status. Candidates will be notified during the interview and selection process if the role(s) for which they have applied require proof of vaccination as a condition of employment. Boston Scientific continues to evaluate its policies and protocols regarding the COVID-19 vaccine and will comply with all applicable state and federal law and healthcare credentialing requirements. As employees of the Company, you will be expected to meet the ongoing requirements for your roles, including any new requirements, should the Company’s policies or protocols change with regard to COVID-19 vaccination. Nearest Major Market: Minneapolis Job Segment: Learning, Testing, Developer, Programmer, Information Technology, Human Resources, Technology",
         "developer",
         "Work mode: Hybrid Onsite Location(s): Maple Grove, MN, US, 55311 Additional Location(s): US-MN-Maple Grove Diversity - Innovation - Caring - Global Collaboration - Winning Spirit - High Performance At Boston Scientific, we’ll give you the opportunity to harness all that’s within you by working in teams of diverse and high-performing employees, tackling some of the most important health industry challenges. With access to the latest tools, information and training, we’ll help you in advancing your skills and career. Here, you’ll be supported in progressing – whatever your ambitions. The Instructional Designer Content Developer (Cardiology Training) works closely with business partners, subject matter experts (SMEs), and other key stakeholders to plan and develop high-quality learning experiences to support business goals. This individual is responsible for the development of content, which may include interactive, multimedia, instructor led. This position reports to the Cardiology Training Operations Manager. Candidates will provide work portfolio as part of the application process. The interview will include a portfolio review and discussion. Your responsibilities will include: Partnering with subject matter experts and other stakeholders to analyze the learning needs. Planning, organizing, and developing learning solutions using a variety of modalities. Synthesizing and translating technical information into clear, effective, and engaging learning. Ensuring a consistent approach to the learning experience. Being proficient with a wide variety of learning tools, including but not limited to Storyline, RISE, game-based learning, videos, InDesign. Managing multiple projects with frequent priority shifts, working with high attention to accuracy and detail, and delivering within expected timelines. Being familiar with Learning Management Systems, as it relates to ensuring content works appropriately. Managing and organizing content in a centralized repository to ensure accuracy of material. Minimum Qualifications: Bachelor’s degree and/or equivalent of industry experience Four years of Instructional Design and content creation Innovative, curious mindset and ability to work independently to meet deadlines Excellent written and verbal communication skills Experience editing content for clarity and accuracy Experience using Microsoft 365 tools Experience using Articulate 360 software Experience using video editing software Experience using software to create animated characters Experience using Adobe InDesign Preferred Qualifications: Experience working within an FDA regulated environment Experience using Sales and Learning Enablement Platforms, (such as Showpad, Allego, SmartWinnr, etc) Requisition ID: 598020 Minimum Salary: $ 99100 Maximum Salary: $ 188300 Compensation for non-exempt (hourly), non-sales roles may also include variable compensation from time to time (e.g., any overtime and shift differential) and annual bonus target (subject to plan eligibility and other requirements). Compensation for exempt, non-sales roles may also include variable compensation, i.e., annual bonus target and long-term incentives (subject to plan eligibility and other requirements. For MA positions: It is unlawful to require or administer a lie detector test for employment. Violators are subject to criminal penalties and civil liability. As a leader in medical science for more than 40 years, we are committed to solving the challenges that matter most – united by a deep caring for human life. Our mission to advance science for life is about transforming lives through innovative medical solutions that improve patient lives, create value for our customers, and support our employees and the communities in which we operate. Now more than ever, we have a responsibility to apply those values to everything we do – as a global business and as a global corporate citizen. So, choosing a career with Boston Scientific (NYSE: BSX) isn’t just business, it’s personal. And if you’re a natural problem-solver with the imagination, determination, and spirit to make a meaningful difference to people worldwide, we encourage you to apply and look forward to connecting with you! At Boston Scientific, we recognize that nurturing a diverse and inclusive workplace helps us be more innovative and it is important in our work of advancing science for life and improving patient health. That is why we stand for inclusion, equality, and opportunity for all. By embracing the richness of our unique backgrounds and perspectives, we create a better, more rewarding place for our employees to work and reflect the patients, customers, and communities we serve. Boston Scientific Corporation has been and will continue to be an equal opportunity employer. To ensure full implementation of its equal employment policy, the Company will continue to take steps to assure that recruitment, hiring, assignment, promotion, compensation, and all other personnel decisions are made and administered without regard to race, religion, color, national origin, citizenship, sex, sexual orientation, gender identify, gender expression, veteran status, age, mental or physical disability, genetic information or any other protected class. Please be advised that certain US based positions, including without limitation field sales and service positions that call on hospitals and/or health care centers, require acceptable proof of COVID-19 vaccination status. Candidates will be notified during the interview and selection process if the role(s) for which they have applied require proof of vaccination as a condition of employment. Boston Scientific continues to evaluate its policies and protocols regarding the COVID-19 vaccine and will comply with all applicable state and federal law and healthcare credentialing requirements. As employees of the Company, you will be expected to meet the ongoing requirements for your roles, including any new requirements, should the Company’s policies or protocols change with regard to COVID-19 vaccination. Nearest Major Market: Minneapolis Job Segment: Learning, Testing, Developer, Programmer, Information Technology, Human Resources, Technology",
         "Work mode: Hybrid Onsite Location(s): Maple Grove, MN, US, 55311 Additional Location(s): US-MN-Maple Grove Diversity - Innovation - Caring - Global Collaboration - Winning Spirit - High Performance At Boston Scientific, we’ll give you the opportunity to harness all that’s within you by working in teams of diverse and high-performing employees, tackling some of the most important health industry challenges. With access to the latest tools, information and training, we’ll help you in advancing your skills and career. Here, you’ll be supported in progressing – whatever your ambitions. The Instructional Designer Content Developer (Cardiology Training) works closely with business partners, subject matter experts (SMEs), and other key stakeholders to plan and develop high-quality learning experiences to support business goals. This individual is responsible for the development of content, which may include interactive, multimedia, instructor led. This position reports to the Cardiology Training Operations Manager. Candidates will provide work portfolio as part of the application process. The interview will include a portfolio review and discussion. Your responsibilities will include: Partnering with subject matter experts and other stakeholders to analyze the learning needs. Planning, organizing, and developing learning solutions using a variety of modalities. Synthesizing and translating technical information into clear, effective, and engaging learning. Ensuring a consistent approach to the learning experience. Being proficient with a wide variety of learning tools, including but not limited to Storyline, RISE, game-based learning, videos, InDesign. Managing multiple projects with frequent priority shifts, working with high attention to accuracy and detail, and delivering within expected timelines. Being familiar with Learning Management Systems, as it relates to ensuring content works appropriately. Managing and organizing content in a centralized repository to ensure accuracy of material. Minimum Qualifications: Bachelor’s degree and/or equivalent of industry experience Four years of Instructional Design and content creation Innovative, curious mindset and ability to work independently to meet deadlines Excellent written and verbal communication skills Experience editing content for clarity and accuracy Experience using Microsoft 365 tools Experience using Articulate 360 software Experience using video editing software Experience using software to create animated characters Experience using Adobe InDesign Preferred Qualifications: Experience working within an FDA regulated environment Experience using Sales and Learning Enablement Platforms, (such as Showpad, Allego, SmartWinnr, etc) Requisition ID: 598020 Minimum Salary: $ 99100 Maximum Salary: $ 188300 Compensation for non-exempt (hourly), non-sales roles may also include variable compensation from time to time (e.g., any overtime and shift differential) and annual bonus target (subject to plan eligibility and other requirements). Compensation for exempt, non-sales roles may also include variable compensation, i.e., annual bonus target and long-term incentives (subject to plan eligibility and other requirements. For MA positions: It is unlawful to require or administer a lie detector test for employment. Violators are subject to criminal penalties and civil liability. As a leader in medical science for more than 40 years, we are committed to solving the challenges that matter most – united by a deep caring for human life. Our mission to advance science for life is about transforming lives through innovative medical solutions that improve patient lives, create value for our customers, and support our employees and the communities in which we operate. Now more than ever, we have a responsibility to apply those values to everything we do – as a global business and as a global corporate citizen. So, choosing a career with Boston Scientific (NYSE: BSX) isn’t just business, it’s personal. And if you’re a natural problem-solver with the imagination, determination, and spirit to make a meaningful difference to people worldwide, we encourage you to apply and look forward to connecting with you! At Boston Scientific, we recognize that nurturing a diverse and inclusive workplace helps us be more innovative and it is important in our work of advancing science for life and improving patient health. That is why we stand for inclusion, equality, and opportunity for all. By embracing the richness of our unique backgrounds and perspectives, we create a better, more rewarding place for our employees to work and reflect the patients, customers, and communities we serve. Boston Scientific Corporation has been and will continue to be an equal opportunity employer. To ensure full implementation of its equal employment policy, the Company will continue to take steps to assure that recruitment, hiring, assignment, promotion, compensation, and all other personnel decisions are made and administered without regard to race, religion, color, national origin, citizenship, sex, sexual orientation, gender identify, gender expression, veteran status, age, mental or physical disability, genetic information or any other protected class. Please be advised that certain US based positions, including without limitation field sales and service positions that call on hospitals and/or health care centers, require acceptable proof of COVID-19 vaccination status. Candidates will be notified during the interview and selection process if the role(s) for which they have applied require proof of vaccination as a condition of employment. Boston Scientific continues to evaluate its policies and protocols regarding the COVID-19 vaccine and will comply with all applicable state and federal law and healthcare credentialing requirements. As employees of the Company, you will be expected to meet the ongoing requirements for your roles, including any new requirements, should the Company’s policies or protocols change with regard to COVID-19 vaccination. Nearest Major Market: Minneapolis Job Segment: Learning, Testing, Developer, Programmer, Information Technology, Human Resources, Technology",
         "Bachelor’s degree and/or equivalent of industry experience Four years of Instructional Design and content creation Innovative, curious mindset and ability to work independently to meet deadlines Excellent written and verbal communication skills Experience editing content for clarity and accuracy Experience using Microsoft 365 tools Experience using Articulate 360 software Experience using video editing software Experience using software to create animated characters Experience using Adobe InDesign Preferred Qualifications: Experience working within an FDA regulated environment Experience using Sales and Learning Enablement Platforms, (such as Showpad, Allego, SmartWinnr, etc) Requisition ID: 598020 Minimum Salary: $ 99100 Maximum Salary: $ 188300 Compensation for non-exempt (hourly), non-sales roles may also include variable compensation from time to time (e.g., any overtime and shift differential) and annual bonus target (subject to plan eligibility and other requirements). Compensation for exempt, non-sales roles may also include variable compensation, i.e., annual bonus target and long-term incentives (subject to plan eligibility and other requirements. For MA positions: It is unlawful to require or administer a lie detector test for employment. Violators are subject to criminal penalties and civil liability. As a leader in medical science for more than 40 years, we are committed to solving the challenges that matter most – united by a deep caring for human life. Our mission to advance science for life is about transforming lives through innovative medical solutions that improve patient lives, create value for our customers, and support our employees and the communities in which we operate. Now more than ever, we have a responsibility to apply those values to everything we do – as a global business and as a global corporate citizen. So, choosing a career with Boston Scientific (NYSE: BSX) isn’t just business, it’s personal. And if you’re a natural problem-solver with the imagination, determination, and spirit to make a meaningful difference to people worldwide, we encourage you to apply and look forward to connecting with you! At Boston Scientific, we recognize that nurturing a diverse and inclusive workplace helps us be more innovative and it is important in our work of advancing science for life and improving patient health. That is why we stand for inclusion, equality, and opportunity for all. By embracing the richness of our unique backgrounds and perspectives, we create a better, more rewarding place for our employees to work and reflect the patients, customers, and communities we serve. Boston Scientific Corporation has been and will continue to be an equal opportunity employer. To ensure full implementation of its equal employment policy, the Company will continue to take steps to assure that recruitment, hiring, assignment, promotion, compensation, and all other personnel decisions are made and administered without regard to race, religion, color, national origin, citizenship, sex, sexual orientation, gender identify, gender expression, veteran status, age, mental or physical disability, genetic information or any other protected class. Please be advised that certain US based positions, including without limitation field sales and service positions that call on hospitals and/or health care centers, require acceptable proof of COVID-19 vaccination status. Candidates will be notified during the interview and selection process if the role(s) for which they have applied require proof of vaccination as a condition of employment. Boston Scientific continues to evaluate its policies and protocols regarding the COVID-19 vaccine and will comply with all applicable state and federal law and healthcare credentialing requirements. As employees of the Company, you will be expected to meet the ongoing requirements for your roles, including any new requirements, should the Company’s policies or protocols change with regard to COVID-19 vaccination. Nearest Major Market: Minneapolis Job Segment: Learning, Testing, Developer, Programmer, Information Technology, Human Resources, Technology",
         603
        ],
        [
         null,
         "Steelgate LLC",
         "Work mode: Hybrid Onsite Location(s): Maple Grove, MN, US, 55311 Additional Location(s): US-MN-Maple Grove Diversity - Innovation - Caring - Global Collaboration - Winning Spirit - High Performance At Boston Scientific, we’ll give you the opportunity to harness all that’s within you by working in teams of diverse and high-performing employees, tackling some of the most important health industry challenges. With access to the latest tools, information and training, we’ll help you in advancing your skills and career. Here, you’ll be supported in progressing – whatever your ambitions. The Instructional Designer Content Developer (Cardiology Training) works closely with business partners, subject matter experts (SMEs), and other key stakeholders to plan and develop high-quality learning experiences to support business goals. This individual is responsible for the development of content, which may include interactive, multimedia, instructor led. This position reports to the Cardiology Training Operations Manager. Candidates will provide work portfolio as part of the application process. The interview will include a portfolio review and discussion. Your responsibilities will include: Partnering with subject matter experts and other stakeholders to analyze the learning needs. Planning, organizing, and developing learning solutions using a variety of modalities. Synthesizing and translating technical information into clear, effective, and engaging learning. Ensuring a consistent approach to the learning experience. Being proficient with a wide variety of learning tools, including but not limited to Storyline, RISE, game-based learning, videos, InDesign. Managing multiple projects with frequent priority shifts, working with high attention to accuracy and detail, and delivering within expected timelines. Being familiar with Learning Management Systems, as it relates to ensuring content works appropriately. Managing and organizing content in a centralized repository to ensure accuracy of material. Minimum Qualifications: Bachelor’s degree and/or equivalent of industry experience Four years of Instructional Design and content creation Innovative, curious mindset and ability to work independently to meet deadlines Excellent written and verbal communication skills Experience editing content for clarity and accuracy Experience using Microsoft 365 tools Experience using Articulate 360 software Experience using video editing software Experience using software to create animated characters Experience using Adobe InDesign Preferred Qualifications: Experience working within an FDA regulated environment Experience using Sales and Learning Enablement Platforms, (such as Showpad, Allego, SmartWinnr, etc) Requisition ID: 598020 Minimum Salary: $ 99100 Maximum Salary: $ 188300 Compensation for non-exempt (hourly), non-sales roles may also include variable compensation from time to time (e.g., any overtime and shift differential) and annual bonus target (subject to plan eligibility and other requirements). Compensation for exempt, non-sales roles may also include variable compensation, i.e., annual bonus target and long-term incentives (subject to plan eligibility and other requirements. For MA positions: It is unlawful to require or administer a lie detector test for employment. Violators are subject to criminal penalties and civil liability. As a leader in medical science for more than 40 years, we are committed to solving the challenges that matter most – united by a deep caring for human life. Our mission to advance science for life is about transforming lives through innovative medical solutions that improve patient lives, create value for our customers, and support our employees and the communities in which we operate. Now more than ever, we have a responsibility to apply those values to everything we do – as a global business and as a global corporate citizen. So, choosing a career with Boston Scientific (NYSE: BSX) isn’t just business, it’s personal. And if you’re a natural problem-solver with the imagination, determination, and spirit to make a meaningful difference to people worldwide, we encourage you to apply and look forward to connecting with you! At Boston Scientific, we recognize that nurturing a diverse and inclusive workplace helps us be more innovative and it is important in our work of advancing science for life and improving patient health. That is why we stand for inclusion, equality, and opportunity for all. By embracing the richness of our unique backgrounds and perspectives, we create a better, more rewarding place for our employees to work and reflect the patients, customers, and communities we serve. Boston Scientific Corporation has been and will continue to be an equal opportunity employer. To ensure full implementation of its equal employment policy, the Company will continue to take steps to assure that recruitment, hiring, assignment, promotion, compensation, and all other personnel decisions are made and administered without regard to race, religion, color, national origin, citizenship, sex, sexual orientation, gender identify, gender expression, veteran status, age, mental or physical disability, genetic information or any other protected class. Please be advised that certain US based positions, including without limitation field sales and service positions that call on hospitals and/or health care centers, require acceptable proof of COVID-19 vaccination status. Candidates will be notified during the interview and selection process if the role(s) for which they have applied require proof of vaccination as a condition of employment. Boston Scientific continues to evaluate its policies and protocols regarding the COVID-19 vaccine and will comply with all applicable state and federal law and healthcare credentialing requirements. As employees of the Company, you will be expected to meet the ongoing requirements for your roles, including any new requirements, should the Company’s policies or protocols change with regard to COVID-19 vaccination. Nearest Major Market: Minneapolis Job Segment: Learning, Testing, Developer, Programmer, Information Technology, Human Resources, Technology",
         "developer",
         "Work mode: Hybrid Onsite Location(s): Maple Grove, MN, US, 55311 Additional Location(s): US-MN-Maple Grove Diversity - Innovation - Caring - Global Collaboration - Winning Spirit - High Performance At Boston Scientific, we’ll give you the opportunity to harness all that’s within you by working in teams of diverse and high-performing employees, tackling some of the most important health industry challenges. With access to the latest tools, information and training, we’ll help you in advancing your skills and career. Here, you’ll be supported in progressing – whatever your ambitions. The Instructional Designer Content Developer (Cardiology Training) works closely with business partners, subject matter experts (SMEs), and other key stakeholders to plan and develop high-quality learning experiences to support business goals. This individual is responsible for the development of content, which may include interactive, multimedia, instructor led. This position reports to the Cardiology Training Operations Manager. Candidates will provide work portfolio as part of the application process. The interview will include a portfolio review and discussion. Your responsibilities will include: Partnering with subject matter experts and other stakeholders to analyze the learning needs. Planning, organizing, and developing learning solutions using a variety of modalities. Synthesizing and translating technical information into clear, effective, and engaging learning. Ensuring a consistent approach to the learning experience. Being proficient with a wide variety of learning tools, including but not limited to Storyline, RISE, game-based learning, videos, InDesign. Managing multiple projects with frequent priority shifts, working with high attention to accuracy and detail, and delivering within expected timelines. Being familiar with Learning Management Systems, as it relates to ensuring content works appropriately. Managing and organizing content in a centralized repository to ensure accuracy of material. Minimum Qualifications: Bachelor’s degree and/or equivalent of industry experience Four years of Instructional Design and content creation Innovative, curious mindset and ability to work independently to meet deadlines Excellent written and verbal communication skills Experience editing content for clarity and accuracy Experience using Microsoft 365 tools Experience using Articulate 360 software Experience using video editing software Experience using software to create animated characters Experience using Adobe InDesign Preferred Qualifications: Experience working within an FDA regulated environment Experience using Sales and Learning Enablement Platforms, (such as Showpad, Allego, SmartWinnr, etc) Requisition ID: 598020 Minimum Salary: $ 99100 Maximum Salary: $ 188300 Compensation for non-exempt (hourly), non-sales roles may also include variable compensation from time to time (e.g., any overtime and shift differential) and annual bonus target (subject to plan eligibility and other requirements). Compensation for exempt, non-sales roles may also include variable compensation, i.e., annual bonus target and long-term incentives (subject to plan eligibility and other requirements. For MA positions: It is unlawful to require or administer a lie detector test for employment. Violators are subject to criminal penalties and civil liability. As a leader in medical science for more than 40 years, we are committed to solving the challenges that matter most – united by a deep caring for human life. Our mission to advance science for life is about transforming lives through innovative medical solutions that improve patient lives, create value for our customers, and support our employees and the communities in which we operate. Now more than ever, we have a responsibility to apply those values to everything we do – as a global business and as a global corporate citizen. So, choosing a career with Boston Scientific (NYSE: BSX) isn’t just business, it’s personal. And if you’re a natural problem-solver with the imagination, determination, and spirit to make a meaningful difference to people worldwide, we encourage you to apply and look forward to connecting with you! At Boston Scientific, we recognize that nurturing a diverse and inclusive workplace helps us be more innovative and it is important in our work of advancing science for life and improving patient health. That is why we stand for inclusion, equality, and opportunity for all. By embracing the richness of our unique backgrounds and perspectives, we create a better, more rewarding place for our employees to work and reflect the patients, customers, and communities we serve. Boston Scientific Corporation has been and will continue to be an equal opportunity employer. To ensure full implementation of its equal employment policy, the Company will continue to take steps to assure that recruitment, hiring, assignment, promotion, compensation, and all other personnel decisions are made and administered without regard to race, religion, color, national origin, citizenship, sex, sexual orientation, gender identify, gender expression, veteran status, age, mental or physical disability, genetic information or any other protected class. Please be advised that certain US based positions, including without limitation field sales and service positions that call on hospitals and/or health care centers, require acceptable proof of COVID-19 vaccination status. Candidates will be notified during the interview and selection process if the role(s) for which they have applied require proof of vaccination as a condition of employment. Boston Scientific continues to evaluate its policies and protocols regarding the COVID-19 vaccine and will comply with all applicable state and federal law and healthcare credentialing requirements. As employees of the Company, you will be expected to meet the ongoing requirements for your roles, including any new requirements, should the Company’s policies or protocols change with regard to COVID-19 vaccination. Nearest Major Market: Minneapolis Job Segment: Learning, Testing, Developer, Programmer, Information Technology, Human Resources, Technology",
         "Work mode: Hybrid Onsite Location(s): Maple Grove, MN, US, 55311 Additional Location(s): US-MN-Maple Grove Diversity - Innovation - Caring - Global Collaboration - Winning Spirit - High Performance At Boston Scientific, we’ll give you the opportunity to harness all that’s within you by working in teams of diverse and high-performing employees, tackling some of the most important health industry challenges. With access to the latest tools, information and training, we’ll help you in advancing your skills and career. Here, you’ll be supported in progressing – whatever your ambitions. The Instructional Designer Content Developer (Cardiology Training) works closely with business partners, subject matter experts (SMEs), and other key stakeholders to plan and develop high-quality learning experiences to support business goals. This individual is responsible for the development of content, which may include interactive, multimedia, instructor led. This position reports to the Cardiology Training Operations Manager. Candidates will provide work portfolio as part of the application process. The interview will include a portfolio review and discussion. Your responsibilities will include: Partnering with subject matter experts and other stakeholders to analyze the learning needs. Planning, organizing, and developing learning solutions using a variety of modalities. Synthesizing and translating technical information into clear, effective, and engaging learning. Ensuring a consistent approach to the learning experience. Being proficient with a wide variety of learning tools, including but not limited to Storyline, RISE, game-based learning, videos, InDesign. Managing multiple projects with frequent priority shifts, working with high attention to accuracy and detail, and delivering within expected timelines. Being familiar with Learning Management Systems, as it relates to ensuring content works appropriately. Managing and organizing content in a centralized repository to ensure accuracy of material. Minimum Qualifications: Bachelor’s degree and/or equivalent of industry experience Four years of Instructional Design and content creation Innovative, curious mindset and ability to work independently to meet deadlines Excellent written and verbal communication skills Experience editing content for clarity and accuracy Experience using Microsoft 365 tools Experience using Articulate 360 software Experience using video editing software Experience using software to create animated characters Experience using Adobe InDesign Preferred Qualifications: Experience working within an FDA regulated environment Experience using Sales and Learning Enablement Platforms, (such as Showpad, Allego, SmartWinnr, etc) Requisition ID: 598020 Minimum Salary: $ 99100 Maximum Salary: $ 188300 Compensation for non-exempt (hourly), non-sales roles may also include variable compensation from time to time (e.g., any overtime and shift differential) and annual bonus target (subject to plan eligibility and other requirements). Compensation for exempt, non-sales roles may also include variable compensation, i.e., annual bonus target and long-term incentives (subject to plan eligibility and other requirements. For MA positions: It is unlawful to require or administer a lie detector test for employment. Violators are subject to criminal penalties and civil liability. As a leader in medical science for more than 40 years, we are committed to solving the challenges that matter most – united by a deep caring for human life. Our mission to advance science for life is about transforming lives through innovative medical solutions that improve patient lives, create value for our customers, and support our employees and the communities in which we operate. Now more than ever, we have a responsibility to apply those values to everything we do – as a global business and as a global corporate citizen. So, choosing a career with Boston Scientific (NYSE: BSX) isn’t just business, it’s personal. And if you’re a natural problem-solver with the imagination, determination, and spirit to make a meaningful difference to people worldwide, we encourage you to apply and look forward to connecting with you! At Boston Scientific, we recognize that nurturing a diverse and inclusive workplace helps us be more innovative and it is important in our work of advancing science for life and improving patient health. That is why we stand for inclusion, equality, and opportunity for all. By embracing the richness of our unique backgrounds and perspectives, we create a better, more rewarding place for our employees to work and reflect the patients, customers, and communities we serve. Boston Scientific Corporation has been and will continue to be an equal opportunity employer. To ensure full implementation of its equal employment policy, the Company will continue to take steps to assure that recruitment, hiring, assignment, promotion, compensation, and all other personnel decisions are made and administered without regard to race, religion, color, national origin, citizenship, sex, sexual orientation, gender identify, gender expression, veteran status, age, mental or physical disability, genetic information or any other protected class. Please be advised that certain US based positions, including without limitation field sales and service positions that call on hospitals and/or health care centers, require acceptable proof of COVID-19 vaccination status. Candidates will be notified during the interview and selection process if the role(s) for which they have applied require proof of vaccination as a condition of employment. Boston Scientific continues to evaluate its policies and protocols regarding the COVID-19 vaccine and will comply with all applicable state and federal law and healthcare credentialing requirements. As employees of the Company, you will be expected to meet the ongoing requirements for your roles, including any new requirements, should the Company’s policies or protocols change with regard to COVID-19 vaccination. Nearest Major Market: Minneapolis Job Segment: Learning, Testing, Developer, Programmer, Information Technology, Human Resources, Technology",
         "Bachelor’s degree and/or equivalent of industry experience Four years of Instructional Design and content creation Innovative, curious mindset and ability to work independently to meet deadlines Excellent written and verbal communication skills Experience editing content for clarity and accuracy Experience using Microsoft 365 tools Experience using Articulate 360 software Experience using video editing software Experience using software to create animated characters Experience using Adobe InDesign Preferred Qualifications: Experience working within an FDA regulated environment Experience using Sales and Learning Enablement Platforms, (such as Showpad, Allego, SmartWinnr, etc) Requisition ID: 598020 Minimum Salary: $ 99100 Maximum Salary: $ 188300 Compensation for non-exempt (hourly), non-sales roles may also include variable compensation from time to time (e.g., any overtime and shift differential) and annual bonus target (subject to plan eligibility and other requirements). Compensation for exempt, non-sales roles may also include variable compensation, i.e., annual bonus target and long-term incentives (subject to plan eligibility and other requirements. For MA positions: It is unlawful to require or administer a lie detector test for employment. Violators are subject to criminal penalties and civil liability. As a leader in medical science for more than 40 years, we are committed to solving the challenges that matter most – united by a deep caring for human life. Our mission to advance science for life is about transforming lives through innovative medical solutions that improve patient lives, create value for our customers, and support our employees and the communities in which we operate. Now more than ever, we have a responsibility to apply those values to everything we do – as a global business and as a global corporate citizen. So, choosing a career with Boston Scientific (NYSE: BSX) isn’t just business, it’s personal. And if you’re a natural problem-solver with the imagination, determination, and spirit to make a meaningful difference to people worldwide, we encourage you to apply and look forward to connecting with you! At Boston Scientific, we recognize that nurturing a diverse and inclusive workplace helps us be more innovative and it is important in our work of advancing science for life and improving patient health. That is why we stand for inclusion, equality, and opportunity for all. By embracing the richness of our unique backgrounds and perspectives, we create a better, more rewarding place for our employees to work and reflect the patients, customers, and communities we serve. Boston Scientific Corporation has been and will continue to be an equal opportunity employer. To ensure full implementation of its equal employment policy, the Company will continue to take steps to assure that recruitment, hiring, assignment, promotion, compensation, and all other personnel decisions are made and administered without regard to race, religion, color, national origin, citizenship, sex, sexual orientation, gender identify, gender expression, veteran status, age, mental or physical disability, genetic information or any other protected class. Please be advised that certain US based positions, including without limitation field sales and service positions that call on hospitals and/or health care centers, require acceptable proof of COVID-19 vaccination status. Candidates will be notified during the interview and selection process if the role(s) for which they have applied require proof of vaccination as a condition of employment. Boston Scientific continues to evaluate its policies and protocols regarding the COVID-19 vaccine and will comply with all applicable state and federal law and healthcare credentialing requirements. As employees of the Company, you will be expected to meet the ongoing requirements for your roles, including any new requirements, should the Company’s policies or protocols change with regard to COVID-19 vaccination. Nearest Major Market: Minneapolis Job Segment: Learning, Testing, Developer, Programmer, Information Technology, Human Resources, Technology",
         603
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "Title",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Company",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Full Job Description",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Search Word",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Description",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Description_English",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Requirements_Text",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Token_Count",
         "type": "\"integer\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define a function to count tokens\n",
    "def count_tokens(text):\n",
    "    return len(text.split())\n",
    "\n",
    "count_tokens_udf = udf(count_tokens, IntegerType())\n",
    "requirements_token_count = requirements_df.withColumn(\"Token_Count\", count_tokens_udf(col(\"Requirements_Text\")))\n",
    "\n",
    "# Filter rows with more than 512 tokens\n",
    "rows_with_more_than_512_tokens = requirements_token_count.filter(col(\"Token_Count\") > 512)\n",
    "display(rows_with_more_than_512_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "79362962-45f1-454f-bba5-018f6765a119",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Project- Indeed Requirements Extractions",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}